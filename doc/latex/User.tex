Je\+Vois 将视频捕捉和机器视觉处理直接结合在智能相机中。以下是如何开始使用它。

新用户请务必查看 \href{/start/start.html}{\texttt{ Je\+Vois Start}}。


\begin{DoxyItemize}
\item \mbox{\hyperlink{UserQuick}{Je\+Vois-\/\+A33 快速入门用户指南}}
\item \mbox{\hyperlink{ProUserQuick}{Je\+Vois-\/\+Pro 快速入门用户指南}}
\item \mbox{\hyperlink{ProNetwork}{Je\+Vois-\/\+Pro：连接到有线或 Wi\+Fi 网络}}
\item \mbox{\hyperlink{UserStartLinux}{Je\+Vois-\/\+A33：\+Linux 主机入门}}
\item \mbox{\hyperlink{UserStartWindows}{Je\+Vois-\/\+A33：开始使用 Windows 主机}}
\item \mbox{\hyperlink{UserStartMac}{Je\+Vois-\/\+A33：\+Mac 主机入门 \textbackslash{}tableofcontents}}
\item \mbox{\hyperlink{UserStartCaveats}{Je\+Vois-\/\+A33：入门注意事项 \textbackslash{}tableofcontents}}
\item \mbox{\hyperlink{UserModes}{视频模式和映射用户指南}}
\item \mbox{\hyperlink{UserDemos}{捆绑视觉模块和演示的用户指南}}
\item \mbox{\hyperlink{UserLighting}{优化不同光照条件下的性能}}
\item \mbox{\hyperlink{MicroSD}{Micro\+SD 卡组织和文件}}
\item \mbox{\hyperlink{NewMicroSD}{如何为 Je\+Vois 格式化新的 Micro\+SD 卡}}
\item \mbox{\hyperlink{UserSerial}{串口使用指南}}
\item \mbox{\hyperlink{UserSerialStyle}{标准化串行消息格式}}
\item \mbox{\hyperlink{ProConnectors}{Je\+Vois-\/\+Pro 辅助连接器}}
\item \mbox{\hyperlink{UserProFan}{Je\+Vois-\/\+Pro 调整风扇速度}}
\item \mbox{\hyperlink{UserProUSBserial}{Je\+Vois-\/\+Pro 串行 U\+SB 通信}}
\item \mbox{\hyperlink{UserCli}{命令行界面用户指南}}
\item \mbox{\hyperlink{ArduinoTutorial}{教程：如何编写与 Je\+Vois 交互的 Arduino 代码}}
\item \mbox{\hyperlink{CaseMounting}{Je\+Vois-\/\+A33 外壳安装指南}}
\item \mbox{\hyperlink{ProCaseMounting}{Je\+Vois-\/\+Pro 外壳安装指南}}
\item \mbox{\hyperlink{HardwareFiles}{硬件：原理图、机壳 S\+TL 文件等 \textbackslash{}tableofcontents}}
\item \mbox{\hyperlink{Lenses}{Je\+Vois-\/\+A33 镜头选项}}
\item \mbox{\hyperlink{Sensors}{Je\+Vois-\/\+A33 相机传感器选项}}
\item \mbox{\hyperlink{Fanless}{Je\+Vois-\/\+A33 无风扇操作}}
\item \mbox{\hyperlink{Multicam}{Je\+Vois-\/\+A33 通过连接到一个 U\+SB 总线的多个 Je\+Vois 摄像机流式传输视频}}
\item \mbox{\hyperlink{UserDNNoverview}{在 Je\+Vois-\/\+A33 和 Je\+Vois-\/\+Pro 上运行神经网络}} 
\end{DoxyItemize}\hypertarget{UserQuick}{}\doxysubsection{Je\+Vois-\/\+A33 快速入门用户指南}\label{UserQuick}
有关更多详细信息和分步说明，请参阅 \mbox{\hyperlink{User}{用户指南}} 下的不同部分

新用户请务必查看 \href{/start/start.html}{\texttt{ Je\+Vois Start}}。



有关更多具体信息，请参阅：


\begin{DoxyItemize}
\item \mbox{\hyperlink{UserStartLinux}{Je\+Vois-\/\+A33：\+Linux 主机入门}}
\item \mbox{\hyperlink{UserStartWindows}{Je\+Vois-\/\+A33：开始使用 Windows 主机}}
\item \mbox{\hyperlink{UserStartMac}{Je\+Vois-\/\+A33：\+Mac 主机入门 \textbackslash{}tableofcontents}}
\item \mbox{\hyperlink{UserStartCaveats}{Je\+Vois-\/\+A33：入门注意事项 \textbackslash{}tableofcontents}} 
\end{DoxyItemize}\hypertarget{ProUserQuick}{}\doxysubsection{Je\+Vois-\/\+Pro 快速入门用户指南}\label{ProUserQuick}
基础知识 ======

有关更多详细信息和分步说明，请参阅 用户下的不同部分

新用户请务必查看 \href{/start/start.html}{\texttt{ Je\+Vois Start}}。


\begin{DoxyItemize}
\item 您的 H\+D\+MI 显示器必须至少支持 1080p/60\+Hz（1920x1080，60 帧/秒）。如果您的计算机显示器不工作，请尝试使用高清或 4K 电视。
\item 标准 U\+SB 键盘和鼠标应该会自动检测。如果您喜欢的键盘和鼠标没有被检测到，请尝试使用您最通用的键盘和鼠标。
\item 要将 micro\+SD 卡插入 Je\+Vois-\/\+Pro，请参阅 \mbox{\hyperlink{JeVoisProIntro}{Je\+Vois-\/\+Pro：新用户介绍}}
\item 要连接 Je\+Vois-\/\+Pro，请参阅 \mbox{\hyperlink{ProUserConnect}{将 Je\+Vois-\/\+Pro 连接到电源和数据}}
\end{DoxyItemize}

故障排除 ================


\begin{DoxyItemize}
\item {\bfseries{我看到了 Je\+Vois-\/\+Pro 启动徽标，但之后我的显示器变黑，或者报告图片超出范围。}} 您的显示器至少需要支持 1080p (1920x1080)。在一些早期发货中，我们将分辨率设置为 1080p30\+Hz，但事实证明 1080p60\+Hz 得到了更广泛的支持。请尝试此修复：
\item 小心地从 Je\+Vois-\/\+Pro 中弹出 micro\+SD 卡，如 \href{https://www.youtube.com/watch?v=0wMplgtwuAc}{\texttt{ 此视频}} 所示
\item 使用读卡器将其连接到计算机
\item 打开名为 {\bfseries{B\+O\+OT}} 的驱动器
\item 在其中，找到文件 {\bfseries{env.\+txt}} 并使用纯文本编辑器（例如 Notepad、\+Text\+Edit、nano 等）打开它。只需双击它就可以了。
\item 向下滚动到显示“hdmi=1080p30hz”的行，并将 30 替换为 60
\item 保存文件并干净地弹出磁盘
\item 将 micro\+SD 重新插入 Je\+Vois-\/\+Pro，它应该可以工作。
\item {\bfseries{视频的顶部和底部被裁剪}}。许多电视确实默认会略微裁剪图片。您需要浏览电视菜单，找到“全原生”、“全分辨率”、“全 100”等图片设置。以下是 Sceptre 4K 电视的示例：   上图：此电视在正常模式下，图片略微裁剪（参见屏幕底部的文本行）。点击图片放大。   上图：使用电视遥控器将电视设置为“全 100”可消除裁剪。点击图片放大。
\end{DoxyItemize}

启动模式 ===========

在 G\+UI 的 {\bfseries{系统选项卡下，您可以为}} Je\+Vois-\/\+Pro 选择不同的启动模式：


\begin{DoxyItemize}
\item Je\+Vois：在启动时启动 Je\+Vois 软件。
\item Ubuntu 控制台：在启动时启动文本控制台。
\item Ubuntu 图形：启动 X-\/\+Windows 并提供图形登录。
\end{DoxyItemize}

进入控制台或图形模式后，在终端中发出以下命令进行切换：


\begin{DoxyCode}{0}
\DoxyCodeLine{sudo systemctl set-\/default jevoispro.target \textcolor{comment}{\# 启动到 JeVois 软件 sudo systemctl set-\/default multi-\/user.target \# 启动到 Ubuntu 控制台 sudo systemctl set-\/default graphic.target \# 启动到 Ubuntu 图形 }}
\end{DoxyCode}


然后


\begin{DoxyCode}{0}
\DoxyCodeLine{sudo shutdown -\/h now }
\end{DoxyCode}


拔掉电源并重新插入。

\begin{DoxyNote}{Note}
软件重置（shutdown -\/r）目前不起作用。这可能是硬件问题，但我们稍后可能会创建软件解决方法。
\end{DoxyNote}
密码 ==========

用户 {\itshape jevois} 的密码为 {\bfseries{jevois}} 并且可以使用 sudo（使用该密码）。

用户 {\itshape root} 的密码为 {\bfseries{jevois}} 

Je\+Vois-\/\+Pro 软件默认以 root 身份运行。

手动启动 Je\+Vois 软件 =====================================

如果您已切换到控制台启动，则登录后（以 jevois/jevois 或 root/jevois 身份），您可以从命令行启动 Je\+Vois 软件：


\begin{DoxyCode}{0}
\DoxyCodeLine{sudo jevoispro.sh }
\end{DoxyCode}


请注意，\+A\+RM 为我们的芯片 (Amlogic A311D) 提供的 G\+PU 驱动程序仅在全屏帧缓冲模式下工作。因此，它们在 Je\+Vois-\/\+Pro 模式或控制台模式下启动时工作正常。但是，如果您从 X-\/windows 中的终端运行“sudo jevoispro.\+sh”，您将遇到两个图形界面 (X-\/windows 和 Je\+Vois G\+UI) 之间的冲突。您将看到 2 个鼠标指针，一些 X 窗口将在 Je\+Vois 显示屏上刷新，等等。因此，如果您想手动运行 jevoispro.\+sh，请从控制台模式执行。

当您处于控制台模式时，您可以通过输入以下命令启动 X-\/windows：


\begin{DoxyCode}{0}
\DoxyCodeLine{startx }
\end{DoxyCode}


当您从 X 注销时，您将返回到您的控制台。

这对于开发非常有用。您可以执行以下操作：


\begin{DoxyItemize}
\item 切换到控制台启动并重新启动
\item 以 root/jevois 身份登录
\item 运行 {\ttfamily jevoispro.\+sh}
\item 如果要退出，请激活图形用户界面的 {\ttfamily allowquit} 参数（您需要先打开显示系统参数）。或者您也可以从 {\ttfamily jevoispro.\+sh -\/-\/gui -\/-\/allowquit} 开始，这将允许您在按下 E\+SC 键时退出 Je\+Vois 软件。
\item 如果您需要编辑一些文件、下载一些文件等，并且您喜欢在 X-\/windows 中执行这些操作，则在完成后运行 {\ttfamily startx} 并从中注销。
\item 然后您可以再次运行 {\ttfamily jevoispro.\+sh}，等等。
\end{DoxyItemize}

Wi\+Fi 或有线网络 ==========================

参见 \mbox{\hyperlink{ProNetwork}{Je\+Vois-\/\+Pro：连接到有线或 Wi\+Fi 网络}}

启用 4K 显示分辨率 =================================

通过在 micro\+SD 卡上的 {\bfseries{/boot/env.txt}} 中编辑 {\ttfamily hdmi} 值来执行此操作。例如，对于 30Hz 的 4K：

\textbackslash{}逐字 hdmi=2160p30hz \textbackslash{}end逐字

请注意，相机在 4K 分辨率下的整体运行速度会比默认的 1080p 分辨率下略慢。我们认为这是由于内存总线上的争用加剧所致，因为我们从相机传感器到 G\+PU 再到显示器全程都使用 D\+M\+A，因此 C\+PU 工作负载在 4K 分辨率下不会显著增加。

超频 C\+PU ======================

在我们的测试中，将 C\+PU 超频至 2.\+4 G\+Hz（大核，默认为 2.\+208 G\+Hz）和 2.\+208 G\+Hz（小核，默认为 1.\+8 G\+Hz）非常稳定，特别是如果您确保冷却性能强劲（请参阅 \mbox{\hyperlink{UserProFan}{Je\+Vois-\/\+Pro 调整风扇速度}} 编辑风扇设置）。

首先，您需要通过编辑 micro\+SD 卡上的 {\bfseries{/boot/env.txt}} 来启用超频：


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{\# 小核 A53 最大 CPU 频率}}
\DoxyCodeLine{\textcolor{comment}{\# 500/667/1000/1200/1398/1512/1608/1704/1800(默认)/1908/2016/2100/2208 max\_freq\_a53=2208}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# 大核A73最大CPU频率}}
\DoxyCodeLine{\textcolor{comment}{\# 500/667/1000/1200/1398/1512/1608/1704/1800/1908/2016/2100/2208(默认)/2304/2400 max\_freq\_a73=2400 }}
\end{DoxyCode}


这只是设置了最大可能频率。但默认情况下，启动时的工作频率仍为 2.\+2/1.8 G\+Hz。

然后重新启动，在 G\+UI 中选择“参数”选项卡，然后启用“显示系统参数”，在“引擎选项”下，您可以设置所需的 C\+PU 最大速度。如果您希望在启动时将这些值设置为默认值，则可以在 {\ttfamily params.\+cfg} 配置文件中设置这些值（参见 G\+UI 中的“配置”选项卡）。 \hypertarget{ProNetwork}{}\doxysubsection{Je\+Vois-\/\+Pro：连接到有线或 Wi\+Fi 网络}\label{ProNetwork}
最简单：\+U\+SB 转有线网络 ==================================

如果您有一个运行 D\+H\+CP 服务器的有线网络，则您只需使用如下所示的 U\+SB 转以太网适配器即可。

  

它应该会自动检测和配置。要从 Je\+Vois-\/\+Pro 控制台检查，您可以发出“shell ifconfig”并检查配置。然后您可以转到“系统”选项卡并尝试 ping jevois.\+usc.\+edu

使用 R\+T\+L8812\+AU 适配器的 U\+SB 转 Wifi 网络 =================================================

许多 Wifi 适配器默认不包含在 Linux 内核中，因为它们包含闭源代码。

我们已预装了多种品牌适配器中流行的 Realtek R\+T\+L8812\+AU 芯片的驱动程序。

  

要选择 Wifi 网络，最简单的方法是按以下步骤操作：
\begin{DoxyItemize}
\item 在 Je\+Vois-\/\+Pro 系统选项卡中，选择重新启动到 Linux 控制台。
\item 重新启动相机。
\item 以 {\itshape root} 身份登录，密码为 {\itshape jevois} 
\item 键入 {\ttfamily startx}
\item 在右上角，选择网络图标，选择一个网络并输入 Wifi 密码。
\item 检查网络是否正常工作，例如，启动 Web 浏览器并浏览。
\item 在右上角，注销。这将使您返回到控制台。
\item 检查网络是否仍在工作，例如 {\ttfamily ping jevois.\+usc.\+edu}
\item 键入 {\ttfamily jevoispro.\+sh} 以启动 Je\+Vois 软件
\item 在系统选项卡中，选择重新启动到 Je\+Vois-\/\+Pro 并重新启动机器。
\end{DoxyItemize}

该配置应该是持久的，并且您的 Wifi 网络应该在启动时自动选择。

M.\+2 P\+C\+I-\/express Wifi 网络 =================================

如果您不使用 Coral T\+P\+U，则可以使用 Je\+Vois-\/\+Pro 中的 M.\+2 A+E 插槽连接 Wifi 卡。

  

步骤如下：


\begin{DoxyItemize}
\item 选择使用 P\+C\+Ie 的。我们在使用基于 Intel 的卡方面取得了良好的成功。
\item 确保该芯片受 Linux 内核 4.\+9.\+x 支持；特别是，一些最新的 Intel A\+X210 芯片组需要内核 5.\+10+，并且无法在 Je\+Vois-\/\+Pro 上运行。如果您打算使用 Intel 芯片组，请参阅\href{https://www.intel.com/content/www/us/en/support/articles/000005511/wireless.html}{\texttt{ 此处}}，或者在网上搜索其他芯片组的 Linux 兼容性。
\item 确保它是 M.\+2 2230 (22mm x 30mm) A-\/key 或 E-\/key（大多数 M.\+2 Wifi 卡应该都是）。
\item 打开 Je\+Vois-\/\+Pro（4 个螺钉）
\item 如果有 T\+PU 板，请将其移除
\item 插入 Wifi 卡
\item 使用 M2x5mm 螺钉将其固定
\end{DoxyItemize}

应该可以检测到卡。然后，您可以按照上述方法针对 U\+SB 转 Wifi 的情况进行配置。 \hypertarget{UserStartLinux}{}\doxysubsection{Je\+Vois-\/\+A33：\+Linux 主机入门}\label{UserStartLinux}
最简单的入门方法是使用 \mbox{\hyperlink{JeVoisInventor}{Je\+Vois-\/\+A33：\+Je\+Vois Inventor 图形用户界面}}

以下是替代方法。

Je\+Vois 智能相机的使用方式与普通 U\+SB 相机相同。要开始使用 Linux 主机：


\begin{DoxyItemize}
\item 从 \href{http://jevois.org}{\texttt{ http\+://jevois.\+org}} 下载磁盘映像并将其刷入 Micro\+SD 卡。


\item 将 Micro\+SD 卡插入 Je\+Vois 智能相机，\+Micro\+SD 触点朝上，如下所示。

  

  


\item 将相机连接到主机。智能相机需要高达 3.\+5 瓦的功率，这超出了单个 U\+SB 2.\+0 端口的设计供电限制，但在单个 U\+SB 3.\+0 端口的限制范围内。使用能够无损传输全部功率的高质量 U\+S\+B-\/mini\+U\+SB 电缆非常重要。寻找带有 24awg 电源线的电缆。建议您在主机上使用 U\+SB 3.\+0 端口，因为它们可以提供更多功率。如果没有，您可以使用 U\+SB Y 型电缆连接到主机上的两个 U\+SB 2.\+0 端口，或者连接到一个 U\+SB 2.\+0 端口和一个外部 U\+SB 电源（例如，手机充电器）。请确保不要使用 U\+SB 集线器，除非该集线器具有强大的外部电源（变压器、壁式适配器）。


\item 观察 U\+SB 连接器旁边的智能相机上的 L\+E\+D：
\begin{DoxyItemize}
\item 绿色：电源已打开且足够强。
\item 约 3 秒后：橙色闪烁：相机传感器芯片已被检测到并初始化。
\item 约 5 秒后：橙色常亮：智能相机已准备就绪。
\item 再等待几秒钟，让主机检测到相机并准备好进行视频捕获。
\end{DoxyItemize}


\item 启动视频捕获软件。尝试 {\ttfamily guvcview} （可能需要 \textquotesingle{}sudo apt-\/get install guvcview\textquotesingle{} 或使用 Linux 包管理器查找并安装 {\ttfamily guvcview} ）

首次使用 {\ttfamily guvcview} 时，它可能会挂起，尝试打开主机上的声音设备。为避免这种情况，请从 Linux 终端首次启动 {\ttfamily guvcview，如下所示：} \begin{DoxyVerb}sudo apt-get install guvcview
guvcview -ao none -f YUYV -x 640x360 # On Raspberry Pi host, use '-a none -o none' instead of '-ao none'
\end{DoxyVerb}
 guvcview 会记住下次打开时不要尝试使用声音 (-\/ao none)。下次您可以从 Ubuntu 菜单启动它，而无需终端。

guvcview 提供了出色的图形用户界面，但并不适用于所有像素格式。有时在更改像素格式（例如从 M\+J\+PG 到 Y\+U\+Y\+V）时也会崩溃。另一种方法是使用 {\ttfamily ffplay} （可能需要 \textquotesingle{}sudo apt-\/get install ffmpeg\textquotesingle{} 或使用 Linux 包管理器查找并安装 {\ttfamily ffmpeg} ）

ffplay 可以显示 Je\+Vois 支持的所有像素格式，如果格式与硬件支持的格式不完全匹配，则会拒绝该格式。例如：

\begin{DoxyVerb}sudo apt-get install ffmpeg
ffplay /dev/video0 -pixel_format yuyv422 -video_size 640x300
\end{DoxyVerb}


Je\+Vois 支持的 pixel\+\_\+format 值为（更多信息请参阅 \mbox{\hyperlink{UserModes}{视频模式和映射用户指南}} ）：\+Y\+U\+YV 为 \textquotesingle{}yuyv422\textquotesingle{}、\+G\+R\+AY 为 \textquotesingle{}gray\textquotesingle{}、\+R\+G\+B565 为 \textquotesingle{}rgb565\textquotesingle{}、\+M\+J\+PG 为 \textquotesingle{}mjpeg\textquotesingle{}、\+B\+G\+R24 为 \textquotesingle{}bgr24\textquotesingle{}、\+B\+A\+Y\+ER 为 \textquotesingle{}bayer\+\_\+rggb8\textquotesingle{}。

请注意，在 Raspberry Pi 3 上，显示帧速率可能会很慢，尤其是在省电模式下（屏幕右上角出现小黄色闪电，表示电源太弱，无法让 Pi 全速运行）。确保使用强大的 U\+SB 充电器为 Pi 供电（例如，输出电流为 2.\+1A）。\+Raspberry Pi 的速度对于实时视频捕获和显示来说有点太慢了。建议使用更快的 Linux 台式计算机以获得最佳视频性能。


\item 请随意使用控件（亮度、对比度等）。它们都应该在 {\ttfamily guvcview} 中工作。请记住，某些控件依赖于其他控件，就像在任何 U\+SB 相机中一样。例如，\char`\"{}\+Exposure (\+Absolute)\char`\"{} 将保持灰色，直到您将 \char`\"{}\+Exposure, Auto\char`\"{} to \char`\"{}\+Manual Mode\char`\"{}。




\item 通过在视频捕获软件中选择不同的视频分辨率，可以实现选择不同的机器视觉算法。例如，在 guvcview 中，首先单击 \char`\"{}\+Video Controls\char`\"{} 选项卡，然后单击e \char`\"{}\+Resolution\char`\"{} 下拉菜单：




\item 拔下 Je\+Vois 智能相机之前，请确保退出相机查看软件。否则，您的主机可能会在尝试使用不再存在的相机时变得非常困惑。


\item 关闭 Je\+Vois 相机前无需执行关机程序。只需关闭视频捕捉软件并拔下相机电源即可。


\end{DoxyItemize}

\doxysubparagraph*{}\hypertarget{UserStartLinux_obslinux}{}\doxysubsubsection{Linux 入门 -\/ Open Broadcaster Studio}\label{UserStartLinux_obslinux}
Open Broadcaster Studio 是另一个很棒的免费程序，它允许您根据 Je\+Vois 的需要选择不同的视频分辨率。


\begin{DoxyItemize}
\item 从 \href{https://obsproject.com}{\texttt{ https\+://obsproject.\+com}} 查看 O\+BS Studio
\item 在 Ubuntu 16.\+04 及更高版本下，按如下方式安装： \begin{DoxyVerb}  sudo apt install obs-studio\end{DoxyVerb}

\item 将 Je\+Vois 连接到您的计算机并允许其启动。
\item 打开 O\+BS Studio（只需在终端中输入 {\ttfamily obs} 或在 Ubuntu 菜单中找到），在屏幕左下方，单击 {\bfseries{Sources}} 下的 {\ttfamily +} 图标以添加新的{\bfseries{视频捕获设备（\+V4\+L2）}}。 
\item 创建一个新的源 
\item 如果您有多个摄像头，请选择 Jevois-\/\+A33 智能摄像头作为其设备，您将看到来自 Je\+Vois 的实时视频。 
\item 双击该源时，会出现一个对话框。在其中，您可以选择：
\begin{DoxyItemize}
\item 设备：\+Je\+Vois-\/\+A33 智能相机
\item 分辨率：选择您想要尝试的任何分辨率
\item 帧速率：选择{\bfseries{保持不变}}或选择您选择的一个。 
\end{DoxyItemize}
\item 尽情享受吧！您可以拖动并调整视频预览的大小以获得最佳观看体验。 
\end{DoxyItemize}

\doxysubparagraph*{}\hypertarget{UserStartLinux_troubleshootlinux}{}\doxysubsubsection{故障排除}\label{UserStartLinux_troubleshootlinux}
如果一切不正常，请尝试在 Linux 终端中输入 {\ttfamily dmesg} ，并观察打印内容的末尾。您应该看到类似以下内容：

\begin{DoxyVerb}[...]
[4768736.704777] usb 1-1.3: new high-speed USB device number 13 using xhci_hcd
[4768736.809464] usb 1-1.3: New USB device found, idVendor=1d6b, idProduct=0102
[4768736.809470] usb 1-1.3: New USB device strings: Mfr=1, Product=2, SerialNumber=0
[4768736.809473] usb 1-1.3: Product: JeVois-A33 Smart Camera
[4768736.809476] usb 1-1.3: Manufacturer: JeVois Inc
[4768736.847915] uvcvideo: Found UVC 1.00 device JeVois-A33 Smart Camera (1d6b:0102)
[4768736.849892] input: JeVois-A33 Smart Camera as /devices/pci0000:00/0000:00:1c.6/0000:09:00.0/usb1/1-1/1-1.3/1-1.3:1.0/input/input29
[4768736.851499] cdc_acm 1-1.3:1.2: ttyACM0: USB ACM device
\end{DoxyVerb}


如果没有，请参见下文。 
\begin{DoxyItemize}
\item {\ttfamily guvcview} 未检测到 Je\+Vois 智能相机

可能的原因包括：


\begin{DoxyItemize}
\item 您忘记将 micro\+SD 卡插入 Je\+Vois 相机，请将其插入并重试。
\item 您的 micro\+SD 卡包含不正确的软件。请尝试再次刷新软件。
\item 您过早启动了 guvcview，您的计算机尚未检测到 Je\+Vois 相机。智能相机在大约 5 秒内启动，但您的主机可能还需要几秒钟才能发现相机并为其进行配置。
\item 您的主机经历了太多 U\+SB 连接/断开循环，并且感到困惑。请尝试重新启动它。
\item 您正尝试通过损坏的 U\+SB 集线器连接 Je\+Vois 相机。请尝试直接连接到计算机主板上的 U\+SB 端口。
\item 其他程序正在使用摄像头，或阻止摄像头检测。这种情况有时会发生，例如，如果您在 guvcview 仍在运行时断开摄像头，guvcview 会对此感到不满并感到困惑。请确保将其完全终止，例如在 Linux 终端中输入以下内容： \begin{DoxyVerb}  sudo killall -9 guvcview\end{DoxyVerb}
 然后尝试再次连接 Je\+Vois 摄像头。 
\end{DoxyItemize}
\item {\ttfamily guvcview} 显示来自另一台摄像头的视频（例如，笔记本电脑上的内置摄像头）

您可以使用 {\ttfamily guvcview} 中的下拉菜单来选择您的 Je\+Vois 相机（单击“视频控制”选项卡，然后单击“设备”下拉菜单），或者像这样启动 guvcview

\begin{DoxyVerb}guvcview -d /dev/video1
\end{DoxyVerb}


在 Linux 上，第一个连接的摄像头是 {\ttfamily /dev/video0} ，下一个是 {\ttfamily /dev/video1} ，依此类推。


\item 我想以特定的视觉模式启动，但当 {\ttfamily guvcview} 启动时，它只使用我之前选择的最后一个模式

你可以告诉 {\ttfamily guvcview} 以特定模式启动，例如

\begin{DoxyVerb}guvcview -ao none -f YUYV -x 640x312  # On Raspberry Pi host, use '-a none -o none' instead of '-ao none'
\end{DoxyVerb}


将启动显著性+面部+物体识别演示。


\end{DoxyItemize}\hypertarget{UserStartWindows}{}\doxysubsection{Je\+Vois-\/\+A33：开始使用 Windows 主机}\label{UserStartWindows}
最简单的入门方法是使用 \mbox{\hyperlink{JeVoisInventor}{Je\+Vois-\/\+A33：\+Je\+Vois Inventor 图形用户界面}}

以下是替代方法。

Je\+Vois 智能相机的使用方式与普通 U\+SB 相机相同。要开始使用 Windows 主机：


\begin{DoxyItemize}
\item 从 \href{http://jevois.org}{\texttt{ http\+://jevois.\+org}} 下载磁盘映像并将其刷入 Micro\+SD 卡。


\item 将 Micro\+SD 卡插入 Je\+Vois 智能相机，\+Micro\+SD 触点朝上，如下所示。

  

  


\item 将相机连接到主机。智能相机需要高达 3.\+5 瓦的功率，这超出了单个 U\+SB 2.\+0 端口的设计供电限制，但在单个 U\+SB 3.\+0 端口的限制范围内。使用能够无损传输全部功率的高质量 U\+S\+B-\/mini\+U\+SB 电缆非常重要。寻找带有 24awg 电源线的电缆。建议您在主机上使用 U\+SB 3.\+0 端口，因为它们可以提供更多功率。如果没有，您可以使用 U\+SB Y 型电缆连接到主机上的两个 U\+SB 2.\+0 端口，或者连接到一个 U\+SB 2.\+0 端口和一个外部 U\+SB 电源（例如，手机充电器）。请确保不要使用 U\+SB 集线器，除非该集线器具有强大的外部电源（变压器、壁式适配器）。


\item 观察 U\+SB 连接器旁边的智能相机上的 L\+E\+D：
\begin{DoxyItemize}
\item 绿色：电源已打开且足够强。
\item 约 3 秒后：橙色闪烁：相机传感器芯片已被检测到并初始化。
\item 约 5 秒后：橙色常亮：智能相机已准备就绪。
\item 再等待几秒钟，让主机检测到相机并准备好进行视频捕获。
\end{DoxyItemize}


\item 启动视频捕获软件。您可能想尝试 V\+L\+C、\+Skype 等。这里我们将使用 {\bfseries{A\+M\+Cap。}} 


\begin{DoxyItemize}
\item 下载并安装 A\+M\+Cap 软件。您可以在 \href{http://noeld.com/updates.asp}{\texttt{ http\+://noeld.\+com/updates.\+asp}} 免费获取。
\item 启动 A\+M\+Cap 软件。在“设备”下，确保选择 Je\+Vois 智能相机（如果您有多个相机，例如笔记本电脑中还有一个内置网络摄像头）。例如，我们在 Je\+Vois 上运行 Ar\+Uco 演示，并使用 A\+M\+Cap 在主机 PC 上查看结果：
\end{DoxyItemize}




\begin{DoxyItemize}
\item 通过在视频捕获软件中选择不同的视频分辨率来选择不同的机器视觉算法。要更改视频分辨率，请选择“选项”、“视频设备”、“捕获格式”，如下所示：
\end{DoxyItemize}




\begin{DoxyItemize}
\item 看到“属性”对话框后，选择可用的“颜色空间/压缩”之一（大多数机器视觉模块输出 {\bfseries{Y\+U\+Y2}} 视频）和一个“输出尺寸”分辨率（如下所示），以在 Je\+Vois 相机上启动相应的机器视觉算法：
\end{DoxyItemize}




\begin{DoxyItemize}
\item 要访问相机的控制（如亮度、对比度等），可以通过选择“选项”、“视频设备”、“属性”来完成，如下所示：
\end{DoxyItemize}





请注意，在 Windows 上以及对于 V\+LC 等某些视频软件，许多视频捕获应用程序的延迟（捕获和显示之间的延迟或滞后）非常严重。这不是 Je\+Vois 的限制。与 Linux 主机一起使用时，不会出现延迟。


\item 拔下 Je\+Vois 智能相机之前，请确保退出相机查看软件。否则，您的主机可能会在尝试使用不再存在的相机时变得非常困惑。


\item 关闭 Je\+Vois 相机前无需执行关机程序。只需关闭视频捕捉软件并拔下相机电源即可。


\end{DoxyItemize}

\doxysubparagraph*{}\hypertarget{UserStartWindows_windows10}{}\doxysubsubsection{针对 Windows 10 的特殊说明}\label{UserStartWindows_windows10}
部分 Windows 10 用户（但不是全部）报告了使用 Je\+Vois 的问题。摄像头被正确检测和设置，但无法从中捕获视频。

从 开始，我们启用了一种解决方法，希望可以解决这个问题。它与 Windows 10 向 Je\+Vois 发送非法请求有关，\+Je\+Vois 对此回应为 U\+SB 停顿（在这种情况下应该如此），但 Windows 10 对此感到不满。

在 Windows 10 下，当您插入 Je\+Vois 并让 Windows 配置它时，您应该会看到以下设备：
\begin{DoxyItemize}
\item 摄像机
\item 存储设备（默认情况下为空，您需要告诉 Je\+Vois 导出其 micro\+SD 卡才能实际看到那里的一些文件）
\item 串行端口，您可以使用它向 Je\+Vois 发送命令。
\end{DoxyItemize}



如果您使用的 Je\+Vois 软件版本早于，则摄像机将被命名为“\+Video Control”（这是 Windows 的另一个错误；它使用摄像机控制单元的名称，而不是制造商和产品名称）。这表明您应该更新到 或更高版本。

\doxysubparagraph*{}\hypertarget{UserStartWindows_obswindows}{}\doxysubsubsection{使用适用于 Windows 的 Open Broadcaster Studio}\label{UserStartWindows_obswindows}
Open Broadcaster Studio 是一款出色的免费程序，允许您根据 Je\+Vois 的需要选择不同的视频分辨率。


\begin{DoxyItemize}
\item 从 \href{https://obsproject.com}{\texttt{ https\+://obsproject.\+com}} 下载 O\+BS Studio
\item 安装它，在安装过程中，只需说您不会流式传输视频。
\item 将 Je\+Vois 连接到您的计算机并允许其启动。
\item 打开 O\+BS Studio，在屏幕左下方，单击 {\bfseries{来源下的}} {\ttfamily +} 图标以添加新的{\bfseries{视频捕获设备}}。
\item 创建一个新的源 
\item 双击该源时，会出现一个对话框。在其中，选择：
\item 设备：\+Je\+Vois-\/\+A33 摄像机（这是 Windows 分配给 Je\+Vois 的名称；在不同的 Windows 版本上可能会有所不同，如果您有内置网络摄像头，只需选择您知道不是内置网络摄像头的设备即可）。
\item 分辨率/\+F\+PS 类型：自定义
\item 分辨率：选择您想要尝试的任何分辨率
\item F\+P\+S：最高 F\+PS 
\item 尽情享受吧！您可以拖动并调整视频预览的大小，以获得最佳观看体验。
\end{DoxyItemize}

以下是 在 Windows 10 上的顺利运行：



\doxysubparagraph*{}\hypertarget{UserStartWindows_enablegreywindows}{}\doxysubsubsection{启用灰度捕获}\label{UserStartWindows_enablegreywindows}
除了能够输出彩色流式视频外，当启用某些机器视觉算法时，\+Je\+Vois 还可以流式传输灰度视频。这在运行机器视觉算法时特别有用，这些算法会产生要在主机上进一步处理的结果。例如，请参阅 \href{/moddoc/EdgeDetection/modinfo.html}{\texttt{ 边缘检测模块}} 或 \href{/moddoc/OpticalFlow/modinfo.html}{\texttt{ 光流模块}}。在 Windows 下，\+A\+M\+Cap 需要安装额外的过滤器才能捕获灰度视频（在 U\+SB 视频规范中，灰度称为 Y800 模式）。

以下说明由 Je\+Vois 用户 \href{/qa/index.php?qa=user&qa_1=pelrun}{\texttt{ pelrun}} \href{/qa/index.php?qa=346&qa_1=grey-mode-in-amcap-on-windows-10-causes-error}{\texttt{ 贡献}}。非常感谢，pelrun！


\begin{DoxyItemize}
\item 下载 \href{http://www.gdcl.co.uk/YUVxfm.zip}{\texttt{ http\+://www.\+gdcl.\+co.\+uk/\+Y\+U\+Vxfm.\+zip}}。镜像副本位于 \href{/data/YUVxfm.zip}{\texttt{ 此处}}。
\item 将其解压至 {\bfseries{c\+:\textbackslash{}windows\textbackslash{}system32}}
\item 以管理员权限打开命令提示符窗口
\item 在命令窗口中输入 {\ttfamily regsvr32 c\+:\textbackslash{}windows\textbackslash{}system32\textbackslash{}Y\+U\+Vxfm.\+dll}。
\end{DoxyItemize}

这将安装一个支持 Y800 模式的 directshow 过滤器，并允许您使用输出灰度视频的 Je\+Vois 机器视觉模块。

\doxysubparagraph*{}\hypertarget{UserStartWindows_troubleshootwindows}{}\doxysubsubsection{故障排除}\label{UserStartWindows_troubleshootwindows}
如果您遇到问题并使用 Windows 10，请确保您更新到 或更高版本，因为我们在这些更高版本中启用了一些解决方法来处理 Windows 10 中的一些错误。 \hypertarget{UserStartMac}{}\doxysubsection{Je\+Vois-\/\+A33：\+Mac 主机入门 \textbackslash{}tableofcontents}\label{UserStartMac}
最简单的入门方法是使用 \mbox{\hyperlink{JeVoisInventor}{Je\+Vois-\/\+A33：\+Je\+Vois Inventor 图形用户界面}}

以下是替代方法。

\doxysubparagraph*{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#@section userstartmac 开始使用 Mac -\/ 基本 Photo\+Booth}

Je\+Vois 智能相机的使用方式与普通 U\+SB 相机相同。要开始使用 Mac 主机：


\begin{DoxyItemize}
\item 从 \href{http://jevois.org}{\texttt{ http\+://jevois.\+org}} 下载磁盘映像并将其刷入 Micro\+SD 卡。


\item 将 Micro\+SD 卡插入 Je\+Vois 智能相机，\+Micro\+SD 触点朝上，如下所示。

  

  


\item 将相机连接到主机。智能相机需要高达 3.\+5 瓦的功率，这超出了单个 U\+SB 2.\+0 端口的设计供电限制，但在单个 U\+SB 3.\+0 端口的限制范围内。使用能够无损传输全部功率的高质量 U\+S\+B-\/mini\+U\+SB 电缆非常重要。寻找带有 24awg 电源线的电缆。建议您在主机上使用 U\+SB 3.\+0 端口，因为它们可以提供更多功率。如果没有，您可以使用 U\+SB Y 型电缆连接到主机上的两个 U\+SB 2.\+0 端口，或者连接到一个 U\+SB 2.\+0 端口和一个外部 U\+SB 电源（例如，手机充电器）。请确保不要使用 U\+SB 集线器，除非该集线器具有强大的外部电源（变压器、壁式适配器）。


\item 观察 U\+SB 连接器旁边的智能相机上的 L\+E\+D：
\begin{DoxyItemize}
\item 绿色：电源已打开且足够强。
\item 约 3 秒后：橙色闪烁：相机传感器芯片已被检测到并初始化。
\item 约 5 秒后：橙色常亮：智能相机已准备就绪。
\item 再等待几秒钟，让主机检测到相机并准备好进行视频捕获。
\end{DoxyItemize}


\item 启动视频捕捉软件。这里我们将使用应用程序目录中捆绑的 Photo\+Booth 应用程序。

从“应用程序”文件夹启动 Photo\+Booth。您应该看到以下内容：

\textbackslash{}图片 html photobooth1.\+png

Photobooth 不允许您访问对比度、曝光等控件。但您可以从 App Store 获取第三方应用程序来执行这些操作。以下是从 App Store 获取（免费）后使用网络摄像头设置的示例：



您还可以尝试 V\+L\+C、\+Skype、\+Facetime 等。内置的 Photobooth 应用程序非常挑剔，如果相机显示 B\+A\+Y\+ER 或 R\+G\+B565 视频模式、太多模式等，它将拒绝使用相机。它也不允许您选择视频分辨率。要在 Mac 上使用 Je\+Vois 相机，建议您仅使用一种可用的视频分辨率对其进行配置（{\ttfamily videomappings.\+cfg} 文件中的一个条目）。有关更多信息，请参阅 User\+Modes。

\doxysubparagraph*{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#@section obsmac Mac 入门 -\/ Open Broadcaster Studio}



Open Broadcaster Studio 是一款出色的免费程序，允许您根据 Je\+Vois 的需要选择不同的视频分辨率。


\begin{DoxyItemize}
\item 从 \href{https://obsproject.com}{\texttt{ https\+://obsproject.\+com}} 下载 O\+BS Studio
\item 安装它，在安装过程中，只需说您不会流式传输视频。
\item 将 Je\+Vois 连接到您的计算机并允许其启动。
\item 打开 O\+BS Studio，在屏幕左下方，单击 {\bfseries{来源下的}} {\ttfamily +} 图标以添加新的{\bfseries{视频捕获设备}}。
\item 创建一个新的源 
\item 选择 Jevois-\/\+A33 智能相机作为其设备，取消选中{\bfseries{使用预设}}以启用所有 Je\+Vois 分辨率，选择您想要尝试的分辨率，选择{\bfseries{简单 F\+PS 值}}，然后选择其中一个可用的 F\+PS 值。
\item 双击该源时，会出现一个对话框。在其中，您可以选择：
\item 设备：\+Je\+Vois-\/\+A33 智能相机
\item 确保未选中 {\bfseries{使用预设}}
\item 分辨率：选择您想要尝试的任何分辨率
\item F\+P\+S：当您更改分辨率时，有时会为您提供一些 {\bfseries{合理的 F\+PS 值}}，但更简单的方法是切换回 {\bfseries{简单的 F\+PS 值}}，然后选择 Je\+Vois 提供的值。
\item 尽情享受吧！您可以拖动并调整视频预览的大小以获得最佳观看体验。 
\end{DoxyItemize}

\doxysubparagraph*{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#@section userstartmaccamtwist 开始使用 Mac -\/ Cam\+Twist Studio}



通过在视频捕获软件中选择不同的视频分辨率，可以选择不同的机器视觉算法。在 Mac 上，大多数网络摄像头应用程序不允许您选择视频分辨率。但有一些允许。其中一个例子是 Cam\+Twist Studio。

为了使其工作：


\begin{DoxyItemize}
\item 下载 \href{http://camtwiststudio.com/download/}{\texttt{ Cam\+Twist Studio}}。我们使用了最新（开发）版本，它在我们的 El Capitan Mac 上运行良好。


\item 将其安装到您的 Mac 上。


\item 插入您的 Je\+Vois 相机，等待橙色 L\+ED 闪光，然后等待橙色 L\+ED 常亮。


\item 启动 Cam\+Twist Studio。


\item 在 Cam\+Twist 窗口中，双击“步骤 1：选择视频源”下的 {\ttfamily Webcam。} 


\item 然后在 Cam\+Twist 窗口右侧的 {\ttfamily 设置下，选择“\+Je\+Vois} A33 智能相机”。

\textbackslash{}图像 html camtwist-\/setcam.\+png


\item 在屏幕顶部的菜单栏上，选择 {\ttfamily 查看} {\ttfamily -\/$>$} {\ttfamily 预览。这将显示来自} Je\+Vois 智能相机的实时视频。帧速率不是很高，但下面将修复。默认情况下，分辨率为 320x240（\+M\+J\+P\+E\+G），\+Je\+Vois 智能相机不进行任何处理（即，它的行为与普通相机一样）。

\textbackslash{}图像 html camtwist-\/prefs.\+png


\item 在屏幕顶部的菜单栏上，转到 {\ttfamily Cam\+Twist} {\ttfamily -\/$>$} {\ttfamily 首选项。单击首选项窗口顶部的“视频设备”。然后选择} Je\+Vois-\/\+A33 智能相机。最后，使用 {\ttfamily 格式下拉菜单选择各种分辨率。每次选择新分辨率时，它还会在智能相机上选择不同的机器视觉算法。请参阅} \href{http://jevois.org/start/start.html\#demos-section}{\texttt{ Je\+Vois Start，在“演示”下}} 以获取默认视频映射列表（在 Je\+Vois 上运行的算法取决于您在 Cam\+Twist 中选择的分辨率）。


\item 在 {\ttfamily 首选项窗口的} {\ttfamily 常规下，您可以更改预览框的帧速率和分辨率。更改后您需要重新启动} Cam\+Twist。您还需要手动将预览窗口的角落拖动到其新大小。






\item 拔下 Je\+Vois 智能相机之前，请确保退出相机查看软件。否则，您的主机可能会在尝试使用不再存在的相机时变得非常困惑。


\item 关闭 Je\+Vois 相机前无需执行关机程序。只需关闭视频捕捉软件并拔下相机电源即可。


\end{DoxyItemize}

\doxysubparagraph*{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#@section userstartmacother 开始使用 Mac -\/ ffplay}



从 ffmpeg 网站 \href{https://ffmpeg.org/download.html\#build-mac}{\texttt{ https\+://ffmpeg.\+org/download.\+html\#build-\/mac}} 下载预编译的 ffplay 二进制文件（免费），然后打开终端（在应用程序中，实用程序下）并运行：

\begin{DoxyVerb}~/bin/ffplay -f avfoundation -i "JeVois" -video_size 640x300 -framerate 60 -pixel_format yuyv422 \end{DoxyVerb}
（假设您将 ffplay 保存到您的 $\sim$/bin/ 目录中）。

请注意，在 Mac 上，许多视频捕获应用程序（包括 ffplay）的延迟（捕获和显示之间的延迟或滞后）非常严重。这不是 Je\+Vois 的限制。与 Linux 主机一起使用时，不会出现延迟。

\doxysubparagraph*{}



\doxysubparagraph*{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#@section troubleshootmac 故障排除}



到目前为止这里还没有任何物品。 
\end{DoxyItemize}\hypertarget{UserStartCaveats}{}\doxysubsection{Je\+Vois-\/\+A33：入门注意事项 \textbackslash{}tableofcontents}\label{UserStartCaveats}

\begin{DoxyItemize}
\item 在 Mac 上，只有少数免费应用程序（例如 Cam\+Twist Studio）才支持选择特定的网络摄像头分辨率。这适用于任何 U\+SB 摄像头，而不仅仅是 Je\+Vois 智能摄像头。\+Mac O\+SX 似乎只决定使用哪种分辨率，而您无法控制它。要将 Je\+Vois 智能摄像头与 Mac 一起使用并确保特定的视频分辨率，您可以编辑智能摄像头的 videomappings.\+cfg 并在该文件中仅保留一种分辨率。\+O\+SX 将别无选择，只能使用该分辨率。如果您是程序员，据报道，使用 Open\+CV 从 Mac 上的 Je\+Vois 抓取帧是成功的，请参阅 \href{http://jevois.org/qa/index.php?qa=114}{\texttt{ http\+://jevois.\+org/qa/index.\+php?qa=114}}
\item 在 Mac 上，无法访问相机控件（曝光、对比度等）。但是，一些第三方应用程序可用于此目的。例如，\+Apple 应用商店中提供的“网络摄像头设置”应用程序。
\item 在 Windows 上，选择相机分辨率和曝光等设置也变得很困难，只有少数免费应用程序（如 A\+M\+Cap）允许您选择相机分辨率。您可能想要探索第三方应用程序，或者像在 Mac 上一样，仅使用一种可用的视频分辨率配置您的 videomappings.\+cfg。如果您是一名程序员，据报道，使用 Open\+CV 从 Mac 上的 Je\+Vois 抓取帧是成功的，请参阅 \href{http://jevois.org/qa/index.php?qa=114}{\texttt{ http\+://jevois.\+org/qa/index.\+php?qa=114}}，因为这也可能适用于 Windows。
\item i\+OS 支持：使用 O\+TG 线连接到 i\+Pad（i\+OS 9），i\+Pad 报告说不支持任何 U\+SB 摄像头（不仅仅是 Je\+Vois 智能摄像头）。看来 i\+OS 不支持 U\+SB 摄像头。
\item Android 支持：使用 O\+TG 电缆，\+Je\+Vois 智能相机被一些第三方应用程序检测到，但我们无法成功从中流式传输。需要进行更多调查。
\end{DoxyItemize}

由于这些注意事项，\+Je\+Vois 最适合与 Linux 主机一起使用。 \hypertarget{UserModes}{}\doxysubsection{视频模式和映射用户指南}\label{UserModes}
您的 Je\+Vois 智能相机是一款非常灵活的嵌入式 Linux 计算机，可以运行各种机器视觉算法。

：运行哪种算法取决于以下两种情况：1）由通过 U\+SB 链路连接到 Je\+Vois 的主机选择；2）在不使用主机时使用命令行界面选择（例如，\+Je\+Vois 仅连接到 Arduino）。

当使用主机时，通过在主机上选择特定的视频分辨率来实现特定机器视觉算法的选择。

：运行哪种算法可以通过 1) Je\+Vois-\/\+Pro 的集成 G\+UI 或 2) 通过串行端口使用命令行界面进行选择。


\begin{DoxyItemize}
\item 像素格式
\item 视频映射
\end{DoxyItemize}

 \hypertarget{UserDemos}{}\doxysubsection{捆绑视觉模块和演示的用户指南}\label{UserDemos}
新用户请务必查看 \href{/start/start.html\#demo-section}{\texttt{ Je\+Vois Start}} 上的模块列表和相应的视频分辨率。

高级用户和程序员，这些模块的完整文档和源代码位于 \href{http://jevois.org/basedoc/}{\texttt{ Je\+Vois\+Base 文档}}。

只需{\bfseries{单击下面每个视觉模块的图标}}即可查看其文档。 \hypertarget{UserLighting}{}\doxysubsection{优化不同光照条件下的性能}\label{UserLighting}
Je\+Vois 智能相机中的传感器功能非常强大，但有时需要进行一些调整才能在低光照条件下正常运行。

这些技巧主要针对，因为 配备了高端 Starvis 背光（即超灵敏）传感器，在低光条件下表现非常出色。不过， 用户可能仍对以下一些技巧感兴趣。

所捕获视频的亮度取决于（至少）：


\begin{DoxyItemize}
\item 曝光时间。曝光时间越长，收集的光子越多，视频就越亮。曝光时间受帧速率限制，也就是说，更快的帧速率会限制最大可能的曝光时间，因为需要将帧发送出去进行处理。
\item 传感器增益，即对来自感光器的原始信号进行放大。增益越高，图像越亮，但噪声也越大。
\item 伽马曲线，这是在后期处理中应用的校正曲线，用于调整像素值，可能使它们更亮或更暗。除了伽马曲线之外，\+Je\+Vois 图像传感器还具有可编程颜色矩阵，它指定如何将像素值从原始像素阵列（\+B\+A\+Y\+ER 格式；参见 Pixel\+Formats）转换为给定的传感器图像格式（例如 Y\+U\+Y\+V）。通过在该颜色矩阵中输入更高的值，可以实现图像的整体更高亮度。
\end{DoxyItemize}

默认设置 -\/ -\/ -\/ -\/ -\/ -\/ -\/ -\/

默认情况下，\+Je\+Vois 会尝试保持给定视频映射中指定的帧速率。这样做的原因是，连接到 Je\+Vois 的某些下游计算机可能需要指定的帧速率才能实现流畅的实时操作。对于与 Je\+Vois 捆绑在一起的一些机器视觉模块，帧速率很高，例如 的帧速率为 60 帧/秒甚至 120 帧/秒。

在较高的帧速率下，可用于曝光的时间非常短。

在弱光下操作 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

让我们将 Je\+Vois-\/\+A33 与专业摄像机（索尼 F\+D\+R-\/\+A\+X1，价格约为 Je\+Vois-\/\+A33 的 100 倍）以及廉价的 U\+SB 摄像机（小型子弹头摄像机）进行比较。



当光线较暗时（此处，我们在日落前但日落后不久关掉了灯），所有摄像头拍摄的图像都会变暗，如下所示。此处，我们可以看到子弹头摄像头通过将帧速率降低到 4 帧/秒来适应，以便获得更多曝光时间（子弹头摄像头的图片显示在计算机屏幕上，用于显示帧的 guvcview 报告 4.\+12 帧/秒）。



昂贵的索尼相机在这里被设置为以固定的 60 fps 进行拍摄，我们可以在该相机的小型 L\+CD 屏幕上看到，尽管成本高得多，但该相机在低光和高帧率下也难以产生明亮的图像。

让我们仔细看看 Je\+Vois 相机。在低光照条件下，使用高帧率时，视频会变得非常非常暗，如下所示。



Je\+Vois 提供了几种方法来解决这个问题：

亮度控制 -\/ -\/ -\/ -\/ -\/ -\/ -\/ -\/ -\/

首先要尝试的是，\+Je\+Vois 提供了用于亮度、对比度等的标准 U\+SB 摄像头控件。这些控件会影响颜色矩阵。您可能希望先在视频捕获软件中尝试使用这些控件，看看在您的照明条件下是否可以获得足够好的图像质量。

允许自动降低帧速率 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

\begin{DoxyNote}{Note}
以下提示适用于默认 传感器（\+Omnivision ov9653）。某些控件可能不适用于其他传感器（例如，\+Aptina A\+R0135 全局快门；请参阅“帮助”以列出可用的控件）。
\end{DoxyNote}
如果亮度控制不够，一种策略是允许在低光下使用 Je\+Vois 时降低帧速率，以延长曝光时间。这可以使用 Je\+Vois 命令行界面中提供的 {\ttfamily presetwb} 相机参数来实现（参见 User\+Cli）。不幸的是，\+U\+SB 视频类规范中似乎不存在此类控件，因此我们无法将它们公开给主机，以便它们在视频捕获软件中显示为可用控件。因此，您必须使用 Je\+Vois 命令行界面修改这些控件。让我们切换到夜间模式（在 Video4\+Linux2 规范中称为 {\bfseries{shade）：}} 

{\ttfamily setcam presetwb 9}

（{\ttfamily help} 报告的可用值为：0\+:manual 1\+:auto 2\+:incandescent 3\+:fluorescent 4\+:fluorescent\+\_\+h 5\+:horizo​​n 6\+:daylight 7\+:flash 8\+:cloudy 9\+:shade）。



请随意尝试其他预设。预设 9 允许最大程度地自动降低帧速率，最多可降低 8 倍。其他一些预设仅允许较小程度的降低，或者在低光条件下不自动调整帧速率。

\begin{DoxyNote}{Note}
修改摄像机预设时存在滞后现象，即从预设 1 切换到 9 然后再切换回 1 会使摄像机处于与原始状态不同的状态。只需关闭 Je\+Vois 电源然后再打开即可恢复到原始状态。
\end{DoxyNote}
使用较低的固定帧速率 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

在与 Je\+Vois 捆绑的演示中，我们经常使用 60 帧/秒来展示 Je\+Vois 动态处理视频的速度。

但是，如果您不需要以 60 帧/秒的速度使用 Object\+Tracker 模块检测彩色物体，并且您的应用程序以 15 帧/秒的速度运行就足够了，那么只需编辑相应的视频映射并降低 {\bfseries{videomappings.\+cfg}} 文件中的 U\+SB 输出帧速率和摄像头帧速率（参见 Video\+Mapping）。

Je\+Vois 启动时，默认使用自动曝光和增益控制，较低的帧速率将允许更大范围的自动曝光和增益调整，从而使 Je\+Vois 在低光照条件下更好地运行。

手动曝光和增益 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

另一个选择是转向手动控制。这里有两个控制措施值得关注：


\begin{DoxyItemize}
\item 曝光：光传感器收集光线的时间。曝光时间受帧速率限制（即曝光时间不能超过帧周期）。曝光时间越长，视频就越亮，但也更容易出现运动模糊。
\item 增益：表示从光传感器接收到的模拟信号在数字化之前应被放大到何种程度。较高的增益会使视频更亮，但也会放大噪音。
\end{DoxyItemize}

首先将视频查看器中的{\bfseries{曝光、自动}}控件设置为{\bfseries{手动模式}}，然后开始设置{\bfseries{曝光（绝对）}}和{\bfseries{增益}}控件。请注意，尽管曝光控制的范围从 0 到 1000，但根据帧速率，只有该范围的一小部分可用（即，曝光时间不能增加到比帧周期更长的时间。如果尝试将曝光时间设置为比帧周期更长，曝光将自动限制在略低于帧周期的水平）。

一般来说，应该在增益和曝光值之间找到一个折衷点。如果运动模糊不是问题，那么尽可能高的曝光和尽可能低的增益将产生较少噪声和颗粒感的图像。

\begin{DoxyNote}{Note}
由于自动增益在 U\+SB 视频类规范中未定义为相机控制，因此在 Je\+Vois 中我们将自动曝光和自动增益设置结合在一起：当您选择手动曝光时，它也会选择手动增益，当您选择自动曝光时，它也会选择自动增益。
\end{DoxyNote}


增益越高，图像看起来就越粗糙，如果必须保持较高的帧速率，则看起来就越不美观。

但这对于机器视觉算法来说不一定是个问题。

例如，在上图中，我们将增益调得非常高，以便在非常暗的条件下仍能以 30 帧/秒的速度运行。\+Je\+Vois 捕获的视频中明显存在明显的像素噪声。但是……\+Je\+Vois 内部运行的 算法似乎没有受到影响，并且运行良好，可以轻松检测和解码场景中存在的两个 Ar\+Uco 标记！

这是一个更极端的例子，在几乎完全黑暗的环境下，将曝光和增益调到最大。图像质量很糟糕（参见标记黑色区域上的非常高的像素噪声）。但 Ar\+Uco 标记检测得很好……

\textbackslash{}图片 html 低光之夜.\+jpg

进一步探索 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

Je\+Vois 允许您通过 {\ttfamily setcamreg} 和 {\ttfamily getcamreg} 命令来访问相机传感器寄存器（必须先将参数 {\ttfamily camreg} 设置为 true，作为防止意外使用这些命令的额外保护）。请注意，更改与像素时钟和图像格式细节、脉冲极性等有关的任何寄存器都可能导致传感器崩溃，您必须关闭 Je\+Vois 才能恢复。

您可能想要探索将不同的伽马曲线、不同的颜色矩阵等加载到传感器中，看看是否可以获得更好的低光性能。 \hypertarget{MicroSD}{}\doxysubsection{Micro\+SD 卡组织和文件}\label{MicroSD}
\hypertarget{MicroSD_autotoc_md68}{}\doxysubsubsection{Micro\+S\+D 卡的组织方式}\label{MicroSD_autotoc_md68}
Je\+Vois 智能相机中的 Micro\+SD 卡包含智能相机处理器上运行的所有软件。其中包括：


\begin{DoxyItemize}
\item 启动和配置低级硬件元素所需的文件，例如 D\+D\+R3 内存和 micro\+SD 卡驱动程序以及 Linux 内核。
\item Linux 操作系统，包括标准 Linux 命令行实用程序，以及许多库，如 Open\+C\+V、boost、\+Eigen3 等。
\item Je\+Vois 机器视觉模块和数据。
\end{DoxyItemize}\hypertarget{MicroSD_autotoc_md69}{}\doxysubsubsection{在桌面或笔记本电脑上使用 Micro\+S\+D 卡}\label{MicroSD_autotoc_md69}
修改 Micro\+SD 卡的内容（例如添加新的机器视觉模块或获取 Je\+Vois 录制的视频文件）可以通过将 Micro\+SD 卡从 Je\+Vois 智能相机中取出并将其连接到台式机或笔记本电脑来实现。

\begin{DoxyWarning}{Warning}
您的 Je\+Vois 智能相机具有 {\bfseries{push-\/push}} Micro\+SD 卡槽。将卡推入直至卡入卡槽发出咔嗒声以装入卡槽，然后再次推入直至卡入卡槽并弹出以卸载卡槽。您是否尝试将 Micro\+SD 卡拉出，否则可能会损坏 Je\+Vois 智能相机的 Micro\+SD 卡槽。
\end{DoxyWarning}
\hypertarget{MicroSD_autotoc_md70}{}\doxyparagraph{Je\+Vois-\/\+A33 Micro\+SD}\label{MicroSD_autotoc_md70}
  \hypertarget{MicroSD_autotoc_md71}{}\doxyparagraph{Je\+Vois-\/\+Pro Micro\+SD}\label{MicroSD_autotoc_md71}
  \hypertarget{MicroSD_autotoc_md72}{}\doxyparagraph{在计算机上使用 Micro\+S\+D 卡}\label{MicroSD_autotoc_md72}
在台式机或笔记本电脑上访问 Micro\+SD 卡有两种基本方法：


\begin{DoxyItemize}
\item 使用大多数计算机商店出售的 U\+SB 读卡器，并将其连接到台式机或笔记本电脑的 U\+SB 端口
\end{DoxyItemize}




\begin{DoxyItemize}
\item 使用 Micro-\/\+SD 至 SD 卡适配器，并将 SD 卡插入计算机（如果计算机有插槽）（例如 Mac 笔记本电脑）：
\end{DoxyItemize}



\hypertarget{MicroSD_autotoc_md73}{}\doxysubsubsection{Micro\+S\+D 分区和分区类型}\label{MicroSD_autotoc_md73}
该卡分为三个分区（逻辑卷）：


\begin{DoxyItemize}
\item {\bfseries{B\+O\+O\+T（\+D\+O\+S/\+Windows}} F\+A\+T32 格式）：包含启动所需的文件，包括 Linux 内核
\item {\bfseries{L\+I\+N\+U\+X（\+Linux}} ext4 格式，在 Windows 和 Mac 电脑上读取 Micro\+SD 卡时可能不会显示）：包含 Linux 操作系统和程序
\item {\bfseries{J\+E\+V\+O\+I\+S（\+D\+O\+S/\+Windows}} F\+A\+T32 格式）：包含所有 Je\+Vois 机器视觉模块和数据文件，包括智能相机可能创建的文件（例如，将视频保存到 micro\+SD 时）。
\end{DoxyItemize}

由于 L\+I\+N\+UX 分区的类型为 ext4，这是 Linux 的原生文件系统，但在 Windows 和 Mac 上默认无法识别，因此当您在 Windows 或 Mac 计算机上读取 Micro\+SD 卡时，您可能无法看到或访问它。这通常不是问题，因为只有高级黑客（将在 Linux 计算机上编程）才需要修改 L\+I\+N\+UX 分区的内容。

对于普通用户，您需要的只是 J\+E\+V\+O\+IS 分区，如下所述。

以下是插入 Micro\+SD 卡后 Mac 笔记本电脑上发生的情况的示例：出现两个卷，\+B\+O\+OT 和 J\+E\+V\+O\+I\+S，可以浏览这两个卷中的文件。\+L\+I\+N\+UX 卷未出现在这台 Mac 上（但请注意，第三方应用程序也可用于允许 Mac 读取 ext4 分区）。

\begin{DoxyWarning}{Warning}
Micro\+SD 卡还具有额外的和必要的 \char`\"{}files\char`\"{} ，这些文件直接存储在卡上的特定扇区（物理闪存盘位置）上。这些是引导加载程序（系统启动）文件，是 Je\+Vois 嵌入式处理器启动时加载的第一个文件。由于处理器在早期启动阶段还不知道分区、文件系统等，因此它所知道的全部操作就是从 SD 卡读取原始扇区。您通常不需要修改这些特殊文件。但请注意，如果您想将一张 Je\+Vois Micro\+SD 卡的内容复制到新卡，则需要进行完整的物理逐扇区复制。有关如何执行此操作的说明，请参阅 New\+Micro\+S\+D。
\end{DoxyWarning}
\hypertarget{MicroSD_autotoc_md74}{}\doxysubsubsection{Micro\+S\+D 卡内容}\label{MicroSD_autotoc_md74}
以下是典型的 micro\+SD 卡上的文件简图树（ 类似但不完全相同）：

\begin{DoxyVerb}├── BOOT  ########## (16 MB FAT32 partition)
│   ├── README.txt               # information file for Windows users who may not see the JEVOIS partition
│   ├── script.bin               # low-level hardware configuration file
│   ├── uEnv.txt                 # optional command-line arguments for the Linux Kernel
│   └── uImage                   # Linux kernel


├── LINUX ########## (1 GB Linux ext4 partition)
│   ├── bin                      ### Directory for standard Unix commands
│   │   ├── ash                  # some Unix command
│   │   ├── bash                 # some other Unix command
│   │   ├── busybox              # ...
│   │   ├── cat

...

│   ├── etc                      ### Directory for Unix configuration files
│   │   ├── fstab
│   │   ├── group
│   │   ├── hostname
│   │   ├── hosts

...

│   ├── lib                      ### Directory for Unix system libraries
│   │   ├── ld-2.23.so
│   │   ├── ld-linux-armhf.so.3
│   │   ├── libatomic.so.1.2.0
│   │   ├── libc-2.23.so
│   │   ├── libcrypt-2.23.so
│   │   ├── libc.so.6
│   │   ├── libdl-2.23.so
│   │   ├── libgcc_s.so
│   │   ├── libm-2.23.so
│   │   ├── libm.so.6
│   │   ├── libnsl-2.23.so

...

│   ├── sbin                     ### Directory for system administration Unix commands
│   │   ├── arp
│   │   ├── blkid
│   │   ├── devmem
│   │   ├── fdisk
│   │   ├── freeramdisk
│   │   ├── fsck

...

│   ├── tmp                      ### Scratch directory for temporary files
│   ├── usr                      ### Directory for user Unix commands and shared data
│   │   ├── bin
│   │   │   ├── ar
│   │   │   ├── attr
│   │   │   ├── awk
│   │   │   ├── basename
│   │   │   ├── bunzip2
│   │   │   ├── bzcat

...

│   │   ├── lib                  ### Directory for Unix user libraries
│   │   │   ├── libattr.so.1.1.0
│   │   │   ├── libavcodec.so.56.60.100
│   │   │   ├── libavdevice.so.56.4.100
│   │   │   ├── libavfilter.so.5.40.101
│   │   │   ├── libavformat.so.56.40.101
│   │   │   ├── libavheap.so
│   │   │   ├── libavresample.so.2.1.0
│   │   │   ├── libavutil.so.54.31.100
│   │   │   ├── libbfd-2.25.51.so
│   │   │   ├── libbfd-2.26.1.so
│   │   │   ├── libblas.so
│   │   │   ├── libboost_atomic.so.1.61.0
│   │   │   ├── libboost_chrono.so.1.61.0
│   │   │   ├── libboost_container.so.1.61.0

...

│   │   ├── sbin
│   │   │   ├── addgroup         ### Directory for more Unix system administration commands
│   │   │   ├── adduser
│   │   │   ├── arping
│   │   │   ├── chroot

...

│   │   └── share                ### Directory for shared data used by Unix commands
│   │       ├── awk
│   │       │   ├── assert.awk
│   │       │   ├── bits2str.awk
│   │       │   ├── cliff_rand.awk
│   │       │   ├── ctime.awk
│   │       │   ├── ftrans.awk
│   │       │   ├── getopt.awk
│   │       │   ├── gettime.awk

...
│   └── var                      ### Directory for Unix system log files and other volatile files
│       ├── cache
│       ├── lib
│       │   └── misc
│       ├── lock
│       ├── log
│       ├── run
│       ├── spool
│       └── tmp



├── JEVOIS ########## (6+ GB FAT32 partition)
│   ├── config                   ### Directory for JeVois engine configuration file
│   │   ├── initscript.cfg
│   │   ├── JeVois.cmake
│   │   ├── jevois_config.cmake
│   │   ├── params.cfg
│   │   └── videomappings.cfg
│   ├── data                     ### Directory for optional user data, some JeVois modules also save outputs into it
│   ├── lib                      ### Directory for JeVois libraries, i.e., collections of shared vision algorithms
│   │   └── JeVois               # One sub-directory for each JeVois "Vendor" (provider of JeVois modules)
│   │       └── libjevoisbase.so.1.0
│   ├── modules                  ### Directory for JeVois machine vision modules
│   │   └── JeVois               # One sub-directory for each JeVois "Vendor" (provider of JeVois modules)
│   │       ├── Convert          # One directory for each module
│   │       │   ├── Convert.so   # The compiled module code that will be loaded when that module is selected
│   │       │   ├── icon.png     # Extra data about the module
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   └── screenshot1.png
│   │       ├── DemoArUco
│   │       │   ├── calibration.yaml
│   │       │   ├── DemoArUco.so
│   │       │   ├── icon.png
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   ├── screenshot1.png
│   │       │   └── screenshot2.png
│   │       ├── DemoGPU
│   │       │   ├── DemoGPU.so
│   │       │   ├── icon.png
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   ├── screenshot1.png
│   │       │   ├── shaders      # This module uses auxiliary files for GPU shader code
│   │       │   │   ├── blurfragshader.glsl
│   │       │   │   ├── dilatefragshader.glsl
│   │       │   │   ├── erodefragshader.glsl
│   │       │   │   ├── medianfragshader.glsl
│   │       │   │   ├── multfragshader.glsl
│   │       │   │   ├── simplefragshader.glsl
│   │       │   │   ├── simplevertshader.glsl
│   │       │   │   ├── sobelfragshader.glsl
│   │       │   │   ├── threshfragshader.glsl
│   │       │   │   ├── twirlfragshader.glsl
│   │       │   │   └── yuvfragshader.glsl
│   │       │   └── video1.mkv

...

│   │       ├── DemoSalGistFaceObj
│   │       │   ├── DemoSalGistFaceObj.so
│   │       │   ├── facedetector
│   │       │   │   ├── haarcascade_eye_tree_eyeglasses.xml
│   │       │   │   └── haarcascade_frontalface_alt.xml
│   │       │   ├── icon.png
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   ├── movie.avi
│   │       │   ├── screenshot1.png
│   │       │   └── tiny-dnn     # 该模块使用神经网络数据的辅助文件 
│   │       │       ├── CIFAR10
│   │       │       │   ├── batches.meta.txt
│   │       │       │   ├── data_batch_1.bin
│   │       │       │   ├── data_batch_2.bin
│   │       │       │   ├── data_batch_3.bin
│   │       │       │   ├── data_batch_4.bin
│   │       │       │   ├── data_batch_5.bin
│   │       │       │   ├── readme.html
│   │       │       │   ├── test_batch.bin
│   │       │       │   └── weights.tnn
│   │       │       └── MNIST
│   │       │           ├── t10k-images.idx3-ubyte
│   │       │           ├── t10k-labels.idx1-ubyte
│   │       │           ├── train-images.idx3-ubyte
│   │       │           ├── train-labels.idx1-ubyte
│   │       │           └── weights.tnn

...

│   │       ├── SaliencySURF
│   │       │   ├── icon.png
│   │       │   ├── images       # Images of the things this module can recognize
│   │       │   │   ├── books.png
│   │       │   │   ├── doorframe.png
│   │       │   │   ├── doorlock2.png
│   │       │   │   ├── doorlock.png
│   │       │   │   ├── lightswitch2.png
│   │       │   │   ├── lightswitch.png
│   │       │   │   ├── spot25.png
│   │       │   │   ├── spot26.png
│   │       │   │   └── usbbatt.png
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   ├── params.cfg
│   │       │   ├── SaliencySURF.so
│   │       │   └── screenshot1.png

...

│   ├── packages                 ### Simply copy downloaded .jvpkg files here and JeVois will unpack and install them
│   └── scripts
│       ├── astylerc
│       ├── docinstall.sh
│       ├── extract-code-snippets.pl
│       ├── jevois-modinfo.pl
│       └── list-sources.sh

...\end{DoxyVerb}
\hypertarget{MicroSD_autotoc_md75}{}\doxysubsubsection{Micro\+S\+D 分区大小调整}\label{MicroSD_autotoc_md75}
如果您的卡大于我们提供的图像尺寸，您可能需要调整 J\+E\+V\+O\+IS 或 J\+E\+V\+O\+I\+S\+P\+RO 分区的大小以使用卡上所有可用的空间。

J\+E\+V\+O\+IS 或 J\+E\+V\+O\+I\+S\+P\+RO 分区使用 V\+F\+A\+T/\+F\+A\+T32 文件系统，以实现与各种主机的最大兼容性。要在 Linux 下调整其大小，请使用 {\ttfamily gparted} （您可能必须先使用 {\ttfamily sudo apt install gparted} 安装它）。\hypertarget{MicroSD_autotoc_md76}{}\doxysubsubsection{Je\+Vois-\/\+A33：在 Je\+Vois 运行时访问和修改 Micro\+SD}\label{MicroSD_autotoc_md76}


当卡位于 Je\+Vois 智能相机内时，您可以访问 micro\+SD 上 {\bfseries{J\+E\+V\+O\+IS}} 分区的内容。\+Je\+Vois 可以（根据需要）使 {\bfseries{J\+E\+V\+O\+IS}} 分区作为虚拟 U\+SB 闪存驱动器通过 U\+SB 向连接的主机计算机显示。

要启用此功能，请连接到 Je\+Vois 命令行界面（参见 User\+Cli）并发出命令：

\begin{DoxyVerb}usbsd
\end{DoxyVerb}


您会注意到主机检测到了一个新的 U\+SB 闪存驱动器。



\begin{DoxyNote}{Note}
由于能够在更改 micro\+SD 内容的同时切换各种视觉模块会带来一些潜在的数据一致性问题，因此目前，我们已限制通过 U\+SB 的文件访问，仅在不流式传输视频时才有效。同样，需要重新启动 Je\+Vois 相机才能允许它使用主机上的任何新文件或修改过的文件。
\end{DoxyNote}
在 Linux 上，使用 及更高版本，您可以使用主机命令 {\ttfamily jevois-\/usbsd start} 指示连接的 Je\+Vois 相机开始导出其 micro\+S\+D，而无需打开串行终端应用程序并连接到 Je\+Vois。同样，您可以发出 {\ttfamily jevois-\/usbsd stop} 来释放卡并重新启动 Je\+Vois。

典型的工作流程如下：


\begin{DoxyItemize}
\item 将 Je\+Vois 连接到主机并让其启动。
\item 确保您没有从 Je\+Vois 捕获视频。
\item 连接到 Je\+Vois 命令行界面（使用硬件串行端口或 U\+SB 串行；参见 User\+Cli）。
\item 当你想修改 Je\+Vois 内部 micro\+SD 的内容时，请发出 {\ttfamily usbsd} 命令。虚拟 U\+SB 闪存驱动器将出现在主机上。
\item 使用 及更高版本，您不需要打开串行终端并在其中输入，而是可以直接从任何 Linux shell 使用新的主机命令 {\ttfamily jevois-\/usbsd start} 。
\item 添加/修改/删除文件。这包括：
\begin{DoxyItemize}
\item 修改 {\bfseries{J\+E\+V\+O\+IS\+:/config}} 中的配置或参数文件
\item 编辑 {\bfseries{J\+E\+V\+O\+IS\+:/modules}} 下用 Python 编写的模块
\item 添加任何数据，例如 Object\+Detect 模块的训练图像
\item 检索任何数据，例如 Je\+Vois 录制的视频文件
\item 将使用 {\ttfamily ./rebuild-\/platform.sh} 编译的新 C++ 模块的 .jvpkg 包复制到 J\+E\+V\+O\+IS\+:/packages/
\end{DoxyItemize}
\item 完成后，正确弹出虚拟 U\+SB 驱动器（拖到垃圾箱、单击弹出按钮等）。\+Je\+Vois 将检测到此情况并自动重新启动，然后可以使用新文件或修改后的文件。您应该在 Je\+Vois L\+ED 上看到以下内容：
\begin{DoxyItemize}
\item 闪烁 -\/ 关机完成
\item 常亮绿色 -\/ 重新启动
\item 橙色闪烁 -\/ 检测到摄像头传感器
\item 常亮橙色：准备就绪 
\end{DoxyItemize}
\end{DoxyItemize}\hypertarget{NewMicroSD}{}\doxysubsection{如何为 Je\+Vois 格式化新的 Micro\+SD 卡}\label{NewMicroSD}
Je\+Vois 要求在其 Micro\+SD 上对分区（逻辑卷）和文件进行非常具体的组织。此外，\+Micro\+SD 卡上的特定物理位置（扇区）必须有两个低级引导加载程序（硬件启动）“文件”。出于这个原因，在准备用于 Je\+Vois 的 Micro\+SD 卡时必须小心谨慎。\hypertarget{NewMicroSD_newmicrosd1}{}\doxysubsubsection{简单方法：下载并刷新 Je\+Vois 磁盘映像}\label{NewMicroSD_newmicrosd1}
最简单的方法是下载并刷新预配置的 Je\+Vois 磁盘映像。这些可在 jevois.\+org 上找到，其中包含所有操作系统、支持数据和核心 Je\+Vois 软件。使用 Je\+Vois 磁盘映像准备新的 Micro\+SD 卡后，您将能够使用笔记本电脑或台式电脑非常轻松地向其中添加新的机器视觉模块。\hypertarget{NewMicroSD_使用}{}\doxyparagraph{resin.\+io 的 Etcher 轻松为 Windows/\+Mac/\+Linux 刷入 micro\+SD}\label{NewMicroSD_使用}
Etcher 是一个免费的开源程序，用于将磁盘映像刻录到 U\+SB 驱动器和 SD 卡，它是跨平台的，并提供了在 Windows、\+Mac 和 Linux 上看起来相同的简单图形界面。


\begin{DoxyItemize}
\item 下载并安装免费开源的 \href{https://etcher.io/}{\texttt{ Etcher}}
\item 从 \href{http://jevois.org/start/}{\texttt{ Je\+Vois Start}} 下载 Je\+Vois Micro\+SD 映像文件。使用 Etcher 时无需解压文件，它可以接受压缩文件。如果您的计算机自动解压文件（例如，在某些 Mac 上），那没问题，您只需在以下步骤中使用生成的解压文件，该文件应命名为 jevois-\/image-\/1.\+0-\/8\+G.\+img 或类似名称。
\item 使用 U\+SB 转 micro\+SD 适配器或其他方法（例如，带有 SD 插槽的 Mac 上的 micro\+SD 转 SD 适配器）将您的 micro\+SD 卡连接到您的计算机。
\item 启动 Etcher。
\item 选择您下载的 .zip 图像文件（或从下载中解压的 .img 文件）。
\item 选择与您的 micro\+SD 卡对应的驱动器。
\item 单击“闪存”并等待完成。您的卡已准备好插入 Je\+Vois 智能相机。
\end{DoxyItemize}

\hypertarget{NewMicroSD_newmicrosdlinux}{}\doxyparagraph{更传统的刷入 Je\+Vois 磁盘映像：\+Linux}\label{NewMicroSD_newmicrosdlinux}
如果使用 Etcher 轻松刷新（如上所述）对您不起作用，请使用这些说明。

在 Linux 上，最简单的方法是在终端中使用 {\ttfamily dd。首先，识别分配给} SD 卡的设备。在 Ubuntu 上，转到 Ubuntu 菜单并输入 {\ttfamily disks，然后启动} {\bfseries{Disks}} 程序。



单击最有可能是您的 Micro\+SD 卡的图标，然后仔细检查显示的信息，例如大小、品牌名称等。一旦您确定这是您的新 Micro\+SD 卡，请注意底部显示的设备名称。这里是 {\ttfamily /dev/sdf，这是我们将用来写入} Je\+Vois 磁盘映像的名称。

\begin{DoxyNote}{Note}
确保解压下载的文件。不要尝试将 .zip 文件刷入 micro\+S\+D，否则将无法正常工作。
\end{DoxyNote}
\begin{DoxyVerb}cd Downloads
wget http://jevois.org/data/jevois-image-latest-8G.zip
unzip jevois-image-latest-8G.zip
sudo dd if=jevois-image-1.0-8G.img of=/dev/sdX bs=1M  # exact .img file name may vary
sync
\end{DoxyVerb}


您应该将上面的 {\ttfamily sdX} 替换为您在上一步中记下的设备名称。请确保等到 {\ttfamily sync} 命令（刷新磁盘缓存）完成，否则可能尚未将所有磁盘映像数据提交到您的 Micro\+S\+D。现在您可以弹出 Micro\+SD 卡并将其插入 Je\+Vois 智能相机。

对于 {\ttfamily dd} 命令，{\ttfamily if} 指定源文件（或设备），{\ttfamily of} 指定目标文件（或设备），{\ttfamily bs} 是要使用的块大小。

\begin{DoxyWarning}{Warning}
请务必仔细检查您使用的设备名称。一个小小的拼写错误就可能毁掉您计算机硬盘上的内容。
\end{DoxyWarning}
\hypertarget{NewMicroSD_newmicrosdwindows}{}\doxyparagraph{更传统的刷入 Je\+Vois 磁盘映像：\+Windows}\label{NewMicroSD_newmicrosdwindows}
如果使用 Etcher 轻松刷新（如上所述）对您不起作用，请使用这些说明。

\begin{DoxyNote}{Note}
确保解压下载的文件。不要尝试将 .zip 文件刷入 micro\+S\+D，否则将无法正常工作。
\end{DoxyNote}
您可以使用 \href{https://sourceforge.net/p/usbwriter/wiki/Documentation/}{\texttt{ https\+://sourceforge.\+net/p/usbwriter/wiki/\+Documentation/}} 中的 U\+S\+B\+Writer

您还可以尝试 \href{http://www.alexpage.de/usb-image-tool/download/}{\texttt{ U\+SB 映像工具}} 或 \href{https://sourceforge.net/projects/win32diskimager/}{\texttt{ Win32 磁盘映像器}}

有关如何使用这些工具，请参阅\href{http://www.runeaudio.com/documentation/quick-start/sd-card-setup-windows/}{\texttt{ 此处}}的说明。\hypertarget{NewMicroSD_newmicrosdmac}{}\doxyparagraph{更传统的刷入 Je\+Vois 磁盘映像：\+Mac}\label{NewMicroSD_newmicrosdmac}
如果使用 Etcher 轻松刷新（如上所述）对您不起作用，请使用这些说明。

\begin{DoxyNote}{Note}
确保解压下载的文件。不要尝试将 .zip 文件刷入 micro\+S\+D，否则将无法正常工作。
\end{DoxyNote}
在 Mac 上最简单的方法是在终端中使用 {\ttfamily dd。首先，确定分配给} SD 卡的设备。为此，打开终端（位于应用程序 -\/$>$ 实用程序 -\/$>$ 终端），然后输入：

\begin{DoxyVerb}diskutil list
\end{DoxyVerb}


您应该会看到类似如下所示的内容，表明我们的 Micro\+SD 卡已分配给此特定 Mac 上的 {\ttfamily /dev/disk1：} 



请务必检查名称和大小，因为这是我们现在要擦除的设备。在终端中，输入：

\begin{DoxyVerb}diskutil unmountDisk /dev/diskX
cd Downloads
wget http://jevois.org/data/jevois-image-latest-8G.zip
unzip jevois-image-latest-8G.zip
sudo dd if=jevois-image-1.0-8G.img of=/dev/diskX bs=1M # exact .img file name may vary
sync
\end{DoxyVerb}


您应该将上面的 {\ttfamily diskX} 替换为您在上一步中记下的设备名称。请确保等到 {\ttfamily sync} 命令（刷新磁盘缓存）完成，否则可能尚未将所有磁盘映像数据提交到您的 Micro\+S\+D。您现在可以弹出 Micro\+SD 卡并将其插入 Je\+Vois 智能相机。

对于 {\ttfamily dd} 命令，{\ttfamily if} 指定源文件（或设备），{\ttfamily of} 指定目标文件（或设备），{\ttfamily bs} 是要使用的块大小。

\begin{DoxyWarning}{Warning}
请务必仔细检查您使用的设备名称。一个小小的拼写错误就可能毁掉您计算机硬盘上的内容。
\end{DoxyWarning}
在 Mac 上，您还可以尝试使用 \href{https://alltheware.wordpress.com/2012/12/11/easiest-way-sd-card-setup/}{\texttt{ R\+Pi SD 卡生成器}} 来刷新您的 SD 卡。\hypertarget{NewMicroSD_copymicrosd}{}\doxysubsubsection{将 Je\+Vois Micro\+S\+D 复制到另一个}\label{NewMicroSD_copymicrosd}
除了您可以看到的分区和文件之外，\+Je\+Vois Micro\+SD 卡还有两个额外的基本“文件”，它们直接存储在卡上的特定扇区（物理闪存盘位置）上。这两个是引导加载程序（系统启动）文件，是 Je\+Vois 嵌入式处理器启动时加载的前两个文件。由于处理器在早期启动阶段还不知道分区、文件系统等，因此它所知道的只是从 SD 卡读取原始扇区。您通常不需要修改这两个特殊文件。但请注意，如果您想将一张 Je\+Vois Micro\+SD 卡的内容复制到新卡上，则需要进行完整的物理逐扇区复制。

如果您定制了 Je\+Vois Micro\+SD 卡，例如在其上安装了许多机器视觉模块，并且想要将其复制到另一张新的 Micro\+SD 卡，请按以下步骤操作：

在 Linux 和 Mac 上，您可以再次使用 {\ttfamily dd，首先将现有的} Micro\+SD 转储到台式机或笔记本电脑上的文件中，然后我们将该文件写入新的 Micro\+SD 卡：


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{\# Insert source card:}}
\DoxyCodeLine{}
\DoxyCodeLine{sudo dd \textcolor{keywordflow}{if}=/dev/sdX of=mycard.img bs=1M}
\DoxyCodeLine{}
\DoxyCodeLine{sync}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# Properly eject source card.}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# Insert destination (blank) card:}}
\DoxyCodeLine{}
\DoxyCodeLine{sudo dd \textcolor{keywordflow}{if}=mycard.img of=/dev/sdX bs=1M}
\DoxyCodeLine{}
\DoxyCodeLine{sync}
\end{DoxyCode}


对于 {\ttfamily dd} 命令，{\ttfamily if} 指定源文件（或设备），{\ttfamily of} 指定目标文件（或设备），{\ttfamily bs} 是要使用的块大小。

在 Windows 上，再次使用 U\+S\+B\+Writer。\hypertarget{NewMicroSD_newmicrosd2}{}\doxysubsubsection{更复杂的方法：使用完整的 Je\+Vois 从源代码构建过程编写新的 Micro\+S\+D 卡}\label{NewMicroSD_newmicrosd2}
为 Je\+Vois 创建 Micro\+SD 卡的另一种方法是使用 Je\+Vois 开发环境提供的编译和安装脚本。

这允许您安装自定义内核、自定义硬件配置、自定义 Linux 安装（可能还有新的系统库和程序）等。

不建议新手使用，仅适用于 Linux。此过程在程序员手册中有详细说明。

有关更多信息，请参阅 \mbox{\hyperlink{Programmer}{程序员指南}} 以及特别是 Programmer\+S\+D\+K。 \hypertarget{UserSerial}{}\doxysubsection{串口使用指南}\label{UserSerial}
Je\+Vois 智能相机上的硬件串行端口（\+U\+A\+RT 端口）是 T\+TL 电平（不是 R\+S-\/232 电平），并且支持 3.\+3V 和 5V 逻辑。

使用的逻辑电压由连接的微控制器提供给智能相机（红线，\+I\+O\+R\+EF 电压）。此电压应由您的微控制器提供，并且应是 RX 和 TX 信号工作的电压）。\+Arduino 开发板为此目的提供了 I\+O\+R\+EF 引脚。\+I\+O\+R\+EF 是 Je\+Vois 的输入。因此，5V Arduino 将向 I\+O\+R\+EF 输出 5V，并将使用 5V 电平进行 RX 和 T\+X。相比之下，3.3V Arduino 将向 I\+O\+R\+EF 输出 3.\+3V，并将使用 3.\+3V 电平进行 RX 和 T\+X。

要连接到 Arduino 开发板，通常需要执行以下操作（显示，引脚排列与 相同）：

  

请注意连接器的方向和彩色电线的顺序，上面的 和下面的：

  

\begin{DoxyNote}{Note}
确保所有引脚上的电压不要超过 5.\+5V，否则可能会损坏 Je\+Vois 设备。

串行端口（所有引脚合计）的功耗小于 1m\+A。因此，直接将任何 Arduino 的 I\+O\+R\+EF 引脚（通常额定为 50mA 或更低）与 Je\+Vois 一起使用是合适的。

Je\+Vois 不通过 4 针串行连接器上的针脚供电。\+I\+O\+R\+EF 是 Je\+Vois 的输入，仅提供电压参考来确定 RX 和 TX 针脚上应使用哪些电压，但 I\+O\+R\+EF 不以任何方式连接到 Je\+Vois 的主电源。 仅通过 mini-\/\+U\+SB 连接器供电，而 仅通过其筒式插孔电源连接器供电。
\end{DoxyNote}
\hypertarget{UserSerial_autotoc_md144}{}\doxyparagraph{更改串行端口设置}\label{UserSerial_autotoc_md144}
您可以通过编辑 micro\+SD 卡上的文件 {\bfseries{J\+E\+V\+O\+IS\+:/config/params.cfg}}（来源为 {\bfseries{$\sim$/jevois/\+Config/params.cfg}}）自定义串行端口的设置以匹配微控制器可以支持的设置。支持以下选项（请参阅 \mbox{\hyperlink{JeVoisDaemon}{jevois-\/daemon 可执行文件}} 了解启动时支持的更多配置选项，并参阅 \mbox{\hyperlink{classjevois_1_1Serial}{jevois\+::\+Serial}} 了解串行接口的完整文档）：


\begin{DoxyItemize}
\item {\bfseries{serialdev}} -\/ 串行设备的名称。4 针连接器的硬件串行端口在 Je\+Vois 平台上始终为 {\bfseries{/dev/tty\+S0}}。
\item {\bfseries{serial\+:mode}} -\/ 输入的终端仿真模式，应为 {\bfseries{Plain}} 或 {\bfseries{V\+T100。默认为}} {\bfseries{Plain。}} 
\item {\bfseries{serial\+:baudrate}} -\/ 要使用的波特率。应为 110、300、600、1200、2400、4800、9600、14400、19200、38400、57600、115200、230400、380400、460800、921600、1000000、1152000、1500000、2000000、2500000、3000000、3500000、 4000000 之一。默认值为 {\bfseries{115200。请注意，此处列出的某些值理论上受硬件支持，但似乎不起作用。可能需要对}} Linux 内核中 Allwinner 芯片的串行驱动程序进行一些调整。已确认值 {\bfseries{9600、{\bfseries{115200}} 和}} {\bfseries{1500000（1}}.5 Mbps）可以正常工作。如果通过蓝牙 B\+LE 链路传输串行数据，则应使用 {\bfseries{9600。}} 
\item {\bfseries{serial\+:linestyle}} -\/ 行尾样式：应为
\item {\bfseries{LF}} 表示 0x0a \mbox{[}\textbackslash{}n\mbox{]};
\item {\bfseries{CR}} 表示 0x0d \mbox{[}\textbackslash{}r\mbox{]};
\item {\bfseries{C\+R\+LF}} 表示 0x0d 0x0a \mbox{[}\textbackslash{}r\textbackslash{}n\mbox{]};
\item {\bfseries{Zero}} 表示 0x00 \mbox{[}\textbackslash{}0\mbox{]};
\item {\bfseries{Sloppy}} 表示 C\+R、\+L\+F、\+C\+R\+L\+F、0xd0（由某些键盘发出，而不是 Return）中的任何一个，或 Zero 作为输入，\+C\+R\+LF 作为输出。{\bfseries{Sloppy}} 是默认值。
\item {\bfseries{serial\+:format}} -\/ 数据格式。应为包含 3 个字符的字符串：
\item 数据位数：{\bfseries{5}} 至 {\bfseries{8，默认为}} {\bfseries{8}} 
\item 奇偶校验：{\bfseries{N}} 表示无，{\bfseries{O}} 表示奇数，{\bfseries{E}} 表示偶数。默认为 {\bfseries{N}} 
\item 停止位：{\bfseries{1}} 或 {\bfseries{2。默认为}} {\bfseries{1}} 
\item 示例：{\bfseries{8N1（默认）}} 
\end{DoxyItemize}

例如，在将串行数据传输到蓝牙 B\+LE 发射器时，为了将串行速率降低到 9600 波特，{\bfseries{params.\+cfg}} 应包含：

\begin{DoxyVerb}serialdev=/dev/ttyS0 serial:baudrate=9600 serial:linestyle=LF \end{DoxyVerb}


\begin{DoxyNote}{Note}
第一行 (serialdev=/dev/tty\+S0) 是其他选项被接受所必需的。这是因为，否则，串行端口在解析 {\bfseries{params.\+cfg}} 之前将保持未定义状态（{\bfseries{serialdev}} 默认为空），并且稍后在 jevois-\/engine 启动其操作时将为其分配一个默认值 /dev/tty\+S0。
\end{DoxyNote}
\hypertarget{UserSerial_autotoc_md145}{}\doxyparagraph{使用低功耗蓝牙（\+B\+L\+E）的无线串行}\label{UserSerial_autotoc_md145}
我们已成功使用 Adafruit Feather 32u4 Bluefruit LE 通过蓝牙传输 Je\+Vois 串行数据。使用此功能，您可以通过运行蓝牙串行应用程序（例如 Blue\+Fruit 应用程序）的平板电脑控制 Je\+Vois。

我们将其串行引脚连接到 Je\+Vois 的串行端口，并编写了一段简单的代码，该代码只会在串行引脚和 Feather 的 B\+LE 模块之间转发串行数据。它在 9600 波特下工作良好，但在 115200 波特下会卡住。看起来 B\+LE 上的串行传输限制为 9600 波特。查看 {\bfseries{J\+E\+V\+O\+IS\+:/config/params.cfg}} 以了解我们在通过蓝牙传输串行数据时使用的配置选项。其他串行到 B\+LE 模块可用并且应该也可以正常工作，但我们尚未测试。\+Feather 32u4 Bluefruit LE 的主要缺点是它的价格（30 美元）。 \hypertarget{UserSerialStyle}{}\doxysubsection{标准化串行消息格式}\label{UserSerialStyle}


Je\+Vois 提供了一组标准化的串行输出消息，目的是协调多个机器视觉模块之间的串行消息，以便不同的视觉模块能够以相同的方式控制 Arduino 或类似的嵌入式控制器。然后，用户可以尝试使用不同的机器视觉模块，而无需重写和重新刷新他们的 Arduino 代码。例如，电动平移/倾斜云台可以直接由基于颜色的物体跟踪器、基于显着性的视觉注意模块、物体识别模块或 Ar\+Uco 虚拟现实标记检测模块控制，使用相同的 Arduino 代码接收来自 Je\+Vois 的控制消息并启动平移/倾斜电机。

标准化串行消息重点（至少目前）是发送 Je\+Vois 检测到的事物的位置和身份信息（1\+D、2D 或 3D）。

希望发送如下定义的标准化消息的模块应该从 \mbox{\hyperlink{classjevois_1_1StdModule}{jevois\+::\+Std\+Module}} 派生，而不是从 \mbox{\hyperlink{classjevois_1_1Module}{jevois\+::\+Module}} 派生。jevois\+::\+Std\+Module 类添加了允许最终用户控制串行消息格式的参数，以及帮助程序员发出标准化消息的附加成员函数。

\mbox{\hyperlink{classjevois_1_1StdModule}{jevois\+::\+Std\+Module}} 的参数 {\ttfamily serstyle} 和 {\ttfamily serprec} 定义以下标准化串行消息样式。参数 {\ttfamily serstamp} 允许使用帧编号、日期和/或时间对每条消息进行额外的标记。

\begin{DoxyNote}{Note}
请注意，每次加载视觉处理模块时，{\ttfamily serstyle} 和 {\ttfamily serprec} 都会重置为默认值。因此，您应该在加载模块后设置它们。参数 {\ttfamily sertamp} 不受模块更改的影响，因为它归 Je\+Vois 引擎所有。
\end{DoxyNote}
坐标约定和精度 ========================================

所有 1D 和 2D 坐标均使用 Je\+Vois 标准坐标（介于 -\/1000 和 1000 之间），如 \mbox{\hyperlink{group__coordhelpers}{用于将坐标从相机分辨率转换为标准坐标的辅助函数}} 中所定义。

所有 3D 坐标均假定来自经过校准的相机，并以真实世界空间的毫米为单位表示。

参数 {\ttfamily serprec} 定义这些坐标通过串行发送的精度，即小数点后的小数位数。例如：


\begin{DoxyItemize}
\item 当 {\ttfamily serprec} 为 0 时，坐标将以整数形式发送，例如 123（无尾随小数点）。
\item 当 {\ttfamily serprec} 为 1 时，坐标将以 1 位小数发送，例如 123.\+4
\item 当 {\ttfamily serprec} 为 2 时，坐标将以 2 位小数发送，例如 123.\+45
\item 依此类推。
\end{DoxyItemize}

鉴于 \mbox{\hyperlink{group__coordhelpers}{用于将坐标从相机分辨率转换为标准坐标的辅助函数}} 为 1D 和 2D 坐标提供的 -\/1000 到 1000 的范围已经很大，或者 3D 坐标的精度相当高（毫米），因此预期 {\ttfamily serprec} 仅在特殊情况下才为非零。大多数 Arduino 控制软件可以合理地预期仅支持 {\ttfamily serprec=0。} 

一维（1\+D）位置消息======================================

1D 位置消息用于传达某物在 1D 轴（通常是水平轴）上的位置。例如， 模块中消失点的 {\itshape x} 坐标。

来自机器视觉模块的输入：


\begin{DoxyItemize}
\item {\itshape x} 报告对象中心的标准化一维位置。
\item {\itshape id} 描述所报告对象是什么的文本字符串（例如，它具有哪个 Ar\+Uco 标记 I\+D）。为了便于接收 Arduino 解析，\+ID 中不应有空格。任何空格都将被下划线替换。
\item {\itshape size} 报告对象的标准化 1D 大小（因此，对象从 x-\/size/2 延伸到 x+size/2）。请注意，size 将以与坐标相同的精度输出。
\item {\itshape extra} 有关报告对象的任何附加文本字符串。
\item {\itshape xmin} 和 {\itshape xmax} 报告对象两个边缘的标准化 1D 位置。对于 1D 对象，指定 {\itshape xmin} 和 {\itshape xmax} 相当于指定 {\itshape x} 和 {\itshape size（但在} 2D、3D 等中并非总是如此）。
\end{DoxyItemize}

串行消息：

serstyle $\vert$ 消息 -\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- Terse $\vert$ {\ttfamily T1 x} Normal $\vert$ {\ttfamily N1 id x size} Detail $\vert$ {\ttfamily D1 id xmin xmax extra} Fine $\vert$ N/A -\/ 将改为发出 {\ttfamily D1D} 消息。

二维（2\+D）位置消息======================================

2D 位置消息用于传达 2D 空间中某物的位置（通常是相机图像的平面）。例如， 模块检测到的对象的 {\itshape x},y 标准化坐标。

来自机器视觉模块的输入：


\begin{DoxyItemize}
\item {\itshape x,y} 报告对象中心的标准化二维位置。
\item {\itshape id} 描述所报告对象是什么的文本字符串（例如，它具有哪个 Ar\+Uco 标记 I\+D）。为了便于接收 Arduino 解析，\+ID 中不应有空格。任何空格都将被下划线替换。
\item {\itshape w,h} 报告对象的标准化宽度和高度（因此，对象水平方向从 x-\/w/2 延伸到 x+w/2，垂直方向从 y-\/h/2 延伸到 y+h/2）。请注意，尺寸数据将以与坐标数据相同的精度输出。
\item {\itshape extra} 有关报告对象的任何附加文本字符串。
\item {\itshape x1,y1} ... {\itshape x4,y4} 报告对象周围边界矩形的 4 个角的标准化 x,y 坐标。
\item {\itshape x1,y1} ... {\itshape xn,yn} 报告对象周围边界多边形的 {\itshape n} 个顶点的标准化 x,y 坐标。请注意，n 可能因对象而异。
\end{DoxyItemize}

串行消息：

塞尔风格$\vert$留言-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- 简洁$\vert$ {\ttfamily T2 x y} 正常 $\vert$ {\ttfamily N2 id x y w h} 详细信息 $\vert$ {\ttfamily D2 id x1 y1 x2 y2 x3 y3 x4 y4 额外} {\ttfamily F2 id n x1 y1 ... xn yn 额外}

\begin{DoxyNote}{Note}
{\bfseries{Normal}} 和 {\bfseries{Detail}} 消息的边界框的紧密度取决于机器视觉模块生成的信息。通常，机器视觉模块将使用定义形状（多边形轮廓）的 2D 顶点列表调用 \mbox{\hyperlink{classjevois_1_1StdModule}{jevois\+::\+Std\+Module}} 的串行消息函数。在 {\bfseries{Normal}} 样式中，垂直边界矩形适合这些顶点以生成消息，旋转矩形适合顶点以生成 {\bfseries{Detail}} 消息。
\end{DoxyNote}
三维（3\+D）位置消息========================================

\begin{DoxyWarning}{Warning}
这尚未完全测试！
\end{DoxyWarning}
3D 位置消息用于传达现实世界 3D 空间中某物的位置，通常可从已校准相机且相机观察到已知现实世界大小的物体的模块获得。例如，\+Ar\+Uco 模块可以恢复已知现实世界大小的标记的完整 3D 位置和姿势。

我们使用 \href{https://en.wikipedia.org/wiki/Right-hand_rule}{\texttt{ 右手定则}} 来表示 3D 坐标，因为它是机器人学中的主导惯例。我们还遵循机器人操作系统 (R\+OS) 的 \href{http://www.ros.org/reps/rep-0103.html}{\texttt{ R\+E\+P-\/0103}} 中关于相机框架（称为{\itshape 后缀框架}）的惯例，以简化互操作性，但我们以毫米而不是米为单位报告距离：


\begin{DoxyItemize}
\item X 轴指向右
\item Y 轴指向下
\item Z 轴指向前
\end{DoxyItemize}

来自机器视觉模块的输入：


\begin{DoxyItemize}
\item {\itshape x,y,z} 报告物体中心的实际 3D 位置（以毫米为单位），距离相机的光学中心。
\item {\itshape id} 描述所报告对象是什么的文本字符串（例如，它具有哪个 Ar\+Uco 标记 I\+D）。为了便于接收 Arduino 解析，\+ID 中不应有空格。任何空格都将被下划线替换。
\item {\itshape w,h,d} 报告物体的宽度（X 轴）、高度（Y 轴）和深度（Z 轴），单位为毫米（因此，物体水平方向从 x-\/w/2 延伸到 x+w/2，垂直方向从 y-\/h/2 延伸到 y+h/2，沿相机光轴方向从 z-\/d/2 延伸到 z+d/2）。请注意，尺寸数据将以与坐标数据相同的精度输出。
\item {\itshape extra} 有关报告对象的任何附加文本字符串。
\item {\itshape q1,q2,q3,q4} 一个将物体的框架与相机的框架相关联的四元数（如果合适）。
\item {\itshape x1,y1,zn} ... {\itshape xn,yn,zn} 定义对象周围 3D 多面体的 {\itshape n} 个顶点的 3D 坐标。
\end{DoxyItemize}

串行消息：

塞尔风格$\vert$留言-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- 简洁$\vert$ {\ttfamily T3 x y z} 正常 $\vert$ {\ttfamily N3 id x y z w h d} 详细信息 $\vert$ {\ttfamily D3 id x y z w h d q1 q2 q3 q4 额外} {\ttfamily F3 id n x1 y1 z1 ... xn yn zn 额外}

新的机器视觉模块可以使用 \mbox{\hyperlink{classjevois_1_1StdModule}{jevois\+::\+Std\+Module}} 类中提供的便捷函数来发送标准化串行消息。

\begin{DoxyNote}{Note}
如果您将使用四元数数据（{\bfseries{详细消息样式），您可能应该将}} {\ttfamily serprec} 参数设置为非零值以获得四元数值的足够精度。
\end{DoxyNote}
物体识别消息 ==============================



、 等多个模块可识别可能属于给定类别集的对象。这些模块会为每个检测到的对象发送对象识别消息。

识别由多个类别：分数对组成，其中 {\itshape 类别是对象类别（对象类型）的名称，{\itshape 分数是此类别的识别分数，范围为} 0.\+0} ... 100.\+0

请注意，许多算法都会提供此类配对的列表作为其结果，以涵盖可能出现的模糊识别。例如，{\bfseries{cat\+:77.\+2 dog\+:27.\+3}} 表示算法非常确信它正在看一只猫，但是，如果置信度较低，它认为它也可能正在看一只狗。

serstyle $\vert$ 消息 -\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- 简洁 $\vert$ {\ttfamily TO topcateg} 正常 $\vert$ {\ttfamily NO topcateg\+:topscore} 详细信息 $\vert$ {\ttfamily DO topcateg\+:topscore categ2\+:score2 ... categN\+:scoreN} 精细 $\vert$ {\ttfamily FO topcateg\+:topscore categ2\+:score2 ... categN\+:scoreN}

其中 {\itshape topcateg} 是得分最高的类别的类别名称，{\itshape topscore} 是其得分，而 {\itshape categ2} 是得分第二高的类别，依此类推。2...N 次级识别的数量可能因消息而异，也可能为零，但 {\itshape topcateg} 和 {\itshape topscore} 始终保证存在（如果没有结果，则不会发送任何消息）。

请注意，某些对象类别名称可能包含空格，例如 {\bfseries{dining table}}；构造消息时，任何空格都会被下划线替换（例如 {\bfseries{dining\+\_\+table}}），以便 Arduino 和类似程序更容易解析消息。

物体检测 + 识别消息 ===========================================

一些模块，如、 和 首先检测可能包含对象的一个​​或多个边界框，然后识别每个框中可能存在哪个对象。

这些模块发送如上所述的二维（2\+D）位置消息（\+T2、\+N2、\+D2、\+F2 消息），并在 {\itshape id} 和 {\itshape extra} 字段中包含以下信息：

serstyle $\vert$ id $\vert$ extra -\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- 简洁 $\vert$ {\ttfamily topcateg} $\vert$ (无额外) 正常 $\vert$ {\ttfamily topcateg\+:topscore} $\vert$ (无额外) 详细信息 $\vert$ {\ttfamily topcateg\+:topscore} $\vert$ {\ttfamily categ2\+:score2 ... categN\+:scoreN} 精细 $\vert$ {\ttfamily topcateg\+:topscore} $\vert$ {\ttfamily categ2\+:score2 ... categN\+:scoreN}

其中 {\itshape topcateg} 是得分最高的类别的类别名称，{\itshape topscore} 是其得分，而 {\itshape categ2} 是得分第二高的类别，依此类推。与对象识别消息相同的注释也适用。

可选地在串行消息上标记帧号、日期和时间 ============================================================================



参数 {\ttfamily serstamp} 允许选择性地按日期、时间或帧号标记标准化串行消息。

请注意，\+Je\+Vois 没有电池，因此每次通电时，其内部时钟都会重置为 1970 年 1 月 1 日 U\+T\+C。但是，外部计算机可以使用 Je\+Vois {\ttfamily date} 命令设置日期。有关 {\ttfamily date 命令} 以及如何设置/检索 Je\+Vois 的日期和时间的更多信息，请参阅 User\+Cli。

标记被添加到标准化串行消息的前面，后面跟着一个空格。请注意，使用标记将在每个标准化串行消息的开头添加一个字段（用于标记）。如果 Arduino 被编程为响应 T2 消息，那么如果接收以日期或帧号开头的消息，它可能会感到困惑，因此 Arduino 代码应该进行相应调整。

冲压方式：

$\vert$serstamp $\vert$ 邮票格式 $\vert$ 帧 769 的示例，于 2017 年 12 月 24 日 15\+:52\+:42 $\vert$ $\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$ $\vert$无 $\vert$ 无邮票 $\vert$ $\vert$ $\vert$帧 $\vert$ F\+R\+A\+ME $\vert$ 769 $\vert$ $\vert$时间 $\vert$ hh\+:mm\+:ss $\vert$ 15\+:52\+:42 $\vert$ $\vert$\+Frame\+Time $\vert$ F\+R\+A\+M\+E/hh\+:mm\+:ss $\vert$ 769/15\+:52\+:42 $\vert$ $\vert$\+Frame\+Date\+Time $\vert$ F\+R\+A\+M\+E/\+Y\+Y\+Y\+Y-\/\+M\+M-\/\+D\+D/hh\+:mm\+:ss $\vert$ 769/2017-\/12-\/24/15\+:52\+:42 $\vert$

因此，如果 {\ttfamily serstyle} 为 {\bfseries{Terse，且检测到}} x=123、y=456 处的目标，则消息将从默认的 {\ttfamily serstamp} 变为 {\bfseries{None：}} 

\textbackslash{}逐字 T2 123 456 \textbackslash{}end逐字

到，使用 {\bfseries{Frame\+Date\+Time}} 的 {\ttfamily serstamp：} 

\textbackslash{}逐字 769/2017-\/12-\/24/15\+:52\+:42 T2 123 456 \textbackslash{}end逐字

可选框架标记 ========================



参数 {\ttfamily sermark} 允许发送以下消息，要么在处理来自摄像机传感器的视频帧之前（开始标记消息），要么在处理之后（停止标记消息），或者两者兼而有之：

$\vert$sermark $\vert$ 开始标记消息 $\vert$ 停止标记消息 $\vert$ $\vert$-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$ $\vert$无 $\vert$ (无消息) $\vert$ (无消息) $\vert$ $\vert$开始 $\vert$ 标记开始 $\vert$ (无消息) $\vert$ $\vert$停止 $\vert$ (无消息) $\vert$ 标记停止 $\vert$ $\vert$两者 $\vert$ 标记开始 $\vert$ 标记停止 $\vert$

请注意，可能会在标记之前发送一个戳记，具体取决于参数 {\ttfamily serstamp} 的值。

限制每个视频帧的串行消息数量 ===========================================================



Je\+Vois Engine 的参数 {\ttfamily serlimit} 可以设置为限制每个视频帧上发送的串行消息数量，以避免串行链路过载。例如，如果模块为每个检测到的项目发送一条消息，但存在许多项目，则可以使用 {\ttfamily serlimit} 来限制将通过串行端口报告的项目数量。

请注意，如果模块使用来自异步线程的 send\+Serial() 发送消息，则无法严格执行每帧的限制。 {\ttfamily serlimit} 的基本工作方式是，对于 send\+Serial() 或其派生函数（如 Send\+Serial\+Img2\+D() 等）发送的每条消息，都会增加一个（线程安全）计数器，并且每次调用模块的 process() 函数（无论是正常完成还是异常）完成后，计数器都会重置为零。

嵌入式控制器和机器人的建议 =======================================================


\begin{DoxyItemize}
\item 只能沿着一个轴朝向某物（例如，机器人汽车的转向）的机器人通常会期待 {\ttfamily T1} 消息。
\item 只能朝向 2D 图像平面中的某个物体（例如，电动平移/倾斜云台）的机器人通常会期待 {\ttfamily T2} 消息。
\item 可以将末端执行器移向 3D 空间中的物体的机器人（例如，没有夹持器的机械臂）通常会期待 {\ttfamily T3} 消息。
\item 机器人会根据物体采取不同的动作，通常会期望 {\ttfamily N1、{\ttfamily N2} 或} {\ttfamily N3} 消息，然后解码 {\itshape id} 字段来决定要做什么。
\item 机器人还需要在受控环境中了解物体的尺寸（例如，检查机器人可能会弹出传送带上的有缺陷的物品，摄像机放置在传送带上方固定距离处并向下观察它）通常会期望 {\ttfamily D1、{\ttfamily D2} 或} {\ttfamily D3} 消息，或者，如果形状很重要，则期望 {\ttfamily F2} 或 {\ttfamily F3} 消息。
\item 可以将末端执行器移向 3D 空间中的物体并抓住该物体的机器人（例如，带有夹持器的机械臂）通常会期望 {\ttfamily N3、{\ttfamily D3} 或} {\ttfamily F3} 消息。 
\end{DoxyItemize}\hypertarget{ProConnectors}{}\doxysubsection{Je\+Vois-\/\+Pro 辅助连接器}\label{ProConnectors}
6 针 A\+UX 电源连接器 ===========================

此连接器（位于相机顶部的两个 U\+SB 端口之间，请参阅 Pro\+Hardware）为您可能想要连接到 Je\+Vois-\/\+Pro 的辅助设备提供电源。此电源来自 Je\+Vois-\/\+Pro 的主 6-\/24V\+DC 筒形插孔输入。

  

注意连接器的方向和上面彩色电线的顺序。

引脚排列如下：

引脚 $\vert$ 电线颜色 $\vert$ 功能 -\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- 1 $\vert$ 黑色 $\vert$ G\+ND 2 $\vert$ 红色 $\vert$ 5V / 1A（与 U\+SB 主机 1 共享，从 Je\+Vois-\/\+Pro 后面看时连接器位于左侧） 3 $\vert$ 橙色 $\vert$ 5V / 1A（与 U\+SB 主机 2 共享，从 Je\+Vois-\/\+Pro 后面看时连接器位于右侧） 4 $\vert$ 黄色 $\vert$ 3.\+3V / 750mA 5 $\vert$ 蓝色 $\vert$ 1.\+8V / 500mA 6 $\vert$ 黑色 $\vert$ G\+ND

配对连接器零件编号：\+J\+ST S\+H\+R-\/06\+V-\/\+S-\/\+B，间距 1.\+0mm，6 针 J\+S\+T-\/\+SH 系列。

这些连接器的针脚几乎不可能用手压接，除非您有 J\+ST 出售的 1000 美元以上的特殊工具。因此，请妥善保管 Je\+Vois-\/\+Pro 相机附带的电缆。延长电线，而不是将它们剪得很短……

请注意，此连接器每个引脚的额定电流为 1A。由于只有两个 G\+ND 引脚，因此请尽量不要在其他 4 个引脚上消耗超过 2A 的电流。

8 针 G\+P\+IO 连接器 =====================

此连接器（位于微型 H\+D\+MI 连接器旁边，请参阅 Pro\+Hardware）提供 6 个通用输入/输出引脚 (G\+P\+IO)。这些引脚可以以多种方式配置，如下所述。

与 4 针串行端口一样，此端口需要在第 6 针（\+I\+O\+R\+E\+F）上提供输入电压。这是 Je\+Vois-\/\+Pro 的输入，您必须提供该输入以告诉 Je\+Vois-\/\+Pro 您希望 G\+P\+IO 针以哪个电压水平运行：3.3V 或 5V。有关更多信息，请参阅 User\+Serial。

  

注意连接器的方向和上面彩色电线的顺序。

引脚排列如下：

引脚 $\vert$ 电线颜色 $\vert$ 功能 $\vert$ A311D SoC $\vert$ 内核 G\+P\+IO -\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- 1 $\vert$ 紫色 $\vert$ J\+V\+G\+P\+I\+O0 / S\+PI M\+O\+SI / S\+P\+D\+I\+F\+\_\+\+O\+UT / U\+A\+R\+T\+\_\+\+R\+TS $\vert$ G\+P\+I\+O\+H\+\_\+4 $\vert$ 431 2 $\vert$ 橙色 $\vert$ J\+V\+G\+P\+I\+O1 / S\+PI M\+I\+SO / S\+P\+D\+I\+F\+\_\+\+IN / U\+A\+R\+T\+\_\+\+C\+TS / P\+W\+M\+\_\+F $\vert$ G\+P\+I\+O\+H\+\_\+5 $\vert$ 432 3 $\vert$ 白色 $\vert$ J\+V\+G\+P\+I\+O2 / S\+PI SS / U\+A\+R\+T\+\_\+\+RX / I\+R\+\_\+\+O\+UT / O\+N\+E\+W\+I\+RE / I\+S\+O7816\+\_\+\+C\+LK $\vert$ G\+P\+I\+O\+H\+\_\+6 $\vert$ 433 4 $\vert$ 蓝色 $\vert$ J\+V\+G\+P\+I\+O3 / S\+PI S\+C\+LK / U\+A\+R\+T\+\_\+\+TX / I\+S\+O7816\+\_\+\+D\+A\+TA $\vert$ G\+P\+I\+O\+H\+\_\+7 $\vert$ 434 5 $\vert$ 绿色 $\vert$ J\+V\+G\+P\+I\+O4 / I2C S\+DA $\vert$ G\+P\+I\+O\+Z\+\_\+14 $\vert$ 425 6 $\vert$黄色 $\vert$ J\+V\+G\+P\+I\+O5 / I2C S\+CL $\vert$ G\+P\+I\+O\+Z\+\_\+15 $\vert$ 426 7 $\vert$ 红色 $\vert$ I\+O\+R\+E\+F（您提供 G\+P\+IO 工作的电压：3.3V 或 5V）$\vert$ -\/ $\vert$ -\/ 8 $\vert$ 黑色 $\vert$ G\+ND $\vert$ -\/ $\vert$ -\/

配对连接器零件编号：\+J\+ST S\+H\+R-\/08\+V-\/\+S-\/\+B，间距 1.\+0mm，8 针 J\+S\+T-\/\+SH 系列。

这些连接器的针脚几乎不可能用手压接，除非您有 J\+ST 出售的 1000 美元以上的特殊工具。因此，请妥善保管 Je\+Vois-\/\+Pro 相机附带的电缆。延长电线，而不是将它们剪得很短……

\begin{DoxyWarning}{Warning}
应始终提供 I\+O\+R\+E\+F，并且与 G\+P\+IO 的工作电压相匹配。如果您要使用 6 针 A\+UX 电源连接器为小工具供电，您可以方便地从该连接器获取它。因此，例如，如果您使用 6 针 A\+UX 电源连接器的黄色线为 3.\+3V 小工具供电，则还可以将相同的 3.\+3V 电压馈送到 8 针 G\+P\+IO 连接器的 I\+O\+R\+E\+F（红色）线。
\end{DoxyWarning}
\textbackslash{}警告 I\+O\+R\+EF 和所有 G\+P\+IO 应在 3.\+3V 至 5V 之间的电压下工作。如果超过 5.\+5V，可能会损坏 Je\+Vois-\/\+Pro 上的 G\+P\+IO 缓冲芯片。

\begin{DoxyNote}{Note}
我们最初认为我们可以在此连接器上支持 1.\+8V -\/ 5V。然而，最近我们在用于此连接器电压转换的 N\+XP N\+T\+B0104\+GU,115 数据表中看到了一个脚注，其中说连接器上的电压不应低于 C\+PU 芯片上的电压（在我们的设计中为 3.\+3V）。因此，请考虑 1.\+8V 不受官方支持，尽管在我们执行的基本测试中它似乎运行良好。从长远来看，它可能会损坏 N\+B\+T0104 芯片。
\end{DoxyNote}
具有自动方向感应的电压转换 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

J\+V\+G\+P\+I\+O0 到 J\+V\+G\+P\+I\+O3 通过电压电平转换器（\+N\+XP N\+T\+B0104\+GU,115 芯片）连接。该芯片会自动检测输入或输出方向。这是一个很棒的功能，因为我们不需要为每个 G\+P\+IO 增加一个额外的引脚来指示它当前是用作输入还是输出，并相应地设置转换器的方向。但它也有一些注意事项：如果您使用引脚作为输出，但将其连接到可以提供电流的设备，例如因为设备的输入端有一个上拉电阻，\+N\+T\+B0104 芯片可能会反转其方向。通常这不会损坏您的硬件，但可能会导致意外结果。

例如，我们尝试使用 S\+PI 总线将 Sparkfun I\+C\+M20948 外部 I\+MU 连接到 Je\+Vois-\/\+Pro 的 G\+P\+IO 连接器。我们无法让它工作，并且总是从设备读取垃圾，并且无法使用示波器看到 Sparkfun 板引脚上的 S\+PI 传输。事实证明，\+Sparkfun 板有自己的一组电压转换器，所有引脚上都有大约 2.\+2k 上拉电阻。这可能足以让我们的 N\+T\+B0104 认为 Sparkfun 板的所有引脚都是输出，因此它将自身配置为通过所有 4 个 S\+PI 引脚将数据从 Sparkfun 板发送到 Je\+Vois-\/\+Pro 的 A311\+D。这是一个问题，因为 M\+O\+S\+I、\+SS 和 S\+C\+LK 实际上应该将数据从 A311D 发送到 Sparkfun 板。为了解决这个问题，您可能需要在 Sparkfun I\+MU 前面插入一些单向缓冲区（例如，74\+H\+C125 或类似产品，其中 3 个缓冲区连接 A311\+D-\/$>$Sparkfun（\+M\+O\+S\+I、\+S\+S、\+S\+C\+L\+K）和一个连接 Sparkfun-\/$>$A311\+D（\+M\+I\+S\+O）；请注意，我们还没有尝试过这个，但我们很快就会尝试）。

\begin{DoxyNote}{Note}
根据 N\+T\+B0104 数据表，如果您确实需要在某些输入上使用上拉电阻，请确保其值为 50k 欧姆或更大，以避免方向反转。
\end{DoxyNote}
由于 N\+B\+T0104，当用作输入时，\+J\+V\+G\+P\+I\+O0 至 J\+V\+G\+P\+I\+O3 也具有“粘性”，因为 N\+T\+B0104 将保持当前驱动状态，直到主动更改为止。例如：


\begin{DoxyItemize}
\item 将 J\+V\+G\+P\+I\+O0（紫色线）配置为输入（见下文）
\item 将 I\+O\+R\+EF 设置为 5V 并保持
\item 将 5V 施加到紫色线，\+J\+V\+G\+P\+I\+O0 将读为“1”
\item 将紫色线与 5V 断开，仍将读为“1”
\item 将 0V（\+G\+N\+D）施加到紫色线，现在 J\+V\+G\+P\+I\+O0 将读为“0”
\item 将紫色线与 G\+ND 断开，仍将读为“0”
\end{DoxyItemize}

J\+V\+G\+P\+I\+O4 和 J\+V\+G\+P\+I\+O5 使用简单的 M\+O\+S\+F\+ET 进行电压转换，并使用 2k 上拉电阻连接到 I\+O\+R\+E\+F。配置为输入时（见下文），这些引脚会因为上拉电阻而默认读取“1”，除非您主动将它们驱动至 0V（\+G\+N\+D），在这种情况下它们将读取“0”。

欲了解更多信息，请查看以下原理图：\mbox{\hyperlink{HardwareFiles}{硬件：原理图、机壳 S\+TL 文件等 \textbackslash{}tableofcontents}}

基本 G\+P\+IO 使用 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

要激活给定的 G\+P\+I\+O，请从上表的最后一列查找其内核 G\+P\+IO 编号，然后在 Linux shell 中以 root 身份发出这些命令（或在 Je\+Vois 控制台中，使用 {\ttfamily shell} 作为前缀），将下面的 {\itshape 431} 替换为您要使用的内核 G\+P\+IO 编号：


\begin{DoxyCode}{0}
\DoxyCodeLine{echo 431 > /sys/class/gpio/export \# 声明 GPIO 编号 431 = GPIOH\_4 / JVGPIO0 / 紫线 echo out > /sys/class/gpio/gpio431/direction \# 用作输出，或 'in' 用作输入 echo 1 > /sys/class/gpio/gpio431/value \# 开启，或 '0' 禁用 cat /sys/class/gpio/gpio431/value \# 查看当前值 }
\end{DoxyCode}


对于方向，您还可以使用 {\itshape low} 设置为输出并立即以无故障的方式将输出级别设置为低，或者使用 {\itshape high} 设置为输出并立即将输出级别设置为无故障的高。

如果您想在声明该 G\+P\+IO 后释放它：


\begin{DoxyCode}{0}
\DoxyCodeLine{echo 431 > /sys/class/gpio/unexport }
\end{DoxyCode}


使用 J\+V\+G\+P\+I\+O0 -\/ J\+V\+G\+P\+I\+O5 作为输入 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

J\+V\+G\+P\+I\+O0 的示例：


\begin{DoxyCode}{0}
\DoxyCodeLine{ echo 431 > /sys/class/gpio/export \# 声明 GPIO 编号 431 = GPIOH\_4 / JVGPIO0 / 紫线 echo in > /sys/class/gpio/gpio431/direction}
\DoxyCodeLine{}
\DoxyCodeLine{\# 对紫色线施加与 IOREF 相同的电压}
\DoxyCodeLine{}
\DoxyCodeLine{cat /sys/class/gpio/gpio431/value \#查看当前值，应该显示“1”}
\DoxyCodeLine{}
\DoxyCodeLine{\# 将紫色线连接到GND}
\DoxyCodeLine{}
\DoxyCodeLine{cat /sys/class/gpio/gpio431/value \# 查看当前值，现在应该显示“0” }
\end{DoxyCode}


使用 J\+V\+G\+P\+I\+O0 -\/ J\+V\+G\+P\+I\+O3 作为输出 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

J\+V\+G\+P\+I\+O0 的示例：


\begin{DoxyCode}{0}
\DoxyCodeLine{ echo 431 > /sys/class/gpio/export \# 声明 GPIO 编号 431 = GPIOH\_4 / JVGPIO0 / 紫色线 echo out > /sys/class/gpio/gpio431/direction}
\DoxyCodeLine{\# 确保紫色线上没有上拉、下拉等，请参阅上面的注释。}
\DoxyCodeLine{\# 将 IOREF 连接到 3.3V 或 5V。将电压表连接到紫色线 echo 1 > /sys/class/gpio/gpio431/value \# 电压表应读取与您提供给 IOREF 的电压相同的电压 echo 0 > /sys/class/gpio/gpio431/value \# 电压表应读取 0V }
\end{DoxyCode}


使用 J\+V\+G\+P\+I\+O4 -\/ J\+V\+G\+P\+I\+O5 作为输出 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

我们可能犯了一个错误，使用了 A311D 无法克服的过强上拉电阻。或者可能存在特定问题，因为这些引脚在 A311D 上有特殊的 O\+D（开漏）驱动器，但我们在 A311D 数据表中找不到太多相关信息。在我们尝试解决这个问题时，请使用此技巧：

J\+V\+G\+P\+I\+O4 示例：


\begin{DoxyCode}{0}
\DoxyCodeLine{ echo 425 > /sys/class/gpio/export \# 声明 GPIO 编号 425 = GPIOZ\_14 / JVGPIO4 / 绿线}
\DoxyCodeLine{\# 将 IOREF 连接到 3.3V 或 5V。将电压表连接到绿线 echo low > /sys/class/gpio/gpio431/direction \# 电压表应读取 0V echo in > /sys/class/gpio/gpio431/direction \# 电压表应读取与您提供给 IOREF 的电压相同的电压 }
\end{DoxyCode}


事实上，将 1 写入 {\itshape 值似乎没有任何效果，输出始终为低。通过将引脚的方向切换为} {\itshape } ，我们基本上将其断开，并让我们的上拉电阻将其驱动为高电平。

使用 Je\+Vois-\/\+Pro G\+P\+IO 作为 S\+P\+I、\+U\+A\+R\+T、\+I2C 等 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

\begin{DoxyNote}{Note}
请耐心等待，因为这项工作仍在进行中。我们将在测试特定外围设备时很快发布更详细的教程。我们列表中的第一个是 S\+PI 和 I2C O\+L\+ED 显示器。
\end{DoxyNote}
编辑 micro\+SD 的 B\+O\+OT 分区上的文件 {\bfseries{env.\+txt（当}} Je\+Vois-\/\+Pro 在控制台模式下运行时，文件位于 {\bfseries{/boot/env.txt}}）。最后，找到内核覆盖列表并附加所需的内核覆盖（将其添加到 {\itshape 覆盖中，用空格分隔）。这样做将在启动时声明特定功能的引脚，并在这些引脚上加载和启动该功能的相应内核驱动程序：} 


\begin{DoxyCode}{0}
\DoxyCodeLine{\# 设备树覆盖 \#}
\DoxyCodeLine{\# aux-\/i2c -\/-\/ 在 AUX 引脚 5 (SDA) 和 6 (SCL) 上启用 I2C 驱动程序。}
\DoxyCodeLine{\# aux-\/onewire -\/-\/ 在 AUX 引脚 3 上启用 OneWire 驱动程序。}
\DoxyCodeLine{\# aux-\/spi -\/-\/ 在 AUX 引脚 1 (MOSI)、2 (MISO)、3 (SS)、4 (SCLK) 上启用 SPI 驱动程序。}
\DoxyCodeLine{\# aux-\/uart -\/-\/ 在 AUX 引脚 1 (RTS)、2 (CTS)、3 (RX)、4 (TX) 上启用 UART 驱动程序。}
\DoxyCodeLine{\# icm20948 -\/-\/ 在 JeVois M.2 传感器连接器上启用 ICM-\/20948 IMU（位于 IMX290 摄像头板上）。}
\DoxyCodeLine{\# imx290 -\/-\/ 在 JeVois M.2 传感器连接器上启用 Sony IMX290 摄像头传感器。}
\DoxyCodeLine{\# wifi-\/bt -\/-\/ 启用 WIFI/BT M.2 PCIe 卡，而不是默认的 Myriad-\/X 或 Coral-\/TPU M.2 PCIe 卡。}
\DoxyCodeLine{\# emmc -\/-\/ 启用自定义 eMMC，仅适用于 JeVois 双 TPU + eMMC 板。}
\DoxyCodeLine{\# sdio -\/-\/ 在 M.2 PCIe 端口上启用 SDIO 功能，与 SDIO wifi 卡和其他卡一起使用。}
\DoxyCodeLine{\# wdt -\/-\/ 启用看门狗定时器。}
\DoxyCodeLine{\# remote -\/-\/ 启用红外遥控输入（可在 JeVois-\/Pro 主板上的测试板上使用）。}
\DoxyCodeLine{}
\DoxyCodeLine{覆盖=icm20948 imx290 }
\end{DoxyCode}


然后重新启动，新的内核设备就会出现。例如，当您激活 {\itshape aux-\/spi} 覆盖时，您应该会得到一个新设备 {\bfseries{/dev/spidev1.0}}（除了 Je\+Vois-\/\+Pro 板载 I\+MU 内部使用的 /dev/spidev32766.0）。

请注意上面解释的自动感应电压转换注意事项。

有关 G\+P\+IO 的更多信息 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

在 Je\+Vois-\/\+Pro 使用的 Amlogic A311D 芯片上，\+G\+P\+IO 被组织成两个 {\itshape 组，每个组由不同的控制器处理。第一个组是} A\+O（始终开启）组，由 C\+PU 无法关闭的电源供电。此组通常用于内部 G\+P\+I\+O，例如为 C\+PU 核心组启用电源、调试 U\+A\+RT 等。第二个组用于在正常运行中使用的更通用的 G\+P\+I\+O，例如 I2C 和 S\+PI 外设等。

负责各个bank的\+Linux内核设备如下：

内核设备 $\vert$ 银行 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/--- pinctrl@ff800014 $\vert$ AO (始终开启) pinctrl@ff634480 $\vert$ 标准

每个银行都由多个 {\itshape 引脚组成。您可以在此处获取引脚列表：} 


\begin{DoxyCode}{0}
\DoxyCodeLine{cat /sys/kernel/debug/pinctrl/pinctrl@ff800014/pins \# 列出 AO 库中的引脚 cat /sys/kernel/debug/pinctrl/pinctrl@ff634480/pins \# 列出标准库中的引脚 }
\end{DoxyCode}


就内核驱动程序而言，这些列表建立了银行引脚号（例如，引脚 15）与 A311D 芯片上相应的物理引脚（例如，标准银行中的引脚 15 是芯片上的物理引脚 G\+P\+I\+O\+Z\+\_\+14）之间的映射。

通过为每个库添加偏移量到该库中的给定引脚，两个库的引脚进一步组合并重新映射到单个 G\+P\+IO {\itshape 范围。您可以在此处获取偏移量：} 


\begin{DoxyCode}{0}
\DoxyCodeLine{cat /sys/kernel/debug/pinctrl/pinctrl@ff800014/gpio-\/ranges \# AO 库 cat /sys/kernel/debug/pinctrl/pinctrl@ff634480/gpio-\/ranges \# 标准库 }
\end{DoxyCode}


因此事情安排如下：

银行 $\vert$ 银行偏移 $\vert$ 引脚数 $\vert$ G\+P\+IO 范围 -\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---$\vert$-\/-\/-\/-\/-\/-\/-\/-\/-\/--- AO $\vert$ 496 $\vert$ 16 $\vert$ 496 -\/ 511 标准 $\vert$ 410 $\vert$ 86 $\vert$ 410 -\/ 495

这就是我们在本节开头的表格中得出内核 G\+P\+IO列的方法：例如，紫色线是芯片上的 G\+P\+I\+O\+H\+\_\+4，它是标准控制器的引脚 21，其基数为 410。因此，410 + 21 = 431 是 G\+P\+I\+O\+H\+\_\+4 的最终 G\+P\+IO 编号。

欲了解更多信息，请查看以下原理图：\mbox{\hyperlink{HardwareFiles}{硬件：原理图、机壳 S\+TL 文件等 \textbackslash{}tableofcontents}} \hypertarget{UserProFan}{}\doxysubsection{Je\+Vois-\/\+Pro 调整风扇速度}\label{UserProFan}
 上的风扇采用具有两种状态和滞后的简单算法进行控制：


\begin{DoxyItemize}
\item 只要温度低于 {\itshape temp\+\_\+max，风扇速度就会降低} 
\item 当温度超过 {\itshape temp\+\_\+max} 时，风扇速度会切换至高速
\item 风扇速度将保持高速，直到温度降至 {\itshape temp\+\_\+min} 以下，此时风扇速度会切换回低速。
\end{DoxyItemize}

在我们的测试中，这远没有斜坡调制那么烦人，斜坡调制会随着温度的升高而增加风扇速度，从而让人分心。

调整风扇参数=============================

 上的风扇由一个小程序控制，该程序可控制 C\+P\+U、\+Coral T\+P\+U（如果已安装）和 Hailo-\/8 S\+P\+U（如果已安装）的温度，并使用上述算法调整风扇速度。要更改设置，请转到 G\+UI 中的“配置”选项卡，然后在文件列表底部选择“浏览/创建文件...”

  

导航到并打开：{\bfseries{/lib/systemd/system/jevoispro-\/fan.service}}

然后，您可以按照顶部注释块中所述将选项添加到 {\ttfamily Exec\+Start} 行。

  

例如：

Exec\+Start=/sbin/jevoispro-\/fan -\/d 4.\+8 

当相机的 C\+PU 负载不高时，可以使风扇更安静，从而使 C\+PU 温度较低。如果为 {\ttfamily -\/d} 选择的值太低，风扇可能根本不会旋转，这是不推荐的。

编辑文件后，保存它，然后在 G\+UI 的控制台选项卡中输入：

\begin{DoxyVerb}!systemctl restart jevoispro-fan \end{DoxyVerb}


（或重新启动相机）。启动时风扇全速运转几秒钟，然后算法接管。 \hypertarget{UserProUSBserial}{}\doxysubsection{Je\+Vois-\/\+Pro 串行 U\+SB 通信}\label{UserProUSBserial}
从 开始，您可以启用将日志和模块输出消息发送到 的 mini-\/\+U\+SB 端口的功能。只需在 G\+UI 的“系统”选项卡中选中该选项即可，如下所示：

  

并重新启动相机。

然后使用常规 U\+SB 转 mini-\/\+U\+SB 电缆将 Je\+Vois Pro 的 mini-\/\+U\+SB 端口连接到主机上的标准 U\+SB 端口。当 启动时，您的主机将检测到 U\+SB 串行设备。然后您可以连接到它以与 通信。例如，在 Linux 主机上，当 连接时，主机上会出现一个新设备 {\bfseries{/dev/tty\+A\+C\+M0。然后您可以使用}} {\ttfamily screen} 程序进行连接：

\begin{DoxyVerb}sudo screen /dev/ttyACM0 115200 \end{DoxyVerb}


然后按照 \mbox{\hyperlink{UserCli}{命令行界面用户指南}} 中所述向 发出命令

 增强了 Je\+Vois 软件中的串行驱动程序，使其能够应对电缆断开/重新连接。但是，仍然存在一些注意事项，因为似乎没有正确的方法可以从 Linux 用户空间真正知道电缆是否已连接。但是，如果 正在发送消息并且电缆未连接，则与串行端口关联的小缓冲区最终会溢出。在这种情况下， 将关闭串行设备并尝试重新打开它。这通常会在电缆重新连接后成功。请注意，如果您的模块没有写入大量消息，您将不会在相机上知道电缆已断开连接，直到您尝试输出足够的消息以导致该缓冲区溢出。 \hypertarget{UserCli}{}\doxysubsection{命令行界面用户指南}\label{UserCli}
\doxysubparagraph*{}\hypertarget{UserCli_cmdline}{}\doxysubsubsection{命令行界面概述}\label{UserCli_cmdline}
除了通过视频捕捉软件与 Je\+Vois 相机交互之外，您还可以使用两个可用串行端口中的任意一个：


\begin{DoxyItemize}
\item 通过智能相机上的 4 针连接器的硬件串行端口（见上文）。
\item 当摄像机出现在串行总线上时，\+U\+SB 串行端口也会同时出现在主机上。
\item 在 上，图形用户界面的控制台。
\end{DoxyItemize}

您或其他机器（例如 Arduino）可以连接到 Je\+Vois 并向智能相机发出简单命令。这些命令允许调整相机参数、视觉处理参数以及 Je\+Vois 智能相机的一般操作。

您可以使用 Je\+Vois 命令行界面执行的操作包括：
\begin{DoxyItemize}
\item 调整相机传感器的对比度、曝光度、增益、白平衡等。
\item 显示有关 Je\+Vois 的基本信息，例如可用 R\+AM 内存、\+C\+PU 频率、\+C\+PU 温度。
\item 根据当前加载和运行的视觉模块调整机器视觉参数。许多机器视觉模块会公开阈值、操作模式等参数，您可以使用 Je\+Vois 命令行界面进行调整。
\item 运行包含任意数量有效命令的脚本。
\item 决定将输出和日志串行消息发送到何处（发送到硬件串行端口、发送到 serial-\/ver-\/\+U\+S\+B、发送到两者或不发送到任何位置）。
\item 检查可用的视频模式和机器视觉算法，然后选择特定的一种。
\item 可能执行特定机器视觉模块可能提供的自定义命令。
\end{DoxyItemize}

\begin{DoxyNote}{Note}
请注意，默认情况下，命令回显处于关闭状态，这意味着，当您通过串行链路连接到 Je\+Vois 时，您将看不到您输入的内容。这是为了避免将所有可能要发送到 Je\+Vois 相机的命令发回 Arduino。大多数串行通信软件都有一个 \char`\"{}turn on local echo\char`\"{} 选项，这将允许您查看您输入的内容，但将由您的串行终端程序处理，而不是让 Je\+Vois 发回您输入的所有字符。

由于命令行界面主要用于机器对机器通信，因此目前不提供编辑功能。这意味着如果您输入了错误的字符并尝试删除它，则错误字符和删除字符都将发送到 Je\+Vois，您的命令将失败。如果您在输入时容易出现许多拼写错误，只需在您选择的任何编辑器中输入命令，然后将其复制并粘贴到 Je\+Vois 命令行界面中即可。
\end{DoxyNote}
按照以下说明使用串行 U\+SB 连接到 Je\+Vois：


\begin{DoxyItemize}
\item \mbox{\hyperlink{USBserialLinux}{使用串行 U\+SB 连接到 Je\+Vois：\+Linux 主机}}
\item \mbox{\hyperlink{USBserialWindows}{使用 U\+SB 串行连接到 Je\+Vois：\+Windows 主机}}
\item \mbox{\hyperlink{USBserialMac}{使用 U\+SB 串行连接到 Je\+Vois：\+Mac 主机}}
\item \mbox{\hyperlink{UserProUSBserial}{Je\+Vois-\/\+Pro 串行 U\+SB 通信}}
\end{DoxyItemize}

\begin{DoxyNote}{Note}
在 {\bfseries{host}} 模式下运行 Je\+Vois 软件时，您只需在启动 jevois-\/daemon 的终端窗口中直接输入命令即可与 Je\+Vois 进行交互。有关更多详细信息，请参阅 \mbox{\hyperlink{JeVoisDaemon}{jevois-\/daemon 可执行文件}} 。
\end{DoxyNote}
\doxysubparagraph*{}\hypertarget{UserCli_cmdlinestart}{}\doxysubsubsection{命令行界面入门}\label{UserCli_cmdlinestart}
连接后，您可以使用命令行界面。支持的命令、常规操作参数和相机传感器控制如下（以下部分将进一步详细说明）：

\begin{DoxyVerb}help - print help message
info - show system information including CPU speed, load and temperature
setpar <name> <value> - set a parameter value
getpar <name> - get a parameter value(s)
runscript <filename> - run script commands in specified file
setcam <ctrl> <val> - set camera control <ctrl> to value <val>
getcam <ctrl> - get value of camera control <ctrl>
listmappings - list all available video mappings
setmapping <num> - select video mapping <num>, only possible while not streaming
setmapping2 <CAMmode> <CAMwidth> <CAMheight> <CAMfps> <Vendor> <Module> - set no-USB-out video mapping defined on the fly, while not streaming
ping - returns 'ALIVE'
serlog <string> - forward string to the serial port(s) specified by the serlog parameter
serout <string> - forward string to the serial port(s) specified by the serout parameter
usbsd - export the JEVOIS partition of the microSD card as a virtual USB drive
sync - commit any pending data write to microSD
restart - restart the JeVois smart camera

常规选项：
  --tracelevel (无符号整数) 默认值为 [0] 
    设置要显示的最低跟踪级别 
       导出者：引擎

--nickname (string) 默认=[jevois] 
  与此相机关联的昵称，当多个 JeVois 相机连接到同一个 USB 总线时很有用 
     导出者：engine

--help (bool) default=[false] 
  打印此帮助消息 
     导出者：引擎值=[true]

--loglevel (jevois::manager::LogLevel) default=[info] List:[fatal|error|info] 
  设置要显示的最低日志级别 
     导出者：engine


Engine Options: 
  --videoerrors (bool) 默认=[true] 
    显示视频流中的任何机器视觉模块错误（异常）。仅在将视频流式传输到 USB 时生效。
       导出者：引擎

--cpumode (jevois::engine::CPUmode) default=[Performance] List:[PowerSave|Conservative|OnDemand|Interactive|Performance] 
  CPU 频率调节模式 
     由 engine 导出

--videomapping (int) default=[-1] 
  要使用的视频映射索引，或 -1 使用默认映射 
     导出者：engine

--cpumax (无符号整数) 默认值 = [1344] 列表：[120|240|312|408|480|504|600|648|720|816|912|1008|1044|1056|1080|1104|1116|1152|1200|1224|1248|1296|1344] 
  CPU 最大频率（MHz） 
     导出者：engine

--serialdev (字符串) 默认值 = [stdio] 
  硬件（4 针连接器）串行设备名称，或 'stdio' 以使用控制台，或为空以表示没有硬件串行端口 
     导出者：引擎

--serlog (jevois::engine::SerPort) default=[None] List:[None|All|Hard|USB] 
  显示选定串行端口上的日志和调试消息 
     导出者：engine

--serout (jevois::engine::SerPort) default=[None] List:[None|All|Hard|USB] 将模块串行消息发送到选定的串行端口 导出者：engine

--camturbo (bool) default=[false] 通过放宽对 DMA 相干视频缓冲内存的需求来启用相机 turbo 模式。这可以将对捕获的图像数据的访问速度提高几倍，但也可能会在某些模块（如 PassThrough）中产生条纹​​伪影。条纹是缓存中的不正确数据。您应该尝试每个特定模块。不建议将 Turbo 模式用于任何生产级应用程序。导出者：引擎值=[true]

--usbserialdev (字符串) 默认值=[] USB 串行设备名称，或为空 导出者：引擎

--camreg (bool) default=[false] 通过 setcamreg 和 getcamreg 启用对相机寄存器的原始访问 导出者：engine

--python (bool) 默认值为 [true] 为 true 时，启用对用 Python 编写的模块的支持。否则，尝试加载 Python 模块将引发异常。禁用 Python 可节省大量内存，在使用运行大型深度神经网络的 C++ 模块时可能很有用。导出者：引擎

--cameradev (字符串) 默认=[/dev/video0] 相机设备名称（如果以 /dev/v... 开头），或电影文件名（例如 movie.mpg）或图像序列（例如 im%02d.jpg，用于读取帧 im00.jpg、im01.jpg 等）。导出者：引擎

--cameranbuf (无符号整数) 默认值=[0] 视频输入（摄像头）缓冲区的数量，或 0 表示自动。导出者：引擎

--gadgetdev (字符串) 默认=[] 小工具设备名称。这仅在平台硬件上使用。在主机硬件上，除非 gadgetdev 为 None（用于基准测试）或不是以 /dev/ 开头的电影文件的文件词干（并且应该包含单个 int 参数的 printf 样式指令，即电影编号），否则将使用显示窗口。导出者：引擎

--serlimit (无符号长整型) 默认值=[0] 模块使用 sendSerial() 可以发送的最大串行消息数，对于每个视频帧，或 0 表示无限制。模块发送的任何超过第一个 serlimit 的消息都将被丢弃。这有利于避免串行链路过载，例如，在运行 ArUco 检测器并且 JeVois 的视野中存在大量 ArUco 标签的情况下。导出者：引擎

--gadgetnbuf (无符号整数) 默认值=[0] 视频输出 (USB 视频) 缓冲区的数量，或 0 表示自动 导出者：引擎

--multicam (bool) default=[false] 允许一个 USB 总线上最多 3 个 JeVois 摄像头。启用此选项可减少每个 JeVois 摄像头使用的 USB 带宽量，从每个 USB 同步微帧 3kb 减少到 1kb。所有 3 个 JeVois 摄像头都必须启用此选项，并且 JeVois Linux 内核模块也应该已加载多摄像头。导出者：引擎

--quietcmd (bool) 默认值=[false] 设置为 true 时，在命令行界面收到每个正确命令后不发出“OK”消息。仅推荐高级用户使用。导出者：engine

可用的相机控制：

- 亮度 [int] 最小值=-3 最大值=3 步长=1 默认值=0 curr=0
- 对比度 [int] 最小值=0 最大值=6 步长=1 默认值=3 curr=3
- 饱和度 [int] 最小值=0 最大值=4 步长=1 默认值=2 curr=2
- autowb [bool] 默认值=1 curr=0
- dowb [int] 最小值=0 最大值=1 步长=1 默认值=0 curr=1
- redbal [int] 最小值=0 最大值=255 步长=1 默认值=128 curr=125
- bluebal [int] 最小值=0 最大值=255 步长=1 默认值=128 curr=151
- autogain [bool] 默认值=1 curr=1
- gain [int] 最小值=16 最大值=1023 步长=1 默认值=16 curr=58
- hflip [bool] 默认值=0 curr=0
- vflip [bool] 默认值=0 curr=0
- powerfreq [菜单] 值 0：禁用 1：50hz 2：60hz curr=2
- 锐度 [int] 最小值=0 最大值=32 步长=1 def=6 curr=6
- autoexp [菜单] 值 0：自动 1：手动 curr=0
- absexp [int] 最小值=1 最大值=1000 步长=1 def=1000 curr=500
- presetwb [菜单] 值 0：手动 1：自动 2：白炽灯 3：荧光灯 4：荧光灯_h 5：地平线 6：日光 7：闪光 8：多云 9：阴影 curr=1\end{DoxyVerb}


根据当前加载的机器视觉模块，可能会有其他参数和其他命令可用。例如，{\bfseries{Save\+Video}} 模块允许两个新命令，“start”（开始将视频录制到磁盘）和“stop”（停止将视频录制到磁盘）。它还带来了一些特定于视频编码的新选项。加载此模块时（通过在相机查看器软件中选择相应的视频分辨率），输入“help”将显示以下新部分：

\begin{DoxyVerb}PARAMETERS:

Video Saving Options:  
  --fourcc（字符串）默认值=[MJPG] Regex:[^\w{4}$] 
    要使用的编解码器的 FourCC。OpenCV VideoWriter 文档未明确说明支持哪些编解码器。据推测，ffmpeg 库在 OpenCV 内部使用。因此，ffmpeg 支持的任何视频编码器都应该可以使用。经过测试的编解码器包括：MJPG、MP4V、AVC1。请确保您还选择了正确的文件扩展名（例如，MJPG 为 .avi，MP4V 为 .mp4，等等）
        导出者：SaveVideo

  --fps (双精度) 默认值=[30] 
    文件中存储的视频帧/秒，用于播放期间
       导出者：SaveVideo

--filename (string) default=[video%06d.avi] 
  要写入的视频文件的名称。如果路径不是绝对路径，则将在其前面添加 /jevois/data/savevideo/。名称应包含一个 int 参数的类似 printf 的指令，该指令将从 0 开始，并在每个 streamoff 命令上递增。
     导出者：SaveVideo 
\end{DoxyVerb}


和 \begin{DoxyVerb}MODULE-SPECIFIC COMMANDS:

start - start saving video
stop - stop saving video and increment video file number
\end{DoxyVerb}


您还可以使用 {\ttfamily help2} 仅显示当前加载模块的参数和命令。

\doxysubparagraph*{}\hypertarget{UserCli_cmdline2}{}\doxysubsubsection{命令行界面使用}\label{UserCli_cmdline2}
命令区分大小写，必须完全按照此处所示输入。由于命令行界面主要供机器（例如 Arduino）使用，并且为了优化速度，如上所述，对于拼写错误和其他与所需命令格式的偏差，我们只能容忍极小的宽容。\hypertarget{UserCli_cmdsertype}{}\doxyparagraph{串行通信类型}\label{UserCli_cmdsertype}
Je\+Vois 区分两种类型的串行通信：

1) {\bfseries{serlog：}}用于日志消息（错误消息、用户通知等）。日志消息按严重性等级分类，并且始终以“\+D\+B\+G”（调试级别）、“\+I\+N\+F”（信息级别）、“\+E\+R\+R”（错误级别）或“\+F\+T\+L”（致命错误级别）开头。

2）{\bfseries{serout：}}用于机器使用的基于文本的输出（例如，\+Je\+Vois 检测到的物体的坐标，发送到 Arduino）。

实际端口（例如硬件 4 针连接器与 U\+SB 串行端口）到 {\ttfamily serlog} 和 {\ttfamily serout} 的分配由参数控制，详情如下。分配非常灵活，例如，您可以决定将 {\ttfamily serlog} 消息发送到 4 针硬件串行端口和 U\+SB 串行端口，或者不发送到任何端口，或者只发送到一个端口等，而将 {\ttfamily serout} 消息仅发送到硬件 4 针串行端口，或者发送到所有端口，不发送到任何端口等。

请注意，可以设置参数 {\ttfamily serlimit} 来限制每个视频帧上发送的串行消息数量，以避免串行链路过载。例如，如果模块为每个检测到的项目发送一条消息，但存在许多项目，则可以使用 {\ttfamily serlimit} 来限制将通过串行端口报告的项目数量。\hypertarget{UserCli_cmdbehavior}{}\doxyparagraph{命令行一般行为}\label{UserCli_cmdbehavior}
当 Je\+Vois 引擎在给定的串行端口上收到命令时，就会执行该命令并将任何输出发送回同一串行端口。

所有成功的命令都以最后一行结束，内容是 \begin{DoxyVerb}OK
\end{DoxyVerb}


失败的命令会发出一些错误消息，该消息始终以“\+E\+R\+R”开头，例如： \begin{DoxyVerb}ERR Unsupported command
\end{DoxyVerb}


许多命令不会产生任何额外的输出，因此只返回一行“\+O\+K”或以“\+E\+R\+R”开头的行。\hypertarget{UserCli_cmdeol}{}\doxyparagraph{命令行行尾标记}\label{UserCli_cmdeol}
Je\+Vois 的默认行尾行为是 {\itshape sloppy，其包括：} 


\begin{DoxyItemize}
\item 在输入（发送到 Je\+Vois 的字符串）时，\+C\+R（0x0d 或 \mbox{[}\textbackslash{}r\mbox{]}）、\+L\+F（0x0a 或 \mbox{[}\textbackslash{}n\mbox{]}）、\+C\+R\+L\+F、0xd0（由某些键盘发出而不是 Return）或 0x00 \mbox{[}\textbackslash{}0\mbox{]} 中的任何一个都被接受为有效的行尾标记。 接收到的行尾标记之前且不包括行尾标记的字符将被视为一个将被解析和执行的命令。
\item 对于输出（\+Je\+Vois 发送的字符串），\+Je\+Vois 相机发出 C\+R\+LF 行尾字符。
\end{DoxyItemize}

这是在 Je\+Vois 智能相机启动时可配置的。有关详细信息，请参阅 \mbox{\hyperlink{classjevois_1_1Serial}{jevois\+::\+Serial}} 的 jevois\+::serial\+::linestyle 参数。但请注意，此参数在 Je\+Vois 启动后变为隐藏。因此，您只能通过 Je\+Vois 智能相机启动时执行的 initscript.\+cfg 脚本更改串行行尾行为。有关详细信息，请参阅 Je\+Vois\+Daemon。\hypertarget{UserCli_cmdgeneral}{}\doxyparagraph{命令行通用命令和参数}\label{UserCli_cmdgeneral}
这里描述了无论加载哪个视觉模块始终可用的通用命令。\hypertarget{UserCli_cmdhelp}{}\doxysubparagraph{帮助 -\/ 打印帮助信息}\label{UserCli_cmdhelp}
打印帮助信息。帮助信息仅发送到发出帮助命令的串行端口。\hypertarget{UserCli_cmdinfo}{}\doxysubparagraph{info -\/ 显示系统信息，包括 C\+P\+U 速度、负载和温度}\label{UserCli_cmdinfo}
显示有关 Je\+Vois 智能相机的一些重要信息：\begin{DoxyVerb}INFO: JeVois 1.1
INFO: Linux version 3.4.39
INFO: CPU: 1344MHz, 32C, load: 1.02 1.01 0.86 1/50 83
INFO: MemTotal: 238452 kB, MemFree: 194292 kB
INFO: OUT: YUYV 640x300 @ 60fps CAM: YUYV 320x240 @ 60fps MOD: JeVois:DemoSaliency
OK
\end{DoxyVerb}
\hypertarget{UserCli_cmdsetpar}{}\doxysubparagraph{setpar $<$name$>$ $<$val$>$ -\/ 设置参数值}\label{UserCli_cmdsetpar}
例如，命令\begin{DoxyVerb}setpar cpumax 1200
\end{DoxyVerb}
 returns \begin{DoxyVerb}OK
\end{DoxyVerb}
 and a subsequent command \begin{DoxyVerb}info
\end{DoxyVerb}
 would show the updated C\+PU frequency of 1200 M\+Hz\+: \begin{DoxyVerb}INFO: JeVois 1.1
INFO: Linux version 3.4.39
INFO: CPU: 1200MHz, 31C, load: 1.00 1.01 0.89 1/50 83
INFO: MemTotal: 238452 kB, MemFree: 194292 kB
INFO: OUT: YUYV 640x300 @ 60fps CAM: YUYV 320x240 @ 60fps MOD: JeVois:DemoSaliency
OK
\end{DoxyVerb}
\hypertarget{UserCli_cmdgetpar}{}\doxysubparagraph{getpar $<$name$>$ -\/ 获取参数值}\label{UserCli_cmdgetpar}
此命令的答案由参数名称和当前参数值组成。例如，命令

\begin{DoxyVerb}getpar cpumax
\end{DoxyVerb}
 returns (assuming the parameter has just been set to 1200 as above) \begin{DoxyVerb}cpumax 1200
OK
\end{DoxyVerb}
\hypertarget{UserCli_cmdrunscript}{}\doxysubparagraph{runscript $<$filename$>$ -\/ 在指定文件中运行脚本命令}\label{UserCli_cmdrunscript}
运行脚本，该脚本只是一个文件，其中包含的命令格式与通过命令行界面交互输入的命令格式完全相同。如果文件名不是绝对的（不以 / 符号开头），则假定文件名相对于当前加载的视觉模块的位置。\hypertarget{UserCli_cmdsetcam}{}\doxysubparagraph{setcam $<$ctrl$>$ $<$val$>$ -\/ 将相机控制 $<$ctrl$>$ 设置为值 $<$val$>$}\label{UserCli_cmdsetcam}
设置相机控制。帮助消息提供了可用相机控制及其允许值的列表。请注意，某些控制在某些模式下无效，例如，在尝试将值设置为 {\ttfamily absexp（手动曝光值）之前，您应该关闭} {\ttfamily autoexp（自动曝光控制）。} 

例如\begin{DoxyVerb}setcam autogain 0
setcam gain 232
\end{DoxyVerb}
\hypertarget{UserCli_cmdgetcam}{}\doxysubparagraph{getcam $<$ctrl$>$ -\/ 获取相机控制 $<$ctrl$>$ 的值}\label{UserCli_cmdgetcam}
例如，在上述 {\ttfamily setcam} 命令之后，发出

\begin{DoxyVerb}getcam gain
\end{DoxyVerb}


would return \begin{DoxyVerb}gain 232
OK
\end{DoxyVerb}


请注意，有时相机传感器硬件会修改通过 {\ttfamily setcam} 给出的值，例如对其进行四舍五入、剪切等，而 {\ttfamily getcam} 允许您取回实际设置到传感器芯片中的值。\hypertarget{UserCli_cmdlistmappings}{}\doxysubparagraph{listmappings -\/ 列出所有可用的视频映射}\label{UserCli_cmdlistmappings}
列出所有视频映射，定义相机图像大小、帧速率和像素格式、\+U\+SB 输出图像大小、帧速率和像素格式以及要运行的机器视觉模块之间的关联。映射的定义位于 videomappings.\+cfg 文件中。{\ttfamily listmappings} 命令允许您获取列表中给定映射的数字索引，稍后您可以使用 {\ttfamily setmapping} 命令使用它。例如：

\begin{DoxyVerb}listmappings
\end{DoxyVerb}


可能会返回类似的列表（取决于 videomappings.\+cfg 的内容）

\begin{DoxyVerb}AVAILABLE VIDEO MAPPINGS:

    0 - OUTPUT: NONE 0x0 @ 0fps CAMERA: YUYV 320x240 @ 60fps) MODULE: SaveVideo
    1 - OUTPUT: NONE 0x0 @ 0fps CAMERA: YUYV 320x240 @ 30fps) MODULE: RoadNavigation
    2 - OUTPUT: NONE 0x0 @ 0fps CAMERA: YUYV 320x240 @ 30fps) MODULE: SaveVideo
    3 - OUTPUT: NONE 0x0 @ 0fps CAMERA: YUYV 176x144 @ 120fps) MODULE: SaveVideo
    4 - OUTPUT: RGGB 640x480 @ 30fps CAMERA: RGGB 640x480 @ 30fps) MODULE: PassThrough
    5 - OUTPUT: RGGB 352x288 @ 60fps CAMERA: RGGB 352x288 @ 60fps) MODULE: PassThrough
    6 - OUTPUT: RGGB 176x144 @ 120fps CAMERA: RGGB 176x144 @ 120fps) MODULE: PassThrough
    7 - OUTPUT: MJPG 352x288 @ 60fps CAMERA: RGGB 352x288 @ 60fps) MODULE: Convert
    8 - OUTPUT: MJPG 320x240 @ 60fps CAMERA: RGBP 320x240 @ 60fps) MODULE: Convert
    9 - OUTPUT: MJPG 176x144 @ 120fps CAMERA: RGGB 176x144 @ 120fps) MODULE: Convert
   10 - OUTPUT: RGBP 320x240 @ 22fps CAMERA: YUYV 320x240 @ 22fps) MODULE: DemoGPU
   11 - OUTPUT: YUYV 960x240 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: DemoNeon
   12 - OUTPUT: YUYV 640x312 @ 50fps CAMERA: YUYV 320x240 @ 50fps) MODULE: DemoSalGistFaceObj
   13 - OUTPUT: YUYV 640x300 @ 60fps CAMERA: YUYV 320x240 @ 60fps) MODULE: DemoSaliency
   14 - OUTPUT: YUYV 640x300 @ 10fps CAMERA: YUYV 320x240 @ 10fps) MODULE: BurnTest
   15 - OUTPUT: YUYV 352x288 @ 60fps CAMERA: YUYV 352x288 @ 60fps) MODULE: SaveVideo
   16 - OUTPUT: YUYV 320x288 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: SaliencySURF
   17 - OUTPUT: YUYV 320x286 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: DemoQRcode
   18 - OUTPUT: YUYV 320x260 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: DemoArUco
   19 - OUTPUT: YUYV 320x256 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: RoadNavigation
   20 - OUTPUT: YUYV 320x254 @ 60fps CAMERA: YUYV 320x240 @ 60fps) MODULE: ObjectTracker
   21 - OUTPUT: YUYV 320x252 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: ObjectDetect
   22 - OUTPUT: YUYV 320x240 @ 60fps CAMERA: YUYV 320x240 @ 60fps) MODULE: SaveVideo
   23 - OUTPUT: YUYV 320x240 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: SaveVideo
   24 - OUTPUT: YUYV 320x120 @ 30fps CAMERA: YUYV 160x120 @ 30fps) MODULE: DemoBackgroundSubtract
   25 - OUTPUT: YUYV 176x160 @ 120fps CAMERA: YUYV 176x144 @ 120fps) MODULE: RoadNavigation
   26 - OUTPUT: YUYV 176x144 @ 120fps CAMERA: YUYV 176x144 @ 120fps) MODULE: SaveVideo
   27 - OUTPUT: YUYV 160x120 @ 60fps CAMERA: YUYV 160x120 @ 60fps) MODULE: SaveVideo
   28 - OUTPUT: YUYV 88x72 @ 120fps CAMERA: YUYV 88x72 @ 120fps) MODULE: SaveVideo
   29 - OUTPUT: YUYV 64x192 @ 25fps CAMERA: YUYV 320x240 @ 25fps) MODULE: SalientRegions
   30 - OUTPUT: GREY 320x960 @ 45fps CAMERA: YUYV 320x240 @ 45fps) MODULE: EdgeDetectionX4
   31 - OUTPUT: GREY 320x240 @ 59fps CAMERA: YUYV 320x240 @ 59fps) MODULE: EdgeDetection
   32 - OUTPUT: GREY 320x240 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: SuperPixelSeg
   33 - OUTPUT: GREY 176x288 @ 100fps CAMERA: YUYV 176x144 @ 100fps) MODULE: OpticalFlow
   34 - OUTPUT: GREY 176x144 @ 120fps CAMERA: YUYV 176x144 @ 120fps) MODULE: DemoEyeTracker
   35 - OUTPUT: GREY 176x144 @ 119fps CAMERA: YUYV 176x144 @ 119fps) MODULE: EdgeDetection
   36 - OUTPUT: GREY 160x495 @ 60fps CAMERA: YUYV 160x120 @ 60fps) MODULE: DemoCPUGPU
   37 - OUTPUT: GREY 128x117 @ 5fps CAMERA: YUYV 160x120 @ 5fps) MODULE: DenseSift
   38 - OUTPUT: GREY 120x25 @ 60fps CAMERA: YUYV 320x240 @ 60fps) MODULE: SaliencyGist
OK
\end{DoxyVerb}


有关视频映射的更多信息，请参阅 User\+Modes。\hypertarget{UserCli_cmdsetmapping}{}\doxysubparagraph{setmapping $<$num$>$ -\/ 选择视频映射 $<$num$>$，仅在非流媒体时可用}\label{UserCli_cmdsetmapping}
\begin{DoxyNote}{Note}
{\bfseries{请注意，此命令仅在某些特殊情况下有用，并且可能会造成混淆。在大多数情况下，选择在}} Je\+Vois 上运行哪个机器视觉模块可以通过以下方式完成：1) 通过在连接到 Je\+Vois 的主机上运行的视频捕获软件上选择视频分辨率（这是带有流式视频输出的操作），或 2) 使用下面详述的 {\ttfamily setmapping2} 命令（对于嵌入式机器人，没有流式视频输出的操作）。
\end{DoxyNote}
通常，视频映射由主机通过选择给定的视频分辨率、帧速率和像素格式来选择。但是，在某些情况下，{\ttfamily setmapping} 很有用：


\begin{DoxyEnumerate}
\item 如果当前映射的 U\+SB 输出像素格式为“\+N\+O\+N\+E”，即当前没有通过 U\+SB 传输视频。
\item 如果主机当前没有从 Je\+Vois 相机流式传输，并且主机（或 Arduino）想要选择特定的映射（通常，选择无 U\+SB 输出的映射很有用，因为无论如何在主机上启动摄像机软件时都会选择通过 U\+SB 流式传输视频的映射）。
\end{DoxyEnumerate}

例子：

\begin{DoxyVerb}setmapping 0
\end{DoxyVerb}


will return \begin{DoxyVerb}OK
\end{DoxyVerb}


如果主机当前没有通过 U\+SB 从 Je\+Vois 流式传输视频，则映射将更改为 0。但如果视频正在流式传输到主机，答案将是： \begin{DoxyVerb}ERR Command error [setmapping 0]: Cannot set mapping while streaming: Stop your webcam program on the host computer first.
\end{DoxyVerb}


只需关闭主机上的相机捕捉软件并重试即可。

\begin{DoxyNote}{Note}
如果您发出 {\bfseries{setmapping}} 命令，然后在主机上打开视频观看软件，则该软件很可能会覆盖您刚刚使用 {\bfseries{setmapping}} 执行的操作，并且无论如何都会选择其自己的映射。因此，实际上，{\bfseries{setmapping}} 通常仅适用于选择无 U\+SB 输出的模式。另请参阅 {\bfseries{setmapping2，它可能在避免通过索引设置映射时可能出现的混淆方面更好，因为该索引可能会随着}} {\bfseries{videomapping.\+cfg}} 文件的编辑而发生变化。

对于通过 U\+SB 流式传输输出视频的映射，主机还确定何时开始流式传输（当您在主机上启动相机捕获软件时）以及何时停止流式传输（当您退出该程序时）。但是，对于 U\+SB 输出为 N\+O\+NE 的映射，主机上没有运行相机捕获软件，因此需要指示 Je\+Vois 相机开始或停止流式传输（请参阅下面的 {\ttfamily streamon} 和 {\ttfamily streamoff} 命令）。

当选择无 U\+SB 输出模式时，我们不会自动开始流式传输，因为用户可能希望在流式传输之前先进行其他配置。例如，用户可能选择带有 Save\+Video 模块的模式，该模块会将摄像机帧保存到磁盘，然后设置该模块的参数以选择给定的文件名和视频编码格式，然后才开始流式传输。
\end{DoxyNote}
当选择 U\+SB 输出类型为 N\+O\+NE 的模式时，将有两个附加命令可用：{\bfseries{streamon}} 和 {\bfseries{streamoff，详情如下。}} \hypertarget{UserCli_cmdsetmapping2}{}\doxysubparagraph{setmapping2 $<$\+C\+A\+Mmode$>$ $<$\+C\+A\+Mwidth$>$ $<$\+C\+A\+Mheight$>$ $<$\+C\+A\+Mfps$>$ $<$\+Vendor$>$ $<$\+Module$>$ -\/ 设置非 U\+S\+B 输出视频映射，在非流式传输时进行动态定义}\label{UserCli_cmdsetmapping2}
这允许人们动态定义和设置没有 U\+SB 输出的新视频映射。

此命令对于从 Arduino 等嵌入式系统配置 Je\+Vois 智能相机非常有用，因为它可能不知道 {\bfseries{videomappings.\+cfg}} 中它希望使用的特定映射的映射号。

详情请参阅 User\+Modes。这里因为没有 U\+SB 输出，我们只需要指定相机格式、分辨率和帧速率，以及要使用哪个机器视觉模块。

例如：

\begin{DoxyVerb}setmapping2 YUYV 640 480 20.0 JeVois DemoArUco
\end{DoxyVerb}
 将加载 {\bfseries{Demo\+Ar\+Uco}} 模块并使用配置为 640x480 @ 20fps Y\+U\+YV 视频图像的相机运行它。

\begin{DoxyNote}{Note}
无法使用类似的命令进行 U\+SB 输出映射，因为 Je\+Vois 智能相机必须在首次连接到主机时向主机公布可以通过 U\+SB 传输的所有支持视频分辨率的完整列表。

对于没有通过 U\+SB 进行视频流传输的映射（使用 {\ttfamily setmmapping2} 设置），主机上没有运行摄像头捕获软件来指示 Je\+Vois 开始视频流传输。因此，需要指示 Je\+Vois 摄像头开始或停止流传输（请参阅下面的 {\ttfamily streamon} 和 {\ttfamily streamoff} 命令）。这是手动完成的，以便用户可以决定何时开始和停止流传输。

{\ttfamily setmapping2} 应仅与支持无 U\+SB 输出处理的机器视觉模块一起使用。这些模块的源代码中将有一个 {\bfseries{process(\+Input\+Frame \&\& inframe)}} 函数。如果您的 Je\+Vois 智能相机在给定的 {\ttfamily setmapping2} 命令后似乎无法工作，请尝试 {\ttfamily setpar serlog U\+SB} 并使用终端和串行 U\+SB 连接连接到 Je\+Vois。如果您看不到任何消息，可能是您忘记了 {\ttfamily streamon} 命令。如果您看到错误消息，可能是您的模块不支持无 U\+SB 输出处理。
\end{DoxyNote}
\hypertarget{UserCli_cmdstreamon}{}\doxysubparagraph{streamon -\/ 启动摄像头视频流}\label{UserCli_cmdstreamon}
仅当当前视频映射具有 N\+O\+NE 类型的 U\+SB 输出（包括使用 {\ttfamily setmapping2} 选择的模式）时，此命令才会存在。

它将指示 Je\+Vois 智能相机开始从相机传感器流式传输视频帧。选择没有 U\+SB 输出的视频模式后，需要发出 {\ttfamily streamon} 命令。否则，智能相机将无限期地等待此命令。\hypertarget{UserCli_cmdstreamoff}{}\doxysubparagraph{streamoff -\/ 停止摄像头视频流}\label{UserCli_cmdstreamoff}
此命令仅在当前视频映射具有 N\+O\+NE 类型的 U\+SB 输出时才会存在（包括使用 {\ttfamily setmapping2} 选择的模式）。它将指示 Je\+Vois 智能相机停止从相机传感器流式传输视频帧。

当使用类型为 N\+O\+NE 的 U\+SB 输出映射时，必须手动发出 {\ttfamily streamoff} 命令，然后才能发出下一个 {\ttfamily setmapping} 或 {\ttfamily setmapping2} 命令。\hypertarget{UserCli_cmdping}{}\doxysubparagraph{ping -\/ 返回‘\+A\+L\+I\+V\+E’}\label{UserCli_cmdping}
该命令的目的是检查 Je\+Vois 智能相机是否崩溃，例如在测试当前正在开发和调试的新机器视觉模块时。\hypertarget{UserCli_cmdserlog}{}\doxysubparagraph{serlog $<$string$>$ -\/ 将字符串转发到 serlog 参数指定的串行端口}\label{UserCli_cmdserlog}
它与 {\ttfamily serlog} 参数配合使用，该参数确定哪个串行端口用于日志消息。{\ttfamily serlog} 命令只是将给定的字符串转发到 {\ttfamily serlog} 参数选择的串行端口。

例如，这很有用，允许连接到 Je\+Vois 硬件串行端口的 Arduino 发送调试消息，这些消息可以被连接到 Je\+Vois 的串行 U\+SB 端口的人读取。

例如，连接到 Je\+Vois 硬件 4 针连接器的 Arduino 可能会通过其串行端口发出：

\begin{DoxyVerb}setpar serlog USB
serlog Arduino started
serlog Arduino compass calibrated
\end{DoxyVerb}


然后使用串行 U\+SB 端口连接到 Je\+Vois 相机的人（或其他机器）将看到：

\begin{DoxyVerb}Arduino started
Arduino compass calibrated
\end{DoxyVerb}


请记住，\+Je\+Vois 相机本身发出的日志消息（例如错误消息）也会发送到 {\ttfamily serlog} 参数选择的端口。\hypertarget{UserCli_cmdserout}{}\doxysubparagraph{serout $<$string$>$ -\/ 将字符串转发到 serout 参数指定的串行端口}\label{UserCli_cmdserout}
其操作类似于 {\ttfamily serlog} 命令，但使用 {\ttfamily serout} 参数选择的串行端口。

例如，要以交互方式调试某些 Arduino 代码，可能需要手动输入 Je\+Vois 机器视觉模块会发出的字符串类型，以确保 Arduino 始终正确解释它们。假设我们正在调试 Je\+Vois 提供的平移/倾斜 Arduino 代码。可能需要尝试手动发出一些“\+T2 targetx targety”消息，以检查平移/倾斜摄像头是否以正确的方式移动。将 Arduino 连接到 Je\+Vois 的 4 针硬件串行端口，并通过串行 U\+SB 端口与 Je\+Vois 交互，人类可以输入：

\begin{DoxyVerb}setpar serout Hard
serout T2 0 0
serout T2 1000 1000
serout T2 -1000 -1000
serout T2 &^%$@ try to crash arduino by using buggy T2 command
\end{DoxyVerb}


然后，“\+T2 x y”字符串将被转发到 Arduino，\+Arduino 应相应地移动平移/倾斜电机。对于最后一个（格式错误的）\+T2 命令，\+Arduino 应正确拒绝它并且不移动电机。

请记住，\+Je\+Vois 相机本身发出的模块数据输出消息（例如，检测到的目标物体的坐标）也会发送到 {\ttfamily serout} 参数选择的端口。\hypertarget{UserCli_cmdusbsd}{}\doxysubparagraph{usbsd -\/ 将 micro\+S\+D 卡的 J\+E\+V\+O\+I\+S 分区导出为虚拟 U\+S\+B 驱动器}\label{UserCli_cmdusbsd}


此命令允许通过 U\+SB 访问 Je\+Vois 内部 micro\+SD 卡的 J\+E\+V\+O\+IS 分区，就像它是连接到主机的 U\+SB 拇指驱动器一样。此命令仅在不流式传输视频时有效。

在 Je\+Vois 内部使用 micro\+SD 进行写入时，会出现数据缓存和同步问题，目前已按如下方式解决：


\begin{DoxyItemize}
\item 在命令行界面上发出 {\ttfamily usbsd} 命令时，micro\+SD 的 J\+E\+V\+O\+IS 分区首先对 Je\+Vois 处理器变为只读。这意味着 Je\+Vois 将无法再保存数据（例如，某些模块保存的视频文件），并且无法执行需要写入 micro\+SD 的其他操作，例如在加载 Python 模块时自动编译它们。然后，\+J\+E\+V\+O\+IS 分区将作为虚拟 U\+SB 闪存驱动器导出到主机，具有读写访问权限。
\item 用户随后可以自由浏览 micro\+SD 的内容、添加文件、删除文件和修改文件。不过 Je\+Vois 不会立即知道这些更改。
\item 然后用户应该正确弹出虚拟 U\+SB 驱动器。\+Je\+Vois 将检测到此情况并重新启动以便能够使用用户所做的修改。
\end{DoxyItemize}\hypertarget{UserCli_cmdsync}{}\doxysubparagraph{sync -\/ 将任何待处理的数据写入 micro\+SD}\label{UserCli_cmdsync}


发出此命令以确保写入 micro\+SD 的数据已提交到卡中，例如在您重新启动或断开 Je\+Vois 之前。\hypertarget{UserCli_cmddate}{}\doxysubparagraph{日期 \mbox{[}日期和时间\mbox{]} -\/ 获取或设置系统日期和时间}\label{UserCli_cmddate}


Je\+Vois 平台硬件没有用于实时时钟的电池。因此，每次重启时，其时间都会重置为纪元（1970 年 1 月 1 日 U\+T\+C）。使用此命令设置日期和时间或获取日期和时间。语法与 Unix {\ttfamily date} 命令相同。这很有用，例如，在录制视频时获取准确的时间戳。由于 Je\+Vois 没有电池供电的时钟，因此下次断电时任何日期设置都将丢失。

例如，请参阅\href{http://man7.org/linux/man-pages/man1/date.1.html}{\texttt{ 此处}} 了解有关 Unix date 命令的更多信息。用于设置日期的格式为：

\begin{DoxyVerb}MMDDhhmm[[CC]YY][.ss]]
\end{DoxyVerb}


其中方括号表示可选字段，{\bfseries{MM}} 是月份，{\bfseries{DD}} 是日期，{\bfseries{hh}} 是小时，{\bfseries{mm}} 是分钟，{\bfseries{CC}} 是年份的前两位（世纪）数字，{\bfseries{YY}} 是年份的后两位数字，{\bfseries{ss}} 是秒。

例如，在连接到 Je\+Vois 的串行终端中向 Je\+Vois 发出以下“date”命令：

\begin{DoxyVerb}date 0504153018
\end{DoxyVerb}


returns

\begin{DoxyVerb}date now Fri May  4 15:30:00 UTC 2018
OK
\end{DoxyVerb}


在 Linux 主机上，要将 Je\+Vois 相机上的日期和时间设置为与主机相同，您只需将 Linux date 命令的输出转发为 Je\+Vois date 命令的输入：在 Linux 主机的终端窗口中，输入：


\begin{DoxyCode}{0}
\DoxyCodeLine{jevois-\/cmd date `date +\%m\%d\%H\%M\%Y.\%S`}
\end{DoxyCode}
\hypertarget{UserCli_cmdrestart}{}\doxysubparagraph{restart -\/ 重新启动 Je\+Vois 智能相机}\label{UserCli_cmdrestart}


此命令只是重新启动 Je\+Vois 智能相机。\hypertarget{UserCli_cmdquit}{}\doxysubparagraph{quit – 退出该程序}\label{UserCli_cmdquit}


在主机模式下运行时，只需在启动它的终端中输入“quit”即可退出 {\ttfamily jevois-\/daemon。} \hypertarget{UserCli_cmdshell}{}\doxysubparagraph{shell $<$command$>$ -\/ 在 Je\+Vois 上执行 Unix 命令}\label{UserCli_cmdshell}
请谨慎使用此功能，因为您可能会破坏 Je\+Vois 的操作系统。这主要用于调试。例如，尝试：

\begin{DoxyVerb}shell dmesg
\end{DoxyVerb}


查看 Je\+Vois 的启动日志。\hypertarget{UserCli_moreclicmds}{}\doxysubparagraph{可能有更多命令可用}\label{UserCli_moreclicmds}
由于该文档可能落后于 Je\+Vois 上运行的实际软件，请检查 Je\+Vois 控制台中的“帮助”以查找任何尚未在此处记录的新命令。\hypertarget{UserCli_cmdpar}{}\doxyparagraph{命令行上可用的常规参数}\label{UserCli_cmdpar}
如上所述，不同的机器视觉模块将添加用户可通过命令行使用的参数（可能还有新命令）。这里我们描述了引擎导出的参数。无论当前加载了哪个机器视觉模块，这些参数始终可用：\hypertarget{UserCli_parloglevel}{}\doxysubparagraph{loglevel (jevois\+::manager\+::\+Log\+Level) default=\mbox{[}info\mbox{]} List\+:\mbox{[}fatal$\vert$error$\vert$info$\vert$debug\mbox{]} -\/ 设置要显示的最低日志级别}\label{UserCli_parloglevel}
Je\+Vois 代码使用提供的命令 \mbox{\hyperlink{group__debugging_ga136d9d772791ddd40a7781b0f6b01dd6}{L\+D\+E\+B\+U\+G()}}、\+L\+I\+N\+F\+O()、\+L\+E\+R\+R\+O\+R() 和 \mbox{\hyperlink{group__debugging_ga07fea0c726b5acfbb6c0d5483dd15d0d}{L\+F\+A\+T\+A\+L()}} 发出日志消息。loglevel 参数允许用户在运行时选择日志详细程度。将显示所选级别或更严重的消息。例如，当选择 {\ttfamily loglevel} 为 {\ttfamily info} 时，将显示 \mbox{\hyperlink{group__debugging_gadf127ca2262cc160830da49c37d04e85}{L\+I\+N\+F\+O()}}、\+L\+E\+R\+R\+O\+R() 和 \mbox{\hyperlink{group__debugging_ga07fea0c726b5acfbb6c0d5483dd15d0d}{L\+F\+A\+T\+A\+L()}} 消息。

\begin{DoxyNote}{Note}
作为速度优化，可以在编译时禁用 D\+E\+B\+UG 级别日志消息，从而避免浪费一些 C\+PU 来测试日志级别的当前值，然后决定是否发出调试消息。在 Je\+Vois 编译期间关闭 J\+E\+V\+O\+I\+S\+\_\+\+L\+D\+E\+B\+U\+G\+\_\+\+E\+N\+A\+B\+LE 时，这些测试将在编译时被绕过，并且所有 \mbox{\hyperlink{group__debugging_ga136d9d772791ddd40a7781b0f6b01dd6}{L\+D\+E\+B\+U\+G()}} 命令都只是无操作（它们不执行任何操作，也不使用任何 C\+P\+U，就像它们刚刚被删除一样）。

因此，如果在编译 Je\+Vois 期间 J\+E\+V\+O\+I\+S\+\_\+\+L\+D\+E\+B\+U\+G\+\_\+\+E\+N\+A\+B\+LE 处于关闭状态，则可能的值 {\ttfamily debug} 将不会作为可能的 {\ttfamily loglevel} 值之一出现。
\end{DoxyNote}
\hypertarget{UserCli_partracelevel}{}\doxysubparagraph{tracelevel (unsigned int) default=\mbox{[}0\mbox{]} -\/ 设置要显示的最低跟踪级别}\label{UserCli_partracelevel}
程序员可以使用 \mbox{\hyperlink{group__debugging_ga9061a9b1a920652dd863efb219c0d9d4}{J\+E\+V\+O\+I\+S\+\_\+\+T\+R\+A\+C\+E()}} 宏发出调试消息，告知用户某个特定函数何时执行。\+J\+E\+V\+O\+I\+S\+\_\+\+T\+R\+A\+C\+E() 将在函数启动时发出一条消息，在函数结束时发出另一条消息。这对于检测正在开发的模块可能在哪里锁定并应进行修复非常有用。

J\+E\+V\+O\+I\+S\+\_\+\+T\+R\+A\+CE 接受一个参数，即一个整数，称为 {\ttfamily level。然后可以调整} {\ttfamily tracelevel} 参数以仅显示级别低于 {\ttfamily tracelevel} 当前值的跟踪消息。跟踪级别越高，您将看到的消息越多。程序员决定在各种函数中使用哪个跟踪级别。

\begin{DoxyNote}{Note}
因为 \mbox{\hyperlink{group__debugging_ga9061a9b1a920652dd863efb219c0d9d4}{J\+E\+V\+O\+I\+S\+\_\+\+T\+R\+A\+C\+E()}} 使用 \mbox{\hyperlink{group__debugging_ga136d9d772791ddd40a7781b0f6b01dd6}{L\+D\+E\+B\+U\+G()}} 发出其跟踪消息，所以除非 Je\+Vois 在编译时启用了 J\+E\+V\+O\+I\+S\+\_\+\+L\+D\+E\+B\+U\+G\+\_\+\+E\+N\+A\+B\+L\+E（默认情况下并非如此），否则这些消息不会出现。这样做的原因是为了避免在生产模型中运行时浪费时间进行测试以确定我们是否应该发出调试消息。同样，\+Je\+Vois 必须在启用 J\+E\+V\+O\+I\+S\+\_\+\+T\+R\+A\+C\+E\+\_\+\+E\+N\+A\+B\+LE 的情况下进行编译，跟踪消息才能正常工作。
\end{DoxyNote}
\hypertarget{UserCli_parserout}{}\doxysubparagraph{serout (jevois\+::engine\+::\+Ser\+Port) default=\mbox{[}\+None\mbox{]} List\+:\mbox{[}\+None$\vert$\+All$\vert$\+Hard$\vert$\+U\+S\+B\mbox{]} -\/ 将模块串行消息发送到选定的串行端口}\label{UserCli_parserout}
此参数的值表示 serout 类型的消息将被发送到哪个串行端口。

参见上面关于 {\ttfamily serout} 命令的讨论。\hypertarget{UserCli_parserlog}{}\doxysubparagraph{serlog (jevois\+::engine\+::\+Ser\+Port) default=\mbox{[}\+None\mbox{]} List\+:\mbox{[}\+None$\vert$\+All$\vert$\+Hard$\vert$\+U\+S\+B\mbox{]} -\/ 显示选定串行端口上的日志和调试消息}\label{UserCli_parserlog}
此参数的值表示 serlog 类型的消息将被发送到哪个串行端口。

参见上面关于 {\ttfamily serlog} 命令的讨论。\hypertarget{UserCli_parcpumax}{}\doxysubparagraph{cpumax (无符号整数) 默认值=\mbox{[}1344\mbox{]} 列表\+:\mbox{[}120$\vert$240$\vert$312$\vert$408$\vert$480$\vert$504$\vert$600$\vert$648$\vert$720$\vert$816$\vert$912$\vert$1008$\vert$1044$\vert$1056$\vert$1080$\vert$1104$\vert$1116$\vert$1152$\vert$1200$\vert$1224$\vert$1248$\vert$1296$\vert$1344\mbox{]} -\/ C\+P\+U 最大频率（\+M\+Hz）}\label{UserCli_parcpumax}
允许用户（或 Arduino）设置 Je\+Vois C\+PU 的最大运行频率。这在某些情况下可能有助于限制 C\+PU 速度，例如当使用电量不足的电池为 Je\+Vois 供电时。\hypertarget{UserCli_parcpumode}{}\doxysubparagraph{cpumode (jevois\+::engine\+::\+C\+P\+Umode) default=\mbox{[}\+Performance\mbox{]} List\+:\mbox{[}\+Power\+Save$\vert$\+Conservative$\vert$\+On\+Demand$\vert$\+Interactive$\vert$\+Performance\mbox{]} -\/ C\+P\+U 频率调制模式}\label{UserCli_parcpumode}
允许用户选择不同的方案，以便在运行过程中动态调整 Je\+Vois C\+PU 频率。这在 Linux 社区中也称为频率调节器。

默认情况下，假设 Je\+Vois 智能相机将始终以最大可能速度处理视频。因此，默认情况下 {\ttfamily cpumode} 设置为 {\ttfamily Performance。当} C\+PU 使用率不高时，其他模式会降低 C\+PU 速度，例如当 C\+PU 正在等待相机的下一张图像时。

\begin{DoxyNote}{Note}
一般而言，除非您在某些极端情况下使用 Je\+Vois 相机，否则我们建议将 {\ttfamily cpumode} 保持为其默认设置 {\ttfamily Performance，因为这将提供最可靠的帧速率。使用其他模式时，帧速率可能会出现较大波动。} 
\end{DoxyNote}
\hypertarget{UserCli_parcamreg}{}\doxysubparagraph{camreg (bool) default=\mbox{[}false\mbox{]} -\/ 通过 setcamreg 和 getcamreg 启用对相机寄存器的原始访问}\label{UserCli_parcamreg}
此命令允许直接访问 Je\+Vois 智能相机传感器芯片上的低级寄存器。默认情况下，此功能处于关闭状态。此功能仅适用于低级黑客，他们试图通过尝试低级相机传感器寄存器的不同设置来提高图像质量。

\begin{DoxyWarning}{Warning}
当你摆弄低级寄存器时，你的 Je\+Vois 智能相机很容易崩溃。你已收到警告。一个错误的值会导致整个智能相机崩溃。
\end{DoxyWarning}
当参数 {\ttfamily camreg} 设置为 true 时，两个新命令变得可用：


\begin{DoxyItemize}
\item setcamreg {\ttfamily reg} {\ttfamily val} -\/ 将原始相机寄存器 {\ttfamily reg} 设置为值 {\ttfamily val} 
\item getcamreg {\ttfamily reg} -\/ 获取原始相机寄存器的值 {\ttfamily reg} 
\end{DoxyItemize}

在这两种情况下，{\ttfamily reg} 和 {\ttfamily val} 都是无符号的 8 位值。为方便起见，十进制值和十六进制值（使用前缀 {\ttfamily 0x} 表示十六进制）均受支持。

在配备 A\+R0135 全局快门和 I\+C\+M-\/20948 I\+MU 的改进型 Je\+Vois 装置上，以下命令也可用：
\begin{DoxyItemize}
\item setimureg {\ttfamily reg} {\ttfamily val} -\/ 将原始 I\+MU 寄存器 {\ttfamily reg} 设置为值 {\ttfamily val} 
\item getimureg {\ttfamily reg} -\/ 获取原始 I\+MU 寄存器的值 {\ttfamily reg} 
\item setimuregs {\ttfamily reg} {\ttfamily num} {\ttfamily val1} ... {\ttfamily valn} -\/ 设置原始 I\+MU 寄存器值数组
\item getimuregs {\ttfamily reg} {\ttfamily num} -\/ 获取原始 I\+MU 寄存器值数组
\item setdmpreg {\ttfamily reg} {\ttfamily val} -\/ 将原始 D\+MP 寄存器 {\ttfamily reg} 设置为值 {\ttfamily val} 
\item getdmpreg {\ttfamily reg} -\/ 获取原始 D\+MP 寄存器的值 {\ttfamily reg} 
\item setdmpregs {\ttfamily reg} {\ttfamily num} {\ttfamily val1} ... {\ttfamily valn} -\/ 设置原始 D\+MP 寄存器值数组
\item getdmpregs {\ttfamily reg} {\ttfamily num} -\/ 获取原始 D\+MP 寄存器值数组
\end{DoxyItemize}

\doxysubparagraph*{}\hypertarget{UserCli_cmdscr}{}\doxysubsubsection{命令行脚本}\label{UserCli_cmdscr}
有时，在加载模块时设置一些参数或执行一些命令很有用。

Je\+Vois 允许您将参数设置和命令存储在模块目录中名为 {\bfseries{script.\+cfg}} 的文件中。文件 {\bfseries{script.\+cfg}} 可能包含任何命令序列，就像您在 Je\+Vois 命令行界面中以交互方式输入它们一样。

以下是 Object\+Tracker 模块的示例，该模块根据颜色跟踪对​​象。对于此模块，最好将 Je\+Vois 相机传感器设置为全手动模式，因为自动增益、曝光和白平衡会影响同一物体在不同视点和光源位置下的 R\+GB 像素值。由于 Object\+Tracker 中的跟踪基于传感器返回的颜色值，因此全手动相机模式可以提供更可靠的跟踪。


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{\# Demo configuration script for ObjectTracker module.}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# Set camera to fixed color balance, gain, and exposure, so that we get more reliable colors than we would obtain under}}
\DoxyCodeLine{\textcolor{comment}{\# automatic mode:}}
\DoxyCodeLine{setcam autowb 0}
\DoxyCodeLine{setcam autogain 0}
\DoxyCodeLine{setcam autoexp 0}
\DoxyCodeLine{setcam redbal 110}
\DoxyCodeLine{setcam bluebal 170}
\DoxyCodeLine{setcam gain 16}
\DoxyCodeLine{setcam absexp 500}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# Detect a light blue flash drive by setting the appropriate value ranges for Hue, Saturation, and Value in the}}
\DoxyCodeLine{\textcolor{comment}{\# ObjectTracker module:}}
\DoxyCodeLine{setpar hrange 95...110}
\DoxyCodeLine{setpar srange 100...255}
\DoxyCodeLine{setpar vrange 60...253}
\end{DoxyCode}


Object\+Tracker 的 {\bfseries{script.\+cfg}} 文件存储在您的 micro\+SD 上的 {\bfseries{J\+E\+V\+O\+IS\+:/modules/\+Je\+Vois/\+Object\+Tracker/script.cfg}} 源中，位于 {\bfseries{$\sim$/jevoisbase/src/\+Modules/\+Object\+Tracker/script.cfg}}。 \hypertarget{USBserialLinux}{}\doxysubsubsection{使用串行 U\+SB 连接到 Je\+Vois：\+Linux 主机}\label{USBserialLinux}
该功能目前在 上还不可用，但很快就会可用……\hypertarget{USBserialLinux_serusblinuxgen}{}\doxyparagraph{在 Linux 主机上查找串行 U\+S\+B 设备}\label{USBserialLinux_serusblinuxgen}
在 Linux 上，首先查找插入 Je\+Vois 智能相机时创建的端口。除非您已经有其他调制解调器设备连接到主机，否则最有可能的是 {\bfseries{/dev/tty\+A\+C\+M0。要找出答案，请在连接}} Je\+Vois 智能相机后，在 Linux 终端中输入“dmesg”时检查显示的消息。等待至少 10 秒钟让智能相机启动并被主机检测到。“dmesg”命令的输出应包含一些有关检测 Je\+Vois 智能相机（包括其视频组件和串行端口组件）的消息：

\begin{DoxyVerb}[...] [4768736.704777] usb 1-1.3：使用 xhci_hcd 的新高速 USB 设备编号 13 [4768736.809464] usb 1-1.3：发现新 USB 设备，idVendor=1d6b，idProduct=0102 [4768736.809470] usb 1-1.3：新 USB 设备字符串：Mfr=1，Product=2，SerialNumber=0 [4768736.809473] usb 1-1.3：产品：JeVois-A33 智能相机 [4768736.809476] usb 1-1.3：制造商：JeVois Inc [4768736.847915] uvcvideo：发现 UVC 1.00 设备JeVois-A33 智能摄像头 (1d6b:0102) [4768736.849892] 输入：JeVois-A33 智能摄像头为 /devices/pci0000:00/0000:00:1c.6/0000:09:00.0/usb1/1-1/1-1.3/1-1.3:1.0/input/input29 [4768736.851499] cdc_acm 1-1.3:1.2: ttyACM0: USB ACM 设备 \end{DoxyVerb}


在上面的例子中，\+Je\+Vois 智能相机被检测为 U\+V\+C（\+U\+SB 视频类）设备，并在 {\bfseries{/devices/pci}}... 中创建了相应的视频设备条目，该条目通常也会被别名为 {\bfseries{/dev/video0}} 以方便访问。此外，\+Je\+Vois 相机的串行 U\+SB 端口被检测为 C\+D\+C-\/\+A\+CM 串行端口，并在此示例中分配了设备名称 {\bfseries{tty\+A\+C\+M0。}} 

要使用串行 U\+SB 链接连接到您的 Je\+Vois 智能相机，请启动终端程序。默认配置为 115200 8N1。\hypertarget{USBserialLinux_serusblinuxperm}{}\doxyparagraph{权限问题}\label{USBserialLinux_serusblinuxperm}
在 Ubuntu 上，会默认安装并运行一个名为 Modem\+Manager 的程序。它将尝试连接到任何新的串行 U\+SB 设备，并通过向其发送调制解调器配置命令来探测它。\+Je\+Vois 将忽略这些命令，但 Modem\+Manager 会在 Je\+Vois 连接后继续向 Je\+Vois 发送字符串长达一分钟。因此，最好直接删除 Modem\+Manager：

\begin{DoxyVerb}sudo apt purge modemmanager # 彻底删除它，以后如果需要，您可以随时重新安装它 \end{DoxyVerb}


在 Linux 上，默认情况下，您可能没有权限访问 Je\+Vois 串行 U\+SB 端口。您可以通过两种方式解决此问题：
\begin{DoxyItemize}
\item 将您的用户添加到 {\bfseries{dialout}} 组，方法是发出\begin{DoxyVerb}sudo usermod -aG dialout $USER groups $USER # 检查您现在是否在 dialout 组中 \end{DoxyVerb}
 并重新启动您的机器以使设置生效。
\item 或者只是更改端口的访问权限（但请注意，每次插入 Je\+Vois 相机时都必须这样做）：\begin{DoxyVerb}sudo chmod 777 /dev/ttyACM0 \end{DoxyVerb}

\end{DoxyItemize}

要测试连接，最好使用 \mbox{\hyperlink{JeVoisInventor}{Je\+Vois-\/\+A33：\+Je\+Vois Inventor 图形用户界面}}\hypertarget{USBserialLinux_serusblinuxscreen}{}\doxyparagraph{使用 screen 命令}\label{USBserialLinux_serusblinuxscreen}
\begin{DoxyVerb}sudo apt-get install screen # 如果尚未安装 sudo screen /dev/ttyACM0 115200 \end{DoxyVerb}


\begin{DoxyNote}{Note}
据我们所知，“screen”程序不提供命令回显选项（查看您正在输入的内容）。因此，当您输入时，您将看不到您输入的内容。这是正常的。

要在使用“屏幕”时向上滚动，请键入 {\ttfamily C\+T\+R\+L-\/A} {\ttfamily E\+S\+C，然后可以使用箭头键或鼠标滚轮向上滚动。当您准备返回交互模式时，请键入} {\ttfamily R\+E\+T\+U\+RN} 两次。
\end{DoxyNote}
\hypertarget{USBserialLinux_serusblinuxminicom}{}\doxyparagraph{使用 minicom 软件}\label{USBserialLinux_serusblinuxminicom}
您还可以使用 {\ttfamily minicom} 或其他串行通信软件。\+Minicom 很不错，因为它允许您启用本地回显（这样您就可以看到您输入的内容）：

\begin{DoxyVerb}sudo apt-get install minicom # 如果尚未安装 sudo minicom -D /dev/ttyACM0 \end{DoxyVerb}


要启用本地回显，请键入以下按键：{\ttfamily C\+T\+R\+L-\/A} {\ttfamily Z（用于配置菜单），然后} {\ttfamily E（本地回显打开/关闭）。请注意，尽管} minicom 让您看起来可以纠正拼写错误，但您仍然不能；例如，键入“helx”然后 {\ttfamily B\+A\+C\+K\+S\+P\+A\+CE} 然后“p”（将 helx 更正为 help）将传输消息“helx”后跟 {\ttfamily B\+A\+C\+K\+S\+P\+A\+CE} 字符，后跟“p”，而这对于 Je\+Vois 来说仍然是一个错误命令。\hypertarget{USBserialLinux_serusblinuxbeware}{}\doxyparagraph{警惕 Linux 上的 Modem\+Manager 或类似程序}\label{USBserialLinux_serusblinuxbeware}
许多 Linux 发行版（包括 Ubuntu）都会监控调制解调器的连接，以便能够以即插即用的方式检测到它们。由于 Je\+Vois 串行 U\+SB 端口在主机看来就像一个新的调制解调器（这样就不需要驱动程序了），因此当您连接 Je\+Vois 时，主机可能会尝试向 Je\+Vois 发送调制解调器配置命令。

Je\+Vois 将安全地忽略这些命令，但主机可能需要几分钟才能放弃尝试将 Je\+Vois 初始化为可以通过电话线拨号的调制解调器。当您的主机尝试将 Je\+Vois 配置为调制解调器时，它发送的命令将干扰您可能输入的任何命令。为了避免这种情况并允许您在主机检测到串行 U\+SB 端口后立即使用它，请关闭 Linux 主机的调制解调器管理器功能。例如，在 Ubuntu 上：

\begin{DoxyVerb}sudo Killall ModemManager \end{DoxyVerb}


使用快捷 shell 命令 jevois-\/cmd ==========================================



在 Linux 下，{\bfseries{jevois}} 软件包在主机的 {\bfseries{/usr/bin}} 中提供了命令 {\ttfamily jevois-\/cmd}（源代码位于 {\bfseries{$\sim$/jevois/scripts}}），可以直接在主机的任何终端中执行（而不是在打开某个串行终端后在 Je\+Vois 命令行界面中运行）。使用方法如下：

\begin{DoxyVerb}jevois-cmd 帮助 \end{DoxyVerb}


使用串行 U\+SB 端口连接到 Je\+Vois，向 jevois 发出命令“help”，收集并显示 Je\+Vois 返回的结果。

可以发送任何有效的 Je\+Vois 命令行命令。例如：

\begin{DoxyVerb}jevois-cmd 设置 cpumax 1200 \end{DoxyVerb}


应该返回

\begin{DoxyVerb}确定 \end{DoxyVerb}


以及随后的

\begin{DoxyVerb}jevois-cmd 信息 \end{DoxyVerb}


应显示更新后的 C\+PU 频率 1200 M\+Hz，如下所示：

\begin{DoxyVerb}INFO：JeVois 1.3.0 INFO：Linux 版本 3.4.39 INFO：CPU：1200MHz，28C，负载：0.98 0.53 0.22 1/59 86 INFO：MemTotal：238452 kB，MemFree：170188 kB INFO：OUT：YUYV 640x300 @ 60fps CAM：YUYV 320x240 @ 60fps MOD：JeVois：DemoSaliency OK \end{DoxyVerb}


\begin{DoxyNote}{Note}
如果 Je\+Vois 抱怨错误，但您知道您的命令是正确的，那么 Linux {\bfseries{Modem\+Manager}} 可能正在您的主机上运行，​​并试图将 Je\+Vois 配置为调制解调器，向其发送 Je\+Vois 不感兴趣的各种命令。见上文。 
\end{DoxyNote}
\hypertarget{USBserialWindows}{}\doxysubsubsection{使用 U\+SB 串行连接到 Je\+Vois：\+Windows 主机}\label{USBserialWindows}
该功能目前在 上还不可用，但很快就会可用……\hypertarget{USBserialWindows_serusbwingen}{}\doxyparagraph{在 Windows 主机上查找串行 U\+S\+B 设备}\label{USBserialWindows_serusbwingen}
{\bfseries{这应该只会影响部分 Windows 7 和 Windows 8 用户。如果您没有看到下面显示的故障 C\+DC 串行设备，则无需执行任何操作。}}

在某些版本的 Windows 上，\+Je\+Vois 的串行 U\+SB 端口将被自动检测和配置。但是，在其他版本上，可能需要安装“inf”文件。


\begin{DoxyItemize}
\item 首先，查看您的{\bfseries{设备管理器}}，检查{\bfseries{其他设备}}下是否有错误的{\bfseries{C\+DC 串行}}设备。如果没有，\+Je\+Vois 串行-\/over-\/\+U\+SB 可能已被检测和配置，您可以继续下一部分。 
\item 如果您看到错误设备，请通过右键单击下载此文件，然后通过以下链接{\bfseries{将目标另存为...}}：http\+://jevois.org/data/jevois-\/serial.\+inf \begin{DoxyNote}{Note}
确保文件确实以文件扩展名 {\bfseries{}}.inf 保存，否则 Windows 将无法在下一步中检测到它。在某些版本的 Windows 中，文件最终被保存为 {\bfseries{jevois-\/serial.\+inf.\+txt，然后您应该将其重命名为}} {\bfseries{jevois-\/serial.\+inf}} 
\end{DoxyNote}

\item 在设备管理器中，右键单击有错误的 C\+DC 序列，并选择 {\bfseries{属性。}} 
\item 单击{\bfseries{更新驱动程序}}，然后单击{\bfseries{浏览我的计算机以查找驱动程序软件}}。
\item 选择您保存 {\bfseries{jevois-\/serial.\+inf}} 文件的文件夹（可能是您的 {\bfseries{下载文件夹，请确保其中没有任何其他}} {\bfseries{}}.inf 文件）。当 Windows 抱怨此驱动程序不受信任时，选择仍然安装。
\item 您的设备管理器应从显示 {\bfseries{C\+DC 串行}} 设备更新为 {\bfseries{Je\+Vois-\/\+A33 Serial-\/over-\/\+U\+SB}} 或 {\bfseries{Gadget Serial}}，并且 Windows 应告诉您驱动程序已成功安装。在下面的示例中，\+Je\+Vois serial-\/over-\/\+U\+SB 端口配置为 {\bfseries{C\+O\+M6}} -\/ 这是您应该与串行终端程序一起使用的端口。
\end{DoxyItemize}

\textbackslash{}图像 html windows-\/cdc-\/安装.png\hypertarget{USBserialWindows_serusbwinusing}{}\doxyparagraph{连接到 Je\+Vois}\label{USBserialWindows_serusbwinusing}
我们已经成功使用 \href{https://ttssh2.osdn.jp/index.html.en}{\texttt{ Tera Term}} 和 \href{https://www.compuphase.com/software_termite.htm}{\texttt{ Termite}} 进行连接。打开使用 115200 8N1 创建的 C\+OM 端口。

Termite 与 Je\+Vois 配合使用效果非常好，因为它允许您键入和编辑单个命令行（在屏幕底部），当您按回车键时，它会将最后编辑的行发送给 Je\+Vois。因此，它比其他一些串行终端程序更易于输入错误。



 \hypertarget{USBserialMac}{}\doxysubsubsection{使用 U\+SB 串行连接到 Je\+Vois：\+Mac 主机}\label{USBserialMac}
该功能目前在 上还不可用，但很快就会可用……\hypertarget{USBserialMac_serusbmacgen}{}\doxyparagraph{在 Mac 主机上查找串行 U\+S\+B 设备}\label{USBserialMac_serusbmacgen}
当 Je\+Vois 智能相机连接到 Mac O\+SX 主机时，会自动检测到新的串行 U\+S\+B。其名称的形式为：

\begin{DoxyVerb}/dev/tty.usbmodemXXXX \end{DoxyVerb}
 其中上面显示的“\+X\+X\+X\+X”字符将替换为取决于您的 Mac 电脑的 4 位数字。

要找出您机器上的确切名称，请打开 {\bfseries{终端窗口（在}} {\bfseries{应用程序中，然后是}} {\bfseries{实用程序中），然后输入：}} 

\begin{DoxyVerb}ls /dev/tty.usbmodem* \end{DoxyVerb}


它应该返回设备名称。\hypertarget{USBserialMac_serusbmacscreen}{}\doxyparagraph{使用 screen 命令}\label{USBserialMac_serusbmacscreen}
您可以使用内置的“屏幕”程序连接到您的 Je\+Vois 相机：

\begin{DoxyVerb}screen /dev/tty.usbmodemXXXX 115200 \end{DoxyVerb}
 其中将“\+X\+X\+X\+X”替换为上面“ls”命令返回的数字。

一旦连接，您就可以发出“help”，“info”等命令

\begin{DoxyNote}{Note}
据我们所知，“screen”程序不提供命令回显选项（查看您正在输入的内容）。因此，当您输入时，您将看不到您输入的内容。这是正常的。

要在使用“屏幕”时向上滚动，请键入“\+C\+T\+R\+L-\/\+A”“\+E\+S\+C”，然后可以使用箭头键或鼠标滚轮向上滚动。当您准备返回交互模式时，请键入 {\ttfamily R\+E\+T\+U\+RN} 两次。
\end{DoxyNote}
\hypertarget{USBserialMac_serusbmacother}{}\doxyparagraph{使用其他串行终端程序}\label{USBserialMac_serusbmacother}
还有其他适用于 Mac 的程序比“screen”更易于使用。例如，我们在使用 \href{https://www.emtec.com/zoc/}{\texttt{ Z\+OC 7}} 时取得了良好的效果。 \hypertarget{UserProUSBserial}{}\doxysubsubsection{Je\+Vois-\/\+Pro 串行 U\+SB 通信}\label{UserProUSBserial}
从 开始，您可以启用将日志和模块输出消息发送到 的 mini-\/\+U\+SB 端口的功能。只需在 G\+UI 的“系统”选项卡中选中该选项即可，如下所示：

  

并重新启动相机。

然后使用常规 U\+SB 转 mini-\/\+U\+SB 电缆将 Je\+Vois Pro 的 mini-\/\+U\+SB 端口连接到主机上的标准 U\+SB 端口。当 启动时，您的主机将检测到 U\+SB 串行设备。然后您可以连接到它以与 通信。例如，在 Linux 主机上，当 连接时，主机上会出现一个新设备 {\bfseries{/dev/tty\+A\+C\+M0。然后您可以使用}} {\ttfamily screen} 程序进行连接：

\begin{DoxyVerb}sudo screen /dev/ttyACM0 115200 \end{DoxyVerb}


然后按照 \mbox{\hyperlink{UserCli}{命令行界面用户指南}} 中所述向 发出命令

 增强了 Je\+Vois 软件中的串行驱动程序，使其能够应对电缆断开/重新连接。但是，仍然存在一些注意事项，因为似乎没有正确的方法可以从 Linux 用户空间真正知道电缆是否已连接。但是，如果 正在发送消息并且电缆未连接，则与串行端口关联的小缓冲区最终会溢出。在这种情况下， 将关闭串行设备并尝试重新打开它。这通常会在电缆重新连接后成功。请注意，如果您的模块没有写入大量消息，您将不会在相机上知道电缆已断开连接，直到您尝试输出足够的消息以导致该缓冲区溢出。 \hypertarget{ArduinoTutorial}{}\doxysubsection{教程：如何编写与 Je\+Vois 交互的 Arduino 代码}\label{ArduinoTutorial}
\doxysubsection*{使用 Je\+Vois 和 Arduino 控制伺服器}

\doxysubsubsection*{Je\+Vois 模块输出的串行字符串}

在这个简单的示例中，我们创建一个 Arduino 程序，它将监听来自、、、 或其他模块的消息，这些模块通过串行端口输出包含目标位置信息的消息。这些模块输出以下形式的字符串：

\begin{DoxyVerb}T1 <target_x>
\end{DoxyVerb}


用于一维导航（例如 中消失点的方向），或

\begin{DoxyVerb}T2 <target_x> <target_y>
\end{DoxyVerb}


用于二维坐标。有关自定义串行消息的信息，请参阅 User\+Serial\+Style。

为了使输出独立于视频图像分辨率，所有模块始终将坐标标准化为 -\/1000（全左或全上）到 1000（全右或全下）的范围。

每个视频帧通常输出一个字符串，也就是说，这些字符串以每秒 30 个、每秒 60 个或更高的速率从 Je\+Vois 相机输出。

\doxysubsubsection*{Arduino 伺服控制}

这是一段简单的 Arduino 代码，可以解析 Je\+Vois 发送的字符串并将其转换为控制伺服电机角度的脉冲。此代码可用于控制无线电遥控汽车的转向，或控制安装 Je\+Vois 相机的伺服电动云台的 pan 和 titl 角度。


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{// JeVois control steering or a pan/tilt head from the output of JeVois modules}}
\DoxyCodeLine{\textcolor{comment}{//}}
\DoxyCodeLine{\textcolor{comment}{// We handle messages "T2 <targetx> <targety>", "T1 <targetx>", "PANGAIN <gain>", and "TILTGAIN <gain>".}}
\DoxyCodeLine{\textcolor{comment}{// targetx and targety are assumed to be in the -\/1000 ... 1000 range as output by the JeVois Kalman filters.}}
\DoxyCodeLine{\textcolor{comment}{// Here we only do simple PD control under the assumption that target coordinates have already been filtered upstream.}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{preprocessor}{\#include <Servo.h>}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Pin for LED, blinks as we receive serial commands:}}
\DoxyCodeLine{\textcolor{preprocessor}{\#define LEDPIN 13}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Serial port to use: on chips with USB (e.g., 32u4), that usually is Serial1. On chips without USB, use Serial:}}
\DoxyCodeLine{\textcolor{preprocessor}{\#define SERIAL Serial1}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Pins for up to two servos:}}
\DoxyCodeLine{Servo panservo;}
\DoxyCodeLine{\textcolor{preprocessor}{\#define PANPIN 3}}
\DoxyCodeLine{Servo tiltservo;}
\DoxyCodeLine{\textcolor{preprocessor}{\#define TILTPIN 5}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Initial servo values in degrees:}}
\DoxyCodeLine{\textcolor{preprocessor}{\#define PANZERO 90}}
\DoxyCodeLine{\textcolor{preprocessor}{\#define TILTZERO 90}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// With updates typically coming in at 60Hz or up to 120Hz, we will often need to move by a fraction of a}}
\DoxyCodeLine{\textcolor{comment}{// degree. Hence we keep track of the pan and tilt values multiplied by SCALE. For the gains, a gain of 100}}
\DoxyCodeLine{\textcolor{comment}{// means we will update servo angle by the 0.1*(target value/SCALE) degrees on each update. Higher gains mean}}
\DoxyCodeLine{\textcolor{comment}{// larger angular updates.}}
\DoxyCodeLine{\textcolor{preprocessor}{\#define SCALE 100}}
\DoxyCodeLine{\textcolor{keywordtype}{long} pangain = 100;}
\DoxyCodeLine{\textcolor{keywordtype}{long} tiltgain = 100;}
\DoxyCodeLine{\textcolor{keywordtype}{long} panval = PANZERO * SCALE;}
\DoxyCodeLine{\textcolor{keywordtype}{long} tiltval = TILTZERO * SCALE;}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{// Buffer for received serial port bytes:}}
\DoxyCodeLine{\textcolor{preprocessor}{\#define INLEN 128}}
\DoxyCodeLine{\textcolor{keywordtype}{char} instr[INLEN + 1];}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keywordtype}{void} setup()}
\DoxyCodeLine{\{}
\DoxyCodeLine{  SERIAL.begin(115200);}
\DoxyCodeLine{  SERIAL.setTimeout(1000000);}
\DoxyCodeLine{}
\DoxyCodeLine{  pinMode(LEDPIN, OUTPUT);}
\DoxyCodeLine{  digitalWrite(LEDPIN, LOW);}
\DoxyCodeLine{  }
\DoxyCodeLine{  panservo.attach(PANPIN);}
\DoxyCodeLine{  panservo.write(panval / SCALE);}
\DoxyCodeLine{}
\DoxyCodeLine{  tiltservo.attach(TILTPIN);}
\DoxyCodeLine{  tiltservo.write(tiltval / SCALE);}
\DoxyCodeLine{}
\DoxyCodeLine{  \textcolor{comment}{// We are ready to rock, disable logs and turn on serial outputs on JeVois platform:}}
\DoxyCodeLine{  SERIAL.println(\textcolor{stringliteral}{"setpar serlog None"});}
\DoxyCodeLine{  SERIAL.println(\textcolor{stringliteral}{"setpar serout Hard"});}
\DoxyCodeLine{\}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keywordtype}{void} loop()}
\DoxyCodeLine{\{}
\DoxyCodeLine{  digitalWrite(LEDPIN, LOW);}
\DoxyCodeLine{  \textcolor{keywordtype}{byte} len = SERIAL.readBytesUntil(\textcolor{charliteral}{'\(\backslash\)n'}, instr, INLEN);}
\DoxyCodeLine{  instr[len] = 0;}
\DoxyCodeLine{  digitalWrite(LEDPIN, HIGH);}
\DoxyCodeLine{}
\DoxyCodeLine{  \textcolor{keywordtype}{char} * tok = strtok(instr, \textcolor{stringliteral}{" \(\backslash\)r\(\backslash\)n"});}
\DoxyCodeLine{  \textcolor{keywordtype}{int} state = 0; \textcolor{keywordtype}{int} targx = 0, targy = 0;}
\DoxyCodeLine{  \textcolor{keywordflow}{while} (tok)}
\DoxyCodeLine{  \{}
\DoxyCodeLine{    \textcolor{comment}{// State machine:}}
\DoxyCodeLine{    \textcolor{comment}{// 0: start parsing}}
\DoxyCodeLine{    \textcolor{comment}{// 1: T2 command, parse targx}}
\DoxyCodeLine{    \textcolor{comment}{// 2: T2 command, parse targy}}
\DoxyCodeLine{    \textcolor{comment}{// 3: T2 command complete}}
\DoxyCodeLine{    \textcolor{comment}{// 4: T1 command, parse targx}}
\DoxyCodeLine{    \textcolor{comment}{// 5: T1 command complete}}
\DoxyCodeLine{    \textcolor{comment}{// 6: PANGAIN command, parse pangain}}
\DoxyCodeLine{    \textcolor{comment}{// 7: PANGAIN command complete}}
\DoxyCodeLine{    \textcolor{comment}{// 8: TILTGAIN command, parse tiltgain}}
\DoxyCodeLine{    \textcolor{comment}{// 9: TILTGAIN command complete}}
\DoxyCodeLine{    \textcolor{comment}{// 1000: unknown command}}
\DoxyCodeLine{    \textcolor{keywordflow}{switch} (state)}
\DoxyCodeLine{    \{}
\DoxyCodeLine{      \textcolor{keywordflow}{case} 0:}
\DoxyCodeLine{        \textcolor{keywordflow}{if} (strcmp(tok, \textcolor{stringliteral}{"T2"}) == 0) state = 1;}
\DoxyCodeLine{        \textcolor{keywordflow}{else} \textcolor{keywordflow}{if} (strcmp(tok, \textcolor{stringliteral}{"T1"}) == 0) state = 4;}
\DoxyCodeLine{        \textcolor{keywordflow}{else} \textcolor{keywordflow}{if} (strcmp(tok, \textcolor{stringliteral}{"PANGAIN"}) == 0) state = 6;}
\DoxyCodeLine{        \textcolor{keywordflow}{else} \textcolor{keywordflow}{if} (strcmp(tok, \textcolor{stringliteral}{"TILTGAIN"}) == 0) state = 8;}
\DoxyCodeLine{        \textcolor{keywordflow}{else} state = 1000;}
\DoxyCodeLine{        \textcolor{keywordflow}{break};}
\DoxyCodeLine{        }
\DoxyCodeLine{      \textcolor{keywordflow}{case} 1: targx = atoi(tok); state = 2; \textcolor{keywordflow}{break};}
\DoxyCodeLine{      \textcolor{keywordflow}{case} 2: targy = atoi(tok); state = 3; \textcolor{keywordflow}{break};}
\DoxyCodeLine{      \textcolor{keywordflow}{case} 4: targx = atoi(tok); state = 5; \textcolor{keywordflow}{break};}
\DoxyCodeLine{      \textcolor{keywordflow}{case} 6: pangain = atoi(tok); state = 7; \textcolor{keywordflow}{break};}
\DoxyCodeLine{      \textcolor{keywordflow}{case} 8: tiltgain = atoi(tok); state = 9; \textcolor{keywordflow}{break};}
\DoxyCodeLine{}
\DoxyCodeLine{      \textcolor{keywordflow}{default}: \textcolor{keywordflow}{break}; \textcolor{comment}{// Skip any additional tokens}}
\DoxyCodeLine{    \}}
\DoxyCodeLine{    tok = strtok(0, \textcolor{stringliteral}{" \(\backslash\)r\(\backslash\)n"});}
\DoxyCodeLine{  \}}
\DoxyCodeLine{}
\DoxyCodeLine{  \textcolor{comment}{// Target coordinates are in range -\/1000 ... 1000. Servos want 0 ... 180.}}
\DoxyCodeLine{  \textcolor{comment}{// We also need to negate as needed so that the servo turns to cancel any offset from center:}}
\DoxyCodeLine{  \textcolor{keywordflow}{if} (state == 3 || state == 5)}
\DoxyCodeLine{  \{}
\DoxyCodeLine{    panval -\/= (targx * pangain) / 1000;}
\DoxyCodeLine{    \textcolor{keywordflow}{if} (panval < 5 * SCALE) panval = 5 * SCALE; \textcolor{keywordflow}{else} \textcolor{keywordflow}{if} (panval > 175 * SCALE) panval = 175 * SCALE;}
\DoxyCodeLine{    panservo.write(panval / SCALE);}
\DoxyCodeLine{  \}}
\DoxyCodeLine{  }
\DoxyCodeLine{  \textcolor{keywordflow}{if} (state == 3)}
\DoxyCodeLine{  \{}
\DoxyCodeLine{    tiltval += (targy * tiltgain) / 1000;}
\DoxyCodeLine{    \textcolor{keywordflow}{if} (tiltval < 5 * SCALE) tiltval = 5 * SCALE; \textcolor{keywordflow}{else} \textcolor{keywordflow}{if} (tiltval > 175 * SCALE) tiltval = 175 * SCALE;}
\DoxyCodeLine{    tiltservo.write(tiltval / SCALE);}
\DoxyCodeLine{  \}}
\DoxyCodeLine{\}}
\end{DoxyCode}


\doxysubsubsection*{在 Je\+Vois 平台上使用 script.\+cfg 文件}

有时，在加载模块时设置一些参数或执行一些命令很有用。

Je\+Vois 允许您将参数设置和命令存储在模块目录中名为 {\ttfamily script.\+cfg} 的文件中。文件 {\ttfamily script.\+cfg} 可能包含任何命令序列，就像您在 Je\+Vois 命令行界面中以交互方式输入它们一样。

以下是 Object\+Tracker 模块的一个示例。如下所示，此处的命令不仅会设置 Je\+Vois 上的参数，还会设置 Arduino 控制的云台的平移和倾斜增益：


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{\# Demo configuration script for ObjectTracker module.}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# Set camera to fixed color balance, gain, and exposure, so that we get more reliable colors than we would obtain under}}
\DoxyCodeLine{\textcolor{comment}{\# automatic mode:}}
\DoxyCodeLine{setcam autowb 0}
\DoxyCodeLine{setcam autogain 0}
\DoxyCodeLine{setcam autoexp 0}
\DoxyCodeLine{setcam redbal 110}
\DoxyCodeLine{setcam bluebal 170}
\DoxyCodeLine{setcam gain 16}
\DoxyCodeLine{setcam absexp 500}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# Detect a light blue flash drive:}}
\DoxyCodeLine{setpar hrange 95...110}
\DoxyCodeLine{setpar srange 100...255}
\DoxyCodeLine{setpar vrange 60...253}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# Send info log messages to None, send serial strings from module to Hard serial port:}}
\DoxyCodeLine{setpar serlog \textcolor{keywordtype}{None}}
\DoxyCodeLine{setpar serout Hard}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# Apply high gain to our pan/tilt servos, sending the commands below to our Arduino over the Hard serial port that we}}
\DoxyCodeLine{\textcolor{comment}{\# configured above to handle the serout messages. The Arduino controlling the pan/tilt servos will receive and parse}}
\DoxyCodeLine{\textcolor{comment}{\# these commands, and will set the servo gains:}}
\DoxyCodeLine{serout PANGAIN 400}
\DoxyCodeLine{serout TILTGAIN 300}
\end{DoxyCode}
 \hypertarget{CaseMounting}{}\doxysubsection{Je\+Vois-\/\+A33 外壳安装指南}\label{CaseMounting}
Je\+Vois 智能相机提供 4 个孔，可安全地安装到机器人或其他设备上。

\textbackslash{}警告 孔在工厂时未带螺纹。当您将螺钉拧入其中时，外壳的塑料将被螺钉形成螺纹。建议您只用螺钉安装 Je\+Vois 智能相机一次。多次这样做可能会磨损相机外壳孔的塑料并导致螺钉松动。

\textbackslash{}警告 Je\+Vois 相机外壳上的孔深度略大于 5 毫米。请规划最大 5 毫米的螺丝长度，以避免碰到外壳上螺丝孔的底部。

\textbackslash{}图像 html 案例安装.\+png

您可以下载 \href{http://jevois.org/data/jevois-dimensions.pdf}{\texttt{ Je\+Vois Dimensions Scan -\/ P\+DF}} 或 \href{http://jevois.org/data/jevois-dimensions.png}{\texttt{ Je\+Vois Dimensions Scan -\/ 600-\/D\+PI P\+NG}} 并以 100\% 比例打印以获得安装图案。

\textbackslash{}图像 html jevois-\/dimensions-\/thumb.\+png

自定义安装由 Je\+Vois 用户 Dr\+Rick\+Dagless\+MD 贡献 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---

看看这个很棒的适配器，你可以用 3D 打印机制作它，将 Je\+Vois 安装在普通三脚架上：https\+://www.thingiverse.\+com/thing\+:2358684

\textbackslash{}图片 html 三脚架适配器.\+png \hypertarget{ProCaseMounting}{}\doxysubsection{Je\+Vois-\/\+Pro 外壳安装指南}\label{ProCaseMounting}
 提供 2 个螺纹孔（公制螺丝 M2.\+5x0.\+45）用于牢固地安装到机器人或其他设备上。

更多信息即将发布...

\textbackslash{}警告 Je\+Vois-\/\+Pro 相机外壳上的孔深度略大于 5 毫米。计划最大螺丝长度为 5 毫米，以避免碰到外壳内的电子设备！ \hypertarget{HardwareFiles}{}\doxysubsection{硬件：原理图、机壳 S\+TL 文件等 \textbackslash{}tableofcontents}\label{HardwareFiles}
Je\+Vois-\/\+A33 示意图 ======================


\begin{DoxyItemize}
\item \href{http://jevois.org/data/JeVois-A33-CPU-Board-Schematics.pdf}{\texttt{ Je\+Vois-\/\+A33 C\+PU 板}}
\item \href{http://jevois.org/data/JeVois-A33-Power-Board-Schematics.pdf}{\texttt{ Je\+Vois-\/\+A33 电源板}}
\end{DoxyItemize}

Je\+Vois-\/\+A33 塑料外壳 S\+TL 文件 ====================================

请注意，这些在基于长丝的 3D 打印机上打印效果不佳。它们在激光烧结打印机上打印效果不错，尽管您可能会丢失挤出徽标中的许多细节。

标准情况 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item \href{http://jevois.org/data/JeVois-A33-Case-Top.STL}{\texttt{ Je\+Vois-\/\+A33 顶壳 S\+TL}}
\item \href{http://jevois.org/data/JeVois-A33-Case-Bottom.STL}{\texttt{ Je\+Vois-\/\+A33 底壳 S\+TL}}
\end{DoxyItemize}

无风扇机箱 -\/-\/-\/-\/-\/-\/-\/-\/-\/---

此机箱专为 30x20mm 尺寸的散热器而设计。请注意，在我们的测试中，30x20x6mm 的散热器太小，无法提供足够的冷却。\+Je\+Vois 在负载下会立即过热。这就是我们决定在生产中使用风扇的原因。有关无风扇改装的更多信息，请参阅 Fanless。


\begin{DoxyItemize}
\item \href{http://jevois.org/data/fanless/JeVoisA33-fanless-case-top.STL}{\texttt{ Je\+Vois-\/\+A33 无风扇顶壳 S\+TL}}
\item \href{http://jevois.org/data/fanless/JeVoisA33-fanless-case-bottom.STL}{\texttt{ Je\+Vois-\/\+A33 无风扇底壳 S\+TL}}
\end{DoxyItemize}

带有 A\+R0135 全局快门传感器的改装单元的外壳 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item \href{http://jevois.org/data/JeVois-A33-AR0135-Case-Top.STL}{\texttt{ Je\+Vois-\/\+A33-\/\+A\+R0135 顶壳 S\+TL}}
\item \href{http://jevois.org/data/JeVois-A33-AR0135-Case-Bottom.STL}{\texttt{ Je\+Vois-\/\+A33-\/\+A\+R0135 底壳 S\+TL}}
\end{DoxyItemize}

Je\+Vois-\/\+Pro 示意图 ======================


\begin{DoxyItemize}
\item \href{http://jevois.org/data/JeVois-Pro-Main-Schematics.pdf}{\texttt{ Je\+Vois-\/\+Pro 主板原理图}}
\item \href{http://jevois.org/data/JeVoisPro-Main-ASSEMBLY.pdf}{\texttt{ Je\+Vois-\/\+Pro 主板组件}}
\item \href{http://jevois.org/data/JeVois-Pro-Daughter-Schematics.pdf}{\texttt{ Je\+Vois-\/\+Pro 子板原理图}}
\item \href{http://jevois.org/data/JeVoisPro-Daughter-ASSEMBLY.pdf}{\texttt{ Je\+Vois-\/\+Pro 子板组件}}
\end{DoxyItemize}

Je\+Vois-\/\+Pro 塑料外壳 S\+TL 文件 ====================================

请注意，这些在基于长丝的 3D 打印机上打印效果不佳。它们在激光烧结打印机上打印效果不错，尽管您可能会丢失挤出徽标中的许多细节。

标准情况 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item \href{http://jevois.org/data/JeVoisPro-Case-Front.STL}{\texttt{ Je\+Vois-\/\+Pro 前壳 S\+TL}}
\item \href{http://jevois.org/data/JeVoisPro-Case-Back.STL}{\texttt{ Je\+Vois-\/\+Pro 后壳 S\+TL}} 
\end{DoxyItemize}\hypertarget{Lenses}{}\doxysubsection{Je\+Vois-\/\+A33 镜头选项}\label{Lenses}
截至 2018 年 4 月， 有几种不同的镜头可供选择：



点击 \href{/i/jevois-lenses.png}{\texttt{ 此处查看上图的较大版本}}。\hypertarget{Lenses_autotoc_md62}{}\doxyparagraph{概述}\label{Lenses_autotoc_md62}
以下是快速比较：

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{4}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Lens }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Horizontal field of view }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Infrared-\/cut (IR) filter }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Adjustable focus  }\\\cline{1-4}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Lens }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Horizontal field of view }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Infrared-\/cut (IR) filter }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Adjustable focus  }\\\cline{1-4}
\endhead
Standard &60 degrees &Yes &No (dot of glue on threads)  \\\cline{1-4}
No\+IR &60 degrees &No &Yes  \\\cline{1-4}
90deg &90 degrees, no distortion &Yes &Yes  \\\cline{1-4}
120deg &120 degrees fisheye &Yes &Yes  \\\cline{1-4}
\end{longtabu}


{\bfseries{红外截止 (I\+R-\/cut) 滤光片}}可阻挡红外光，使传感器仅接收可见光。这非常适合白天使用。没有这种滤光片的 {\bfseries{No\+IR}} 镜头非常适合夜间使用。然后，您需要提供红外光源（通常是红外 L\+ED 阵列），它可以使用人眼不可见的光波长照亮您的场景。这样，即使在人类看来完全黑暗的环境中，\+Je\+Vois 仍能通过反射的红外光“看见”。许多安全摄像头都使用此功能提供夜间监控。

{\bfseries{无畸变镜头}}的特点是视野更宽广，但图像的空间畸变非常小，使得世界上的直线在摄像机拍摄的视频中看起来也是直线。

相比之下，超广角{\bfseries{鱼眼镜头}}会遭受所谓的桶形失真，之所以这样命名，是因为相机会将垂直线阵列成像为弯曲的，就像在桶表面上一样。与传统镜头相比，这是鱼眼镜头获得更宽视野的反面。\+Je\+Vois 提供了一种校正桶形失真的算法，该算法在 Je\+Vois 内部的 G\+PU 上运行，例如，请参阅 Je\+Vois 模块。

请注意，除标准镜头外，所有镜头均已在工厂调整为 30 厘米至无穷远的对焦距离。此外，我们要求工厂在对焦后不要粘合镜头。因此，您只需转动镜头即可轻松改变焦距。找到最佳设置后，您应该使用螺纹上的一小滴胶水、油漆、指甲油等固定镜头（就像 Je\+Vois 中预装的标准镜头一样）。\hypertarget{Lenses.dox_autotoc_md63}{}\doxyparagraph{建议和使用场景}\label{Lenses.dox_autotoc_md63}

\begin{DoxyItemize}
\item {\bfseries{标准镜头：}}用途最广泛，无失真，固定焦距为 40cm 至无穷远。提供相对较窄的视野，但这意味着物体看起来更大，目标上的像素更多，可能使它们更容易被 Je\+Vois 理解（例如，解码二维码或 Ar\+Uco 标记）。
\item {\bfseries{无红外镜头}}：无失真，视野与标准镜头相同，可调焦距，无红外截止滤镜。主要用于夜视应用，使​​用红外照明器作为光源。
\item {\bfseries{90 度镜头}}：视野比标准镜头更宽，无失真，可调整焦距。由于没有失真，使用此镜头不需要任何镜筒校正，而使用视野更宽的镜头时则需要镜筒校正。如果您需要比原始镜头更宽的视野，请使用此镜头，而无需校正图像失真。请注意，与原始镜头相比，使用此镜头时 Je\+Vois 前方的物体会显得更小。但作为交换，您将看到光轴两侧更宽广的区域。
\item {\bfseries{120 度镜头}}：最宽视野、桶形失真、可调焦距。如果您想要比原始镜头更宽的视野，请使用此镜头，但请注意，您可能需要花费一些 C\+PU 或 G\+PU 资源来消除桶形失真。请注意，使用此镜头时，\+Je\+Vois 前方的物体与原始镜头相比会显得更小。但作为交换，您将看到光轴两侧更宽广的视野。
\end{DoxyItemize}

这些传感器和镜头可在 \href{https://jevoisinc.com}{\texttt{ https\+://jevoisinc.\+com}} 上找到。\hypertarget{Lenses.dox_autotoc_md64}{}\doxyparagraph{在没有镜头胶的特殊 Je\+Vois 装置上调整或更换镜头}\label{Lenses.dox_autotoc_md64}
无需镜头胶水且配备 ov9653 或 ov7725 传感器的特殊 Je\+Vois 装置可在 \href{https://jevoisinc.com}{\texttt{ https\+://jevoisinc.\+com}} 上购买

这些设备包含在一套安装有标准镜头以及额外的 90 度、120 度和 No\+IR 镜头的套件中。

  \hypertarget{Lenses_autotoc_md65}{}\doxyparagraph{在标准 Je\+Vois 装置中安装新传感器和镜头}\label{Lenses_autotoc_md65}
这需要一些技巧，但可以在不到 5 分钟的时间内完成。请观看下面的视频了解详细信息。

\hypertarget{Lenses_autotoc_md66}{}\doxyparagraph{矫正镜片}\label{Lenses_autotoc_md66}
在某些情况下，在标准镜头前放置矫正镜片也很有用。例如，人们可能想要实现微观精度，或者想要阅读小文本，或者可能只需要聚焦在离相机很近的物体上。



上图是使用 15 倍镜头拍摄的一个例子，该镜头取自一副带有可更换镜头的珠宝商眼镜。使用这种矫正镜头（本例中没有很好地对准，因此出现扭曲），我们可以很好地聚焦在距离 Je\+Vois 很近的 2.\+5 英寸硬盘上的微小文本上。\hypertarget{Lenses_autotoc_md67}{}\doxyparagraph{镜头阴影/均匀性校正}\label{Lenses_autotoc_md67}
不同的镜头具有不同的偏心阴影量。\+Je\+Vois 相机传感器芯片提供了一些低级寄存器设置，以帮助改善不同镜头的图像均匀性。如果您在 Je\+Vois 相机中使用了一些定制镜头，请继续阅读。

以下是使用 90 度无失真镜头和默认设置（适用于 60 度镜头）的示例。观察图像在画面角落附近如何变暗：



镜头阴影的调整是通过应用一些正增益来实现的，该正增益会随着偏心率（与图像中心的距离）的增加而增加，并且应用于中央无校正盘的外部。下图显示了校正区域的中心和中央无校正盘（图像的中心区域名称）：



相机寄存器 L\+C\+C1（0x62）和 L\+C\+C3（0x63）允许通过指定距离传感器中心点的偏移量（每个寄存器的第 7 位指定的方向，其余 6 位指定的幅度）来调整校正盘的位置。

以下是所有相关寄存器：



值得注意的是，寄存器 L\+C\+C3 (0x64) 设置增益（校正强度），而 L\+C\+C4 (0x65) 设置中央无校正盘的半径。除了单个增益参数，还可以通过寄存器 L\+C\+C5 (0x66) 为红色、绿色和蓝色指定 3 个不同的增益（然后使用寄存器 L\+L\+C3 (0x64) 为绿色、\+L\+C\+F\+C\+FB (0x9d) 为蓝色和 L\+C\+C\+FR (0x9e) 为红色）。

下面是一个简单的 Python 程序，它允许您以交互方式调整无校正区域的半径和 R\+GB 的单增益因子：


\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{\#!/usr/bin/python}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# Needed packages: sudo apt-\/get install python python-\/tk}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# This tutorial is a simple program that allows one to play with two low-\/level camera sensor parameters that relate to}}
\DoxyCodeLine{\textcolor{comment}{\# correction for lens sensitivity fall-\/off with eccentricity.}}
\DoxyCodeLine{}
\DoxyCodeLine{serdev = \textcolor{stringliteral}{'/dev/ttyACM0'} \textcolor{comment}{\# serial device of JeVois}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keyword}{from} Tkinter \textcolor{keyword}{import} *}
\DoxyCodeLine{\textcolor{keyword}{import} serial}
\DoxyCodeLine{\textcolor{keyword}{import} time}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}}
\DoxyCodeLine{\textcolor{comment}{\# Send a command to JeVois and show response}}
\DoxyCodeLine{\textcolor{keyword}{def }send\_command(cmd):}
\DoxyCodeLine{    \textcolor{keywordflow}{print} \textcolor{stringliteral}{"HOST>> "} + cmd}
\DoxyCodeLine{    ser.write(cmd + \textcolor{stringliteral}{'\(\backslash\)n'})}
\DoxyCodeLine{    out = \textcolor{stringliteral}{''}}
\DoxyCodeLine{    time.sleep(0.1)}
\DoxyCodeLine{    \textcolor{keywordflow}{while} ser.inWaiting() > 0:}
\DoxyCodeLine{        out += ser.read(1)}
\DoxyCodeLine{    \textcolor{keywordflow}{if} out != \textcolor{stringliteral}{''}:}
\DoxyCodeLine{        \textcolor{keywordflow}{print} \textcolor{stringliteral}{"JEVOIS>> "} + out, \textcolor{comment}{\# the final comma suppresses extra newline, since JeVois already sends one}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}}
\DoxyCodeLine{\textcolor{comment}{\# Callback when radius slider is moved}}
\DoxyCodeLine{\textcolor{keyword}{def }update\_radius(val):}
\DoxyCodeLine{    send\_command(\textcolor{stringliteral}{'setcamreg 0x65 \{\}'}.format(val))}
\DoxyCodeLine{    }
\DoxyCodeLine{\textcolor{comment}{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}}
\DoxyCodeLine{\textcolor{comment}{\# Callback when factor slider is moved}}
\DoxyCodeLine{\textcolor{keyword}{def }update\_factor(val):}
\DoxyCodeLine{    send\_command(\textcolor{stringliteral}{'setcamreg 0x64 \{\}'}.format(val))}
\DoxyCodeLine{    }
\DoxyCodeLine{\textcolor{comment}{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}}
\DoxyCodeLine{\textcolor{comment}{\# Main code}}
\DoxyCodeLine{ser = serial.Serial(serdev, 115200, timeout=1)}
\DoxyCodeLine{send\_command(\textcolor{stringliteral}{'ping'})                   \textcolor{comment}{\# should return ALIVE}}
\DoxyCodeLine{send\_command(\textcolor{stringliteral}{'setpar camreg true'})     \textcolor{comment}{\# enable low-\/level access to camera sensor registers}}
\DoxyCodeLine{send\_command(\textcolor{stringliteral}{'setcamreg 0x66 1'})       \textcolor{comment}{\# enable lens correction}}
\DoxyCodeLine{}
\DoxyCodeLine{master = Tk()}
\DoxyCodeLine{}
\DoxyCodeLine{w1l = Label(master, text = \textcolor{stringliteral}{"Radius"})}
\DoxyCodeLine{w1l.pack()}
\DoxyCodeLine{}
\DoxyCodeLine{w1 = Scale(master, from\_=0, to=255, tickinterval=32, length=600, orient=HORIZONTAL, command=update\_radius)}
\DoxyCodeLine{w1.set(0x80)}
\DoxyCodeLine{w1.pack()}
\DoxyCodeLine{}
\DoxyCodeLine{w2l = Label(master, text = \textcolor{stringliteral}{"Correction factor"})}
\DoxyCodeLine{w2l.pack()}
\DoxyCodeLine{}
\DoxyCodeLine{w2 = Scale(master, from\_=0, to=255, tickinterval=32, length=600, orient=HORIZONTAL, command=update\_factor)}
\DoxyCodeLine{w2.set(0x10)}
\DoxyCodeLine{w2.pack()}
\DoxyCodeLine{}
\DoxyCodeLine{mainloop()}
\end{DoxyCode}


使用此代码，您应该能够改善图像的一致性，但请注意以下注意事项。在运行此 Python 代码之前，请确保您对串行 U\+SB 设备具有写访问权限（例如，{\ttfamily sudo chmod 777 /dev/tty\+A\+C\+M0}，或以 root 身份运行 Python 程序）。



您可能需要调整代码以获得不同的效果。这里的关键元素是：


\begin{DoxyItemize}
\item 请注意，在室内使用时，如果仅将 Je\+Vois 指向空白墙壁，则可能无法正常工作，因为广角镜头、\href{https://en.wikipedia.org/wiki/Diffuse_reflection}{\texttt{ 墙壁的非朗伯表面特性}}和非均匀光源的组合可能会增加明显的阴影。您应该尝试在户外使用，或者使用小型照相亭，就像人们在 e\+Bay 上拍摄想要出售的物品时使用均匀照明的照片一样。
\item 首先向 Je\+Vois 发送命令“setpar camreg true”，以启用对低级传感器寄存器的访问。
\item 然后发出命令“setcamreg R\+EG V\+A\+L”，其中 {\ttfamily R\+EG} 是寄存器地址，{\ttfamily V\+AL} 是值。“setcamreg”命令可以理解十进制、八进制（如果以 0 开头）和十六进制（如果以 0x 开头）寄存器地址。
\end{DoxyItemize}

一旦为特定镜头找到良好的设置，您可能希望在相机启动时发出这些命令，方法是将命令放在 micro\+SD 卡上的 {\bfseries{initscript.\+cfg}} 中。 \hypertarget{Sensors}{}\doxysubsection{Je\+Vois-\/\+A33 相机传感器选项}\label{Sensors}
 智能相机默认使用 Omnivision ov9653 1.\+3\+MP 相机传感器。这是一款非常出色的整体传感器，与 Je\+Vois 单元内处理器的可用计算能力完美匹配。

然而，在某些情况下，人们可能需要使用不同的光学器件或传感器。

以下选项可作为对现有 Je\+Vois 智能相机的修改：

\tabulinesep=1mm
\begin{longtabu}spread 0pt [c]{*{6}{|X[-1]}|}
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Sensor }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Resolution }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Shutter }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Pixel size }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Lens type }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Je\+Vois name  }\\\cline{1-6}
\endfirsthead
\hline
\endfoot
\hline
\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Sensor }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Resolution }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Shutter }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Pixel size }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Lens type }&\PBS\centering \cellcolor{\tableheadbgcolor}\textbf{ Je\+Vois name  }\\\cline{1-6}
\endhead
Omnivision ov9653 (standard) &1.\+3\+MP (1280x1024 max) &Rolling &3.\+18um x 3.\+18um &1/4 inch &ov9650  \\\cline{1-6}
Omnivision ov7725 &0.\+3\+MP (640x480 max) &Rolling &6.\+00um x 6.\+00um &1/4 inch &ov7725  \\\cline{1-6}
On\+Semi A\+R0135 color &1.\+2\+MP (1280x960 max) &Global &3.\+75um x 3.\+75um &M12 (12mm, S-\/mount) &ar0135  \\\cline{1-6}
On\+Semi A\+R0135 monochrome &1.\+2\+MP (1280x960 max) &Global &3.\+75um x 3.\+75um &M12 (12mm, S-\/mount) &ar0135  \\\cline{1-6}
Omnivision ov2640 &2.\+0\+MP (1600x1200 max) &Rolling &2.\+20um x 2.\+20um &1/4 inch &ov2640  \\\cline{1-6}
\end{longtabu}


\begin{DoxyNote}{Note}
带有 M12 镜头座的传感器需要为您的 Je\+Vois 智能相机配备一个新的塑料外壳。它们支持最广泛的镜头，从超广角到远摄。

全局快门意味着所有像素都在同一时间采样，而滚动快门则以光栅扫描方式逐个采样像素。全局快门传感器非常适合：
\begin{DoxyItemize}
\item 无人机
\item 快速移动的机器人
\item 汽车
\item 条形码扫描仪
\item 3D 扫描
\item 位置跟踪
\item 虹膜扫描
\item 增强现实
\item 有关更多信息，请参阅 \href{https://en.wikipedia.org/wiki/Rolling_shutter}{\texttt{ https\+://en.\+wikipedia.\+org/wiki/\+Rolling\+\_\+shutter}}。
\end{DoxyItemize}

通常，像素越大的传感器具有更好的低光性能。单色传感器通常也具有更好的低光性能。有关更多详细信息，请参阅给定传感器的数据表。
\end{DoxyNote}
\hypertarget{Sensors_autotoc_md109}{}\doxyparagraph{镜头}\label{Sensors_autotoc_md109}
对于镜头，请参阅 镜头\hypertarget{Sensors_autotoc_md110}{}\doxyparagraph{安装}\label{Sensors_autotoc_md110}
这需要一些技巧，但可以在不到 5 分钟的时间内完成。请观看下面的视频了解详细信息。



小心使用相机连接器，不要用力拉扯卡舌。卡舌只能滑出约 2 毫米。

  \hypertarget{Sensors_autotoc_md111}{}\doxyparagraph{Je\+Vois智能相机配置}\label{Sensors_autotoc_md111}
\begin{DoxyNote}{Note}
对于 Je\+Vois 软件 及更高版本，这是可选的：传感器类型在启动时自动检测。但您可能仍希望按如下所述选择它，因为这将加快 Je\+Vois 的启动时间，避免 Je\+Vois 一个接一个地尝试所有已知传感器。
\end{DoxyNote}
为了让您的 Je\+Vois 智能相机知道您已经安装了新传感器，您需要在 Je\+Vois 设备的 micro\+SD 上的特殊配置文件中指明传感器的名称。


\begin{DoxyItemize}
\item 将 micro\+SD 插入台式机或笔记本电脑
\item 浏览 B\+O\+OT 分区
\item 使用任何编辑器，在该目录中创建一个名为 {\itshape sensor} 的纯文本文件
\item 在该文件中写入一行纯 A\+S\+C\+II 文本，并使用上面列出的 Je\+Vois 名称。
\end{DoxyItemize}

  

例如（安装 ov7725 传感器后）：


\begin{DoxyItemize}
\item {\bfseries{Linux：{\ttfamily echo}} ov7725 $>$ /media/\$\{U\+S\+ER\}/\+B\+O\+O\+T/sensor}
\item {\bfseries{Mac：{\ttfamily echo}} ov7725 $>$ /\+Volumes/\+B\+O\+O\+T/sensor}
\item {\bfseries{Windows：使用记事本创建并保存文件。确保没有扩展名（即，它被命名为}} {\itshape sensor} 而不是 {\itshape sensor.\+txt}）。
\end{DoxyItemize}\hypertarget{Sensors_autotoc_md112}{}\doxyparagraph{我的 Je\+Vois 相机有哪些传感器？}\label{Sensors_autotoc_md112}
在 Je\+Vois Inventor 的控制台中，输入：


\begin{DoxyCode}{0}
\DoxyCodeLine{获取相机传感器 }
\end{DoxyCode}
\hypertarget{Sensors_autotoc_md113}{}\doxysubsubsection{传感器特定信息}\label{Sensors_autotoc_md113}
\hypertarget{Sensors_autotoc_md114}{}\doxyparagraph{Omnivision ov7725}\label{Sensors_autotoc_md114}
由于像素更大，该传感器比默认的 Je\+Vois 传感器具有更好的低光性能。另一方面，它的分辨率较低。它也可以以 60fps 的速度在 640x480 下抓取（原始传感器在该分辨率下只能达到 30fps），但它被限制在 60fps，无法像原始传感器那样以 120fps 的速度抓取。

如果您觉得原始传感器在低光照条件下难以发挥作用，并且您想在低光照条件下维持高帧速率，请使用此传感器（否则，请参阅 \mbox{\hyperlink{UserLighting}{优化不同光照条件下的性能}} 以获取有关如何在需要时通过动态调整原始 ov9653 传感器上的帧速率来增加曝光时间的提示）。

  

该传感器支持：\+Y\+U\+Y\+V、\+B\+A\+Y\+E\+R、\+R\+G\+B565
\begin{DoxyItemize}
\item V\+GA ( 640 x 480)\+: up to 60 fps
\item C\+IF ( 352 x 288)\+: up to 60 fps
\item Q\+V\+GA ( 320 x 240)\+: up to 60 fps
\item Q\+C\+IF ( 176 x 144)\+: up to 60 fps
\item Q\+Q\+V\+GA ( 160 x 120)\+: up to 60 fps
\item Q\+Q\+C\+IF ( 88 x 72)\+: up to 60 fps
\end{DoxyItemize}\hypertarget{Sensors_autotoc_md115}{}\doxyparagraph{On\+Semi (\+Aptina) A\+R0135}\label{Sensors_autotoc_md115}
\begin{DoxyNote}{Note}
该传感器主要用于工业机器视觉，因此自动图像增强功能比消费级 Omnivision 传感器少。仅提供自动增益和自动曝光，无自动白平衡。

此传感器仅支持 {\bfseries{R\+AW B\+A\+Y\+ER}} 或 {\bfseries{G\+R\+AY}} 输出格式（取决于您使用的是彩色还是单色版本）。\+Je\+Vois 核心软件 及更高版本能够即时从 B\+A\+Y\+ER 或 G\+R\+AY 转换为 Y\+U\+Y\+V，让您仍能运行绝大多数需要 Y\+U\+YV 像素格式的 Je\+Vois 模块。但是，这样做是有代价的（\+Je\+Vois 处理器必须从 B\+A\+Y\+ER 或 G\+R\+AY 转换为 Y\+U\+Y\+V）。在无头模式下操作时（没有视频输出到 U\+SB 端口），您可以通过使用 B\+A\+Y\+ER 作为相机像素格式并确保您的代码可以处理它来消除额外的成本（例如，如果您只对输入帧执行 {\ttfamily get\+Cv\+B\+G\+R()} 或类似操作，则没有问题，该函数可以从任何内容（包括 B\+A\+Y\+E\+R）转换为 B\+G\+R）。
\end{DoxyNote}
此传感器需要为您的 Je\+Vois 设备配备定制塑料外壳。说明大致与上面的安装视频相同，只需小心确保将传感器拉向外壳前部即可：

  

  

  

  

  

该传感器支持：\+B\+A\+Y\+ER 或 M\+O\+N\+O（取决于您拥有的型号），使用 Je\+Vois C\+PU 即时转换为 Y\+U\+YV
\begin{DoxyItemize}
\item S\+X\+GA (1280 x 960)\+: up to 54 fps
\item 720p (1280 x 720)\+: up to 60 fps
\item V\+GA ( 640 x 480)\+: up to 54 fps (binned version of S\+X\+GA)
\item 360p ( 640 x 360)\+: up to 60 fps
\item Q\+V\+GA ( 320 x 240)\+: up to 54 fps (central crop of binned version of S\+X\+GA)
\item 180p ( 320 x 180)\+: up to 60 fps
\item Q\+Q\+V\+GA ( 160 x 120)\+: up to 54 fps (central crop of binned version of S\+X\+GA)
\item 90p ( 160 x 90)\+: up to 60 fps
\end{DoxyItemize}

\begin{DoxyNote}{Note}
截至撰写本文时，我们无法在所有分辨率下实现制造商宣传的最高帧速率。目前，计划 30fps 是更安全的选择。
\end{DoxyNote}
我们为该传感器添加了一个很棒的 I\+M\+U（惯性测量单元），即 T\+D\+K/\+Inven\+Sense I\+C\+M-\/20948。

查看新模块 和。

该芯片的规格相当令人印象深刻：
\begin{DoxyItemize}
\item 3 轴 16 位加速度计，全范围灵敏度可选为 +/-\/2g、+/-\/4g、+/-\/8g 和 +/-\/16g。
\item 加速度计数据速率从 4 Hz 到 1125 Hz。
\item 3 轴 16 位陀螺仪，全范围灵敏度可选为 +/-\/250dps（度/秒）、+/-\/500dps、+/-\/1000dps 和 +/-\/2000dps。
\item 陀螺仪数据速率从 4 Hz 到 1125 Hz。
\item 3 轴 16 位磁力计（指南针），范围宽达 +/-\/4900u\+T（微特斯拉）。
\item 磁力计数据速率为 10 Hz、20 Hz、50 Hz 或 100 Hz。
\item 16 位温度传感器，读出速率高达 8 k\+Hz。
\item R\+AW 数据模式（随时获取当前传感器值）、缓冲 (F\+I\+FO) 数据模式（传感器值以固定速率累积到 F\+I\+FO 中）和数字运动处理模式 (D\+M\+P；原始数据在芯片上处理)。
\item 片上数字运动处理器 (D\+MP) 可以在 I\+MU 芯片内部计算：
\begin{DoxyItemize}
\item 四元数 6（使用加速度计 + 陀螺仪），
\item 四元数 9（使用加速度计 + 陀螺仪 + 指南针），
\item geomag 四元数（使用加速度计 + 指南针），
\item 翻转/拾取检测，
\item 步数检测和计数，
\item 基本活动识别：驾驶、行走、跑步、骑自行车、倾斜、静止。使用片上计算的四元数，使用以高精度、固定速率获取传感器数据并动态应用各种校准、漂移校正和补偿的算法，可以高度准确地实时估计传感器在 3D 世界中的姿势及其移动方式。
\end{DoxyItemize}
\end{DoxyItemize}



请注意，与 I\+MU 的通信是通过 400k\+Hz I2C 总线进行的，这可能会限制数据读出速率，具体取决于从 I\+MU 请求的数据。此 I\+MU 有 3 种基本操作模式（参数 {\ttfamily mode} 只能在 params.\+cfg 中设置）：
\begin{DoxyItemize}
\item R\+A\+W：可以使用 get\+Raw() 或 get() 函数随时访问最新的原始传感器数据。这是最简单的操作模式。一个缺点是，如果您没有以完全规则的间隔调用 get()，则读数中会出现一些时间抖动。\+I\+MU 不为其数据提供任何时间戳。
\item F\+I\+F\+O：在此模式下，来自传感器的数据以精确、恒定的速率堆积到 1 kbyte F\+I\+FO 缓冲区中（当加速度计、陀螺仪和磁力计全部开启时，陀螺仪速率决定 F\+I\+FO 缓冲速率）。主要优点是您可以读出数据，而不必担心以高精度间隔调用 get\+Raw() 或 get()。但您需要注意，当使用高传感器数据速率时，\+F\+I\+FO 可能会很快填满并溢出。
\item D\+M\+P：在此模式下，数据以精确、固定的速率从传感器捕获，并馈送到片上数字运动处理器 (D\+MP)。然后，\+D\+MP 计算四元数、活动识别等，并在这些算法的结果可用时将数据包推送到 F\+I\+F\+O。
\end{DoxyItemize}\hypertarget{Sensors_autotoc_md116}{}\doxyparagraph{Omnivision ov2640}\label{Sensors_autotoc_md116}
该传感器的主要优势在于其分辨率较高。然而，这也有其代价：光敏度不够好，机器视觉处理速度可能较慢，高分辨率下帧速率可能受到 U\+SB 2.\+0 传输速度的限制（视频数据最高为 24 M\+Byte/s）。

如果您想要检测远处的小物体并且不需要很高的帧速率，请使用此传感器。例如，使用此传感器可以很好地检测条形码的 Ar\+Uco 标记。

该传感器支持：\+Y\+U\+Y\+V、\+B\+A\+Y\+E\+R、\+R\+G\+B565
\begin{DoxyItemize}
\item U\+X\+GA (1600 x 1200)\+: up to 15 fps
\item S\+X\+GA (1280 x 1024)\+: up to 15 fps
\item 720p (1280 x 720)\+: up to 15 fps
\item X\+GA (1024 x 768)\+: up to 15 fps
\item S\+V\+GA ( 800 x 600)\+: up to 40 fps
\item V\+GA ( 640 x 480)\+: up to 40 fps
\item C\+IF ( 352 x 288)\+: up to 60 fps
\item Q\+V\+GA ( 320 x 240)\+: up to 60 fps
\item Q\+C\+IF ( 176 x 144)\+: up to 60 fps
\item Q\+Q\+V\+GA ( 160 x 120)\+: up to 60 fps
\item Q\+Q\+C\+IF ( 88 x 72)\+: up to 60 fps
\end{DoxyItemize}

\begin{DoxyNote}{Note}
此传感器的外壳比 ov9650 和 ov7725 大 1 毫米。因此，安装此传感器后，\+Je\+Vois 智能相机外壳的前部不会完全关闭。这是可以预料的，塑料 Je\+Vois 相机外壳的顶部和底部之间会有大约 1 毫米的间隙。
\end{DoxyNote}
\hypertarget{Sensors_autotoc_md117}{}\doxyparagraph{哪一个是哪一个？}\label{Sensors_autotoc_md117}
Omnivision 传感器模块看起来几乎一模一样。查找将传感器连接到 Je\+Vois 电路板的扁平柔性电缆上的标记：


\begin{DoxyItemize}
\item H\+D\+F-\/25 或 H\+D\+F-\/7725：是 ov7725  
\item H\+D\+F-\/53：是 ov9653  
\item H\+D\+F3\+M：位于 ov2640  
\end{DoxyItemize}

就镜头而言：


\begin{DoxyItemize}
\item Standard 和 N\+O\+IR 的镜头孔最小。\+N\+O\+IR 的镜头螺纹上没有胶水，而 Standard 有胶水。
\item 90 度的孔比标准和 N\+O\+IR 的孔稍大一些。
\item 120 度更大，更容易识别。
\end{DoxyItemize}

  


\begin{DoxyItemize}
\item 您可能收到了额外的镜头，这些镜头有时会被拧入方形护罩中以提供保护。在尝试将镜头安装到 Je\+Vois 相机上之前，您应该先拧下护罩。您可以丢弃护罩：
\end{DoxyItemize}

  

   \hypertarget{Fanless}{}\doxysubsection{Je\+Vois-\/\+A33 无风扇操作}\label{Fanless}
在某些情况下，冷却 的风扇声音太大或耗电量太大。\+Je\+Vois 可以在没有风扇的情况下工作。这里我们向您展示如何将您的 Je\+Vois 相机转换为使用散热器而不是风扇。

在开发 Je\+Vois 的过程中，我们最初计划使用散热器进行被动冷却。但是，所需的散热器太大，而且温度太高，所以我们最终选择了风扇。

要求 =============

你会需要：


\begin{DoxyItemize}
\item 一台能用的 Je\+Vois 相机
\item 一把大号平头螺丝刀
\item 钢丝钳或剪刀
\item 强力胶
\item 散热器，这里我们使用 30x30x20mm，带尖刺式散热片，因为这种散热片效率更高
\item 散热器（导热）胶，我们在 ebay 或 aliexpress 上买的
\item 酒精垫
\item 带软钳口的虎钳（例如橡胶）
\end{DoxyItemize}

\textbackslash{}警告 散热器会变得非常热，热到让人无法舒适地触摸。温度最高可达 80C (175F)。

转换为无风扇 =======================


\begin{DoxyItemize}
\item 此修改当然会使您的保修失效。继续操作时风险自负。
\item 使用大号平头螺丝刀打开外壳
\end{DoxyItemize}

  



  


\begin{DoxyItemize}
\item 剪断风扇电线。确保它们不会短路！
\end{DoxyItemize}

  


\begin{DoxyItemize}
\item 您可能需要使用强力胶将相机传感器粘在外壳底部。但请注意，强力胶产生的无形烟雾会永久损坏您的镜头。因此，在将胶水涂到外壳上之前，请确保镜头已盖好。在下图中，您需要将传感器从外壳中轻轻抬起，在传感器外壳上的外壳上涂上少量强力胶，然后将传感器放回原位。
\end{DoxyItemize}

  


\begin{DoxyItemize}
\item 检查 C\+PU 周围的焊接工作。焊点不应高于 C\+P\+U。否则，散热器可能会造成短路。如果您担心焊点会与散热器接触，您可能需要用胶带覆盖一些焊点。
\end{DoxyItemize}

  


\begin{DoxyItemize}
\item 现在准备粘合散热器。首先用酒精棉签清洁散热器、\+C\+PU 和 R\+AM 芯片，让酒精完全干燥。\+C\+PU 上有 {\itshape A33} 标记，\+R\+AM 芯片上有 {\itshape Sa​​msung} 标记。
\end{DoxyItemize}

  


\begin{DoxyItemize}
\item 接下来，在 C\+PU 和 R\+AM 芯片上涂抹少量散热胶。请注意，\+R\+AM 芯片比 C\+PU 薄一点，因此与散热片的接触不会很好，但这没关系，因为 R\+AM 无论如何都不会变得很热。
\end{DoxyItemize}

  


\begin{DoxyItemize}
\item 将散热器压在 C\+PU 上并用虎钳夹紧，不要太紧以免损坏电路板。让其干燥几个小时（建议干燥一整夜）。
\end{DoxyItemize}

  


\begin{DoxyItemize}
\item 准备出发，看上去不太好，但让我们看看它是否可行。
\end{DoxyItemize}

  


\begin{DoxyItemize}
\item 成功，在 20C 的办公室中，运行 30 分钟后，\+C\+PU 温度约为 63C，这使用了大约 375\% 的 C\+P\+U（400\% 意味着将所有 4 个 C\+PU 核心都加载到最大）。
\end{DoxyItemize}

  

两小时后，相机温度最终升至 66C。

如果 C\+PU 温度超过 75C，\+C\+PU 频率将自动从 1.\+34\+G\+Hz 降低至 1.\+2\+G\+Hz。

您还可以使用 Je\+Vois 的参数 {\ttfamily cpumax} 降低最大 C\+PU 时钟。在 Je\+Vois Inventor 的控制台中，输入“help”并查找参数 {\ttfamily cpumax，它将向您显示以} M\+Hz 为单位的可能频率数。然后您可以选择其中一个并进行设置。例如，

\textbackslash{}逐字设置 cpumax 1008 \textbackslash{}end逐字

Tensor\+Flow 预测时间从 25ms/推理增加到 33ms/推理，但在我们的测试相机上，\+C\+PU 温度从 66C 下降到 42C。

您还可以将此命令添加到相机的 {\bfseries{initscript.\+cfg}} 文件中，以便在每次 Je\+Vois 启动时运行它。

\begin{DoxyNote}{Note}
使用我们在工厂测试摄像机时使用的 模块，我们最终达到了 75C，此时 C\+PU 频率自动降至 1.\+2\+G\+Hz。然后温度在 72C 和 75C 之间波动，而 C\+PU 频率在 1.\+2\+G\+Hz 和 1.\+34\+G\+Hz 之间波动。 默认未启用，因为它是一个终端模块（您需要重新启动 Je\+Vois 才能将其关闭）。如果您在 {\bfseries{videomappings.\+cfg}} 中查找 Burn\+Test，您将找到一个注释掉的条目。删除注释字符并重新启动 Je\+Vois 以启用它。如上所述，一旦启动 Burn\+Test，您将需要重新启动 Je\+Vois 才能退出它。虽然系统保持稳定（没有崩溃），但我们怀疑在 75C 附近长时间运行会显著缩短 C\+PU 芯片的使用寿命。这也是我们最终决定在批量生产中使用风扇的原因之一。
\end{DoxyNote}
结论 ===========

它看上去很丑，体积很大，摸起来很烫，但可以进行无风扇改造。

  

如果您不介意以较低的频率运行，则可以使用较小的散热器。请参阅 \href{http://jevois.org/start/software.html}{\texttt{ http\+://jevois.\+org/start/software.\+html}} 并查找“无风扇机箱”以下载可容纳 30x20mm 散热器的机箱的 S\+TL 文件。然后您可以 3D 打印该机箱。在我们早期对 30x20x6mm 散热器的测试中，\+Je\+Vois 在负载下几乎会立即过热。但是，如果您能找到高效且更高的 30x20mm 散热器并且可以在较低的 C\+PU 频率下工作，这可能是一个选择。不过，这必须经过测试。 \hypertarget{Multicam}{}\doxysubsection{Je\+Vois-\/\+A33 通过连接到一个 U\+SB 总线的多个 Je\+Vois 摄像机流式传输视频}\label{Multicam}
默认情况下， 配置为使用所有 U\+SB 等时带宽（isochronous bandwidth），以最大限度地减少延迟。

简而言之，等时传输可以保证实时数据传输，因此非常适合音频和视频。在 8k\+Hz 时钟（125us 周期）上，每个连接设备都可以请求一些时隙（time slots），例如，一个设备可能请求每 8 个时钟周期（微帧 microframe）传输 1 K\+B，另一个设备可能请求每微帧传输 128 字节，等等。然后主机找到一种方法来满足所有连接设备的各种请求。\+Je\+Vois 默认请求最大值，即每微帧 3 K\+B，目的是尽快将所有视频数据推送到主机以最大限度地减少延迟。

从 开始，提供了一个新的启动开关：通过将一个名为 {\bfseries{multicam}} 的空文件写入 micro\+SD 卡的 {\bfseries{B\+O\+OT\+:}} 分区，可以将 Je\+Vois 相机的带宽请求降低到 1 kbyte/microframe (8 M\+Byte/s)。有关此特殊文件的更多信息，请参阅 \mbox{\hyperlink{Debugging}{调试 Je\+Vois 软件}} 和 Micro\+S\+D。使用此新选项，可以从连接到同一 U\+SB 总线的 3 个 Je\+Vois 相机进行流式传输。请注意，所有 3 个相机都必须启用 {\bfseries{multicam}} 启动模式才能正常工作。



由于这会将每个 Je\+Vois 相机的 U\+SB 带宽限制为 8 M\+Byte/s，因此默认情况下不启用此功能。请注意，它还可能限制某些模块可以运行的帧速率。在 Y\+U\+YV 中，这意味着只有低分辨率才能以全帧速率通过。事实上，仅 640 x 480 x 2（bytes/pixel）x 30（fps）就已经是 18 Mbytes/s。

使用 PC 主机硬件时，可以使用扩展卡为每个端口提供专用的 U\+SB 控制器。例如 Star\+Tech P\+E\+X\+U\+S\+B400（4 个独立的 U\+SB 2.\+0 端口，已停产，但可以在 e\+Bay 上找到）或 P\+E\+X\+U\+S\+B3\+S44\+V（4 个独立的 U\+SB 3.\+0 端口）。使用这样的卡，可以从 4 个 Je\+Vois 摄像机以全帧速率（3kb/微帧）进行流式传输，或者从 12 个 Je\+Vois 摄像机以多摄像机速率（1kb/微帧；需要将一个有源 3 端口 U\+SB 集线器连接到扩展卡上的 4 个端口中的每一个）。 \hypertarget{UserDNNoverview}{}\doxysubsection{在 Je\+Vois-\/\+A33 和 Je\+Vois-\/\+Pro 上运行神经网络}\label{UserDNNoverview}
Je\+Vois 模块提供了一个通用引擎，用于在 和 上运行神经网络推理。请注意，目前 Je\+Vois 上还没有提供神经网络训练，因为训练通常需要大型服务器和大型 G\+P\+U。因此，我们假设您有一个已经训练好的模型，您想在 Je\+Vois 相机上使用它来对实时视频流进行运行时推理。

虽然我们在这里重点介绍 Je\+Vois 模块，但有几个较旧的模块提供了 D\+NN 功能：


\begin{DoxyItemize}
\item ：使用 Tensor\+Flow A\+PI 在 C\+PU 上进行 Tensor\+Flow-\/\+Lite 对象分类
\item ：\+Itti 等人 (1998) 显著性模型 + 使用 Tensor\+Flow A\+PI 在 C\+PU 上进行 Tensor\+Flow-\/\+Lite 对象分类
\item ：使用 Tensor\+Flow A\+PI 在 C\+PU 上进行 Tensor\+Flow-\/\+Lite 对象分类
\item ：使用 Darknet A\+PI 在 C\+PU 上进行 Darknet 对象识别
\item ：\+Itti 等人(1998) 显著性模型 + C\+PU 上的 Darknet 对象识别，\+Darknet A\+PI
\item ：\+C\+PU 上的 Darknet Y\+O\+LO 对象检测，\+Darknet A\+PI
\item ：使用 C\+PU 上的 Open\+CV 进行对象检测
\item ：使用 C\+PU 上的 Open\+CV 进行对象检测，\+Python 版本
\item ：使用 C\+PU 上的 Open\+CV 进行对象分类，\+Python 版本
\item ：\+Python 中的面部情绪识别网络
\item 仅限：：使用 Media\+Pipe 的面部标志
\item 仅限：：使用 Media\+Pipe 的手部标志
\item 仅限：：使用 Media\+Pipe 的身体姿势标志
\item 仅限：：并行运行多个神经网络，以象限显示
\item 仅限：：并行运行多个神经网络，重叠显示
\item 仅限：：使用 Coral Python A\+PI 在可选 Coral T\+PU 上运行分类模型
\item 仅限：：使用 Coral Python A\+PI 在可选 Coral T\+PU 上运行检测模型
\item 仅限：：使用 Coral Python A\+PI 在可选 Coral T\+PU 上运行分割模型
\end{DoxyItemize}

\begin{DoxyNote}{Note}
在 上，其中一些模块位于图形界面中的 {\bfseries{Legacy}} 模块列表下。
\end{DoxyNote}
\hypertarget{UserDNNoverview_autotoc_md140}{}\doxysubsubsection{Je\+Vois-\/\+Pro D\+N\+N 与各种硬件加速器的基准测试}\label{UserDNNoverview_autotoc_md140}
参见 \mbox{\hyperlink{JeVoisProBenchmarks}{Je\+Vois-\/\+Pro 深度神经网络基准}}\hypertarget{UserDNNoverview_autotoc_md141}{}\doxysubsubsection{Je\+Vois D\+N\+N 框架概述}\label{UserDNNoverview_autotoc_md141}
 模块实现了一个 \mbox{\hyperlink{classjevois_1_1dnn_1_1Pipeline}{Pipeline}} 组件，该组件作为总体推理协调器，同时还可作为三个子组件的工厂：


\begin{DoxyItemize}
\item 预处理器：从摄像头传感器接收图像并准备进行网络推理（例如，调整大小、将 R\+GB 交换为 B\+G\+R、量化等）。~\newline
 可用变体：
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1PreProcessorBlob}{Pre\+Processor\+Blob}} (C++)：应该适用于大多数需要一张图像作为输入的网络
\item 按照 Pre\+Processor、\+Pre\+Processor\+Python 中描述的接口和 Py\+Pre\+Blob.\+py 中的示例，用 Python 编写自己的程序
\item 网络：接收预处理的图像并运行神经网络推理，产生一些输出。~\newline
 可用变体：
\begin{DoxyItemize}
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1NetworkOpenCV}{Network\+Open\+CV}} (C++)，适用于 Open\+C\+V、\+Open\+Vino/\+Myriad-\/X 和 T\+I\+M-\/\+V\+X/\+N\+PU
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1NetworkNPU}{Network\+N\+PU}} (C++)
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1NetworkHailo}{Network\+Hailo}} (C++)
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1NetworkTPU}{Network\+T\+PU}} (C++)
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1NetworkONNX}{Network\+O\+N\+NX}} (C++)，适用于 O\+N\+NX Runtime（也提供 Python 版本）
\item 按照 Network、\+Network\+Python 中的接口和 Py\+Net\+Open\+C\+V.\+py 中的示例，用 Python 编写您自己的程序
\end{DoxyItemize}
\item Post\+Processor：接收原始网络输出并以人性化的方式呈现它们。例如，在运行对象检测网络后在实时摄像机视频上绘制框。~\newline
 可用变体：
\begin{DoxyItemize}
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1PostProcessorClassify}{Post\+Processor\+Classify}}
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1PostProcessorDetect}{Post\+Processor\+Detect}}
\item Post\+Processor\+Segment（语义分割）
\item Post\+Processor\+Yu\+Net（用于面部检测框 + 眼睛、鼻子和嘴巴上的标记）
\item Post\+Processor\+Stub（在编写自己的预处理器之前，可用于测试模型的速度）
\item 使用 Post\+Processor、\+Post\+Processor\+Python 中的接口和 Py\+Post\+Classify.\+py 中的示例编写自己的预处理器
\end{DoxyItemize}
\end{DoxyItemize}

管道的参数在 Y\+A\+ML 文件中指定，该文件描述了要使用哪个预处理器、哪种网络类型、哪种后处理器以及这些预处理器的各种参数，以及训练后的权重在 micro\+SD 上的存储位置。这些 Y\+A\+ML 文件存储在 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/ 中，可通过用户界面的 Config 选项卡在 上访问。

在 模块中，通过 \mbox{\hyperlink{classjevois_1_1dnn_1_1Pipeline}{Pipeline}} 组件的 {\ttfamily pipe} 参数选择给定网络。该参数中描述的可用管道如下：

\begin{DoxyVerb}<ACCEL>:<TYPE>:<NAME>
\end{DoxyVerb}


其中 A\+C\+C\+EL 是 (Open\+C\+V、\+N\+P\+U、\+S\+P\+U、\+T\+P\+U、\+V\+P\+U、\+N\+P\+U\+X、\+V\+P\+U\+X、\+Python) 之一，\+T\+Y\+PE 是 (Stub、\+Classify、\+Detect、Segment、\+Yu\+Net、\+Python、\+Custom) 之一。

Je\+Vois-\/\+Pro G\+U\+I（\+Pipeline 组件的 {\ttfamily 管道参数）中使用了以下键：} 


\begin{DoxyItemize}
\item $\ast$$\ast$\+Open\+C\+V：$\ast$$\ast$由 Open\+CV D\+NN 框架加载并在 C\+PU 上运行的网络。
\item $\ast$$\ast$\+O\+R\+T：$\ast$$\ast$由 O\+N\+NX Runtime 框架加载并在 C\+PU 上运行的网络。
\item $\ast$$\ast$\+N\+P\+U：$\ast$$\ast$在 Je\+Vois-\/\+Pro 集成的 5-\/T\+O\+PS N\+P\+U（神经处理单元）上原生运行的网络。
\item $\ast$$\ast$\+T\+P\+U：$\ast$$\ast$在可选的 4-\/T\+O\+PS Google Coral T\+PU 加速器（张量处理单元）上运行的网络。
\item $\ast$$\ast$\+S\+P\+U：$\ast$$\ast$在可选的 26-\/T\+O\+PS Hailo8 S\+PU 加速器（流处理单元）上运行的网络。
\item $\ast$$\ast$\+V\+P\+U：$\ast$$\ast$在可选的 1-\/T\+O\+PS MyriadX V\+PU 加速器（矢量处理单元）上运行的网络。
\item $\ast$$\ast$\+N\+P\+U\+X：$\ast$$\ast$由 Open\+CV 加载并通过 T\+I\+M-\/\+VX Open\+CV 扩展在 N\+PU 上运行的网络。为了高效运行，网络应该量化为 int8，否则会出现一些基于 C\+PU 的缓慢仿真。
\item $\ast$$\ast$\+V\+P\+U\+X：$\ast$$\ast$针对 V\+PU 优化的网络，但如果 V\+PU 不可用，则在 C\+PU 上运行。请注意，如果未检测到 V\+PU 加速器，则通过扫描所有 V\+PU 条目并将其目标从 Myriad 更改为 C\+PU 来自动创建 V\+P\+UX 条目。如果检测到 V\+P\+U，则列出 V\+PU 模型，而不列出 V\+P\+UX 模型。\+V\+P\+UX 仿真在 Je\+Vois-\/\+Pro C\+PU 上运行，使用 Arm Compute Library 来高效实现各种网络层和操作。例如：
\end{DoxyItemize}


\begin{DoxyCode}{0}
\DoxyCodeLine{\%YAML 1.0}
\DoxyCodeLine{-\/-\/-\/}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# SqueezeNet v1.1 from https://github.com/DeepScale/SqueezeNet}}
\DoxyCodeLine{SqueezeNet:}
\DoxyCodeLine{  preproc: Blob}
\DoxyCodeLine{  nettype: OpenCV}
\DoxyCodeLine{  postproc: Classify}
\DoxyCodeLine{  model: \textcolor{stringliteral}{"opencv-\/dnn/classification/squeezenet\_v1.1.caffemodel"}}
\DoxyCodeLine{  config: \textcolor{stringliteral}{"opencv-\/dnn/classification/squeezenet\_v1.1.prototxt"}}
\DoxyCodeLine{  intensors: \textcolor{stringliteral}{"NCHW:32F:1x3x227x227"}}
\DoxyCodeLine{  mean: \textcolor{stringliteral}{"0 0 0"}}
\DoxyCodeLine{  scale: 1.0}
\DoxyCodeLine{  rgb: false}
\DoxyCodeLine{  classes: \textcolor{stringliteral}{"classification/imagenet\_labels.txt"}}
\DoxyCodeLine{  classoffset: 1}
\end{DoxyCode}


将在 模块中通过 \mbox{\hyperlink{classjevois_1_1dnn_1_1Pipeline}{Pipeline}} 的 {\ttfamily 管道参数以} {\bfseries{Open\+C\+V\+:\+Classify\+:Squeeze\+Net}} 形式提供

有关 Y\+A\+ML 文件中支持的键的最新列表，请参阅以下定义的所有参数（使用“\+J\+E\+V\+O\+I\+S\+\_\+\+D\+E\+C\+L\+A\+R\+E\+\_\+\+P\+A\+R\+A\+M\+E\+T\+E\+R(...)”）：


\begin{DoxyItemize}
\item \mbox{\hyperlink{GUIhelper_8C_a251ee9f915563bc8c09c1623b5e29e31}{预处理器\+::H}}
\item \mbox{\hyperlink{GUIhelper_8C_a251ee9f915563bc8c09c1623b5e29e31}{网络\+::H}}
\item \mbox{\hyperlink{GUIhelper_8C_a251ee9f915563bc8c09c1623b5e29e31}{后处理器\+::H}}
\item \mbox{\hyperlink{GUIhelper_8C_a251ee9f915563bc8c09c1623b5e29e31}{管道\+::H}}
\end{DoxyItemize}

从上面的链接中，点击{\itshape 转到此文件的源代码}来查看参数定义。\hypertarget{UserDNNoverview_autotoc_md142}{}\doxysubsubsection{添加新网络的程序}\label{UserDNNoverview_autotoc_md142}

\begin{DoxyItemize}
\item 运行时所需的一切（完整的 Open\+C\+V，包含所有可用的后端、目标等、\+Open\+Vino、\+Coral Edge\+T\+PU 库、\+Hailo 库、\+N\+P\+U​​ 库等）都已预先安装在 Je\+Vois 上，因此您无需在相机上安装任何其他软件即可使用这些框架运行您的自定义网络。
\item 获得模型：训练您自己的模型，或下载预先训练的模型。
\item 获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、\+R\+GB 或 B\+G\+R、打包（\+N\+W\+H\+C）或平面（\+N\+C\+H\+W）像素、输入和输出层的名称等）。
\item 要在 上运行，请在您的 Linux 台式机上转换/量化模型，以便对其进行优化以在可用的神经加速器之一上运行，例如集成 N\+P\+U、\+Hailo8、\+Coral T\+PU 等。
\begin{DoxyItemize}
\item 这将要求您在具有大量 R\+A\+M、磁盘空间以及可能具有大型 n\+Vidia G\+PU 的快速 Linux 台式机上为每个目标加速器安装供应商提供的 S\+D\+K（例如，\+Amlogic N\+PU S\+D\+K、\+Open\+Vino S\+D\+K、\+Hailo S\+D\+K、\+Coral Edge\+T\+PU 编译器）。
\item 对于量化，您还需要一个{\itshape 代表性样本数据集}。这通常是来自用于您的模型的验证集的大约 100 张图像。目标是通过原始网络（仅前向推理）运行此数据集并记录在每一层遇到的值的范围。然后，这些值的范围将用于以最佳精度量化各层。
\item 使用您选择的加速器的供应商 S\+D\+K，在快速的 Linux 桌面上转换和量化模型。
\end{DoxyItemize}
\item 将模型复制到 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Je\+Vois micro\+SD 卡
\item 为您的模型创建一个 Je\+Vois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Y\+A\+ML 文件
\item 在相机上，启动 Je\+Vois 模块。它将扫描自定义目录以查找任何有效的 Y\+A\+ML 文件，并通过 D\+NN 模块的 \mbox{\hyperlink{classjevois_1_1dnn_1_1Pipeline}{Pipeline}} 组件的 {\ttfamily 管道参数使您的模型可用。选择该管道以运行您的模型。} 
\item 您可以在模型运行时调整许多参数（例如，置信度阈值、预处理平均值和比例、交换 R\+G\+B/\+B\+G\+R），而其他参数在运行时被冻结（例如，输入张量维度、后处理器类型）。一旦确定了在线可调参数的良好值，您就可以将这些值复制到 Y\+A\+ML 文件中。冻结的参数只能在 Y\+A\+ML 文件中更改。
\end{DoxyItemize}\hypertarget{UserDNNoverview_autotoc_md143}{}\doxysubsubsection{可用框架的详细信息}\label{UserDNNoverview_autotoc_md143}

\begin{DoxyItemize}
\item  and\+: \mbox{\hyperlink{UserDNNconv}{为 Je\+Vois-\/\+Pro 转换和量化深度神经网络}}
\item  and\+: \mbox{\hyperlink{UserDNNopencv}{使用 Open\+CV 在 Je\+Vois-\/\+A33 或 Je\+Vois-\/\+Pro 上运行神经网络}}
\item  only\+: \mbox{\hyperlink{UserDNNnpu}{为 Je\+Vois-\/\+Pro N\+PU 转换并运行神经网络}}
\item  only\+: \mbox{\hyperlink{UserDNNspu}{为 Hailo-\/8 S\+PU 转换并运行神经网络}}
\item  only\+: \mbox{\hyperlink{UserDNNtpu}{为 Coral T\+PU 转换并运行神经网络}}
\item  only\+: \mbox{\hyperlink{UserDNNvpu}{转换并运行 Myriad-\/X V\+PU 的神经网络}}
\item \mbox{\hyperlink{UserDNNtips}{运行自定义神经网络的技巧}} 
\end{DoxyItemize}\hypertarget{UserDNNconv}{}\doxysubsubsection{为 Je\+Vois-\/\+Pro 转换和量化深度神经网络}\label{UserDNNconv}
\hypertarget{UserDNNconv_autotoc_md131}{}\doxyparagraph{转换过程概述}\label{UserDNNconv_autotoc_md131}
一些运行 的硬件加速器要求 D\+NN 模型经过优化、量化并转换为硬件支持的操作集，然后才能在相机中运行。在本教程中，我们探索以下运行时框架的转换：


\begin{DoxyItemize}
\item $\ast$$\ast$\+Open\+C\+V$\ast$$\ast$：接受许多原样模型，与本机框架（例如 Caffe）相比，运行时速度相当快。但是，主要在 C\+PU 上运行，与专用神经加速器相比速度较慢。例外情况包括：
\item {\bfseries{Open\+CV + Inference Engine 后端 + Myriad-\/X 目标 (1.\+4 T\+O\+PS)：}} 模型通过 Open\+CV 和 Open\+Vino 框架在 Myriad-\/X V\+PU 上运行。这是在 上运行 Myriad-\/X 模型的主要方式。
\item $\ast$$\ast$\+Open\+CV + T\+I\+M-\/\+VX 后端 + N\+PU 目标 (5 T\+O\+PS)：$\ast$$\ast$量化模型在集成到 处理器中的 Verisilicon N\+PU 上运行。在 N\+PU 上运行模型可能比专门为 N\+PU 转换模型更简单（见下文）。但是，模型仍然需要量化才能使用此后端，使用此方法加载和初始化模型非常慢，运行时性能可能不如运行与 N\+PU 本机相同的模型时。\+Je\+Vois D\+NN 框架通过 \mbox{\hyperlink{classjevois_1_1dnn_1_1NetworkOpenCV}{Network\+Open\+CV}} 类支持带有 C\+P\+U、\+Myriad-\/X 和 T\+I\+M-\/\+VX 的 Open\+C\+V。
\item $\ast$$\ast$\+O\+N\+NX 运行时$\ast$$\ast$：接受 O\+N\+NX 格式的模型，并直接在 C\+PU 上运行它们，无需进一步转换。可以从 C++ 和 Python 调用。
\item {\bfseries{Verisilicon / Amlogic A311D N\+PU 集成到 Je\+Vois-\/\+Pro 处理器 (5 T\+O\+PS)：}} Verisilicon/\+Amlogic 提供的 N\+PU S\+DK 允许转换和量化模型，以便在 N\+PU 上进行本机操作。在运行时，\+N\+PU 直接连接到 Je\+Vois-\/\+Pro 的主内存，因此提供最快的数据传输速率。\+Je\+Vois 通过 \mbox{\hyperlink{classjevois_1_1dnn_1_1NetworkNPU}{Network\+N\+PU}} 类支持 N\+P\+U。
\item $\ast$$\ast$\+Hailo-\/8 (26 T\+O\+PS)：$\ast$$\ast$首先使用 Hailo Dataflow Compiler 对模型进行量化和优化，然后使用 Hailo Runtime Library 提供的运行时接口运行。\+Je\+Vois D\+NN 通过 \mbox{\hyperlink{classjevois_1_1dnn_1_1NetworkHailo}{Network\+Hailo}} 类支持 Hailo 网络。\+Hailo-\/8 通过 P\+I\+Ce 连接，速度非常快（5 G\+Bits/s）。
\item $\ast$$\ast$\+Google Coral Edge T\+P\+U（4 T\+O\+P\+S/芯片，可能采用双芯片板）：$\ast$$\ast$使用 Tensorflow-\/\+Lite 对模型进行量化，然后使用 Coral Edge\+T\+PU 编译器将其编译为硬件加速器支持的指令。\+Je\+Vois D\+NN 通过 \mbox{\hyperlink{classjevois_1_1dnn_1_1NetworkTPU}{Network\+T\+PU}} 类支持 Coral。使用 M.\+2 板时，\+Coral T\+PU 可以连接到 P\+C\+Ie（5 G\+Bits/s），也可以连接到 U\+S\+B（\+Je\+Vois-\/\+Pro 上仅提供 U\+SB 2.\+0，因为 A311D 处理器只有一个 5 G\+Bits/s 接口，我们将其用于 P\+C\+Ie，速度仅为 480 Mbits/s）。
\end{DoxyItemize}\hypertarget{UserDNNconv_autotoc_md132}{}\doxyparagraph{量化}\label{UserDNNconv_autotoc_md132}
网络量化是将网络权重从通常在服务器级 G\+PU 上使用的 32 位浮点值转换为较小的表示（例如 8 位宽）的过程。这使得模型更小、加载速度更快，并且使用专门设计为使用 8 位权重运行的嵌入式硬件处理器执行速度更快。

量化时，目标是尽可能多地使用减少的可用位来表示原始浮点值。例如，如果已知浮点值在训练期间始终处于某个范围内，例如 \mbox{[}-\/12.\+4 .. 24.\+7\mbox{]}，那么人们会希望进行量化，使得 -\/12.\+4 量化为 0，而 24.\+7 量化为 255。这样，在缩减为 8 位的情况下，整个 8 位范围 \mbox{[}0..255\mbox{]} 将用于以最大精度表示原始浮点数。

因此，成功的量化要求对网络中每一层将要处理的值的范围有一个很好的了解。这可以在训练期间实现（通过使用所谓的{\itshape 量化感知训练}，它将在训练期间跟踪每一层的值的范围），也可以在训练之后使用代表性样本数据集（{\itshape 训练后量化}，其中样本数据集将通过已经训练过的网络，并且将记录每一层处理的值的范围）。

Je\+Vois 支持以下量化方法：\hypertarget{UserDNNconv_autotoc_md133}{}\doxysubparagraph{仿射不对称（\+A\+A）}\label{UserDNNconv_autotoc_md133}
权重表示为无符号的 8 位值 \mbox{[}0..255\mbox{]}，加上比例和零点属性，描述如何将该 8 位值解释为浮点数：


\begin{DoxyCode}{0}
\DoxyCodeLine{int\_val = float\_val / scale + zero\_point \textcolor{comment}{// 从浮点数量化为整数 float\_val = (int\_val -\/ zero\_point) * scale // 从整数反量化为浮点数 }}
\end{DoxyCode}


通常，整个网络层只使用一个尺度和零点，这样我们不必为网络中的每个权重携带这些额外的参数。

例如，假设网络最初预期浮点输入值为 \mbox{[}0.\+0 .. 1.\+0\mbox{]}。我们可以使用 scale = 1/255 和 zero\+\_\+point = 0 来量化它。现在 0.\+0 映射到 0，1.0 映射到 255。

如果网络使用 \mbox{[}-\/1.\+0 .. 1.\+0\mbox{]} 中的输入，我们可以使用比例 = 1/127.\+5 和零点 = 127.\+5 进行量化。\hypertarget{UserDNNconv_autotoc_md134}{}\doxysubparagraph{动态定点（\+D\+F\+P）}\label{UserDNNconv_autotoc_md134}
权重表示为整数值（通常是有符号的 int8 或有符号的 int16），具有特殊的按位解释：
\begin{DoxyItemize}
\item 最高有效位：符号（0 表示正数，1 表示负数）
\item 接下来的 m 位：整数部分；例如，如果原始浮点值在 \mbox{[}-\/3.\+99 .. 3.\+99\mbox{]} 范围内，则 m=2 位足以表示绝对值在 \mbox{[}0 .. 3\mbox{]} 范围内的整数。
\item 接下来的 fl 位：小数部分（以 2 为基数）。
\end{DoxyItemize}

通常，动态定点规范仅指定 {\ttfamily fl} 值，其中 m 只是所选类型的位数（例如，8 位为 8）减去为符号保留的 1 位，再减去为小数部分保留的 fl 位。

D\+FP 也为整个层指定，因此我们不必为网络中的每个权重携带不同的 fl 值。

\begin{DoxyNote}{Note}
使用哪种方法取决于您自己和/或框架支持的内容。例如，\+Coral T\+PU 和 Hailo S\+PU 使用 8 位非对称仿射。\+Open\+CV 通常使用未量化的 float32。\+Myriad-\/X V\+PU 使用未量化的 float16。\+Verisilicon N\+PU 是最通用的，因为它支持 8 位非对称仿射以及 8 位和 16 位动态定点。\+Google 的 Tensorflow 团队通常推荐 uint8 非对称仿射。
\end{DoxyNote}
\hypertarget{UserDNNconv_autotoc_md135}{}\doxyparagraph{Je\+Vois Tensor 规范}\label{UserDNNconv_autotoc_md135}
Je\+Vois 使用以下规范来描述神经网络的输入和输出张量：

\textbackslash{}逐字 \mbox{[}N\+C\+HW\+:$\vert$\+N\+H\+WC\+:$\vert$\+NA\+:$\vert$\+A\+U\+TO\+:\mbox{]}类型：\mbox{[}Nx\+Cx\+Hx\+W$\vert$\+Nx\+Hx\+Wx\+C$\vert$...\mbox{]}\mbox{[}\+:Q\+NT\mbox{[}\+:fl$\vert$\+:scale\+:zero\mbox{]}\mbox{]} 


\begin{DoxyItemize}
\item 第一个字段（可选）：关于如何组织通道（通常，对于颜色输入张量，为红色、绿色和蓝色）的提示；要么：
\item {\bfseries{packed (N\+H\+WC)：}} 张量维度是批大小 N（一批中要处理的图像数量，到目前为止，\+Je\+Vois 上始终为 1，因为我们希望尽快处理每个相机图像），然后是高度，然后是宽度，然后是通道。因此，通道是变化最快的索引，对于 3 个 R\+GB 通道，数据因此在内存中组织为 R\+G\+B\+R\+G\+B\+R\+GB...
\item $\ast$$\ast$平面（\+N\+C\+H\+W）：$\ast$$\ast$现在高度和宽度的变化速度比通道快，因此对于 3 个 R\+GB 通道，这会在内存中产生 3 个连续的单通道图像或平面：\+R\+RR...G\+GG...B\+BB...
\item 如果输入不是 R\+GB 图像，则可能是其他内容。
\end{DoxyItemize}

这主要因为一些网络确实需要平面排序（从网络设计者的角度来看这更容易使用，因为可以独立处理各种颜色平面；但这不是大多数图像格式如 J\+P\+E\+G、\+P\+NG 等或相机传感器所提供的），而其他网络则需要打包像素（这可能会使网络设计更加复杂，但优点是现在可以将原生打包格式的图像直接输入到网络）。


\begin{DoxyItemize}
\item $\ast$$\ast$类型$\ast$$\ast$：值类型，例如，32F 代表 float32，8U 代表 uint8，等等。
\item Nx\+Cx\+Hx\+W（用值替换 N、\+C、\+H、\+W，例如 1x3x224x224）或 Nx\+Hx\+WxC 或任何其他张量大小规范
\item $\ast$$\ast$\+Q\+N\+T：$\ast$$\ast$量化类型：可以是 {\ttfamily N\+O\+N\+E（无量化，如果未给出量化规范则假定），{\ttfamily D\+F\+P：fl（动态定点，小数部分有} {\ttfamily fl} 位；例如，带有} D\+F\+P：7 的 int8 可以表示 \mbox{[}-\/0.\+99 .. 0.\+99\mbox{]} 中的数字，因为最高有效位用于符号，0 位用于整数部分，7 位用于小数部分），或 {\ttfamily A\+A：scale：zero\+\_\+point（仿射非对称）。原则上，{\ttfamily A\+P\+S（仿射每通道非对称）也是可能的，但我们还没有遇到它，因此目前不支持它（如果您需要它，请告诉我们）。}  在内部，\+Je\+Vois} 使用 N\+PU S\+DK 中的 {\ttfamily vsi\+\_\+nn\+\_\+tensor\+\_\+attr\+\_\+t} 结构来表示这些规范，因为与 Tensor\+Flow、\+Open\+CV 等提供的等效结构相比，这是最通用的规范。此结构和量化类型等相关规范在 \href{https://github.com/jevois/jevois/blob/master/Contrib/npu/include/ovxlib/vsi_nn_tensor.h}{\texttt{ https\+://github.\+com/jevois/jevois/blob/master/\+Contrib/npu/include/ovxlib/vsi\+\_\+nn\+\_\+tensor.\+h}} 中定义
\end{DoxyItemize}\hypertarget{UserDNNconv_autotoc_md136}{}\doxyparagraph{预处理及其对量化的影响}\label{UserDNNconv_autotoc_md136}
大多数 D\+NN 都使用某种形式的预处理，即将输入像素值准备到网络预期的范围内。这与量化是分开的，但我们将在下文中看到两者可以相互作用。

例如，\+D\+NN 设计者可能会认为 \mbox{[}-\/1.\+0 .. 1.\+0\mbox{]} 范围内的浮点输入像素值最容易训练，收敛性最好，性能最好。因此，当图像呈现给使用浮点的原始网络时，预处理包括首先将像素值从 \mbox{[}0 .. 255\mbox{]}（通常用于大多数图像格式，如 P\+N\+G、\+J\+P\+EG 等）转换为 \mbox{[}-\/1.\+0 .. 1.\+0\mbox{]} 范围。

大多数预训练网络应与预训练权重一起提供以下预处理信息：


\begin{DoxyItemize}
\item 平均值：输入的平均值是多少（通常在训练期间学习）？
\item 比例：应如何将像素值缩放为浮点值以输入到网络中？
\item stdev：输入值的标准差是多少？
\end{DoxyItemize}

通常指定比例或标准差之一，但在极少数情况下也可以同时使用两者。平均值和标准差值是红、绿、蓝的三元组，而比例值是单个标量数。

然后，预处理根据图像或相机帧中的原始 uint8 值计算要输入到网络中的浮点像素值，如下所示：


\begin{DoxyCode}{0}
\DoxyCodeLine{float\_pix = (int\_pix -\/ 平均值) * 比例 / 标准差 }
\end{DoxyCode}


预处理由设计网络以对浮点值进行操作的网络设计者指定。它最初与量化无关，量化是希望在硬件加速器上高效运行网络的人所需要的。然而，如上所述，两者可能会相互作用，有时实际上会相互抵消。例如：


\begin{DoxyItemize}
\item 假设原始浮点网络使用 \mbox{[}0.\+0 .. 1.\+0\mbox{]} 范围内的输入，预处理平均值为 \mbox{[}0 0 0\mbox{]}，预处理比例为 1/255，预处理标准差为 \mbox{[}1 1 1\mbox{]}。
\item 我们希望使用 uint8 非对称仿射对其进行量化，例如，在 Coral T\+PU 上运行。然后，我们将使用量化器零点 0 和量化器比例 1/255，以最大限度地将 \mbox{[}0.\+0 .. 1.\+0\mbox{]} 范围扩展到可用的 uint8 位。
\end{DoxyItemize}

最后，首先进行预处理然后进行量化将导致无操作：


\begin{DoxyItemize}
\item 输入像素值在 \mbox{[}0 .. 255\mbox{]} 之间
\item 预处理：float\+\_\+pix = (int\+\_\+pix -\/ preproc\+\_\+mean) $\ast$ preproc\+\_\+scale / preproc\+\_\+stdev；结果在 \mbox{[}0.\+0 .. 1.\+0\mbox{]} 之间
\item 量化：quantized\+\_\+int\+\_\+val = float\+\_\+pix / quantizer\+\_\+scale + quantizer\+\_\+zero\+\_\+point；结果返回到 \mbox{[}0 .. 255\mbox{]}
\end{DoxyItemize}

Je\+Vois \mbox{\hyperlink{classjevois_1_1dnn_1_1PreProcessorBlob}{Pre\+Processor\+Blob}} 检测诸如此类的特殊情况，并提供无操作或优化的实现。

完整的预处理涉及一些额外的步骤，例如调整输入图像的大小，可能将 R\+GB 交换为 B\+G\+R，以及可能将压缩 R\+GB 解包为平面 R\+G\+B，如 \mbox{\hyperlink{classjevois_1_1dnn_1_1PreProcessorBlob}{Pre\+Processor\+Blob}} 文档中所述\hypertarget{UserDNNconv_autotoc_md137}{}\doxyparagraph{后期处理和去量化}\label{UserDNNconv_autotoc_md137}
当量化网络运行时，它通常会输出量化表示。

因此，后处理将做两件事：


\begin{DoxyItemize}
\item 使用量化网络的输出层规范所指定的 D\+F\+P、\+AA 等，将 uint8、int8 等反量化回浮点数，并使用量化操作的逆操作。
\item 解释结果并产生人类可用的输出（例如，对于 Y\+O\+L\+O，解码网络输出中的框，可以将其绘制到已处理的图像上）。
\end{DoxyItemize}

有时，反量化是没有必要的；例如，语义分割网络通常只输出一个 uint8 值数组，其中的值直接是输入图像中每个像素分配的对象类别编号。\hypertarget{UserDNNconv_autotoc_md138}{}\doxyparagraph{网络转换程序}\label{UserDNNconv_autotoc_md138}
以下页面描述了每个可用框架的一般程序和详细信息：


\begin{DoxyItemize}
\item \mbox{\hyperlink{UserDNNoverview}{在 Je\+Vois-\/\+A33 和 Je\+Vois-\/\+Pro 上运行神经网络}} -\/ \mbox{\hyperlink{UserDNNopencv}{使用 Open\+CV 在 Je\+Vois-\/\+A33 或 Je\+Vois-\/\+Pro 上运行神经网络}} -\/ \mbox{\hyperlink{UserDNNnpu}{为 Je\+Vois-\/\+Pro N\+PU 转换并运行神经网络}} -\/ \mbox{\hyperlink{UserDNNspu}{为 Hailo-\/8 S\+PU 转换并运行神经网络}} -\/ \mbox{\hyperlink{UserDNNtpu}{为 Coral T\+PU 转换并运行神经网络}} -\/ \mbox{\hyperlink{UserDNNvpu}{转换并运行 Myriad-\/X V\+PU 的神经网络}}
\end{DoxyItemize}

\begin{DoxyNote}{Note}
您可能不需要安装这些框架的完整转换工具包，而是想尝试 U\+S\+C/i\+Lab 在线模型转换器，这是一个简单的 Web 界面，可让您上传原始网络，然后将转换后的网络直接下载到您的 Je\+Vois-\/\+Pro 相机上。
\end{DoxyNote}
\hypertarget{UserDNNconv_autotoc_md139}{}\doxyparagraph{提示}\label{UserDNNconv_autotoc_md139}

\begin{DoxyItemize}
\item 通常，预处理规模很小，例如 1/127.\+5 = 0.\+00784313
\item 通常，预处理平均值为 \mbox{[}0 0 0\mbox{]} 或 \mbox{[}128 128 128\mbox{]} 左右
\item 通常，预处理标准差是 \mbox{[}1 1 1\mbox{]} 或 \mbox{[}64 64 64\mbox{]} 左右
\item 量化参数在模型转换过程中计算。对于使用 AA 的输入层，量化比例通常是一个较小的数字，如 1/127.\+5，而量化零点通常为 0 或 128 左右。 
\end{DoxyItemize}\hypertarget{UserDNNopencv}{}\doxysubsubsection{使用 Open\+CV 在 Je\+Vois-\/\+A33 或 Je\+Vois-\/\+Pro 上运行神经网络}\label{UserDNNopencv}
Open\+CV 提供了一个 D\+NN 模块，允许在 和 上运行神经网络推理。这通常是运行神经网络最简单的方法，因为不需要转换、量化等。然而，这也是 最慢的方法，因为推理在 C\+PU 上运行，这比 上可用的一些专用硬件加速器要慢。

支持的神经网络框架====================================


\begin{DoxyItemize}
\item Caffe
\item Tensor\+Flow
\item O\+N\+N\+X（以及通过转换为 O\+N\+NX 的 py\+Torch）
\item Darknet
\end{DoxyItemize}

程序 =========


\begin{DoxyItemize}
\item 阅读并理解有关 \mbox{\hyperlink{UserDNNoverview}{在 Je\+Vois-\/\+A33 和 Je\+Vois-\/\+Pro 上运行神经网络}} 的 Je\+Vois 文档
\item 查看 \href{https://docs.opencv.org/4.x/d2/d58/tutorial_table_of_content_dnn.html}{\texttt{ 官方 Open\+CV D\+NN 文档}}
\item 运行时推理所需的一切（完整的 Open\+C\+V，包括所有可用的后端、目标等）都已预先安装在您的 Je\+Vois micro\+SD 上。
\item 获得模型：训练您自己的模型，或下载预先训练的模型。
\item 获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、\+R\+GB 或 B\+G\+R、打包（\+N\+W\+H\+C）或平面（\+N\+C\+H\+W）像素等）。
\item 将模型复制到 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Je\+Vois micro\+SD 卡
\item 为您的模型创建一个 Je\+Vois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Y\+A\+ML 文件
\item 启动 Je\+Vois 模块。它将扫描自定义目录以查找任何有效的 Y\+A\+ML 文件，并使您的模型作为 D\+NN 模块的 Pipeline 组件的 {\ttfamily 管道参数的一个可用值。选择该管道以运行您的模型。} 
\end{DoxyItemize}

示例：使用 Caffe 中的 Res\+Net-\/18 进行图像分类 =======================================================

让我们运行 Res\+Net-\/18 图像分类模型。在这里，我们将只获得一个在 Image\+Net 数据集上经过预训练的模型，但对于您在自己的自定义数据集上训练的模型，步骤应该非常相似。

在网上快速搜索“\+Res\+Net-\/18 Caffe”会出现这个链接，它似乎有我们需要的一切：https\+://github.com/\+Holmes\+Shuan/\+Res\+Net-\/18-\/\+Caffemodel-\/on-\/\+Image\+Net


\begin{DoxyEnumerate}
\item 获取模型并复制到micro\+SD -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}

首先我们下载模型。对于 Caffe，有两个文件：一个 {\bfseries{}}.prototxt 文件，描述网络层；一个 {\bfseries{}}.caffemodel 文件，包含训练后的权重。

在该 Git\+Hub 链接上可用的文件中，我们需要 $\ast$$\ast$deploy.prototxt$\ast$$\ast$，它是用于运行时推理的文件；我们将它保存为 $\ast$$\ast$\+J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/resnet-\/18.prototxt$\ast$$\ast$。然后我们获得训练后的权重并将其保存到 $\ast$$\ast$\+J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/resnet-\/18.caffemodel$\ast$$\ast$。

\begin{DoxyNote}{Note}
在 上，将数据保存到 micro\+SD 的最简单方法是将其从相机中弹出并将其连接到您的桌面。在 上，您可能希望将相机连接到网络（请参阅 Pro\+Network）并使用 \mbox{\hyperlink{ProUserQuick}{Je\+Vois-\/\+Pro 快速入门用户指南}} 中说明的方法，以获得更顺畅的工作流程：特别是，请参阅有关在控制台模式下启动的部分，这样就可以轻松地在运行 X 以浏览网页、下载文件等之间切换，然后返回控制台以启动 Je\+Vois 软件。

在 运行时，micro\+SD 的 J\+E\+V\+O\+I\+S\+P\+R\+O：分区安装在 /jevoispro 上，因此文件进入 /jevoispro/share/dnn/custom/
\end{DoxyNote}

\begin{DoxyEnumerate}
\item 获取一些有关预处理的信息 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}

现在我们需要预处理参数，例如图像大小、均值和尺度等。我们查看$\ast$$\ast$train.prototxt$\ast$$\ast$来寻找任何线索，我们发现：


\begin{DoxyItemize}
\item $\ast$$\ast$crop\+\_\+size\+: 224$\ast$$\ast$（这意味着模型需要 224x224 的输入图像）
\item $\ast$$\ast$平均值：104；平均值：117；平均值：123$\ast$$\ast$（我们将使用这些平均值；这里不清楚它们是按 R\+GB 顺序还是 B\+GR 顺序）。
\item 目前尚不清楚模型是否需要 R\+GB 或 B\+G\+R、\+N\+C\+HW 或 N\+H\+W\+C，我们不知道输入的比例或标准差......模型运行后，我们可以研究这些。
\item 要找出输入形状，我们可以使用 Lutz Roeder 出色的 \href{https://netron.app/}{\texttt{ Netron}} 在线模型检查工具：
\item 将浏览器指向 \href{https://netron.app/}{\texttt{ https\+://netron.\+app/}}
\item 单击“打开模型...”
\item 上传 resnet-\/18.\+prototxt
\item 单击输入层和输出层的框以查看有关它们的一些信息
\item 我们发现对于这个 resnet-\/18，输入形状为 1x3x224x224，即 N\+C\+HW 顺序（平面 R\+GB 颜色）
\item Intel Open\+Vino 员工非常擅长记录模型输入和输出。虽然我们在这里使用的特定模型可能与他们使用的模型不完全相同，但快速搜索“openvino resnet-\/18”会出现 \href{https://docs.openvino.ai/latest/omz_models_model_resnet_18_pytorch.html}{\texttt{ https\+://docs.\+openvino.\+ai/latest/omz\+\_\+models\+\_\+model\+\_\+resnet\+\_\+18\+\_\+pytorch.\+html}}，它为我们提供了有关原始模型的一些有趣信息：
\item 输入形状 N\+C\+WH\+:1x3x224x224
\item 平均值 \mbox{[}123.\+675, 116.\+28, 103.\+53\mbox{]}
\item 比例 \mbox{[}58.\+395, 57.\+12, 57.\+375\mbox{]}
\item 通道顺序 R\+GB
\end{DoxyItemize}

让我们使用它们。如 \mbox{\hyperlink{UserDNNconv}{为 Je\+Vois-\/\+Pro 转换和量化深度神经网络}} 中所述，在 Je\+Vois 中，预处理 {\ttfamily scale} 是一个通常很小的标量（如 0.\+0078125），但预处理 {\ttfamily stdev} 也可用，它通常是 \mbox{[}64 64 64\mbox{]} 左右的三元组；因此，为了我们的目的，这里给出的 scale 似乎应该被解释为 {\ttfamily stdev。} 

\begin{DoxyNote}{Note}
理想情况下，您将通过自己训练自己的自定义模型来了解所有这些参数，而不是像我们在这里一样仅仅下载通用的预训练模型。
\end{DoxyNote}

\begin{DoxyEnumerate}
\item 创建一个 Y\+A\+ML zoo 文件，以便 Je\+Vois 可以运行我们的模型 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}

我们根据 上使用 Caffe 在 Open\+CV 中运行的一些其他分类模型对我们的 Y\+A\+ML 文件进行建模。例如，在 {\bfseries{opencv.\+yml}}（可在 的“配置”选项卡中找到）中，我们发现 Squeeze\+Net 也是一个 caffemodel。因此，我们受 Squeeze\+Net 的启发，创建了自己的 Y\+A\+ML 文件 $\ast$$\ast$\+J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/resnet-\/18.yml$\ast$$\ast$：


\begin{DoxyCode}{0}
\DoxyCodeLine{ \%YAML 1.0 -\/-\/-\/}
\DoxyCodeLine{}
\DoxyCodeLine{ResNet-\/18： preproc：Blob nettype：OpenCV postproc：分类模型：“dnn/custom/resnet-\/18.caffemodel”配置：“dnn/custom/resnet-\/18.prototxt”强度：“NCHW：32F：1x3x224x224”平均值：“123.675 116.28 103.53”比例：1.0 stdev：“58.395 57.12 57.375”\textcolor{comment}{\# 见下文，需要调整！ rgb：true 类：“coral/classification/imagenet\_labels.txt”类偏移量：1 }}
\end{DoxyCode}


\begin{DoxyNote}{Note}
对于 {\ttfamily 类，我们使用已预加载到} micro\+SD 上的现有 Image\+Net 标签文件，因为上面使用的 Git\+Hub 存储库未提供该文件。由于该标签文件的第一个条目为“background”，而这在许多模型中并未使用，因此如果我们的网络不使用该额外类名，我们可能必须使用 {\ttfamily classoffset} 1 来移动类标签。如果您使用自定义训练模型，您还应将文件 {\bfseries{resnet-\/18.\+labels}} 复制到 micro\+S\+D，该文件描述了您的类名（每行一个类标签），然后将 classes 参数设置为该文件。
\end{DoxyNote}
如果您想知道 Y\+A\+ML 文件中各个条目的含义，请查看 User\+D\+N\+Noverview，每个条目都记录在使用它们的类中（jevois\+::dnn\+::\+Pre\+Processor、jevois\+::dnn\+::\+Network、jevois\+::dnn\+::\+Post\+Processor、jevois\+::dnn\+::\+Pipeline）。


\begin{DoxyEnumerate}
\item 测试模型并调整任何参数 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 选择 机器视觉模块
\item 将 {\ttfamily 管道参数设置为} {\bfseries{Open\+C\+V\+:\+Classify\+:Res\+Net-\/18}}
\item 如果您没有看到预期的输出，请尝试在 Je\+Vois G\+UI 中实时调整预处理器参数。例如，最初网络没有显示任何高于阈值的输出类别。由于我们不确定 {\ttfamily stdev，我们可以在} G\+UI 中将其设置为 \mbox{[}1 1 1\mbox{]}，现在我们看到了预期的输出！
\item 如果您需要调整 Y\+A\+ML 文件设置，您可以在 的“配置”选项卡下找到该文件。因此，我们在这里编辑 Y\+A\+ML 文件以进行更改：
\begin{DoxyCode}{0}
\DoxyCodeLine{stdev: \textcolor{stringliteral}{"1 1 1"} }
\end{DoxyCode}
 或者，由于 \mbox{[}1 1 1\mbox{]} 是默认值，我们可以删除 {\bfseries{stdev\+:}} 行。
\end{DoxyItemize}

  

它成功了（此处显示在 Je\+Vois-\/\+Pro 上）！由于它在 C\+PU 上运行，所以不是最快的，但模型导入成功。当将相机指向书架时，书柜/书店分类输出通常是我们在 Image\+Net 上训练的分类模型所获得的结果。

也许我们对平均值的顺序（\+R\+GB 与 B\+G\+R）有误。一旦您确认模型需要的是 R\+GB 还是 B\+G\+R，以及 R、G 和 B 的平均值是多少，您就可以在 G\+UI 或 Y\+A\+ML 文件中实时调整平均值参数。


\begin{DoxyEnumerate}
\item 提示 -\/-\/-\/-\/---
\end{DoxyEnumerate}

请参阅 \mbox{\hyperlink{UserDNNtips}{运行自定义神经网络的技巧}} \hypertarget{UserDNNnpu}{}\doxysubsubsection{为 Je\+Vois-\/\+Pro N\+PU 转换并运行神经网络}\label{UserDNNnpu}
 包含一个 5-\/T\+O\+PS 神经处理单元 (N\+PU)，该单元集成在 Amlogic A311D 处理器中。该神经加速器与主内存的连接速度最快（直接 D\+MA 访问），因此数据传输和网络执行速度非常快。此外，它不会像其他一些加速器那样受到片上内存有限的困扰，因此相当大的网络可以在 N\+PU 上运行。

\begin{DoxyNote}{Note}
仅限。 不支持此加速器。
\end{DoxyNote}
支持的神经网络框架====================================


\begin{DoxyItemize}
\item Caffe
\item Tensor\+Flow
\item Tensor\+Flow-\/\+Lite
\item O\+N\+N\+X（以及通过转换为 O\+N\+NX 的 py\+Torch）
\item Darknet
\item Keras
\end{DoxyItemize}

N\+PU 可以运行量化为 uint8、int8 或 int16 权重的模型。它不支持浮点权重，因此需要量化和转换。硬件支持的操作和层类型数量有限，这进一步限制了可以在其上运行的内容。但它比标准 C\+PU 快很多倍。

为了在 N\+PU 上执行，您的模型将被量化，然后在 Linux 桌面上转换为专有 blob 格式，然后可以将其传输到 Je\+Vois-\/\+Pro micro\+SD 进行执行。

程序 =========


\begin{DoxyItemize}
\item 阅读并理解有关 \mbox{\hyperlink{UserDNNoverview}{在 Je\+Vois-\/\+A33 和 Je\+Vois-\/\+Pro 上运行神经网络}} 的 Je\+Vois 文档
\item 确保你理解 \mbox{\hyperlink{UserDNNconv}{为 Je\+Vois-\/\+Pro 转换和量化深度神经网络}} 中的量化概念
\item 查看 \href{https://github.com/khadas/aml_npu_sdk/tree/master/docs}{\texttt{ N\+PU S\+DK 文档}}。特别值得关注的是 \href{https://github.com/khadas/aml_npu_sdk/blob/master/docs/}{\texttt{ 模型转码和运行用户指南}}。
\item N\+PU 仅支持一组特定的层类型。如果您尝试转换包含不受支持的层的网络，转换有时可能看似成功，但转换后的网络可能无法运行。在尝试转换网络之前，请先查看 \href{https://github.com/khadas/aml_npu_sdk/blob/master/docs/}{\texttt{ 层和操作支持指南}}。
\item 您需要下载并安装 Amlogic N\+PU S\+DK 才能在运行 Linux Ubuntu 20.\+04 的台式计算机上转换/量化您的模型。
\item 运行时所需的一切（\+N\+PU 运行时库）都已预先安装在您的 Je\+Vois-\/\+Pro micro\+SD 上。
\item 获得模型：训练您自己的模型，或下载预先训练的模型。
\item 获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、\+R\+GB 或 B\+G\+R、打包（\+N\+W\+H\+C）或平面（\+N\+C\+H\+W）像素等）。
\item 将模型复制到 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Je\+Vois-\/\+Pro micro\+SD 卡
\item 为您的模型创建一个 Je\+Vois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Y\+A\+ML 文件
\item 启动 Je\+Vois 模块。它将扫描自定义目录以查找任何有效的 Y\+A\+ML 文件，并使您的模型作为 D\+NN 模块的 Pipeline 组件的 {\ttfamily 管道参数的一个可用值。选择该管道以运行您的模型。} 
\end{DoxyItemize}

设置 N\+PU S\+DK ========================

\begin{DoxyNote}{Note}
以下所有内容均应在运行 Ubuntu 20.\+04 Linux 的快速 x86\+\_\+64 台式计算机上运行，​​而不是在您的 Je\+Vois-\/\+Pro 相机上运行。最后，我们将转换后的模型复制到 micro\+S\+D，然后使用该模型在 Je\+Vois-\/\+Pro 上运行推理。
\end{DoxyNote}
Amlogic/\+Veri\+Silicon N\+PU S\+DK 由 Khadas 分发，该公司制造使用与 相同的 Amlogic A311D 处理器的开发板。


\begin{DoxyCode}{0}
\DoxyCodeLine{git lfs clone -\/-\/recursive https://github.com/khadas/aml\_npu\_sdk.git cd aml\_npu\_sdk/acuity-\/toolkit/demo }
\end{DoxyCode}


无需安装 Ubuntu 包或 Python wheels，所有内容都包含在该 git repo 中。

其中有 3 个脚本需要编辑，然后在桌面上按顺序运行：


\begin{DoxyItemize}
\item $\ast$$\ast$0\+\_\+import\+\_\+model.sh$\ast$$\ast$：从源框架（\+Caffe、\+Tensor\+Flow 等）转换为中间表示，然后计算样本数据集上每一层遇到的值范围的一些统计数据。这些值范围将用于设置量化参数。
\item $\ast$$\ast$1\+\_\+quantize\+\_\+model.sh$\ast$$\ast$：使用非对称仿射 uint8 或动态定点 int8 或 int16 量化模型。这将生成我们将在 上运行的模型，采用 {\bfseries{.nb}} 专有二进制 blob 格式。
\item $\ast$$\ast$2\+\_\+export\+\_\+case\+\_\+code.sh$\ast$$\ast$：创建一些可以在目标平台（如 Je\+Vois-\/\+Pro）上编译的 C 代码，以创建一个独立的应用程序，该应用程序将在一个图像上加载和运行模型。我们不会使用该代码，因为 Je\+Vois 软件提供了自己的代码，可将模型直接链接到相机传感器和 G\+U\+I。但是，我们将对其进行检查，以便我们可以获取 Y\+A\+ML zoo 文件的输入和输出规范。
\end{DoxyItemize}

对于第 2 步，我们需要一个有代表性的样本数据集，通常是来自训练或验证集的约 100 张图像。这非常重要，因为它将设置量化参数。

示例：使用 Y\+O\+L\+Ov7-\/tiny 进行对象检测 =============================================

我们选择 Y\+O\+L\+Ov7-\/tiny 作为本教程的原因是：


\begin{DoxyItemize}
\item 它以 Darknet 格式提供，仅使用 N\+PU 支持的操作和层
\item Je\+Vois 已经为其提供了后处理器
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 获取模型 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 前往 \href{https://github.com/AlexeyAB/darknet}{\texttt{ https\+://github.\+com/\+Alexey\+A\+B/darknet}}
\item 让我们下载在 416x416 输入上运行的 Y\+O\+L\+Ov7-\/tiny。单击最新版本，然后单击底部资产列表中的 {\bfseries{yolov7-\/tiny.\+weights，或者运行以下命令：@code}} \{.py\} wget \href{https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov7-tiny.weights}{\texttt{ https\+://github.\+com/\+Alexey\+A\+B/darknet/releases/download/yolov4/yolov7-\/tiny.\+weights}} 
\item 我们还需要网络结构的描述，我们可以在 repo 的 {\bfseries{cfg}} 文件夹中找到它：
\begin{DoxyCode}{0}
\DoxyCodeLine{wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov7-\/tiny.cfg }
\end{DoxyCode}

\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 获取样本数据集 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 此模型在 \href{https://cocodataset.org}{\texttt{ C\+O\+CO 数据集}} 上进行训练。让我们下载 \href{http://images.cocodataset.org/zips/val2017.zip}{\texttt{ 2017 年验证集}}：
\begin{DoxyCode}{0}
\DoxyCodeLine{wget http://images.cocodataset.org/zips/val2017.zip unzip val2017.zip }
\end{DoxyCode}

\item 有 5,000 张图像，比我们需要的多。unix 命令“shuf”可以随机打乱名称列表并取前 {\ttfamily n，因此让我们使用它从数据集中抓取} 100 张随机图像。我们将这些文件路径的列表保存到 {\bfseries{dataset.\+txt}}，供 {\bfseries{0\+\_\+import\+\_\+model.\+sh}} 使用：
\begin{DoxyCode}{0}
\DoxyCodeLine{ls ./val2017/*.jpg | shuf -\/n 100 > dataset.txt }
\end{DoxyCode}

\item {\bfseries{dataset.\+txt}} 现在应包含 100 行（由于 shuf 是随机的，因此您的结果会有所不同）：
\begin{DoxyCode}{0}
\DoxyCodeLine{./val2017/000000382030.jpg ./val2017/000000436617.jpg ./val2017/000000138550.jpg ./val2017/000000226154.jpg ./val2017/000000319369.jpg ... }
\end{DoxyCode}

\end{DoxyItemize}

3.编辑并运行0\+\_\+import\+\_\+model.\+sh -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item 该文件包含各种框架的各种注释示例。在这里我们需要：
\item 更改名称
\item 启用 Darknet 简介，注释掉其他框架。注意：pegasus 运行两次，第一次用于导入，然后生成有关输入的元数据。我们只用我们要从中导入的框架替换第一个。
\end{DoxyItemize}

+（\+Darknet 不需要，其他可能需要）将输入大小列表设置为我们的输入大小，根据 $\ast$$\ast$yolov7-\/tiny.cfg$\ast$$\ast$，这里是 1x3x416x416。 +我们需要知道输入预处理比例、平均值、标准差。\+Tiny Y\+O\+LO v7 只期望像素值在 \mbox{[}0.\+0 .. 1.\+0\mbox{]} 内的 R\+GB 图像。因此我们将使用平均值 = \mbox{[}0 0 0\mbox{]}、标准差 = \mbox{[}1 1 1\mbox{]}、比例 = 1/255 = 0.\+0039215686、rgb = true。


\begin{DoxyItemize}
\item 下面，$\ast$$\ast$channel-\/mean-\/value$\ast$$\ast$ 需要 4 个值：3 个颜色通道的 3 个均值和 1 个比例。
\item 我们最终得到这个修改后的 {\bfseries{0\+\_\+import\+\_\+model.\+sh}}\+:
\begin{DoxyCode}{0}
\DoxyCodeLine{ \textcolor{comment}{\#!/bin/bash}}
\DoxyCodeLine{}
\DoxyCodeLine{NAME=yolov7-\/tiny \textcolor{comment}{\# JEVOIS 编辑了 ACUITY\_PATH=../bin/}}
\DoxyCodeLine{}
\DoxyCodeLine{pegasus=\$\{ACUITY\_PATH\}pegasus 如果 [ !-\/e \textcolor{stringliteral}{"\$pegasus"} ]; 然后 pegasus=\$\{ACUITY\_PATH\}pegasus.py fi}
\DoxyCodeLine{}
\DoxyCodeLine{\$pegasus 导入 darknet\(\backslash\) -\/-\/模型 \$\{NAME\}.cfg \(\backslash\) -\/-\/weights \$\{NAME\}.weights \(\backslash\) -\/-\/输出模型 \$\{NAME\}.json \(\backslash\) -\/-\/输出数据 \$\{NAME\}.data \(\backslash\) \$pegasus 生成输入元数据 \(\backslash\) -\/-\/模型 \$\{NAME\}.json \(\backslash\) -\/-\/输入元数据输出 \$\{NAME\}\_inputmeta.yml \(\backslash\) -\/-\/通道平均值“0 0 0 0.0039215686” \(\backslash\) \textcolor{comment}{\# JEVOIS 编辑 -\/-\/源文件数据集.txt }}
\end{DoxyCode}

\end{DoxyItemize}

\begin{DoxyNote}{Note}
请勿剪切和粘贴上面的“\# J\+E\+V\+O\+IS 编辑”注释，它们会破坏代码，请将其删除。
\end{DoxyNote}

\begin{DoxyItemize}
\item 运行它，它应该完成并且没有错误：
\begin{DoxyCode}{0}
\DoxyCodeLine{./0\_import\_model.sh }
\end{DoxyCode}

\item 您可以查看 yolov7-\/tiny\+\_\+inputmeta.\+yml 了解输入参数的描述，查看 yolov7-\/tiny.\+json 了解模型图的描述。
\item 如果此步骤出现错误，则可能是某些操作不受支持，这可能发生在网络末端。在这种情况下，请检查 Netron 中的网络并查看哪一层转换失败，然后添加 {\bfseries{--outputs /some/layer}} 以将网络截断到该层。
\end{DoxyItemize}

4.编辑并运行1\+\_\+quantize\+\_\+model.\+sh -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item 因为我们的输入范围是\mbox{[}0.\+0 .. 1.\+0\mbox{]}，这需要 uint8 非对称仿射量化，以便我们的预处理和随后的量化将减少为无操作（参见 User\+D\+N\+Nconv）。
\item 因此我们启用该功能并更改模型名称，最终得到修改后的 {\bfseries{1\+\_\+quantize\+\_\+model.\+sh}}\+:
\begin{DoxyCode}{0}
\DoxyCodeLine{ \textcolor{comment}{\#!/bin/bash}}
\DoxyCodeLine{}
\DoxyCodeLine{NAME=yolov7-\/tiny \textcolor{comment}{\# JEVOIS 编辑了 ACUITY\_PATH=../bin/}}
\DoxyCodeLine{}
\DoxyCodeLine{pegasus=\$\{ACUITY\_PATH\}pegasus 如果 [ !-\/e \textcolor{stringliteral}{"\$pegasus"} ]; 然后 pegasus=\$\{ACUITY\_PATH\}pegasus.py fi}
\DoxyCodeLine{}
\DoxyCodeLine{\$pegasus quantize \(\backslash\) -\/-\/quantizer asymmetric\_affine \(\backslash\) \textcolor{comment}{\# JEVOIS 编辑 -\/-\/qtype uint8 \(\backslash\) \# JEVOIS 编辑 -\/-\/rebuild \(\backslash\) -\/-\/with-\/input-\/meta \$\{NAME\}\_inputmeta.yml \(\backslash\) -\/-\/model \$\{NAME\}.json \(\backslash\) -\/-\/model-\/data \$\{NAME\}.data }}
\end{DoxyCode}

\item 运行它，它应该会顺利完成：
\begin{DoxyCode}{0}
\DoxyCodeLine{./1\_quantize\_model.sh }
\end{DoxyCode}

\item 您可以查看 yolov7-\/tiny.\+quantize 以查看样本数据集上每个层的最小/最大值范围，以及每个层如何相应地量化。下一个脚本运行时，此文件将被删除。
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 编辑并运行2\+\_\+export\+\_\+case\+\_\+code.\+sh -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 在这里，我们只需要设置模型名称，并选择正确的 N\+PU 模型，对于 中的 A311D 处理器，其为 $\ast$$\ast$\+V\+I\+P\+N\+A\+N\+O\+Q\+I\+\_\+\+P\+I\+D0\+X88$\ast$$\ast$。我们最终得到：
\begin{DoxyCode}{0}
\DoxyCodeLine{ \textcolor{comment}{\#!/bin/bash}}
\DoxyCodeLine{}
\DoxyCodeLine{NAME=yolov7-\/tiny \textcolor{comment}{\# JEVOIS 编辑了 ACUITY\_PATH=../bin/}}
\DoxyCodeLine{}
\DoxyCodeLine{pegasus=\$ACUITY\_PATH/pegasus 如果 [ !-\/e \textcolor{stringliteral}{"\$pegasus"} ]; 然后 pegasus=\$ACUITY\_PATH/pegasus.py fi}
\DoxyCodeLine{}
\DoxyCodeLine{\$pegasus 导出 ovxlib \(\backslash\) -\/-\/model \$\{NAME\}.json \(\backslash\) -\/-\/model-\/data \$\{NAME\}.data \(\backslash\) -\/-\/model-\/quantize \$\{NAME\}.quantize \(\backslash\) -\/-\/\textcolor{keyword}{with}-\/input-\/meta \$\{NAME\}\_inputmeta.yml \(\backslash\) -\/-\/dtype quantized \(\backslash\) -\/-\/optimize VIPNANOQI\_PID0X88 \(\backslash\) \textcolor{comment}{\# JEVOIS 编辑 -\/-\/viv-\/sdk \$\{ACUITY\_PATH\}vcmdtools \(\backslash\) -\/-\/pack-\/nbg-\/unify}}
\DoxyCodeLine{}
\DoxyCodeLine{rm -\/rf \$\{名称\}\_nbg\_unify}
\DoxyCodeLine{}
\DoxyCodeLine{mv../*\_nbg\_unify\$\{名称\}\_nbg\_unify}
\DoxyCodeLine{}
\DoxyCodeLine{cd \$\{名称\}\_nbg\_unify}
\DoxyCodeLine{}
\DoxyCodeLine{mv network\_binary.nb \$\{NAME\}.nb}
\DoxyCodeLine{}
\DoxyCodeLine{光盘 ..}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# 保存正常情况演示导出.数据 mkdir -\/p \$\{NAME\}\_normal\_case\_demo mv *.h *.c .project .cproject *.vcxproj BUILD *.linux *.export.data \$\{NAME\}\_normal\_case\_demo}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# 删除 normal\_case 演示源 \#rm *.h *.c .project .cproject *.vcxproj BUILD *.linux *.export.data}}
\DoxyCodeLine{}
\DoxyCodeLine{rm *.数据 *.量化 *.json *\_inputmeta.yml }
\end{DoxyCode}

\item 运行它，它应该完成并且没有错误：
\begin{DoxyCode}{0}
\DoxyCodeLine{./2\_export\_case\_code.sh }
\end{DoxyCode}

\item 好的，我们需要的一切都在 yolov7-\/tiny\+\_\+nbg\+\_\+unify/
\item 转换后的模型：yolov7-\/tiny.nb
\item C 代码：vnn\+\_\+yolov7tiny.\+c，我们将检查它以得出我们的输入和输出张量规范。
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 创建 Y\+A\+ML zoo 文件 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 我们从 Je\+Vois micro\+SD 中已有的 zoo 文件 npu.\+yml 中的 {\bfseries{Yolo\+V4}} 条目开始（并且可以在 G\+UI 的 Config 选项卡中使用）。
\item 为了获取量化输入和输出的规格，我们检查 yolov7-\/tiny\+\_\+nbg\+\_\+unify/vnn\+\_\+yolov7tiny.\+c 并查找张量定义。我们找到了这个（添加了注释来解释下一步）：
\begin{DoxyCode}{0}
\DoxyCodeLine{ \textcolor{comment}{/*-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/ Tensor Initialize -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/*/} attr.dtype.fmt = VSI\_NN\_DIM\_FMT\_NCHW; \textcolor{comment}{/* @input\_0:out0 */} attr.size[0] = 416; \textcolor{comment}{// JEVOIS：最后一个维度（变化最快；此处为 W）attr.size[1] = 416; // JEVOIS：下一个维度（此处为 H）attr.size[2] = 3; // JEVOIS：下一个维度（此处为 C）attr.size[3] = 1; // JEVOIS：第一个维度（此处为 N）attr.dim\_num = 4; // JEVOIS：输入应为 4D 张量 attr.dtype.scale = 0.003921568393707275; // JEVOIS：AA 量化的比例 attr.dtype.zero\_point = 0; // JEVOIS：AA 量化的零点 attr.dtype.qnt\_type = VSI\_NN\_QNT\_TYPE\_AFFINE\_ASYMMETRIC; // JEVOIS：即 AA 量化 NEW\_NORM\_TENSOR(norm\_tensor[0], attr, VSI\_NN\_TYPE\_UINT8); // JEVOIS：即 8U 类型}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{/* @output\_90\_198:out0 */} attr.size[0] = 52; attr.size[1] = 52; attr.size[2] = 255; attr.size[3] = 1; attr.dim\_num = 4; attr.dtype.scale = 0.0038335032295435667; attr.dtype.zero\_point = 0; attr.dtype.qnt\_type = VSI\_NN\_QNT\_TYPE\_AFFINE\_ASYMMETRIC; \mbox{\hyperlink{NetworkNPU_8C_a677822a5b02c848b6d8eefcc94e6ad74}{NEW\_NORM\_TENSOR}}(norm\_tensor[1], attr, VSI\_NN\_TYPE\_UINT8);}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{/* @output\_94\_205:out0 */} attr.size[0] = 26; attr.size[1] = 26; attr.size[2] = 255; attr.size[3] = 1; attr.dim\_num = 4; attr.dtype.scale = 0.0038371747359633446; attr.dtype.zero\_point = 0; attr.dtype.qnt\_type = VSI\_NN\_QNT\_TYPE\_AFFINE\_ASYMMETRIC; \mbox{\hyperlink{NetworkNPU_8C_a677822a5b02c848b6d8eefcc94e6ad74}{NEW\_NORM\_TENSOR}}(norm\_tensor[2], attr, VSI\_NN\_TYPE\_UINT8);}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{/* @output\_98\_212:out0 */} attr.size[0] = 13; attr.size[1] = 13; attr.size[2] = 255; attr.size[3] = 1; attr.dim\_num = 4; attr.dtype.scale = 0.003918845672160387; attr.dtype.zero\_point = 0; attr.dtype.qnt\_type = VSI\_NN\_QNT\_TYPE\_AFFINE\_ASYMMETRIC; \mbox{\hyperlink{NetworkNPU_8C_a677822a5b02c848b6d8eefcc94e6ad74}{NEW\_NORM\_TENSOR}}(norm\_tensor[3], attr, VSI\_NN\_TYPE\_UINT8);}
\DoxyCodeLine{}
\DoxyCodeLine{因此，我们有一个输入和三个输出（针对 3 个 YOLO 尺度），并且我们从上面生成的代码中得出它们的 JeVois 规格，如下所示（参见 \(\backslash\)ref UserDNNconv）：\(\backslash\)code\{.py\} intensors：“NCHW：8U：1x3x416x416：AA：0.003921568393707275：0” outtensors：“8U：1x255x52x52：AA：0.0038335032295435667：0， 8U：1x255x26x26：AA：0.0038371747359633446：0， 8U：1x255x13x13：AA：0.003918845672160387：0” }
\end{DoxyCode}

\item 对于 Y\+O\+LO 后处理，我们需要锚点的定义。我们从 yolov7-\/tiny.\+cfg 中获取这些内容：
\begin{DoxyCode}{0}
\DoxyCodeLine{anchors = 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 }
\end{DoxyCode}
 在下面的 Y\+A\+ML 文件中，我们将按 Y\+O\+LO 尺度拆分此列表（此处，9 个 w,h 对对应 3 个尺度中的 3 对。我们在下面用分号分隔尺度）。
\item 由于 Y\+O\+L\+Ov7 使用“新样式”的 Y\+O\+LO 坐标，我们需要禁用后处理器 sigmoid 并将后处理器 scalexy 设置为 2.\+0。对于 Y\+O\+L\+Ov5/v7，您可能希望这样做，并将 sigmoid 设置为 true 并将 scalexy 设置为 0.\+0，以便为 Y\+O\+L\+Ov2/v3/v4 使用旧样式的框坐标。您可以在 jevois\+::dnn\+::\+Post\+Processor\+Detect\+Y\+O\+L\+O\+::yolo\+\_\+one() 中查看差异
\item 我们只需修改名称和文件位置，将所有全局定义放入我们的文件中（例如 preproc、nettype 等，它们在 npu.\+yml 中全局设置，因此对于我们正在复制的 Yolo\+V4 条目不会重复），并最终得到以下 $\ast$$\ast$yolov7-\/tiny.yml$\ast$$\ast$（预处理器平均值和比例与我们在 0\+\_\+import\+\_\+model.\+sh 中使用的一样）：
\begin{DoxyCode}{0}
\DoxyCodeLine{ \%YAML 1.0 -\/-\/-\/}
\DoxyCodeLine{}
\DoxyCodeLine{yolov7-\/tiny： preproc：Blob 平均值：“0 0 0” 比例：0.0039215686 nettype：NPU 模型：“dnn/custom/yolov7-\/tiny.nb” 张力：“NCHW：8U：1x3x416x416：AA：0.003921568393707275：0” 输出张力：“8U：1x255x52x52：AA：0.0038335032295435667：0，8U：1x255x26x26：AA：0.0038371747359633446：0，8U：1x255x13x13：AA：0.003918845672160387：0” postproc：检测 检测类型： RAWYOLO 类：“npu/detection/coco-\/labels.txt” 锚点：“10,13, 16,30, 33,23；30,61, 62,45, 59,119；116,90, 156,198, 373,326” sigmoid：false scalexy：2.0 }
\end{DoxyCode}

\item 我们将 yolov7-\/tiny.\+yml 和 yolov7-\/tiny.\+nb 复制到 Je\+Vois-\/\+Pro 上的 /jevoispro/share/dnn/custom/ 然后尝试一下！
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 测试模型并调整任何参数 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 选择 机器视觉模块
\item 将 {\ttfamily 管道参数设置为} {\bfseries{N\+P\+U\+:\+Detect\+:yolov7-\/tiny}}
\end{DoxyItemize}

  

成功了！速度也相当快，仅网络推理（在 N\+PU 上运行的部分）就约为 55 fps。

\begin{DoxyNote}{Note}
您可以在 {\bfseries{1\+\_\+quantize\+\_\+model.\+sh}} 中使用 int8-\/\+D\+FP 量化重复本教程。然后，您只需将 Y\+A\+ML 中的 intensors 和 outtensors 规范更改为获得的 D\+FP 参数。我们做到了，网络运行良好，但速度大约减半（约 22.\+5 fps）。因此，\+AA 量化是此网络的正确选择。
\end{DoxyNote}
提示 ====


\begin{DoxyItemize}
\item 如果您在尝试运行网络时收到“图形验证失败”提示，则可能是您输入的张量规格不正确。在 G\+UI 的“配置”选项卡下，您可以编辑 yolov7-\/tiny.\+yml 并修复它。
\item Khadas 有自己的文档，您可能想查看一下，因为他们的 V\+I\+M3 板使用与 Je\+Vois-\/\+Pro 相同的 Amlogic A311D 处理器。但请注意，在 Je\+Vois 上，我们跳过使用生成的 C 代码，因为 Je\+Vois-\/\+Pro 已经提供了运行 N\+PU 模型所需的所有代码。
\item \href{https://docs.khadas.com/linux/vim3/NPUSDK.html}{\texttt{ https\+://docs.\+khadas.\+com/linux/vim3/\+N\+P\+U\+S\+D\+K.\+html}}
\item \href{https://docs.khadas.com/linux/vim3/ConvertToUseNPU.html}{\texttt{ https\+://docs.\+khadas.\+com/linux/vim3/\+Convert\+To\+Use\+N\+P\+U.\+html}}
\item \href{https://docs.khadas.com/linux/vim3/NPUPerformanceUsage.html}{\texttt{ https\+://docs.\+khadas.\+com/linux/vim3/\+N\+P\+U\+Performance\+Usage.\+html}}
\item \href{https://docs.khadas.com/linux/vim3/NPUOperationTimes.html}{\texttt{ https\+://docs.\+khadas.\+com/linux/vim3/\+N\+P\+U\+Operation\+Times.\+html}}
\item 从 py\+Torch 转换时，如果您收到一些奇怪的错误，例如\begin{DoxyVerb}RuntimeError: [enforce fail at inline_container.cc:208] . file not found: archive/constants.pkl \end{DoxyVerb}
 您的模型可能是使用比 N\+PU S\+DK 中包含的版本更新的 py\+Torch 版本保存的。您可能需要将模型保存到 O\+N\+N\+X，然后尝试再次从 O\+N\+NX 转换。或者可能是模型使用了 N\+PU 不支持的层类型或操作，在这种情况下转换为 O\+N\+NX 将无济于事。您需要将网络更改为仅包含可以映射到 N\+PU 的层和操作。
\end{DoxyItemize}

\begin{DoxyNote}{Note}
到目前为止，我们还无法使用 N\+PU S\+DK 直接从 py\+Torch 成功转换，我们总是会遇到某种错误。但首先将源模型导出到 O\+N\+N\+X，然后在其上运行 N\+PU S\+DK 就可以正常工作，只要在源模型中仅使用 N\+PU 支持的操作即可。
\end{DoxyNote}

\begin{DoxyItemize}
\item 有关我们有时如何跳过不受支持的最后一层（例如，执行重塑、检测框解码、非最大框抑制等）的示例，请参阅 \mbox{\hyperlink{UserDNNvpu}{转换并运行 Myriad-\/X V\+PU 的神经网络}} 和 User\+D\+N\+Nspu。
\item 另请参阅 \mbox{\hyperlink{UserDNNtips}{运行自定义神经网络的技巧}}
\end{DoxyItemize}

另一个示例：使用 Y\+O\+L\+Ov10n 进行对象检测 ==================================================


\begin{DoxyItemize}
\item Y\+O\+L\+Ov10n 的流程几乎相同。我们必须对一些事情进行微调：
\item 从 \href{https://github.com/THU-MIG/yolov10/tree/main}{\texttt{ https\+://github.\+com/\+T\+H\+U-\/\+M\+I\+G/yolov10/tree/main}} 获取代码
\item 完成其安装步骤，包括创建 conda 环境和获取所有依赖项。
\item 您还可以在此阶段使用自定义数据集进行重新训练。
\item 要导出到 O\+N\+N\+X，使用 opset 13 会出现一些转换错误，因此我们使用 opset 12。我们还可以在该步骤中使用“imgsz”参数设置自定义图像分辨率：
\begin{DoxyCode}{0}
\DoxyCodeLine{yolo export model=jameslahm/yolov10n format=onnx opset=12 simply imgsz=288,512 }
\end{DoxyCode}

\item 网络末端的一些层出现大小错误，可能是因为不同的 opset。无论如何，我们想要原始的 Y\+O\+LO 输出。因此，我们在 Netron 中检查了网络，并决定在 {\bfseries{0\+\_\+import\+\_\+model.\+sh}} 中使用 {\ttfamily /model.23/\+Transpose\+\_\+output\+\_\+0} 作为输出层：
\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{comment}{\#...\#Onnx \$pegasus import onnx\(\backslash\) -\/-\/model \$\{NAME\}.onnx \(\backslash\) -\/-\/output-\/model \$\{NAME\}.json \(\backslash\) -\/-\/outputs /model.23/Transpose\_output\_0 \(\backslash\) -\/-\/output-\/data \$\{NAME\}.data}}
\DoxyCodeLine{\textcolor{comment}{\#...}}
\end{DoxyCode}

\item 转换正常。但是，它没有在显示屏上生成任何框。检查输出张量后，所有类的置信度值始终为零。查看转换过程中生成的 yolov10n-\/512x288.\+quantize 显示输出张量中的值范围为 \mbox{[}-\/108.\+24 .. 611.\+29\mbox{]}。实际上，在该输出张量中，对于输入 1x3x288x512，其为 1x3024x84，4 个框坐标（可以在 512x288 内变化，如果框部分超出输入图像，则变化更多）和 80 个类置信度（在 \mbox{[}0..1\mbox{]} 中）被连接在一起。这意味着，使用 8 位量化，\mbox{[}0..1\mbox{]} 中的任何类置信度将始终映射到相同的数字（量化的零点）...
\item 因此我们将量化改为 dynamic\+\_\+fixed\+\_\+point 和 int16。结果使用 5 位表示小数部分，这足以合理地表示类别准确度。
\item 效果很好，并且 N\+PU 的 Y\+O\+L\+Ov10n 现在包含在 Je\+Vois 发行版和 micro\+SD 图像中。 
\end{DoxyItemize}\hypertarget{UserDNNspu}{}\doxysubsubsection{为 Hailo-\/8 S\+PU 转换并运行神经网络}\label{UserDNNspu}
 支持 \href{https://hailo.ai/products/hailo-8-m2-module/}{\texttt{ 26-\/T\+O\+PS Hailo-\/8}} 流处理单元 (S\+PU)，作为使用 P\+C\+Ie 接口的 M.\+2 2230 A+E 板上的可选附加神经加速器。到目前为止，这是此规格中速度最快的加速器。

\begin{DoxyNote}{Note}
仅限。 不支持此加速器。
\end{DoxyNote}
支持的神经网络框架====================================


\begin{DoxyItemize}
\item Tensor\+Flow / Tensor\+Flow-\/\+Lite
\item O\+N\+NX
\item py\+Torch（通过导出到 O\+N\+N\+X）
\end{DoxyItemize}

程序 =========


\begin{DoxyItemize}
\item 阅读并理解有关 \mbox{\hyperlink{UserDNNoverview}{在 Je\+Vois-\/\+A33 和 Je\+Vois-\/\+Pro 上运行神经网络}} 的 Je\+Vois 文档
\item 确保你理解 \mbox{\hyperlink{UserDNNconv}{为 Je\+Vois-\/\+Pro 转换和量化深度神经网络}} 中的量化概念
\item 您需要下载并安装 Hailo Software Suite docker，以便在运行 Linux Ubuntu 20.\+04 的台式计算机上转换/压缩您的模型。{\itshape 需要注册和密码。\+Hailo 保留接受或拒绝您的开发者注册请求的权利。}
\item 运行时推理所需的一切（\+Hailo\+RT 运行时库、\+Hailo P\+C\+Ie 内核驱动程序）都已预先安装在您的 Je\+Vois micro\+SD 上。
\item 获得模型：训练您自己的模型，或下载预先训练的模型。
\item 获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、\+R\+GB 或 B\+G\+R、打包（\+N\+W\+H\+C）或平面（\+N\+C\+H\+W）像素等）。
\item 转换模型如下：
\item 使用 {\ttfamily hailo parser} 将源模型转换为 Hailo 存档 (.har)
\item 使用 {\ttfamily hailo optimize} 为 Hailo-\/8 优化模型并量化为 int8。
\item 使用 {\ttfamily hailo compilation} 将模型转换为可在 Je\+Vois-\/\+Pro 上运行的二进制 blob (.hef)
\item 可以使用其他命令来可视化您的模型、检查其在验证集上的性能等。
\item 尝试使用 {\ttfamily hailo tutorial} 获取 Hailo 的 jupyter 教程。
\item 将转换后的模型复制到 J\+E\+V\+O\+I\+S\+P\+RO\+:/share/dnn/custom/ 下的 Je\+Vois micro\+SD 卡
\item 为您的模型创建一个 Je\+Vois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 J\+E\+V\+O\+I\+S\+P\+RO\+:/share/dnn/custom/ 下的 Y\+A\+ML 文件
\item 启动 Je\+Vois 模块。它将扫描自定义目录以查找任何有效的 Y\+A\+ML 文件，并使您的模型作为 D\+NN 模块的 Pipeline 组件的 {\ttfamily 管道参数的一个可用值。选择该管道以运行您的模型。} 
\end{DoxyItemize}

设置 Hailo 软件套件 ======================================

\begin{DoxyNote}{Note}
以下所有内容均应在运行 Ubuntu 20.\+04 Linux 的快速 x86\+\_\+64 台式计算机上运行，​​而不是在您的 Je\+Vois-\/\+Pro 相机上运行。最后，我们将转换后的模型复制到 micro\+S\+D，然后使用该模型在 Je\+Vois-\/\+Pro 上运行推理。

我们在下面使用的是 Hailo\+R\+T-\/4.\+8.\+1，但更高版本也应该可以正常工作。为了获得最佳兼容性，请下载与相机上安装的版本相同的版本（在相机的控制台中输入 {\ttfamily !dpkg -\/-\/list $\vert$ grep hailo}）。
\end{DoxyNote}

\begin{DoxyItemize}
\item 查看 \href{https://hailo.ai/developer-zone/documentation/sw-suite-2022-07-1}{\texttt{ 官方文档}}
\item \href{https://hailo.ai/products/hailo-software-suite/model-zoo/}{\texttt{ Hailo 模型库}} 有许多可以在 Hailo-\/8 上运行的模型。您还可以在 \href{https://github.com/hailo-ai/hailo_model_zoo}{\texttt{ Git\+Hub}} 上查看其他文件和模型再训练代码。
\item 在 hailo.\+ai 申请开发者账户，登录，然后转到 \href{https://hailo.ai/developer-zone/sw-downloads/}{\texttt{ https\+://hailo.\+ai/developer-\/zone/sw-\/downloads/}}
\item 下载 {\bfseries{Hailo 软件套件 -\/ Docker}}
\item 下载 {\bfseries{Hailo\+RT – Ubuntu 软件包 (deb) for amd64}}
\item 下载 {\bfseries{Hailo\+RT – P\+C\+Ie 驱动程序 Ubuntu 软件包 (deb)}}
\item 安装 P\+C\+Ie 驱动程序和运行时库。这不是绝对必要的，但它会在我们继续进行时消除许多警告（对 D\+K\+MS 说 Y，它将通过内核更新携带驱动程序；如果失败也不要担心，也许你需要安装 dkms、内核头文件等）：
\begin{DoxyCode}{0}
\DoxyCodeLine{sudo dpkg -\/i \string~/Downloads/hailort-\/pcie-\/driver\_4.8.1\_all.deb sudo dpkg -\/i \string~/Downloads/hailort\_4.8.1\_amd64.deb }
\end{DoxyCode}

\item 如果尚未安装 docker，请安装：
\begin{DoxyCode}{0}
\DoxyCodeLine{sudo apt install docker.io sudo usermod -\/aG docker \$\{USER\} \textcolor{comment}{\# 需要重启才能生效}}
\end{DoxyCode}

\item 解压您下载的 Hailo 软件套件：
\begin{DoxyCode}{0}
\DoxyCodeLine{mkdir hailodev cd hailodev unzip \string~/Downloads/hailo\_sw\_suite\_2022-\/07.zip ./hailo\_sw\_suite\_docker\_run.sh }
\end{DoxyCode}
 您应该看到以下内容：
\begin{DoxyCode}{0}
\DoxyCodeLine{ 欢迎使用 Hailo 软件套件容器 要列出可用的命令，请输入：}
\DoxyCodeLine{}
\DoxyCodeLine{-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/ -\/-\/}
\DoxyCodeLine{}
\DoxyCodeLine{HailoRT：hailortcli -\/h 数据流编译器：hailo -\/h Hailo 模型动物园：hailomz -\/h TAPPAS：hailo\_run\_app -\/h}
\DoxyCodeLine{}
\DoxyCodeLine{-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/ -\/-\/}
\DoxyCodeLine{}
\DoxyCodeLine{（hailo\_virtualenv）hailo@mypc:/local/workspace\$ }
\end{DoxyCode}

\item 此时，您可以按照 Hailo 文档从 Hailo Model Zoo 获取模型并重新训练它，获取您自己的模型并进行转换等。我们在下面展示了一个示例。
\item 完成后，只需“退出”docker 容器。
\item 要稍后恢复，请输入“./hailo\+\_\+sw\+\_\+suite\+\_\+docker\+\_\+run.sh --resume”。
\item 要重新启动并用新容器替换旧容器，请输入{\ttfamily ./hailo\+\_\+sw\+\_\+suite\+\_\+docker\+\_\+run.sh -\/-\/override}
\item 要在主机和 Hailo docker 之间复制文件，请在主机上（而不是在容器中）输入以下内容：
\item {\ttfamily sudo docker container ls -\/a} 显示容器的 I\+D，例如 {\bfseries{4f6342fbc915}}
\item {\ttfamily sudo docker cp myfile 4f6342fbc915\+:/local/workspace/} 从主机复制到容器
\item {\ttfamily sudo docker cp 4f6342fbc915\+:/local/workspace/myfile .} 从容器复制到主机
\item 请参阅 \href{https://hailo.ai/developer-zone/documentation/sw-suite-2022-07-1?sp_referrer=working_with_dockers.html}{\texttt{ https\+://hailo.\+ai/developer-\/zone/documentation/sw-\/suite-\/2022-\/07-\/1?sp\+\_\+referrer=working\+\_\+with\+\_\+dockers.\+html}} 了解更多信息（需要登录您的 Hailo 帐户）。
\end{DoxyItemize}

示例：\+Y\+O\+L\+Ov7 物体检测 ==================================

我们下面运行的所有内容都来自我们上面启动的 docker 容器内部。


\begin{DoxyEnumerate}
\item 获取模型 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 前往 \href{https://github.com/WongKinYiu/yolov7}{\texttt{ https\+://github.\+com/\+Wong\+Kin\+Yiu/yolov7}} 查看
\item 我们将使用基础版 Y\+O\+L\+Ov7 完整版来查看 Hailo 板在大型模型上运行速度有多快：
\begin{DoxyCode}{0}
\DoxyCodeLine{wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt }
\end{DoxyCode}

\end{DoxyItemize}

2.由于我们的模型是py\+Torch，所以先将其转换为\+O\+N\+NX -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item 该模型在 py\+Torch 中，但 Y\+O\+L\+Ov7 团队提供了一个“export.\+py”，可以将其导出到 onnx，最近的模型通常都是这样：
\begin{DoxyCode}{0}
\DoxyCodeLine{git clone https://github.com/WongKinYiu/yolov7.git cd yolov7 pip install -\/-\/upgrade pip pip install -\/r requirements.txt python3 export.py -\/-\/weights ../yolov7.pt -\/-\/simplify -\/-\/img-\/size 640 -\/-\/batch-\/size 1 cd ..}
\end{DoxyCode}
 \begin{DoxyNote}{Note}
安装要求会卸载 hailo 提供的 torch，然后安装看似相同的版本。这可能会干扰 Hailo 软件套件的其他方面。因此，您可能需要在不同的虚拟环境或本机主机上执行此操作，然后将结果复制到容器中，如上所示。
\end{DoxyNote}

\item 我们现在有 {\bfseries{yolov7.\+onnx}}
\item 要使用 Netron 进行可视化，请运行 $\ast$$\ast$google-\/chrome \href{https://netron.app}{\texttt{ https\+://netron.\+app}}$\ast$$\ast$（仍在容器内），选择“打开模型...”，然后选择模型，该模型位于容器中的 {\bfseries{/local/workspace/yolov7.onnx}} 中。具体来说，我们看到 3 个输出，1x3x80x80x85、1x3x40x40x85、1x3x20x20x85，这是通常的 3 个 Y\+O\+LO 尺度（形状不寻常，我们稍后会修复）。请注意，原始模型包含一些额外的后处理，但已从导出中删除，这很好，因为它可能不受硬件加速器支持。\+Je\+Vois 软件将提供后处理。输入是 1x3x640x640（\+N\+C\+H\+W）。
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 运行 Hailo 解析器 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item \href{https://hailo.ai/developer-zone/documentation/?type=application-and-release-notes}{\texttt{ Hailo 下载部分}} 中的 Hailo Model Zoo 用户指南有详细的说明。
\item 我们还查看了 \href{https://hailo.ai/developer-zone/documentation/dataflow-compiler-v3-19-0}{\texttt{ Hailo Dataflow Compiler 文档}}
\item 首先，将 O\+N\+NX 中的模型解析为 Hailo 存档 (H\+AR)：
\begin{DoxyCode}{0}
\DoxyCodeLine{hailo parser onnx yolov7.onnx }
\end{DoxyCode}
 我们收到一些关于不支持的层 298、299、301、302、304、305 的错误，并建议重试，“使用这些最终节点名称：\+Conv\+\_\+297、\+Conv\+\_\+300、\+Conv\+\_\+303”。这些是最终重塑之前的输出，例如，conv\+\_\+303（\+Netron 中图形底部的最后一个 Conv 块）为 1x255x20x20，然后重塑为 1x3x20x20x85。事实上，我们应该使用 Conv\+\_\+303，因为这是 \mbox{\hyperlink{classjevois_1_1dnn_1_1PostProcessorDetect}{jevois\+::dnn\+::\+Post\+Processor\+Detect}} 可以处理的 Y\+O\+LO 输出形状。因此我们再试一次（运行 {\bfseries{hailo parser onnx yolov7.\+onnx --help}} 以获取帮助后）：
\begin{DoxyCode}{0}
\DoxyCodeLine{hailo parser onnx yolov7.onnx -\/-\/end-\/node-\/names Conv\_297 Conv\_300 Conv\_303 }
\end{DoxyCode}

\item 成功，我们现在有了$\ast$$\ast$yolov7.har$\ast$$\ast$
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 获取样本数据集 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 我们需要一个样本数据集来量化模型。它将通过模型进行处理（仅前向推理），以确定每一层遇到的值的范围。然后这些范围将用于量化。
\item 如果您在自定义数据集上训练了模型，请将验证集中的大约 100 张图像复制到此处的新目录中。
\item 我们的模型是在 \href{https://cocodataset.org}{\texttt{ C\+O\+CO 数据集}} 上训练的。让我们下载 \href{http://images.cocodataset.org/zips/val2017.zip}{\texttt{ 2017 年验证集}}：
\begin{DoxyCode}{0}
\DoxyCodeLine{wget http://images.cocodataset.org/zips/val2017.zip unzip val2017.zip }
\end{DoxyCode}

\item 有 5,000 张图像，比我们需要的多。unix 命令 {\ttfamily shuf} 可以随机打乱名称列表并取前 {\ttfamily n} 个，因此让我们使用它从数据集中抓取 100 张随机图像并将它们复制到新目录 {\bfseries{sampledata}}\+:
\begin{DoxyCode}{0}
\DoxyCodeLine{mkdir sampledata cp `ls ./val2017/*.jpg | shuf -\/n 100` sampledata/ }
\end{DoxyCode}

\item {\bfseries{sampledata/}} 现在应该包含 100 个 jpeg 图像。
\item Hailo 希望将样本数据集作为 {\itshape “.\+npy 文件，其中包含形状为 (calib\+\_\+size, h, w, c) 的预处理图像的 numpy 数组”}（通过运行 $\ast$$\ast$hailo optimize --help$\ast$$\ast$）。因此，我们需要编写一个小的 python 脚本 {\bfseries{numpy\+\_\+sampledata.\+py}} 来执行此操作：
\begin{DoxyCode}{0}
\DoxyCodeLine{ \textcolor{keyword}{import} numpy \textcolor{keyword}{as} np \textcolor{keyword}{import} os \textcolor{keyword}{from} PIL \textcolor{keyword}{import} Image}
\DoxyCodeLine{}
\DoxyCodeLine{dir = \textcolor{stringliteral}{'sampledata'} 宽度 = 640 高度 = 640 图像数量 = 100}
\DoxyCodeLine{}
\DoxyCodeLine{数据集 = np.ndarray((numimages, height, width, 3), np.float32) idx = 0}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{keywordflow}{for} path \textcolor{keywordflow}{in} os.listdir(dir): fname = os.path.join(dir, path) \textcolor{keywordflow}{if} os.path.isfile(fname): image = Image.open(fname).resize((width, height)); arr = np.array(image).astype(np.float32) arr = (arr -\/ 0.0) / 255.0 \textcolor{comment}{\# 预处理。这里：mean=[0 0 0], scale=1/255 但因模型而异 dataset[idx, :] = arr idx += 1 with open('sampledata.npy', 'wb') as f: np.save(f, dataset) }}
\end{DoxyCode}

\item 我们运行脚本并得到$\ast$$\ast$sampledata.npy$\ast$$\ast$
\end{DoxyItemize}

5.优化模型-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item 在我们的模型上启动 Hailo 优化器并使用我们的样本数据集。这将量化模型：
\begin{DoxyCode}{0}
\DoxyCodeLine{hailo optimize yolov7.har -\/-\/calib-\/set-\/path sampledata.npy }
\end{DoxyCode}

\item 我们得到$\ast$$\ast$yolov7\+\_\+quantized.har$\ast$$\ast$
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 编译模型 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}


\begin{DoxyCode}{0}
\DoxyCodeLine{hailo 编译器 yolov7\_quantized.har }
\end{DoxyCode}


我们得到$\ast$$\ast$yolov7.hef$\ast$$\ast$，将其复制到 的 micro\+SD 中。

编译器预测此模型的 F\+PS 为 12.\+27，考虑到其大小，这个数字听起来相当不错。请注意，它的目标是计算利用率达到 75，而且确实实现了这一目标。也许可以通过一些参数来提高这一数字。为了获得更快的 F\+P\+S，可以使用 yolov7-\/tiny，或者可以减小输入大小。


\begin{DoxyEnumerate}
\item 创建 Je\+Vois-\/\+Pro Y\+A\+ML zoo 文件 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 我们从 Je\+Vois micro\+SD 中已有的动物园文件 spu.\+yml 中的任何 Y\+O\+LO 条目开始（并且可以在 G\+UI 的“配置”选项卡中使用）。
\item 对于 Y\+O\+LO 后处理，我们需要定义锚点（用于预测对象框的原型框形状）。我们从 \href{https://github.com/WongKinYiu/yolov7/blob/main/cfg/deploy/yolov7.yaml}{\texttt{ https\+://github.\+com/\+Wong\+Kin\+Yiu/yolov7/blob/main/cfg/deploy/yolov7.\+yaml}} 中获取这些内容，位于顶部：
\begin{DoxyCode}{0}
\DoxyCodeLine{ 锚点：}
\DoxyCodeLine{-\/ [12,16, 19,36, 40,28] \textcolor{comment}{\# P3/8}}
\DoxyCodeLine{-\/ [36,75, 76,55, 72,146] \textcolor{comment}{\# P4/16}}
\DoxyCodeLine{-\/ [142,110, 192,243, 459,401] \textcolor{comment}{\# P5/32 }}
\end{DoxyCode}
 在下面的 Y\+A\+ML 文件中，我们将用分号分隔 3 个 Y\+O\+LO 尺度的 3 组锚点。
\item 由于 Y\+O\+L\+Ov7 使用“新样式”的 Y\+O\+LO 坐标，我们需要禁用后处理器 sigmoid 并将后处理器 scalexy 设置为 2.\+0。对于 Y\+O\+L\+Ov5/v7，您可能希望这样做。相反，将 sigmoid 设置为 true 并将 scalexy 设置为 0.\+0（默认值）以使用 Y\+O\+L\+Ov2/v3/v4 的旧样式框坐标。您可以在 jevois\+::dnn\+::\+Post\+Processor\+Detect\+Y\+O\+L\+O\+::yolo\+\_\+one() 中查看差异
\item 实际上，我们用于输出的这 3 个 Conv 层在该特定模型中似乎具有线性激活（请在 Netron 中查看）。因此我们需要将 sigmoid 设置为 true，因为后处理器将需要它来进行 Y\+O\+LO 解码。
\item 我们只需修改名称和文件位置，将 spu.\+yml 中的所有全局定义放入我们的文件中（例如 preproc、nettype 等，它们在 spu.\+yml 中全局设置，因此不会在我们要复制的条目中重复），最后得到以下 $\ast$$\ast$yolov7.yml$\ast$$\ast$：
\begin{DoxyCode}{0}
\DoxyCodeLine{ \%YAML 1.0 -\/-\/-\/}
\DoxyCodeLine{}
\DoxyCodeLine{yolov7：preproc：Blob 平均值：“0 0 0” 比例：0.0039215686 nettype：SPU 模型：“dnn/custom/yolov7.hef” postproc：检测 检测类型：RAWYOLO 锚点：“12,16、19,36、40,28；36,75、76,55、72,146；142,110、192,243、459,401” 类：“npu/detection/coco-\/labels.txt” sigmoid：true scalexy：2.0 }
\end{DoxyCode}

\end{DoxyItemize}

\begin{DoxyNote}{Note}
我们不需要（也不能）使用 Hailo 模型指定 {\bfseries{intensors}} 和 $\ast$$\ast$outtensors$\ast$$\ast$，这些规格嵌入在 H\+EF 文件中。
\end{DoxyNote}

\begin{DoxyItemize}
\item 我们将 yolov7.\+yml 和 yolov7.\+hef 复制到 Je\+Vois-\/\+Pro 上的 /jevoispro/share/dnn/custom/ 然后尝试一下！
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 测试模型并调整任何参数 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 选择 机器视觉模块
\item 将 {\ttfamily 管道参数设置为} {\bfseries{S\+P\+U\+:\+Detect\+:yolov7}}
\end{DoxyItemize}

  

成功了！正如编译器所承诺的那样，网络推理的速度确实达到了 12.\+2 F\+P\+S。这是一个大型模型，并且使用 640x640 输入。如果您需要更高的帧速率，请尝试较小的输入或 yolov7-\/tiny。或者尝试 Hailo 团队提供的 Y\+O\+L\+Ov5m-\/640，它在 Je\+Vois-\/\+Pro 上的运行速度超过 45 F\+P\+S。

提示 ====


\begin{DoxyItemize}
\item 您可能希望从 \href{https://hailo.ai/products/hailo-software-suite/model-zoo/}{\texttt{ Hailo Model Zoo}} 中的模型开始。这些模型应该转换得很好，而且您还可以通过查看 G\+F\+L\+O\+PS 数字预先了解它们的速度。但请注意，一些检测模型已使用非常不寻常的输出集进行转换，\+Je\+Vois Post\+Processor 可能不支持这些输出集。
\item Hailo Model Zoo Github 上有多个 docker 和关于如何重新训练其中一些模型的说明：https\+://github.com/hailo-\/ai/hailo\+\_\+model\+\_\+zoo/tree/master/training
\item 另请参阅 \mbox{\hyperlink{UserDNNtips}{运行自定义神经网络的技巧}} 
\end{DoxyItemize}\hypertarget{UserDNNtpu}{}\doxysubsubsection{为 Coral T\+PU 转换并运行神经网络}\label{UserDNNtpu}
 支持 \href{https://coral.ai}{\texttt{ Google Coral}} 4-\/T\+O\+PS 张量处理单元 (T\+PU) 作为可选的硬件神经加速器。可以使用标准 \href{https://coral.ai/products/m2-accelerator-ae/}{\texttt{ Coral M.\+2 2230 A+E P\+C\+Ie 板}}、包含 2 个 Coral T\+PU + 一个 e\+M\+MC 闪存盘（安装在单个 M.\+2 2230 板上）的定制 Je\+Vois 板或任意数量的 \href{https://coral.ai/products/accelerator/}{\texttt{ Coral U\+SB 加密狗}}。请注意，与 480 Mbits/s 的 U\+SB 2.\+0 相比，\+P\+C\+Ie 的数据传输速度更快（5 Gbits/s，而 Je\+Vois-\/\+Pro 处理器只有一个 5 G\+Bits/s 接口，我们将其用于 P\+C\+Ie）。

\begin{DoxyNote}{Note}
仅限。 不支持此加速器。
\end{DoxyNote}
支持的神经网络框架====================================

-\/Tensor\+Flow / Tensor\+Flow-\/\+Lite

T\+PU 可以运行量化为 int8 权重的模型。它不支持浮点权重，因此需要量化和转换。硬件支持的操作和层类型数量有限，这进一步限制了可以在其上运行的内容。此外，加速器上只有少量 R\+A\+M，这进一步限制了可以有效运行的网络规模。但它比标准 C\+PU 快很多倍。

为了在 T\+PU 上执行，您的模型将被量化，然后在 Linux 桌面上转换为 blob 格式，然后可以将其传输到 Je\+Vois-\/\+Pro micro\+SD 进行执行。

程序 =========


\begin{DoxyItemize}
\item 阅读并理解有关 \mbox{\hyperlink{UserDNNoverview}{在 Je\+Vois-\/\+A33 和 Je\+Vois-\/\+Pro 上运行神经网络}} 的 Je\+Vois 文档
\item 确保你理解 \mbox{\hyperlink{UserDNNconv}{为 Je\+Vois-\/\+Pro 转换和量化深度神经网络}} 中的量化概念
\item 查看 \href{https://coral.ai/docs/}{\texttt{ 官方 Google Coral 文档}}
\item T\+PU 仅支持一组特定的层类型。如果您尝试转换包含不受支持的层的网络，转换有时似乎会成功，但转换后的网络可能无法运行，或者使用基于 C\+PU 的模拟运行非常缓慢。在尝试转换网络之前，请检查 \href{https://coral.ai/docs/edgetpu/models-intro/}{\texttt{ 兼容性概述}}。特别要注意 Coral 文档中的以下声明：{\itshape 注意：目前，\+Edge T\+PU 编译器无法多次对模型进行分区，因此一旦发生不受支持的操作，该操作及其后的所有内容都会在 C\+PU 上执行，即使稍后发生受支持的操作也是如此。}
\item 你需要下载并安装 \href{https://coral.ai/docs/edgetpu/compiler/}{\texttt{ Edge\+T\+PU 编译器}}，以便在运行 Linux Ubuntu 20.\+04 的台式计算机上转换/量化你的模型。
\item 运行时推理所需的一切（\+Edge\+T\+PU 运行时库、内核驱动程序、\+Py\+Coral）都已预先安装在您的 Je\+Vois micro\+SD 上。
\item 获得模型：训练您自己的模型，或下载预先训练的模型。
\item 请注意，\+T\+PU 仅有大约 6.\+5 MB 的板载 R\+AM 可用于存储模型参数，这充当了伪缓存（请参阅 \href{https://coral.ai/docs/edgetpu/compiler/}{\texttt{ https\+://coral.\+ai/docs/edgetpu/compiler/}}）。因此，较小的模型可以一次性装入较小的 R\+AM 中，从而获得最佳性能。较大的模型需要通过 P\+C\+Ie 或 U\+SB 链路不断加载/卸载权重。较大的模型在 Je\+Vois-\/\+Pro 集成 N\+PU 上运行得更好，它可以直接访问主 R\+A\+M（\+Je\+Vois-\/\+Pro 上为 4 G\+B）。
\item Google 建议从 \href{https://coral.ai/models/}{\texttt{ https\+://coral.\+ai/models/}} 上的一个模型开始，然后使用你自己的数据对其进行重新训练，如 \href{https://github.com/google-coral/tutorials}{\texttt{ https\+://github.\+com/google-\/coral/tutorials}} 中所述
\item 获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、\+R\+GB 或 B\+G\+R、打包（\+N\+W\+H\+C）或平面（\+N\+C\+H\+W）像素等）。
\item 将模型复制到 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Je\+Vois micro\+SD 卡
\item 为您的模型创建一个 Je\+Vois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Y\+A\+ML 文件
\item 启动 Je\+Vois 模块。它将扫描自定义目录以查找任何有效的 Y\+A\+ML 文件，并使您的模型作为 D\+NN 模块的 Pipeline 组件的 {\ttfamily 管道参数的一个可用值。选择该管道以运行您的模型。} 
\end{DoxyItemize}

设置 Edge\+T\+PU 编译器 =================================

\begin{DoxyNote}{Note}
以下所有内容均应在运行 Ubuntu 20.\+04 Linux 的快速 x86\+\_\+64 台式计算机上运行，​​而不是在您的 Je\+Vois-\/\+Pro 相机上运行。最后，我们将转换后的模型复制到 micro\+S\+D，然后使用该模型在 Je\+Vois-\/\+Pro 上运行推理。
\end{DoxyNote}
按照 \href{https://coral.ai/docs/edgetpu/compiler/}{\texttt{ https\+://coral.\+ai/docs/edgetpu/compiler/}} 上的说明进行操作


\begin{DoxyCode}{0}
\DoxyCodeLine{ curl https://packages.cloud.google.com/apt/doc/apt-\/key.gpg | sudo apt-\/key add -\/}
\DoxyCodeLine{}
\DoxyCodeLine{回显“deb https://packages.cloud.google.com/apt coral-\/edgetpu-\/stable main”| sudo tee /etc/apt/sources.list.d/coral-\/edgetpu.list}
\DoxyCodeLine{}
\DoxyCodeLine{sudo apt-\/get 更新}
\DoxyCodeLine{}
\DoxyCodeLine{sudo apt-\/get 安装 edgetpu-\/编译器}
\DoxyCodeLine{}
\DoxyCodeLine{edgetpu\_compiler -\/-\/help }
\end{DoxyCode}


示例：使用 N\+A\+S\+Net\+Mobile 进行对象分类 ====================================================


\begin{DoxyItemize}
\item 许多预先训练的模型可在 \href{https://coral.ai/models/}{\texttt{ https\+://coral.\+ai/models/}} 上找到
\item 这里，我们使用 N\+A\+S\+Net\+Mobile，因为它还不在列表中。
\item 让我们尝试使用 N\+A\+S\+Net\+Mobile 对 \href{https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb}{\texttt{ Coral colab 进行分类模型再训练}} 进行改进。另请查看 \href{https://github.com/google-coral/tutorials}{\texttt{ 其他 Coral 教程}}。
\item 这里我们跳过训练部分，只使用 Image\+Net 上的预训练模型，专注于量化和转换到 Edge T\+P\+U。
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 安装 Tensor\+Flow -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 首选方法是通过 conda，详情见https\+://www.tensorflow.\+org/install/pip
\item 在这里，我们将在 python3 虚拟环境中获取 tensorflow wheel，这样步骤更少：
\end{DoxyItemize}


\begin{DoxyCode}{0}
\DoxyCodeLine{python3 -\/m venv tf\_for\_tpu source tf\_for\_tpu/bin/activate pip install -\/-\/upgrade pip pip install tensorflow python3 -\/c \textcolor{stringliteral}{"import tensorflow as tf; print(tf.reduce\_sum(tf.random.normal([1000, 1000])))"} \textcolor{comment}{\# 测试安装 }}
\end{DoxyCode}


您可能会看到一些关于缺少 G\+PU 库的警告，我们在这里忽略这些警告（\+C\+PU 足以转换模型），最后是类似 {\bfseries{tf.\+Tensor(-\/337.\+86047, shape=(), dtype=float32)}} 的东西，这是我们的测试命令的结果（值 -\/337.\+86047 会有所不同，因为它是随机的）。


\begin{DoxyEnumerate}
\item 获取训练好的模型 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 我们在 \href{https://keras.io/api/applications/}{\texttt{ https\+://keras.\+io/api/applications/}} 上找到了在 Image\+Net 上预先训练的 Keras/\+Tensorflow N\+A\+S\+Net\+Mobile
\item 我们将按照 \href{https://keras.io/api/applications/nasnet/\#nasnetmobile-function}{\texttt{ https\+://keras.\+io/api/applications/nasnet/\#nasnetmobile-\/function}} 中的说明将其加载到 Tensor\+Flow 中
\item 因此我们开始一个小的$\ast$$\ast$convert.py$\ast$$\ast$脚本，如下所示：
\begin{DoxyCode}{0}
\DoxyCodeLine{ \textcolor{keyword}{import} tensorflow \textcolor{keyword}{as} tf \textcolor{keyword}{import} numpy \textcolor{keyword}{as} np}
\DoxyCodeLine{}
\DoxyCodeLine{模型 = tf.keras.applications.NASNetMobile()}
\DoxyCodeLine{}
\DoxyCodeLine{-\/ 这将使用所有默认值：224x224x3 输入、ImageNet 权重、包括最后的全连接层、包括最终的 softmax 激活。}
\DoxyCodeLine{}
\DoxyCodeLine{-\/ 您可以在此阶段重新训练模型。这里我们将按原样使用它。}
\DoxyCodeLine{}
\DoxyCodeLine{-\/ 如果我们现在运行**convert.py**，它只会下载模型并退出。}
\DoxyCodeLine{}
\DoxyCodeLine{2. 获取量化的样本数据集 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/}
\DoxyCodeLine{}
\DoxyCodeLine{-\/ 由于我们使用的是 ImageNet，我们可以从一些内置的 TensorFlow 函数中获取该数据集，但让我们手动执行此操作以查看如何在自定义数据集上执行此操作。}
\DoxyCodeLine{}
\DoxyCodeLine{-\/ 我们仍然希望数据能够代表我们的训练数据，因此让我们下载 ImageNet 验证集：}
\DoxyCodeLine{}
\DoxyCodeLine{+ 我们访问 https://image-\/net.org，但即使创建了帐户，也只能通过请求进行下载 }
\DoxyCodeLine{+ 因此，我们从 http://academictorrents.com/details/5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5 获取一个 torrent 文件，并使用“transmission-\/gtk”（Ubuntu 上预装）下载数据集。}
\DoxyCodeLine{}
\DoxyCodeLine{+ 我们获得 ILSVRC2012\_img\_val.tar，解压后：\(\backslash\)code\{.py\} mkdir dataset cd dataset tar xvf \string~/Downloads/ILSVRC2012\_img\_val.tar cd .. }
\end{DoxyCode}

\item 我们需要了解预处理的工作原理，以及应该将平均值、标准差和比例应用于原始像素值，以便我们稍后可以设置正确的预处理参数。我们在 \href{https://www.tensorflow.org/api_docs/python/tf/keras/applications/nasnet/preprocess_input}{\texttt{ N\+A\+S\+Net\+Mobile 的 Tensor\+Flow 文档}} 中找到了一些信息，这些信息表明 nasnet.\+preprocess\+\_\+input() 将缩放到 \mbox{[}-\/1 .. 1\mbox{]}。但没有提到方法......进一步查看\mbox{[}源代码\mbox{]}（https\+://github.com/keras-\/team/keras/blob/v2.\+9.\+0/keras/applications/nasnet.py\+::\+L817-\/L819），nasnet.\+preprocess\+\_\+input（）调用\mbox{[}此处\mbox{]}（https\+://github.com/keras-\/team/keras/blob/07e13740fd181fc3ddec7d9a594d8a08666645f6/keras/applications/imagenet\+\_\+utils.\+py\#\+L101）定义的 imagenet\+\_\+utils.\+preprocess\+\_\+input（），后者调用定义的 \+\_\+preprocess\+\_\+numpy\+\_\+input（） \mbox{[}这里\mbox{]}（https\+://github.com/keras-\/team/keras/blob/07e13740fd181fc3ddec7d9a594d8a08666645f6/keras/applications/imagenet\+\_\+utils.\+py\#\+L168）我们最终了解到，在 \textquotesingle{}tf\textquotesingle{} 模式下，我们将使用 mean=\mbox{[}127.\+5 127.\+5 127.\+5\mbox{]} 和 scale=1/127.\+5
\item 我们将以下内容添加到我们的 {\bfseries{convert.\+py}} 中，以我们正在关注的 colab 为蓝本，部分“转换为 T\+F\+Lite”（我们只需要更改图像文件的位置和预处理）：
\begin{DoxyCode}{0}
\DoxyCodeLine{ IMAGE\_SIZE = 224}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# 提供代表性数据集的生成器 def representative\_data\_gen(): dataset\_list = tf.data.Dataset.list\_files('dataset/*') \# 修改后的 JEVOIS for i in range(100): image = next(iter(dataset\_list)) image = tf.io.read\_file(image) image = tf.io.decode\_jpeg(image, channels=3) image = tf.image.resize(image, [IMAGE\_SIZE, IMAGE\_SIZE]) image = tf.cast((image -\/ 127.5) / 127.5, tf.float32) \# 修改后的 JEVOIS image = tf.expand\_dims(image, 0) Yield [image] }}
\end{DoxyCode}

\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 量化模型并转换为 T\+F\+Lite -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}

我们再次将以下内容添加到我们的 {\bfseries{convert.\+py}} 中，以我们关注的 colab 中的“转换为 T\+F\+Lite”部分为蓝本：


\begin{DoxyCode}{0}
\DoxyCodeLine{ 转换器 = tf.lite.TFLiteConverter.from\_keras\_model(模型)}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# 这将启用量化转换器。优化 = [tf.lite.Optimize.DEFAULT]}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# 这设置了量化的代表性数据集 converter.representative\_dataset = representative\_data\_gen}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# 这确保如果任何操作无法量化，转换器就会抛出错误 converter.target\_spec.supported\_ops = [tf.lite.OpsSet.TFLITE\_BUILTINS\_INT8]}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# 对于完整的整数量化，虽然支持的类型默认仅为 int8，但为了清楚起见，我们明确声明了它。converter.target\_spec.supported\_types = [tf.int8]}}
\DoxyCodeLine{}
\DoxyCodeLine{\textcolor{comment}{\# 将输入和输出张量设置为 uint8（在 r2.3 中添加）converter.inference\_input\_type = tf.uint8 converter.inference\_output\_type = tf.uint8 tflite\_model = converter.convert()}}
\DoxyCodeLine{}
\DoxyCodeLine{使用 open(\textcolor{stringliteral}{'NASNetMobile\_quant.tflite'}, \textcolor{stringliteral}{'wb'}) 作为 f: \textcolor{comment}{\# JEVOIS 修改 f.write(tflite\_model) }}
\end{DoxyCode}


我们运行完整的$\ast$$\ast$convert.py$\ast$$\ast$（整理上面的 3 个片段）：


\begin{DoxyCode}{0}
\DoxyCodeLine{python3 转换.py }
\end{DoxyCode}


这需要一段时间（也许我们应该安装 G\+PU 支持），但最终我们得到了 {\bfseries{N\+A\+S\+Net\+Mobile\+\_\+quant.\+tflite}}，它是我们原始模型的量化版本。

让我们快速检查一下，并将我们的量化模型上传到 Lutz Roeder 的出色 \href{https://netron.app/}{\texttt{ Netron}} 在线模型检查工具。上传 {\bfseries{N\+A\+S\+Net\+Mobile\+\_\+quant.\+tflite}} 并检查各个层。特别是，如果您展开任何 Conv 层的输入、权重、偏差和输出详细信息，您将看到数据是如何通过一些相关的量化参数进行 int8 处理的。


\begin{DoxyEnumerate}
\item 将量化的\+T\+F\+Lite模型转换为\+Edge\+T\+PU -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 要从量化的 T\+F\+Lite 转换为 Edge\+T\+P\+U，我们只需运行：
\begin{DoxyCode}{0}
\DoxyCodeLine{edgetpu\_compiler NASNetMobile\_quant.tflite }
\end{DoxyCode}

\item 这将移植尽可能多的层和操作以在 T\+PU 上执行。我们看到这个：
\begin{DoxyCode}{0}
\DoxyCodeLine{ Edge TPU 编译器版本 16.0.384591198 启动了 180 秒的编译超时计时器。}
\DoxyCodeLine{}
\DoxyCodeLine{模型在 5841 毫秒内成功编译。}
\DoxyCodeLine{}
\DoxyCodeLine{输入模型：NASNetMobile\_quant.tflite 输入大小：6.21MiB 输出模型：NASNetMobile\_quant\_edgetpu.tflite 输出大小：8.15MiB 用于缓存模型参数的片上内存：6.31MiB 用于缓存模型参数的剩余片上内存：0.00B 用于流式传输未缓存模型参数的片外内存：635.12KiB Edge TPU 子图数量：1 操作总数：669 操作日志：NASNetMobile\_quant\_edgetpu.log 有关单个操作的详细信息，请参阅操作日志文件。 编译子进程在超时期限内完成。 编译成功！ }
\end{DoxyCode}

\item 我们得到了 $\ast$$\ast$\+N\+A\+S\+Net\+Mobile\+\_\+quant\+\_\+edgetpu.tflite$\ast$$\ast$，我们会将其复制到 Je\+Vois-\/\+Pro micro\+S\+D。\begin{DoxyNote}{Note}
有点太大了！从上面的消息来看，我们正在最大限度地利用板载 R\+A\+M，除了将图像流式传输到 T\+PU 之外，每次推理时都需要在该 R\+AM 和主处理器的 R\+AM 之间交换 635 KB 的模型参数。
\end{DoxyNote}

\item 我们可以检查生成的 N\+A\+S\+Net\+Mobile\+\_\+quant\+\_\+edgetpu.\+log 以确认在这种情况下所有层都已移植到 T\+P\+U：
\begin{DoxyCode}{0}
\DoxyCodeLine{ Edge TPU 编译器版本 16.0.384591198 输入：NASNetMobile\_quant.tflite 输出：NASNetMobile\_quant\_edgetpu.tflite}
\DoxyCodeLine{}
\DoxyCodeLine{操作员计数状态}
\DoxyCodeLine{}
\DoxyCodeLine{PAD 20 映射到边缘 TPU ADD 84 映射到边缘 TPU MAX\_POOL\_2D 4 映射到边缘 TPU MEAN 1 映射到边缘 TPU QUANTIZE 86 映射到边缘 TPU CONV\_2D 196 映射到边缘 TPU CONCATENATION 20 映射到边缘 TPU FULLY\_CONNECTED 1 映射到边缘 TPU RELU 48 映射到边缘 TPU MUL 4 映射到边缘 TPU SOFTMAX 1 映射到边缘 TPU STRIDED\_SLICE 4 映射到边缘 TPU AVERAGE\_POOL\_2D 40 映射到边缘 TPU DEPTHWISE\_CONV\_2D 160 映射到边缘 TPU }
\end{DoxyCode}

\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 为我们的新模型创建一个 zoo Y\+A\+ML 文件 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}

现在我们需要让 Je\+Vois 了解我们的模型，方法是创建一个描述模型和文件位置的小型 Y\+A\+ML 文件。我们只需从预加载的 Je\+Vois $\ast$$\ast$tpu.yml$\ast$$\ast$（在 G\+UI 的配置选项卡中）中获取一个条目即可获得灵感，并创建我们的新 $\ast$$\ast$\+N\+A\+S\+Net\+Mobile.yml$\ast$$\ast$：


\begin{DoxyCode}{0}
\DoxyCodeLine{ \%YAML 1.0 -\/-\/-\/}
\DoxyCodeLine{}
\DoxyCodeLine{NASNetMobile：预处理：Blob 网络类型：TPU 后处理：分类模型：“dnn/custom/NASNetMobile\_quant\_edgetpu.tflite” 强度：“NHWC：8U：1x224x224x3：AA：0.0078125：128” 平均值：“127.5 127.5 127.5” 比例：0.0078125 类：“coral/classification/imagenet\_labels.txt” 类别偏移量：1 }
\end{DoxyCode}


\begin{DoxyNote}{Note}
对于 {\ttfamily 类，我们使用已预加载到} micro\+SD 上的现有 Image\+Net 标签文件，因为我们没有从 Keras 获取该文件。由于该标签文件的第一个条目为“背景”，而我们的模型未使用此条目，因此我们使用 {\ttfamily classoffset} 1 来移动类标签。如果标签似乎不正确，您可以在运行时调整它。如果您使用自定义训练的模型，您还应该将文件 {\bfseries{N\+A\+S\+Net\+Mobile.\+labels}} 复制到 micro\+S\+D，该文件描述了您的类名（每行一个类标签），然后将 classes 参数设置为该文件。
\end{DoxyNote}

\begin{DoxyEnumerate}
\item 复制到 micro\+SD 并运行 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 将 {\bfseries{N\+A\+S\+Net\+Mobile\+\_\+quant\+\_\+edgetpu.\+tflite}} 和 {\bfseries{N\+A\+S\+Net\+Mobile.\+yml}} 复制到 Je\+Vois-\/\+Pro micro\+SD 上的 /jevoispro/share/dnn/custom/。
\item 启动 模块并选择 {\ttfamily pipe} {\bfseries{T\+P\+U\+:\+Classify\+:N\+A\+S\+Net\+Mobile}}
\end{DoxyItemize}

  


\begin{DoxyItemize}
\item 成功了！请注意，此屏幕截图使用的是连接到 U\+SB 2.\+0 的 T\+P\+U，使用 P\+C\+Ie T\+PU 板时速度更快。
\end{DoxyItemize}

提示 ====


\begin{DoxyItemize}
\item 权重大于 6.\+5 MB 的模型可以在 T\+PU 上运行得很好，但速度会更慢。缓存对用户完全透明，并且运行良好。
\item 在 Je\+Vois-\/\+Pro 上，可以同时为多个不同的模型实例化多个 Coral T\+PU 管道。这些模型将自动且透明地在硬件加速器上进行时间复用。例如，在 Je\+Vois 模块 或 中，您可以将多个管道（在模块的 params.\+cfg 文件中）设置为 T\+PU 模型，即使您只有一个 T\+P\+U，也不会出现任何冲突或问题。
\item 如果您有多个 T\+P\+U，则可以使用 Y\+A\+ML 参数 {\bfseries{tpunum}} 在给定的 T\+PU 上运行给定的模型。
\item 另请参阅 \mbox{\hyperlink{UserDNNtips}{运行自定义神经网络的技巧}} 
\end{DoxyItemize}\hypertarget{UserDNNvpu}{}\doxysubsubsection{转换并运行 Myriad-\/X V\+PU 的神经网络}\label{UserDNNvpu}
 支持 \href{https://www.intel.com/content/www/us/en/products/details/processors/movidius-vpu/movidius-myriad-x.html}{\texttt{ Intel Movidius Myriad-\/X}} 矢量处理单元 (V\+PU) 作为可选的附加神经加速器。

\begin{DoxyNote}{Note}
仅限。 不支持此加速器。
\end{DoxyNote}
支持的神经网络框架====================================


\begin{DoxyItemize}
\item Caffe
\item Tensor\+Flow
\item O\+N\+NX
\item py\+Torch（通过导出到 O\+N\+N\+X）
\item M\+X\+Net
\item Paddle\+Paddle
\item Kaldi
\end{DoxyItemize}

V\+PU 可以运行具有 float16（16 位浮点）权重的模型。它不支持标准 32 位浮点权重，因此需要进行转换或压缩。

为了在 V\+PU 上执行，您的模型将在 Linux 桌面上转换为专有 blob 格式，然后可以将其传输到 Je\+Vois-\/\+Pro micro\+SD 进行执行。

在 Je\+Vois-\/\+Pro 上，我们通过作为 Open\+CV 后端安装的 Open\+Vino 运行 V\+PU 模型。因此，加载和在 V\+PU 模型上运行推理的基本机制是 Open\+C\+V，就像在 C\+PU 上运行的模型一样。

可以使用仿真模式，通过 \href{https://github.com/ARM-software/ComputeLibrary}{\texttt{ A\+RM 计算库}} 和 \href{https://github.com/openvinotoolkit/openvino_contrib/blob/master/modules/arm_plugin/README.md}{\texttt{ Open\+Vino A\+RM C\+PU 插件}}，使用 Je\+Vois-\/\+Pro C\+PU 运行针对 V\+PU 优化的模型。不过，速度要慢得多。当 V\+PU 未连接到 Je\+Vois-\/\+Pro 时，所有 V\+PU 网络仍可用作 {\bfseries{V\+P\+UX}} 来发出仿真模式信号。对于最终用户来说，这是完全透明的（无需修改任何设置）。

程序 =========


\begin{DoxyItemize}
\item 阅读并理解有关 \mbox{\hyperlink{UserDNNoverview}{在 Je\+Vois-\/\+A33 和 Je\+Vois-\/\+Pro 上运行神经网络}} 的 Je\+Vois 文档
\item 确保你理解 \mbox{\hyperlink{UserDNNconv}{为 Je\+Vois-\/\+Pro 转换和量化深度神经网络}} 中的量化概念
\item 查看 \href{https://docs.openvino.ai/latest/index.html}{\texttt{ 官方 Open\+Vino 文档}}。具体来说，我们将使用 \href{https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html}{\texttt{ 模型优化器}} 将自定义模型转换为 V\+P\+U。
\item Open\+Vino 文档非常出色，提供了很多 \href{https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_tutorials.html}{\texttt{ 转换教程}}
\item \href{https://docs.openvino.ai/latest/model_zoo.html}{\texttt{ Open Model Zoo}} 提供了许多可下载并转换为 V\+P\+U（或已转换）的模型。
\item V\+PU 仅支持一组特定的层类型。如果您尝试转换包含不受支持的层的网络，转换有时似乎成功，但转换后的网络可能无法运行。请查看 \href{https://docs.openvino.ai/latest/openvino_docs_OV_UG_supported_plugins_VPU.html}{\texttt{ 支持的插件}} 和 \href{https://github.com/openvinotoolkit/openvino/blob/master/docs/ops/opset9.md}{\texttt{ opset9}} 了解相关信息。
\item 您需要下载并安装 Open\+Vino S\+DK 才能在运行 Linux Ubuntu 20.\+04 的台式计算机上转换/压缩您的模型。
\item 运行时推理所需的一切（\+Open\+Vino 运行时库、\+Open\+CV 绑定、\+Open\+Vino A\+RM C\+PU 插件）都已预先安装在您的 Je\+Vois micro\+SD 上。
\item 获得模型：训练您自己的模型，或下载预先训练的模型。
\item 获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、\+R\+GB 或 B\+G\+R、打包（\+N\+W\+H\+C）或平面（\+N\+C\+H\+W）像素等）。
\item 将模型复制到 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Je\+Vois micro\+SD 卡
\item 为您的模型创建一个 Je\+Vois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 J\+E\+V\+O\+IS\mbox{[}P\+RO\mbox{]}\+:/share/dnn/custom/ 下的 Y\+A\+ML 文件
\item 启动 Je\+Vois 模块。它将扫描自定义目录以查找任何有效的 Y\+A\+ML 文件，并使您的模型作为 D\+NN 模块的 Pipeline 组件的 {\ttfamily 管道参数的一个可用值。选择该管道以运行您的模型。} 
\end{DoxyItemize}

设置 Open\+Vino S\+DK =============================

\begin{DoxyNote}{Note}
以下所有内容均应在运行 Ubuntu 20.\+04 Linux 的快速 x86\+\_\+64 台式计算机上运行，​​而不是在您的 Je\+Vois-\/\+Pro 相机上运行。最后，我们将转换后的模型复制到 micro\+S\+D，然后使用该模型在 Je\+Vois-\/\+Pro 上运行推理。
\end{DoxyNote}
我们按照\href{https://docs.openvino.ai/latest/openvino_docs_install_guides_install_dev_tools.html\#doxid-openvino-docs-install-guides-install-dev-tools}{\texttt{ 官方 Open\+Vino 安装说明}}在 Ubuntu 20.\+04 桌面上安装 Open\+Vino S\+D\+K：


\begin{DoxyItemize}
\item 创建一个 python 虚拟环境并获取 Open\+Vino 开发工具：
\end{DoxyItemize}


\begin{DoxyCode}{0}
\DoxyCodeLine{python3 -\/m venv openvino\_env source openvino\_env/bin/activate python -\/m pip install -\/-\/upgrade pip pip install openvino-\/dev[tensorflow2,onnx,caffe,kaldi,mxnet,pytorch] \textcolor{comment}{\# 删除不需要的 mo -\/h \# 验证安装 }}
\end{DoxyCode}


示例：使用 Y\+O\+L\+Ov5s 进行对象检测 ========================================


\begin{DoxyEnumerate}
\item 获取模型 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 前往 \href{https://github.com/ultralytics/yolov5}{\texttt{ https\+://github.\+com/ultralytics/yolov5}}
\item 让我们下载在 640x640 输入上运行的 Y\+O\+L\+Ov5s。单击最新版本，然后单击底部资产列表中的 {\bfseries{yolov5s.\+pt，或者运行以下命令：}} 
\end{DoxyItemize}


\begin{DoxyCode}{0}
\DoxyCodeLine{wget https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt }
\end{DoxyCode}



\begin{DoxyItemize}
\item 你将获得 py\+Torch 格式的 $\ast$$\ast$yolov5s.pt$\ast$$\ast$。
\item 与 N\+PU 或 T\+PU 不同，我们不需要 V\+PU 的样本数据集，因为我们只是将 32 位浮点数截断为 16 位浮点数，这不需要详细了解每一层在运行时会遇到的值范围。
\end{DoxyItemize}

2.由于我们的模型是py\+Torch，所以先将其转换为\+O\+N\+NX -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item \href{https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_PyTorch.html}{\texttt{ Open\+Vino 的 py\+Torch 转换文档}} 要求首先将 py\+Torch 模型导出到 O\+N\+N\+X，然后在其上运行 Open\+Vino 模型优化器。
\item 与许多最近的网络一样，yolov5 repo 提供了一个 export.\+py 脚本来将模型导出为 O\+N\+NX 和其他格式。
\item 因此，我们按如下方式进行（另请参阅https\+://github.com/violet17/yolov5\+\_\+demo）：
\end{DoxyItemize}


\begin{DoxyCode}{0}
\DoxyCodeLine{ git clone https://github.com/ultralytics/yolov5.git cd yolov5 pip install -\/r requirements.txt python3 export.py -\/-\/weights ../yolov5s.pt -\/-\/include onnx -\/-\/simplify -\/-\/img 640 -\/-\/batch 1}
\DoxyCodeLine{\textcolor{comment}{\# 测试转换后的模型：python detect.py -\/-\/weights ../yolov5s.onnx }}
\DoxyCodeLine{\textcolor{comment}{\# 检查 runs/detect/exp/ 中的结果 cd .. }}
\end{DoxyCode}



\begin{DoxyItemize}
\item 我们现在有 {\bfseries{yolov5s.\+onnx}}
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 运行\+Open\+Vino模型优化器 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}

默认情况下，网络输出单个输出张量，该张量连接 3 个 Y\+O\+LO 尺度，而大多数 Y\+O\+LO 后处理器需要 3 个单独的输出。因此，让我们将 {\bfseries{yolov5s.\+onnx}} 加载到 \href{https://netron.app}{\texttt{ https\+://netron.\+app}} 中，以在最终重塑和连接之前找到最后 3 个 Conv 层。我们发现 Conv\+\_\+198 输出 1x255x80x80，\+Conv\+\_\+232 输出 1x255x40x40，\+Conv\+\_\+266 输出 1x255x20x20。因此，我们将使用这些输出，\+Je\+Vois Post\+Processor\+Detect 可以处理这些输出。

点击下图放大。如果你点击 Netron 中的每个蓝色 Conv 层，你会看到它们的名称。

  

另外还可以看看 \href{https://github.com/violet17/yolov5_demo}{\texttt{ https\+://github.\+com/violet17/yolov5\+\_\+demo}}，他做了类似的事情。

我们将模型转换为 float16 (F\+P16)，以便在 Myriad-\/X V\+PU 上运行：


\begin{DoxyCode}{0}
\DoxyCodeLine{mo -\/-\/input\_model yolov5s.onnx -\/s 255 -\/-\/data\_type FP16 -\/-\/output Conv\_198,Conv\_232,Conv\_266 }
\end{DoxyCode}


参数 {\bfseries{-\/s 255}} 将在设备上将输入像素除以 255，因此我们可以直接将未缩放的输入像素输入到网络。更多选项请参阅“mo --help”。

我们获得了$\ast$$\ast$yolov5s.bin$\ast$$\ast$和$\ast$$\ast$yolov5s.xml$\ast$$\ast$，可以在\+Je\+Vois-\/\+Pro上运行。


\begin{DoxyEnumerate}
\item 创建\+Y\+A\+ML zoo文件 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 我们从 Je\+Vois micro\+SD 中已有的 zoo 文件 vpu.\+yaml 中的类似条目开始（并且可以在 G\+UI 的 Config 选项卡中使用）。
\item 对于 Y\+O\+LO 后处理，我们需要定义锚点（用于预测对象框的原型框形状）。我们从 \href{https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml}{\texttt{ https\+://github.\+com/ultralytics/yolov5/blob/master/models/yolov5s.\+yaml}} 获取这些，位于顶部：
\begin{DoxyCode}{0}
\DoxyCodeLine{ 锚点：}
\DoxyCodeLine{-\/ [10,13, 16,30, 33,23] \textcolor{comment}{\# P3/8}}
\DoxyCodeLine{-\/ [30,61, 62,45, 59,119] \textcolor{comment}{\# P4/16}}
\DoxyCodeLine{-\/ [116,90, 156,198, 373,326] \textcolor{comment}{\# P5/32 }}
\end{DoxyCode}
 在下面的 Y\+A\+ML 文件中，我们将用分号分隔 3 个 Y\+O\+LO 尺度的 3 组锚点。
\item 由于 Y\+O\+L\+Ov5 使用“新样式”的 Y\+O\+LO 坐标，我们需要禁用后处理器 sigmoid 并将后处理器 scalexy 设置为 2.\+0。对于 Y\+O\+L\+Ov5/v7，您通常会希望这样做。相反，将 sigmoid 设置为 true 并将 scalexy 设置为 0.\+0（默认值）以使用 Y\+O\+L\+Ov2/v3/v4 的旧样式框坐标。您可以在 jevois\+::dnn\+::\+Post\+Processor\+Detect\+Y\+O\+L\+O\+::yolo\+\_\+one() 中查看差异
\item 实际上，我们用于输出的这 3 个 Conv 层在该特定模型中似乎具有线性激活。因此我们需要将 sigmoid 设置为 true，因为后处理器将需要它来进行 Y\+O\+LO 解码。
\item 我们只需修改名称和文件位置，将 spu.\+yml 中的所有全局定义放入我们的文件中（例如 preproc、nettype 等，它们在 spu.\+yml 中全局设置，因此不会在我们要复制的条目中重复），最后得到以下 $\ast$$\ast$yolov5s.yml$\ast$$\ast$：
\begin{DoxyCode}{0}
\DoxyCodeLine{ \%YAML 1.0 -\/-\/-\/}
\DoxyCodeLine{}
\DoxyCodeLine{yolov5s： preproc：Blob 网络类型：OpenCV 后端：InferenceEngine 目标：Myriad 模型：“dnn/custom/yolov5s.bin” 配置：“dnn/custom/yolov5s.xml” 强度：“NCHW：8U：1x3x640x640” postproc：检测 检测类型：RAWYOLO 锚点：“10,13、16,30、33,23；30,61、62,45、59,119；116,90、156,198、373,326” 类：“npu/detection/coco-\/labels.txt” sigmoid：true scalexy：2.0 }
\end{DoxyCode}

\end{DoxyItemize}

\begin{DoxyNote}{Note}
在这里，只需在规范末尾指定 {\bfseries{intensors\+: \char`\"{}\+N\+C\+H\+W\+:8\+U\+:1x3x640x640\char`\"{}}} 而没有量化细节，我们指示 Je\+Vois 预处理器仅提供原始输入像素，而不进行值缩放（即，平均值 = \mbox{[}0 0 0\mbox{]}，比例 = 1，标准差 = \mbox{[}1 1 1\mbox{]}），因此我们完全跳过指定平均比例和标准差。
\end{DoxyNote}

\begin{DoxyItemize}
\item 我们将 yolov5s.\+yml、yolo5s.\+xml、yolov5s.\+bin 复制到 Je\+Vois-\/\+Pro 上的 /jevoispro/share/dnn/custom/ 然后尝试一下！
\end{DoxyItemize}
\begin{DoxyEnumerate}
\item 测试模型并调整任何参数 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\end{DoxyEnumerate}
\begin{DoxyItemize}
\item 选择 机器视觉模块
\item 将 {\ttfamily 管道参数设置为} {\bfseries{V\+P\+U\+:\+Detect\+:yolov5s}}
\end{DoxyItemize}

  

成功了！这个网络对于 Myriad-\/X 来说有点大，运行速度仅为 1.\+9 F\+P\+S。使用模型的微型版本或使用较小的输入尺寸将获得更高的帧/秒。

提示 ====


\begin{DoxyItemize}
\item 另请参阅 \mbox{\hyperlink{UserDNNtips}{运行自定义神经网络的技巧}} 
\end{DoxyItemize}\hypertarget{UserDNNtips}{}\doxysubsubsection{运行自定义神经网络的技巧}\label{UserDNNtips}
Y\+A\+ML zoo 文件的提示 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item Y\+A\+ML 文件中支持的键：每个键都记录在使用它们的类中，在每个头文件开头的 {\ttfamily J\+E\+V\+O\+I\+S\+\_\+\+D\+E\+C\+L\+A\+R\+E\+\_\+\+P\+A\+R\+A\+M\+E\+T\+E\+R(...)} 指令中：
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1PreProcessor}{jevois\+::dnn\+::\+Pre\+Processor}}
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1Network}{jevois\+::dnn\+::\+Network}}
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1PostProcessor}{jevois\+::dnn\+::\+Post\+Processor}}
\item \mbox{\hyperlink{classjevois_1_1dnn_1_1Pipeline}{jevois\+::dnn\+::\+Pipeline}}
\item 如果您创建自定义 python 预处理器、网络或后处理器并在其中定义 Je\+Vois 参数，那么您也可以在 Y\+A\+ML 文件中设置这些参数。
\item 顺序很重要：当一个组件被实例化时（例如，$\ast$$\ast$preproc\+: Blob$\ast$$\ast$ 将实例化一个 jevois\+::dnn\+::\+Pre\+Processor\+Blob），它的参数就会被赋予存在，但它们之前并不存在。因此，例如，由于 {\ttfamily rgb} 是一个预处理器参数，因此应该在设置 {\ttfamily preproc} 之后在 Y\+A\+ML 文件中指定它。~\newline
 对于 Python pre/net/post 尤其如此：
\item 首先选择您将使用 Python，例如，$\ast$$\ast$preproc\+: Python$\ast$$\ast$
\item 这只会公开一个新参数 {\ttfamily pypre} 来选择要加载哪个 python 文件
\item 然后当您设置时，例如，$\ast$$\ast$pypre：“pydnn/pre/\+Py\+Pre\+Blob.py”$\ast$$\ast$ 所选的 python 代码将被加载和初始化
\item 在初始化期间，python 代码可能会创建新的 Je\+Vois 参数；这里，{\ttfamily scale} 和 {\ttfamily mean} 
\item 因此，现在您只能设置 {\bfseries{scale\+: 0.\+0078125}} 或类似值。
\item 参数在其定义中指定了默认值（在 \mbox{\hyperlink{classjevois_1_1dnn_1_1PreProcessor}{jevois\+::dnn\+::\+Pre\+Processor}} 等中）。您可以删除 Y\+A\+ML 文件中将参数设置为这些默认值的行（例如，可以删除 $\ast$$\ast$rgb\+: true$\ast$$\ast$，因为 {\ttfamily rgb} 的默认值为 true）。这将使您的 Y\+A\+ML 文件更简洁。
\end{DoxyItemize}

预处理提示-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item {\ttfamily classes} 是可选的。如果您只想检查模型在 Je\+Vois 相机上的运行速度，但没有类列表，只需从 Y\+A\+ML 中删除 {\ttfamily classes} 参数即可。\+Je\+Vois 只会显示类号而不是类名。
\item 对于 {\ttfamily classoffset：您身边很可能有电脑键盘，而且这些键盘往往很容易被在} Image\+Net 上训练的模型识别。因此，只需将您的相机对准键盘，并在 Je\+Vois G\+UI 中使用 {\ttfamily classoffset} 即可，直到您得到“电脑键盘”作为输出。
\item {\ttfamily 平均值和} {\ttfamily stdev} 值应与模型的输入图像（\+R\+GB 或 B\+G\+R，由 {\ttfamily rgb} 参数指定）的顺序相同。
\end{DoxyItemize}

后期处理技巧 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---


\begin{DoxyItemize}
\item 分类是最简单的情况。检测通常需要更多工作，因为需要合适的后处理器将网络输出解码为屏幕上无法绘制的框。\+Je\+Vois 为 Y\+O\+LO 系列、\+S\+S\+D、\+Faster\+R\+C\+NN 等提供了标准后处理器，您也可以用 Python 编写自己的后处理器。
\item Y\+O\+L\+Ov2 锚点可能需要乘以 8 才能与 Je\+Vois Post\+Processor 配合使用。您可以在终端中按如下方式执行此操作（此处只需从 yolov2-\/voc.\+cfg 中剪切并粘贴锚点）：
\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordflow}{for} x \textcolor{keywordflow}{in} 1.3221, 1.73145, 3.19275, 4.00944, 5.05587, 8.09892, 9.47112, 4.84053, 11.2364, 10.0071; do echo \textcolor{stringliteral}{"scale=4; \$\{x/,/\} * 8"} | bc; echo \textcolor{stringliteral}{','}; done | xargs }
\end{DoxyCode}
 删除最后一个逗号并放置一些分号以分隔 Y\+O\+LO 尺度（如果需要），然后就可以开始了。有关一些详细信息，请参阅https\+://medium.com/nerd-\/for-\/tech/yolo-\/v2-\/configuration-\/file-\/explained-\/879e2219191。模型转换技巧 -\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/-\/---
\item 在转换模型时，我们可能会有一些疑问：我们的模型使用的是 N\+C\+HW 还是 N\+H\+W\+C？输入层和输出层的名称是什么？我们可以使用 Lutz Roeder 出色的 \href{https://netron.app/}{\texttt{ Netron}} 在线模型检查工具来回答这些问题：
\item 将浏览器指向 \href{https://netron.app/}{\texttt{ https\+://netron.\+app/}}
\item 单击“打开模型...”
\item 上传您的模型
\item 单击输入层和输出层的框以查看有关它们的一些信息 
\end{DoxyItemize}