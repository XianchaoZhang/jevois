<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<section xmlns="http://docbook.org/ns/docbook" version="5.0" xmlns:xlink="http://www.w3.org/1999/xlink" xml:id="_User">

<para>JeVois 将视频捕捉和机器视觉处理直接结合在智能相机中。以下是如何开始使用它。</para>

<para>新用户请务必查看 <link xlink:href="/start/start.html">JeVois Start</link>。</para>

<para><itemizedlist>
<listitem>
<para><link linkend="_UserQuick">JeVois-A33 快速入门用户指南</link></para>
</listitem><listitem>
<para><link linkend="_ProUserQuick">JeVois-Pro 快速入门用户指南</link></para>
</listitem><listitem>
<para><link linkend="_ProNetwork">JeVois-Pro：连接到有线或 WiFi 网络</link></para>
</listitem><listitem>
<para><link linkend="_UserStartLinux">JeVois-A33：Linux 主机入门</link></para>
</listitem><listitem>
<para><link linkend="_UserStartWindows">JeVois-A33：开始使用 Windows 主机</link></para>
</listitem><listitem>
<para><link linkend="_UserStartMac">JeVois-A33：Mac 主机入门 \tableofcontents</link></para>
</listitem><listitem>
<para><link linkend="_UserStartCaveats">JeVois-A33：入门注意事项 \tableofcontents</link></para>
</listitem><listitem>
<para><link linkend="_UserModes">视频模式和映射用户指南</link></para>
</listitem><listitem>
<para><link linkend="_UserDemos">捆绑视觉模块和演示的用户指南</link></para>
</listitem><listitem>
<para><link linkend="_UserLighting">优化不同光照条件下的性能</link></para>
</listitem><listitem>
<para><link linkend="_MicroSD">MicroSD 卡组织和文件</link></para>
</listitem><listitem>
<para><link linkend="_NewMicroSD">如何为 JeVois 格式化新的 MicroSD 卡</link></para>
</listitem><listitem>
<para><link linkend="_UserSerial">串口使用指南</link></para>
</listitem><listitem>
<para><link linkend="_UserSerialStyle">标准化串行消息格式</link></para>
</listitem><listitem>
<para><link linkend="_ProConnectors">JeVois-Pro 辅助连接器</link></para>
</listitem><listitem>
<para><link linkend="_UserProFan">JeVois-Pro 调整风扇速度</link></para>
</listitem><listitem>
<para><link linkend="_UserProUSBserial">JeVois-Pro 串行 USB 通信</link></para>
</listitem><listitem>
<para><link linkend="_UserCli">命令行界面用户指南</link></para>
</listitem><listitem>
<para><link linkend="_ArduinoTutorial">教程：如何编写与 JeVois 交互的 Arduino 代码</link></para>
</listitem><listitem>
<para><link linkend="_CaseMounting">JeVois-A33 外壳安装指南</link></para>
</listitem><listitem>
<para><link linkend="_ProCaseMounting">JeVois-Pro 外壳安装指南</link></para>
</listitem><listitem>
<para><link linkend="_HardwareFiles">硬件：原理图、机壳 STL 文件等 \tableofcontents</link></para>
</listitem><listitem>
<para><link linkend="_Lenses">JeVois-A33 镜头选项</link></para>
</listitem><listitem>
<para><link linkend="_Sensors">JeVois-A33 相机传感器选项</link></para>
</listitem><listitem>
<para><link linkend="_Fanless">JeVois-A33 无风扇操作</link></para>
</listitem><listitem>
<para><link linkend="_Multicam">JeVois-A33 通过连接到一个 USB 总线的多个 JeVois 摄像机流式传输视频</link></para>
</listitem><listitem>
<para><link linkend="_UserDNNoverview">在 JeVois-A33 和 JeVois-Pro 上运行神经网络</link> </para>
</listitem></itemizedlist>
</para>
    <section xml:id="_UserQuick"><title>JeVois-A33 快速入门用户指南</title>    </section>
<para>有关更多详细信息和分步说明，请参阅 <link linkend="_User">用户指南</link> 下的不同部分</para>

<para>新用户请务必查看 <link xlink:href="/start/start.html">JeVois Start</link>。</para>

<para></para>

<para>有关更多具体信息，请参阅：</para>

<para><itemizedlist>
<listitem>
<para><link linkend="_UserStartLinux">JeVois-A33：Linux 主机入门</link></para>
</listitem><listitem>
<para><link linkend="_UserStartWindows">JeVois-A33：开始使用 Windows 主机</link></para>
</listitem><listitem>
<para><link linkend="_UserStartMac">JeVois-A33：Mac 主机入门 \tableofcontents</link></para>
</listitem><listitem>
<para><link linkend="_UserStartCaveats">JeVois-A33：入门注意事项 \tableofcontents</link> </para>
</listitem></itemizedlist>
</para>
    <section xml:id="_ProUserQuick"><title>JeVois-Pro 快速入门用户指南</title>    </section>
<para>基础知识 ======</para>

<para>有关更多详细信息和分步说明，请参阅 用户下的不同部分</para>

<para>新用户请务必查看 <link xlink:href="/start/start.html">JeVois Start</link>。</para>

<para><itemizedlist>
<listitem>
<para>您的 HDMI 显示器必须至少支持 1080p/60Hz（1920x1080，60 帧/秒）。如果您的计算机显示器不工作，请尝试使用高清或 4K 电视。</para>
</listitem><listitem>
<para>标准 USB 键盘和鼠标应该会自动检测。如果您喜欢的键盘和鼠标没有被检测到，请尝试使用您最通用的键盘和鼠标。</para>
</listitem><listitem>
<para>要将 microSD 卡插入 JeVois-Pro，请参阅 <link linkend="_JeVoisProIntro">JeVois-Pro：新用户介绍</link></para>
</listitem><listitem>
<para>要连接 JeVois-Pro，请参阅 <link linkend="_ProUserConnect">将 JeVois-Pro 连接到电源和数据</link></para>
</listitem></itemizedlist>
</para>

<para>故障排除 ================</para>

<para><itemizedlist>
<listitem>
<para><emphasis role="bold">我看到了 JeVois-Pro 启动徽标，但之后我的显示器变黑，或者报告图片超出范围。</emphasis> 您的显示器至少需要支持 1080p (1920x1080)。在一些早期发货中，我们将分辨率设置为 1080p30Hz，但事实证明 1080p60Hz 得到了更广泛的支持。请尝试此修复：</para>
</listitem><listitem>
<para>小心地从 JeVois-Pro 中弹出 microSD 卡，如 <link xlink:href="https://www.youtube.com/watch?v=0wMplgtwuAc">此视频</link> 所示</para>
</listitem><listitem>
<para>使用读卡器将其连接到计算机</para>
</listitem><listitem>
<para>打开名为 <emphasis role="bold">BOOT</emphasis> 的驱动器</para>
</listitem><listitem>
<para>在其中，找到文件 <emphasis role="bold">env.txt</emphasis> 并使用纯文本编辑器（例如 Notepad、TextEdit、nano 等）打开它。只需双击它就可以了。</para>
</listitem><listitem>
<para>向下滚动到显示“hdmi=1080p30hz”的行，并将 30 替换为 60</para>
</listitem><listitem>
<para>保存文件并干净地弹出磁盘</para>
</listitem><listitem>
<para>将 microSD 重新插入 JeVois-Pro，它应该可以工作。</para>
</listitem><listitem>
<para><emphasis role="bold">视频的顶部和底部被裁剪</emphasis>。许多电视确实默认会略微裁剪图片。您需要浏览电视菜单，找到“全原生”、“全分辨率”、“全 100”等图片设置。以下是 Sceptre 4K 电视的示例：   上图：此电视在正常模式下，图片略微裁剪（参见屏幕底部的文本行）。点击图片放大。   上图：使用电视遥控器将电视设置为“全 100”可消除裁剪。点击图片放大。</para>
</listitem></itemizedlist>
</para>

<para>启动模式 ===========</para>

<para>在 GUI 的 <emphasis role="bold">系统选项卡下，您可以为</emphasis> JeVois-Pro 选择不同的启动模式：</para>

<para><itemizedlist>
<listitem>
<para>JeVois：在启动时启动 JeVois 软件。</para>
</listitem><listitem>
<para>Ubuntu 控制台：在启动时启动文本控制台。</para>
</listitem><listitem>
<para>Ubuntu 图形：启动 X-Windows 并提供图形登录。</para>
</listitem></itemizedlist>
</para>

<para>进入控制台或图形模式后，在终端中发出以下命令进行切换：</para>

<para><literallayout><computeroutput>sudo&#32;systemctl&#32;set-default&#32;jevoispro.target&#32;#&#32;启动到&#32;JeVois&#32;软件&#32;sudo&#32;systemctl&#32;set-default&#32;multi-user.target&#32;#&#32;启动到&#32;Ubuntu&#32;控制台&#32;sudo&#32;systemctl&#32;set-default&#32;graphic.target&#32;#&#32;启动到&#32;Ubuntu&#32;图形&#32;
</computeroutput></literallayout></para>

<para>然后</para>

<para><literallayout><computeroutput>sudo&#32;shutdown&#32;-h&#32;now&#32;
</computeroutput></literallayout></para>

<para>拔掉电源并重新插入。</para>

<para><note><title>Note</title>

<para>软件重置（shutdown -r）目前不起作用。这可能是硬件问题，但我们稍后可能会创建软件解决方法。</para>
</note>
密码 ==========</para>

<para>用户 <emphasis>jevois</emphasis> 的密码为 <emphasis role="bold">jevois</emphasis> 并且可以使用 sudo（使用该密码）。</para>

<para>用户 <emphasis>root</emphasis> 的密码为 <emphasis role="bold">jevois</emphasis> </para>

<para>JeVois-Pro 软件默认以 root 身份运行。</para>

<para>手动启动 JeVois 软件 =====================================</para>

<para>如果您已切换到控制台启动，则登录后（以 jevois/jevois 或 root/jevois 身份），您可以从命令行启动 JeVois 软件：</para>

<para><literallayout><computeroutput>sudo&#32;jevoispro.sh&#32;
</computeroutput></literallayout></para>

<para>请注意，ARM 为我们的芯片 (Amlogic A311D) 提供的 GPU 驱动程序仅在全屏帧缓冲模式下工作。因此，它们在 JeVois-Pro 模式或控制台模式下启动时工作正常。但是，如果您从 X-windows 中的终端运行“sudo jevoispro.sh”，您将遇到两个图形界面 (X-windows 和 JeVois GUI) 之间的冲突。您将看到 2 个鼠标指针，一些 X 窗口将在 JeVois 显示屏上刷新，等等。因此，如果您想手动运行 jevoispro.sh，请从控制台模式执行。</para>

<para>当您处于控制台模式时，您可以通过输入以下命令启动 X-windows：</para>

<para><literallayout><computeroutput>startx&#32;
</computeroutput></literallayout></para>

<para>当您从 X 注销时，您将返回到您的控制台。</para>

<para>这对于开发非常有用。您可以执行以下操作：</para>

<para><itemizedlist>
<listitem>
<para>切换到控制台启动并重新启动</para>
</listitem><listitem>
<para>以 root/jevois 身份登录</para>
</listitem><listitem>
<para>运行 <computeroutput>jevoispro.sh</computeroutput></para>
</listitem><listitem>
<para>如果要退出，请激活图形用户界面的 <computeroutput>allowquit</computeroutput> 参数（您需要先打开显示系统参数）。或者您也可以从 <computeroutput>jevoispro.sh --gui --allowquit</computeroutput> 开始，这将允许您在按下 ESC 键时退出 JeVois 软件。</para>
</listitem><listitem>
<para>如果您需要编辑一些文件、下载一些文件等，并且您喜欢在 X-windows 中执行这些操作，则在完成后运行 <computeroutput>startx</computeroutput> 并从中注销。</para>
</listitem><listitem>
<para>然后您可以再次运行 <computeroutput>jevoispro.sh</computeroutput>，等等。</para>
</listitem></itemizedlist>
</para>

<para>WiFi 或有线网络 ==========================</para>

<para>参见 <link linkend="_ProNetwork">JeVois-Pro：连接到有线或 WiFi 网络</link></para>

<para>启用 4K 显示分辨率 =================================</para>

<para>通过在 microSD 卡上的 <emphasis role="bold">/boot/env.txt</emphasis> 中编辑 <computeroutput>hdmi</computeroutput> 值来执行此操作。例如，对于 30Hz 的 4K：</para>

<para>\逐字 hdmi=2160p30hz \end逐字</para>

<para>请注意，相机在 4K 分辨率下的整体运行速度会比默认的 1080p 分辨率下略慢。我们认为这是由于内存总线上的争用加剧所致，因为我们从相机传感器到 GPU 再到显示器全程都使用 DMA，因此 CPU 工作负载在 4K 分辨率下不会显著增加。</para>

<para>超频 CPU ======================</para>

<para>在我们的测试中，将 CPU 超频至 2.4 GHz（大核，默认为 2.208 GHz）和 2.208 GHz（小核，默认为 1.8 GHz）非常稳定，特别是如果您确保冷却性能强劲（请参阅 <link linkend="_UserProFan">JeVois-Pro 调整风扇速度</link> 编辑风扇设置）。</para>

<para>首先，您需要通过编辑 microSD 卡上的 <emphasis role="bold">/boot/env.txt</emphasis> 来启用超频：</para>

<para><literallayout><computeroutput>#&#32;小核&#32;A53&#32;最大&#32;CPU&#32;频率
#&#32;500/667/1000/1200/1398/1512/1608/1704/1800(默认)/1908/2016/2100/2208&#32;max_freq_a53=2208

#&#32;大核A73最大CPU频率
#&#32;500/667/1000/1200/1398/1512/1608/1704/1800/1908/2016/2100/2208(默认)/2304/2400&#32;max_freq_a73=2400&#32;
</computeroutput></literallayout></para>

<para>这只是设置了最大可能频率。但默认情况下，启动时的工作频率仍为 2.2/1.8 GHz。</para>

<para>然后重新启动，在 GUI 中选择“参数”选项卡，然后启用“显示系统参数”，在“引擎选项”下，您可以设置所需的 CPU 最大速度。如果您希望在启动时将这些值设置为默认值，则可以在 <computeroutput>params.cfg</computeroutput> 配置文件中设置这些值（参见 GUI 中的“配置”选项卡）。 </para>
    <section xml:id="_ProNetwork"><title>JeVois-Pro：连接到有线或 WiFi 网络</title>    </section>
<para>最简单：USB 转有线网络 ==================================</para>

<para>如果您有一个运行 DHCP 服务器的有线网络，则您只需使用如下所示的 USB 转以太网适配器即可。</para>

<para>  </para>

<para>它应该会自动检测和配置。要从 JeVois-Pro 控制台检查，您可以发出“shell ifconfig”并检查配置。然后您可以转到“系统”选项卡并尝试 ping jevois.usc.edu</para>

<para>使用 RTL8812AU 适配器的 USB 转 Wifi 网络 =================================================</para>

<para>许多 Wifi 适配器默认不包含在 Linux 内核中，因为它们包含闭源代码。</para>

<para>我们已预装了多种品牌适配器中流行的 Realtek RTL8812AU 芯片的驱动程序。</para>

<para>  </para>

<para>要选择 Wifi 网络，最简单的方法是按以下步骤操作：<itemizedlist>
<listitem>
<para>在 JeVois-Pro 系统选项卡中，选择重新启动到 Linux 控制台。</para>
</listitem><listitem>
<para>重新启动相机。</para>
</listitem><listitem>
<para>以 <emphasis>root</emphasis> 身份登录，密码为 <emphasis>jevois</emphasis> </para>
</listitem><listitem>
<para>键入 <computeroutput>startx</computeroutput></para>
</listitem><listitem>
<para>在右上角，选择网络图标，选择一个网络并输入 Wifi 密码。</para>
</listitem><listitem>
<para>检查网络是否正常工作，例如，启动 Web 浏览器并浏览。</para>
</listitem><listitem>
<para>在右上角，注销。这将使您返回到控制台。</para>
</listitem><listitem>
<para>检查网络是否仍在工作，例如 <computeroutput>ping jevois.usc.edu</computeroutput></para>
</listitem><listitem>
<para>键入 <computeroutput>jevoispro.sh</computeroutput> 以启动 JeVois 软件</para>
</listitem><listitem>
<para>在系统选项卡中，选择重新启动到 JeVois-Pro 并重新启动机器。</para>
</listitem></itemizedlist>
</para>

<para>该配置应该是持久的，并且您的 Wifi 网络应该在启动时自动选择。</para>

<para>M.2 PCI-express Wifi 网络 =================================</para>

<para>如果您不使用 Coral TPU，则可以使用 JeVois-Pro 中的 M.2 A+E 插槽连接 Wifi 卡。</para>

<para>  </para>

<para>步骤如下：</para>

<para><itemizedlist>
<listitem>
<para>选择使用 PCIe 的。我们在使用基于 Intel 的卡方面取得了良好的成功。</para>
</listitem><listitem>
<para>确保该芯片受 Linux 内核 4.9.x 支持；特别是，一些最新的 Intel AX210 芯片组需要内核 5.10+，并且无法在 JeVois-Pro 上运行。如果您打算使用 Intel 芯片组，请参阅<link xlink:href="https://www.intel.com/content/www/us/en/support/articles/000005511/wireless.html">此处</link>，或者在网上搜索其他芯片组的 Linux 兼容性。</para>
</listitem><listitem>
<para>确保它是 M.2 2230 (22mm x 30mm) A-key 或 E-key（大多数 M.2 Wifi 卡应该都是）。</para>
</listitem><listitem>
<para>打开 JeVois-Pro（4 个螺钉）</para>
</listitem><listitem>
<para>如果有 TPU 板，请将其移除</para>
</listitem><listitem>
<para>插入 Wifi 卡</para>
</listitem><listitem>
<para>使用 M2x5mm 螺钉将其固定</para>
</listitem></itemizedlist>
</para>

<para>应该可以检测到卡。然后，您可以按照上述方法针对 USB 转 Wifi 的情况进行配置。 </para>
    <section xml:id="_UserStartLinux"><title>JeVois-A33：Linux 主机入门</title>    </section>
<para>最简单的入门方法是使用 <link linkend="_JeVoisInventor">JeVois-A33：JeVois Inventor 图形用户界面</link></para>

<para>以下是替代方法。</para>

<para>JeVois 智能相机的使用方式与普通 USB 相机相同。要开始使用 Linux 主机：</para>

<para><itemizedlist>
<listitem>

<para>从 <link xlink:href="http://jevois.org">http://jevois.org</link> 下载磁盘映像并将其刷入 MicroSD 卡。</para>

<para></para>
</listitem>
<listitem>

<para>将 MicroSD 卡插入 JeVois 智能相机，MicroSD 触点朝上，如下所示。</para>

<para>  </para>

<para>  </para>

<para></para>
</listitem>
<listitem>

<para>将相机连接到主机。智能相机需要高达 3.5 瓦的功率，这超出了单个 USB 2.0 端口的设计供电限制，但在单个 USB 3.0 端口的限制范围内。使用能够无损传输全部功率的高质量 USB-miniUSB 电缆非常重要。寻找带有 24awg 电源线的电缆。建议您在主机上使用 USB 3.0 端口，因为它们可以提供更多功率。如果没有，您可以使用 USB Y 型电缆连接到主机上的两个 USB 2.0 端口，或者连接到一个 USB 2.0 端口和一个外部 USB 电源（例如，手机充电器）。请确保不要使用 USB 集线器，除非该集线器具有强大的外部电源（变压器、壁式适配器）。</para>

<para></para>
</listitem>
<listitem>

<para>观察 USB 连接器旁边的智能相机上的 LED：<itemizedlist>
<listitem>
<para>绿色：电源已打开且足够强。</para>
</listitem><listitem>
<para>约 3 秒后：橙色闪烁：相机传感器芯片已被检测到并初始化。</para>
</listitem><listitem>
<para>约 5 秒后：橙色常亮：智能相机已准备就绪。</para>
</listitem><listitem>
<para>再等待几秒钟，让主机检测到相机并准备好进行视频捕获。</para>
</listitem></itemizedlist>
</para>

<para></para>
</listitem>
<listitem>

<para>启动视频捕获软件。尝试 <computeroutput>guvcview</computeroutput> （可能需要 &apos;sudo apt-get install guvcview&apos; 或使用 Linux 包管理器查找并安装 <computeroutput>guvcview</computeroutput> ）</para>

<para>首次使用 <computeroutput>guvcview</computeroutput> 时，它可能会挂起，尝试打开主机上的声音设备。为避免这种情况，请从 Linux 终端首次启动 <computeroutput>guvcview，如下所示：</computeroutput> <literallayout><computeroutput>sudo apt-get install guvcview
guvcview -ao none -f YUYV -x 640x360 # On Raspberry Pi host, use &apos;-a none -o none&apos; instead of &apos;-ao none&apos;
</computeroutput></literallayout> guvcview 会记住下次打开时不要尝试使用声音 (-ao none)。下次您可以从 Ubuntu 菜单启动它，而无需终端。</para>

<para>guvcview 提供了出色的图形用户界面，但并不适用于所有像素格式。有时在更改像素格式（例如从 MJPG 到 YUYV）时也会崩溃。另一种方法是使用 <computeroutput>ffplay</computeroutput> （可能需要 &apos;sudo apt-get install ffmpeg&apos; 或使用 Linux 包管理器查找并安装 <computeroutput>ffmpeg</computeroutput> ）</para>

<para>ffplay 可以显示 JeVois 支持的所有像素格式，如果格式与硬件支持的格式不完全匹配，则会拒绝该格式。例如：</para>

<para><literallayout><computeroutput>sudo apt-get install ffmpeg
ffplay /dev/video0 -pixel_format yuyv422 -video_size 640x300
</computeroutput></literallayout></para>

<para>JeVois 支持的 pixel_format 值为（更多信息请参阅 <link linkend="_UserModes">视频模式和映射用户指南</link> ）：YUYV 为 &apos;yuyv422&apos;、GRAY 为 &apos;gray&apos;、RGB565 为 &apos;rgb565&apos;、MJPG 为 &apos;mjpeg&apos;、BGR24 为 &apos;bgr24&apos;、BAYER 为 &apos;bayer_rggb8&apos;。</para>

<para>请注意，在 Raspberry Pi 3 上，显示帧速率可能会很慢，尤其是在省电模式下（屏幕右上角出现小黄色闪电，表示电源太弱，无法让 Pi 全速运行）。确保使用强大的 USB 充电器为 Pi 供电（例如，输出电流为 2.1A）。Raspberry Pi 的速度对于实时视频捕获和显示来说有点太慢了。建议使用更快的 Linux 台式计算机以获得最佳视频性能。</para>

<para></para>
</listitem>
<listitem>

<para>请随意使用控件（亮度、对比度等）。它们都应该在 <computeroutput>guvcview</computeroutput> 中工作。请记住，某些控件依赖于其他控件，就像在任何 USB 相机中一样。例如，&quot;Exposure (Absolute)&quot; 将保持灰色，直到您将 &quot;Exposure, Auto&quot; to &quot;Manual Mode&quot;。</para>

<para></para>

<para></para>
</listitem>
<listitem>

<para>通过在视频捕获软件中选择不同的视频分辨率，可以实现选择不同的机器视觉算法。例如，在 guvcview 中，首先单击 &quot;Video Controls&quot; 选项卡，然后单击e &quot;Resolution&quot; 下拉菜单：</para>

<para></para>

<para></para>
</listitem>
<listitem>

<para>拔下 JeVois 智能相机之前，请确保退出相机查看软件。否则，您的主机可能会在尝试使用不再存在的相机时变得非常困惑。</para>

<para></para>
</listitem>
<listitem>

<para>关闭 JeVois 相机前无需执行关机程序。只需关闭视频捕捉软件并拔下相机电源即可。</para>

<para></para>
</listitem>
</itemizedlist>
</para>

<para><formalpara><title></title></formalpara>
</para>
<section xml:id="_UserStartLinux_1obslinux">
<title>Linux 入门 - Open Broadcaster Studio</title>

<para>Open Broadcaster Studio 是另一个很棒的免费程序，它允许您根据 JeVois 的需要选择不同的视频分辨率。</para>

<para><itemizedlist>
<listitem>
<para>从 <link xlink:href="https://obsproject.com">https://obsproject.com</link> 查看 OBS Studio</para>
</listitem><listitem>
<para>在 Ubuntu 16.04 及更高版本下，按如下方式安装： <literallayout><computeroutput>  sudo apt install obs-studio</computeroutput></literallayout></para>
</listitem><listitem>
<para>将 JeVois 连接到您的计算机并允许其启动。</para>
</listitem><listitem>
<para>打开 OBS Studio（只需在终端中输入 <computeroutput>obs</computeroutput> 或在 Ubuntu 菜单中找到），在屏幕左下方，单击 <emphasis role="bold">Sources</emphasis> 下的 <computeroutput>+</computeroutput> 图标以添加新的<emphasis role="bold">视频捕获设备（V4L2）</emphasis>。 </para>
</listitem><listitem>
<para>创建一个新的源 </para>
</listitem><listitem>
<para>如果您有多个摄像头，请选择 Jevois-A33 智能摄像头作为其设备，您将看到来自 JeVois 的实时视频。 </para>
</listitem><listitem>
<para>双击该源时，会出现一个对话框。在其中，您可以选择：<itemizedlist>
<listitem>
<para>设备：JeVois-A33 智能相机</para>
</listitem><listitem>
<para>分辨率：选择您想要尝试的任何分辨率</para>
</listitem><listitem>
<para>帧速率：选择<emphasis role="bold">保持不变</emphasis>或选择您选择的一个。 </para>
</listitem></itemizedlist>
</para>
</listitem><listitem>
<para>尽情享受吧！您可以拖动并调整视频预览的大小以获得最佳观看体验。 </para>
</listitem></itemizedlist>
</para>

<para><formalpara><title></title></formalpara>
</para>
</section>
<section xml:id="_UserStartLinux_1troubleshootlinux">
<title>故障排除</title>

<para>如果一切不正常，请尝试在 Linux 终端中输入 <computeroutput>dmesg</computeroutput> ，并观察打印内容的末尾。您应该看到类似以下内容：</para>

<para><literallayout><computeroutput>[...]
[4768736.704777] usb 1-1.3: new high-speed USB device number 13 using xhci_hcd
[4768736.809464] usb 1-1.3: New USB device found, idVendor=1d6b, idProduct=0102
[4768736.809470] usb 1-1.3: New USB device strings: Mfr=1, Product=2, SerialNumber=0
[4768736.809473] usb 1-1.3: Product: JeVois-A33 Smart Camera
[4768736.809476] usb 1-1.3: Manufacturer: JeVois Inc
[4768736.847915] uvcvideo: Found UVC 1.00 device JeVois-A33 Smart Camera (1d6b:0102)
[4768736.849892] input: JeVois-A33 Smart Camera as /devices/pci0000:00/0000:00:1c.6/0000:09:00.0/usb1/1-1/1-1.3/1-1.3:1.0/input/input29
[4768736.851499] cdc_acm 1-1.3:1.2: ttyACM0: USB ACM device
</computeroutput></literallayout></para>

<para>如果没有，请参见下文。 <itemizedlist>
<listitem>

<para><computeroutput>guvcview</computeroutput> 未检测到 JeVois 智能相机</para>

<para>可能的原因包括：</para>

<para><itemizedlist>
<listitem>
<para>您忘记将 microSD 卡插入 JeVois 相机，请将其插入并重试。</para>
</listitem><listitem>
<para>您的 microSD 卡包含不正确的软件。请尝试再次刷新软件。</para>
</listitem><listitem>
<para>您过早启动了 guvcview，您的计算机尚未检测到 JeVois 相机。智能相机在大约 5 秒内启动，但您的主机可能还需要几秒钟才能发现相机并为其进行配置。</para>
</listitem><listitem>
<para>您的主机经历了太多 USB 连接/断开循环，并且感到困惑。请尝试重新启动它。</para>
</listitem><listitem>
<para>您正尝试通过损坏的 USB 集线器连接 JeVois 相机。请尝试直接连接到计算机主板上的 USB 端口。</para>
</listitem><listitem>
<para>其他程序正在使用摄像头，或阻止摄像头检测。这种情况有时会发生，例如，如果您在 guvcview 仍在运行时断开摄像头，guvcview 会对此感到不满并感到困惑。请确保将其完全终止，例如在 Linux 终端中输入以下内容： <literallayout><computeroutput>  sudo killall -9 guvcview</computeroutput></literallayout> 然后尝试再次连接 JeVois 摄像头。 </para>
</listitem></itemizedlist>
</para>
</listitem>
<listitem>

<para><computeroutput>guvcview</computeroutput> 显示来自另一台摄像头的视频（例如，笔记本电脑上的内置摄像头）</para>

<para>您可以使用 <computeroutput>guvcview</computeroutput> 中的下拉菜单来选择您的 JeVois 相机（单击“视频控制”选项卡，然后单击“设备”下拉菜单），或者像这样启动 guvcview</para>

<para><literallayout><computeroutput>guvcview -d /dev/video1
</computeroutput></literallayout></para>

<para>在 Linux 上，第一个连接的摄像头是 <computeroutput>/dev/video0</computeroutput> ，下一个是 <computeroutput>/dev/video1</computeroutput> ，依此类推。</para>

<para></para>
</listitem>
<listitem>

<para>我想以特定的视觉模式启动，但当 <computeroutput>guvcview</computeroutput> 启动时，它只使用我之前选择的最后一个模式</para>

<para>你可以告诉 <computeroutput>guvcview</computeroutput> 以特定模式启动，例如</para>

<para><literallayout><computeroutput>guvcview -ao none -f YUYV -x 640x312  # On Raspberry Pi host, use &apos;-a none -o none&apos; instead of &apos;-ao none&apos;
</computeroutput></literallayout></para>

<para>将启动显著性+面部+物体识别演示。</para>

<para></para>
</listitem>
</itemizedlist>
</para>
</section>
    <section xml:id="_UserStartWindows"><title>JeVois-A33：开始使用 Windows 主机</title>    </section>
<para>最简单的入门方法是使用 <link linkend="_JeVoisInventor">JeVois-A33：JeVois Inventor 图形用户界面</link></para>

<para>以下是替代方法。</para>

<para>JeVois 智能相机的使用方式与普通 USB 相机相同。要开始使用 Windows 主机：</para>

<para><itemizedlist>
<listitem>

<para>从 <link xlink:href="http://jevois.org">http://jevois.org</link> 下载磁盘映像并将其刷入 MicroSD 卡。</para>

<para></para>
</listitem>
<listitem>

<para>将 MicroSD 卡插入 JeVois 智能相机，MicroSD 触点朝上，如下所示。</para>

<para>  </para>

<para>  </para>

<para></para>
</listitem>
<listitem>

<para>将相机连接到主机。智能相机需要高达 3.5 瓦的功率，这超出了单个 USB 2.0 端口的设计供电限制，但在单个 USB 3.0 端口的限制范围内。使用能够无损传输全部功率的高质量 USB-miniUSB 电缆非常重要。寻找带有 24awg 电源线的电缆。建议您在主机上使用 USB 3.0 端口，因为它们可以提供更多功率。如果没有，您可以使用 USB Y 型电缆连接到主机上的两个 USB 2.0 端口，或者连接到一个 USB 2.0 端口和一个外部 USB 电源（例如，手机充电器）。请确保不要使用 USB 集线器，除非该集线器具有强大的外部电源（变压器、壁式适配器）。</para>

<para></para>
</listitem>
<listitem>

<para>观察 USB 连接器旁边的智能相机上的 LED：<itemizedlist>
<listitem>
<para>绿色：电源已打开且足够强。</para>
</listitem><listitem>
<para>约 3 秒后：橙色闪烁：相机传感器芯片已被检测到并初始化。</para>
</listitem><listitem>
<para>约 5 秒后：橙色常亮：智能相机已准备就绪。</para>
</listitem><listitem>
<para>再等待几秒钟，让主机检测到相机并准备好进行视频捕获。</para>
</listitem></itemizedlist>
</para>

<para></para>
</listitem>
<listitem>

<para>启动视频捕获软件。您可能想尝试 VLC、Skype 等。这里我们将使用 <emphasis role="bold">AMCap。</emphasis> </para>

<para><itemizedlist>
<listitem>
<para>下载并安装 AMCap 软件。您可以在 <link xlink:href="http://noeld.com/updates.asp">http://noeld.com/updates.asp</link> 免费获取。</para>
</listitem><listitem>
<para>启动 AMCap 软件。在“设备”下，确保选择 JeVois 智能相机（如果您有多个相机，例如笔记本电脑中还有一个内置网络摄像头）。例如，我们在 JeVois 上运行 ArUco 演示，并使用 AMCap 在主机 PC 上查看结果：</para>
</listitem></itemizedlist>
</para>

<para></para>

<para><itemizedlist>
<listitem>
<para>通过在视频捕获软件中选择不同的视频分辨率来选择不同的机器视觉算法。要更改视频分辨率，请选择“选项”、“视频设备”、“捕获格式”，如下所示：</para>
</listitem></itemizedlist>
</para>

<para></para>

<para><itemizedlist>
<listitem>
<para>看到“属性”对话框后，选择可用的“颜色空间/压缩”之一（大多数机器视觉模块输出 <emphasis role="bold">YUY2</emphasis> 视频）和一个“输出尺寸”分辨率（如下所示），以在 JeVois 相机上启动相应的机器视觉算法：</para>
</listitem></itemizedlist>
</para>

<para></para>

<para><itemizedlist>
<listitem>
<para>要访问相机的控制（如亮度、对比度等），可以通过选择“选项”、“视频设备”、“属性”来完成，如下所示：</para>
</listitem></itemizedlist>
</para>

<para></para>

<para></para>

<para>请注意，在 Windows 上以及对于 VLC 等某些视频软件，许多视频捕获应用程序的延迟（捕获和显示之间的延迟或滞后）非常严重。这不是 JeVois 的限制。与 Linux 主机一起使用时，不会出现延迟。</para>

<para></para>
</listitem>
<listitem>

<para>拔下 JeVois 智能相机之前，请确保退出相机查看软件。否则，您的主机可能会在尝试使用不再存在的相机时变得非常困惑。</para>

<para></para>
</listitem>
<listitem>

<para>关闭 JeVois 相机前无需执行关机程序。只需关闭视频捕捉软件并拔下相机电源即可。</para>

<para></para>
</listitem>
</itemizedlist>
</para>

<para><formalpara><title></title></formalpara>
</para>
<section xml:id="_UserStartWindows_1windows10">
<title>针对 Windows 10 的特殊说明</title>

<para>部分 Windows 10 用户（但不是全部）报告了使用 JeVois 的问题。摄像头被正确检测和设置，但无法从中捕获视频。</para>

<para>从 开始，我们启用了一种解决方法，希望可以解决这个问题。它与 Windows 10 向 JeVois 发送非法请求有关，JeVois 对此回应为 USB 停顿（在这种情况下应该如此），但 Windows 10 对此感到不满。</para>

<para>在 Windows 10 下，当您插入 JeVois 并让 Windows 配置它时，您应该会看到以下设备：<itemizedlist>
<listitem>
<para>摄像机</para>
</listitem><listitem>
<para>存储设备（默认情况下为空，您需要告诉 JeVois 导出其 microSD 卡才能实际看到那里的一些文件）</para>
</listitem><listitem>
<para>串行端口，您可以使用它向 JeVois 发送命令。</para>
</listitem></itemizedlist>
</para>

<para></para>

<para>如果您使用的 JeVois 软件版本早于，则摄像机将被命名为“Video Control”（这是 Windows 的另一个错误；它使用摄像机控制单元的名称，而不是制造商和产品名称）。这表明您应该更新到 或更高版本。</para>

<para><formalpara><title></title></formalpara>
</para>
</section>
<section xml:id="_UserStartWindows_1obswindows">
<title>使用适用于 Windows 的 Open Broadcaster Studio</title>

<para>Open Broadcaster Studio 是一款出色的免费程序，允许您根据 JeVois 的需要选择不同的视频分辨率。</para>

<para><itemizedlist>
<listitem>
<para>从 <link xlink:href="https://obsproject.com">https://obsproject.com</link> 下载 OBS Studio</para>
</listitem><listitem>
<para>安装它，在安装过程中，只需说您不会流式传输视频。</para>
</listitem><listitem>
<para>将 JeVois 连接到您的计算机并允许其启动。</para>
</listitem><listitem>
<para>打开 OBS Studio，在屏幕左下方，单击 <emphasis role="bold">来源下的</emphasis> <computeroutput>+</computeroutput> 图标以添加新的<emphasis role="bold">视频捕获设备</emphasis>。</para>
</listitem><listitem>
<para>创建一个新的源 </para>
</listitem><listitem>
<para>双击该源时，会出现一个对话框。在其中，选择：</para>
</listitem><listitem>
<para>设备：JeVois-A33 摄像机（这是 Windows 分配给 JeVois 的名称；在不同的 Windows 版本上可能会有所不同，如果您有内置网络摄像头，只需选择您知道不是内置网络摄像头的设备即可）。</para>
</listitem><listitem>
<para>分辨率/FPS 类型：自定义</para>
</listitem><listitem>
<para>分辨率：选择您想要尝试的任何分辨率</para>
</listitem><listitem>
<para>FPS：最高 FPS </para>
</listitem><listitem>
<para>尽情享受吧！您可以拖动并调整视频预览的大小，以获得最佳观看体验。</para>
</listitem></itemizedlist>
</para>

<para>以下是 在 Windows 10 上的顺利运行：</para>

<para></para>

<para><formalpara><title></title></formalpara>
</para>
</section>
<section xml:id="_UserStartWindows_1enablegreywindows">
<title>启用灰度捕获</title>

<para>除了能够输出彩色流式视频外，当启用某些机器视觉算法时，JeVois 还可以流式传输灰度视频。这在运行机器视觉算法时特别有用，这些算法会产生要在主机上进一步处理的结果。例如，请参阅 <link xlink:href="/moddoc/EdgeDetection/modinfo.html">边缘检测模块</link> 或 <link xlink:href="/moddoc/OpticalFlow/modinfo.html">光流模块</link>。在 Windows 下，AMCap 需要安装额外的过滤器才能捕获灰度视频（在 USB 视频规范中，灰度称为 Y800 模式）。</para>

<para>以下说明由 JeVois 用户 <link xlink:href="/qa/index.php?qa=user&amp;qa_1=pelrun">pelrun</link> <link xlink:href="/qa/index.php?qa=346&amp;qa_1=grey-mode-in-amcap-on-windows-10-causes-error">贡献</link>。非常感谢，pelrun！</para>

<para><itemizedlist>
<listitem>
<para>下载 <link xlink:href="http://www.gdcl.co.uk/YUVxfm.zip">http://www.gdcl.co.uk/YUVxfm.zip</link>。镜像副本位于 <link xlink:href="/data/YUVxfm.zip">此处</link>。</para>
</listitem><listitem>
<para>将其解压至 <emphasis role="bold">c:\windows\system32</emphasis></para>
</listitem><listitem>
<para>以管理员权限打开命令提示符窗口</para>
</listitem><listitem>
<para>在命令窗口中输入 <computeroutput>regsvr32 c:\windows\system32\YUVxfm.dll</computeroutput>。</para>
</listitem></itemizedlist>
</para>

<para>这将安装一个支持 Y800 模式的 directshow 过滤器，并允许您使用输出灰度视频的 JeVois 机器视觉模块。</para>

<para><formalpara><title></title></formalpara>
</para>
</section>
<section xml:id="_UserStartWindows_1troubleshootwindows">
<title>故障排除</title>

<para>如果您遇到问题并使用 Windows 10，请确保您更新到 或更高版本，因为我们在这些更高版本中启用了一些解决方法来处理 Windows 10 中的一些错误。 </para>
</section>
    <section xml:id="_UserStartMac"><title>JeVois-A33：Mac 主机入门 \tableofcontents</title>    </section>
<para>最简单的入门方法是使用 <link linkend="_JeVoisInventor">JeVois-A33：JeVois Inventor 图形用户界面</link></para>

<para>以下是替代方法。</para>

<para><formalpara><title>##############################################################################################@section userstartmac 开始使用 Mac - 基本 PhotoBooth</title></formalpara>
</para>

<para>JeVois 智能相机的使用方式与普通 USB 相机相同。要开始使用 Mac 主机：</para>

<para><itemizedlist>
<listitem>

<para>从 <link xlink:href="http://jevois.org">http://jevois.org</link> 下载磁盘映像并将其刷入 MicroSD 卡。</para>

<para></para>
</listitem>
<listitem>

<para>将 MicroSD 卡插入 JeVois 智能相机，MicroSD 触点朝上，如下所示。</para>

<para>  </para>

<para>  </para>

<para></para>
</listitem>
<listitem>

<para>将相机连接到主机。智能相机需要高达 3.5 瓦的功率，这超出了单个 USB 2.0 端口的设计供电限制，但在单个 USB 3.0 端口的限制范围内。使用能够无损传输全部功率的高质量 USB-miniUSB 电缆非常重要。寻找带有 24awg 电源线的电缆。建议您在主机上使用 USB 3.0 端口，因为它们可以提供更多功率。如果没有，您可以使用 USB Y 型电缆连接到主机上的两个 USB 2.0 端口，或者连接到一个 USB 2.0 端口和一个外部 USB 电源（例如，手机充电器）。请确保不要使用 USB 集线器，除非该集线器具有强大的外部电源（变压器、壁式适配器）。</para>

<para></para>
</listitem>
<listitem>

<para>观察 USB 连接器旁边的智能相机上的 LED：<itemizedlist>
<listitem>
<para>绿色：电源已打开且足够强。</para>
</listitem><listitem>
<para>约 3 秒后：橙色闪烁：相机传感器芯片已被检测到并初始化。</para>
</listitem><listitem>
<para>约 5 秒后：橙色常亮：智能相机已准备就绪。</para>
</listitem><listitem>
<para>再等待几秒钟，让主机检测到相机并准备好进行视频捕获。</para>
</listitem></itemizedlist>
</para>

<para></para>
</listitem>
<listitem>

<para>启动视频捕捉软件。这里我们将使用应用程序目录中捆绑的 PhotoBooth 应用程序。</para>

<para>从“应用程序”文件夹启动 PhotoBooth。您应该看到以下内容：</para>

<para>\图片 html photobooth1.png</para>

<para>Photobooth 不允许您访问对比度、曝光等控件。但您可以从 App Store 获取第三方应用程序来执行这些操作。以下是从 App Store 获取（免费）后使用网络摄像头设置的示例：</para>

<para></para>

<para>您还可以尝试 VLC、Skype、Facetime 等。内置的 Photobooth 应用程序非常挑剔，如果相机显示 BAYER 或 RGB565 视频模式、太多模式等，它将拒绝使用相机。它也不允许您选择视频分辨率。要在 Mac 上使用 JeVois 相机，建议您仅使用一种可用的视频分辨率对其进行配置（<computeroutput>videomappings.cfg</computeroutput> 文件中的一个条目）。有关更多信息，请参阅 UserModes。</para>

<para><formalpara><title>#######################################################################################################@section obsmac Mac 入门 - Open Broadcaster Studio</title></formalpara>
</para>

<para></para>

<para>Open Broadcaster Studio 是一款出色的免费程序，允许您根据 JeVois 的需要选择不同的视频分辨率。</para>

<para><itemizedlist>
<listitem>
<para>从 <link xlink:href="https://obsproject.com">https://obsproject.com</link> 下载 OBS Studio</para>
</listitem><listitem>
<para>安装它，在安装过程中，只需说您不会流式传输视频。</para>
</listitem><listitem>
<para>将 JeVois 连接到您的计算机并允许其启动。</para>
</listitem><listitem>
<para>打开 OBS Studio，在屏幕左下方，单击 <emphasis role="bold">来源下的</emphasis> <computeroutput>+</computeroutput> 图标以添加新的<emphasis role="bold">视频捕获设备</emphasis>。</para>
</listitem><listitem>
<para>创建一个新的源 </para>
</listitem><listitem>
<para>选择 Jevois-A33 智能相机作为其设备，取消选中<emphasis role="bold">使用预设</emphasis>以启用所有 JeVois 分辨率，选择您想要尝试的分辨率，选择<emphasis role="bold">简单 FPS 值</emphasis>，然后选择其中一个可用的 FPS 值。</para>
</listitem><listitem>
<para>双击该源时，会出现一个对话框。在其中，您可以选择：</para>
</listitem><listitem>
<para>设备：JeVois-A33 智能相机</para>
</listitem><listitem>
<para>确保未选中 <emphasis role="bold">使用预设</emphasis></para>
</listitem><listitem>
<para>分辨率：选择您想要尝试的任何分辨率</para>
</listitem><listitem>
<para>FPS：当您更改分辨率时，有时会为您提供一些 <emphasis role="bold">合理的 FPS 值</emphasis>，但更简单的方法是切换回 <emphasis role="bold">简单的 FPS 值</emphasis>，然后选择 JeVois 提供的值。</para>
</listitem><listitem>
<para>尽情享受吧！您可以拖动并调整视频预览的大小以获得最佳观看体验。 </para>
</listitem></itemizedlist>
</para>

<para><formalpara><title>##############################################################################################@section userstartmaccamtwist 开始使用 Mac - CamTwist Studio</title></formalpara>
</para>

<para></para>

<para>通过在视频捕获软件中选择不同的视频分辨率，可以选择不同的机器视觉算法。在 Mac 上，大多数网络摄像头应用程序不允许您选择视频分辨率。但有一些允许。其中一个例子是 CamTwist Studio。</para>

<para>为了使其工作：</para>

<para><itemizedlist>
<listitem>

<para>下载 <link xlink:href="http://camtwiststudio.com/download/">CamTwist Studio</link>。我们使用了最新（开发）版本，它在我们的 El Capitan Mac 上运行良好。</para>

<para></para>
</listitem>
<listitem>

<para>将其安装到您的 Mac 上。</para>

<para></para>
</listitem>
<listitem>

<para>插入您的 JeVois 相机，等待橙色 LED 闪光，然后等待橙色 LED 常亮。</para>

<para></para>
</listitem>
<listitem>

<para>启动 CamTwist Studio。</para>

<para></para>
</listitem>
<listitem>

<para>在 CamTwist 窗口中，双击“步骤 1：选择视频源”下的 <computeroutput>Webcam。</computeroutput> </para>

<para></para>
</listitem>
<listitem>

<para>然后在 CamTwist 窗口右侧的 <computeroutput>设置下，选择“JeVois</computeroutput> A33 智能相机”。</para>

<para>\图像 html camtwist-setcam.png</para>

<para></para>
</listitem>
<listitem>

<para>在屏幕顶部的菜单栏上，选择 <computeroutput>查看</computeroutput> <computeroutput>-&gt;</computeroutput> <computeroutput>预览。这将显示来自</computeroutput> JeVois 智能相机的实时视频。帧速率不是很高，但下面将修复。默认情况下，分辨率为 320x240（MJPEG），JeVois 智能相机不进行任何处理（即，它的行为与普通相机一样）。</para>

<para>\图像 html camtwist-prefs.png</para>

<para></para>
</listitem>
<listitem>

<para>在屏幕顶部的菜单栏上，转到 <computeroutput>CamTwist</computeroutput> <computeroutput>-&gt;</computeroutput> <computeroutput>首选项。单击首选项窗口顶部的“视频设备”。然后选择</computeroutput> JeVois-A33 智能相机。最后，使用 <computeroutput>格式下拉菜单选择各种分辨率。每次选择新分辨率时，它还会在智能相机上选择不同的机器视觉算法。请参阅</computeroutput> <link xlink:href="http://jevois.org/start/start.html#demos-section">JeVois Start，在“演示”下</link> 以获取默认视频映射列表（在 JeVois 上运行的算法取决于您在 CamTwist 中选择的分辨率）。</para>

<para></para>
</listitem>
<listitem>

<para>在 <computeroutput>首选项窗口的</computeroutput> <computeroutput>常规下，您可以更改预览框的帧速率和分辨率。更改后您需要重新启动</computeroutput> CamTwist。您还需要手动将预览窗口的角落拖动到其新大小。</para>

<para></para>

<para></para>

<para></para>
</listitem>
<listitem>

<para>拔下 JeVois 智能相机之前，请确保退出相机查看软件。否则，您的主机可能会在尝试使用不再存在的相机时变得非常困惑。</para>

<para></para>
</listitem>
<listitem>

<para>关闭 JeVois 相机前无需执行关机程序。只需关闭视频捕捉软件并拔下相机电源即可。</para>

<para></para>
</listitem>
</itemizedlist>
</para>

<para><formalpara><title>##############################################################################################@section userstartmacother 开始使用 Mac - ffplay</title></formalpara>
</para>

<para></para>

<para>从 ffmpeg 网站 <link xlink:href="https://ffmpeg.org/download.html#build-mac">https://ffmpeg.org/download.html#build-mac</link> 下载预编译的 ffplay 二进制文件（免费），然后打开终端（在应用程序中，实用程序下）并运行：</para>

<para><literallayout><computeroutput>~/bin/ffplay -f avfoundation -i &quot;JeVois&quot; -video_size 640x300 -framerate 60 -pixel_format yuyv422 </computeroutput></literallayout>（假设您将 ffplay 保存到您的 ~/bin/ 目录中）。</para>

<para>请注意，在 Mac 上，许多视频捕获应用程序（包括 ffplay）的延迟（捕获和显示之间的延迟或滞后）非常严重。这不是 JeVois 的限制。与 Linux 主机一起使用时，不会出现延迟。</para>

<para><formalpara><title></title></formalpara>
</para>

<para></para>

<para><formalpara><title>#######################################################################################################@section troubleshootmac 故障排除</title></formalpara>
</para>

<para></para>

<para>到目前为止这里还没有任何物品。 </para>
</listitem>
</itemizedlist>
</para>
    <section xml:id="_UserStartCaveats"><title>JeVois-A33：入门注意事项 \tableofcontents</title>    </section>
<para><itemizedlist>
<listitem>
<para>在 Mac 上，只有少数免费应用程序（例如 CamTwist Studio）才支持选择特定的网络摄像头分辨率。这适用于任何 USB 摄像头，而不仅仅是 JeVois 智能摄像头。Mac OSX 似乎只决定使用哪种分辨率，而您无法控制它。要将 JeVois 智能摄像头与 Mac 一起使用并确保特定的视频分辨率，您可以编辑智能摄像头的 videomappings.cfg 并在该文件中仅保留一种分辨率。OSX 将别无选择，只能使用该分辨率。如果您是程序员，据报道，使用 OpenCV 从 Mac 上的 JeVois 抓取帧是成功的，请参阅 <link xlink:href="http://jevois.org/qa/index.php?qa=114">http://jevois.org/qa/index.php?qa=114</link></para>
</listitem><listitem>
<para>在 Mac 上，无法访问相机控件（曝光、对比度等）。但是，一些第三方应用程序可用于此目的。例如，Apple 应用商店中提供的“网络摄像头设置”应用程序。</para>
</listitem><listitem>
<para>在 Windows 上，选择相机分辨率和曝光等设置也变得很困难，只有少数免费应用程序（如 AMCap）允许您选择相机分辨率。您可能想要探索第三方应用程序，或者像在 Mac 上一样，仅使用一种可用的视频分辨率配置您的 videomappings.cfg。如果您是一名程序员，据报道，使用 OpenCV 从 Mac 上的 JeVois 抓取帧是成功的，请参阅 <link xlink:href="http://jevois.org/qa/index.php?qa=114">http://jevois.org/qa/index.php?qa=114</link>，因为这也可能适用于 Windows。</para>
</listitem><listitem>
<para>iOS 支持：使用 OTG 线连接到 iPad（iOS 9），iPad 报告说不支持任何 USB 摄像头（不仅仅是 JeVois 智能摄像头）。看来 iOS 不支持 USB 摄像头。</para>
</listitem><listitem>
<para>Android 支持：使用 OTG 电缆，JeVois 智能相机被一些第三方应用程序检测到，但我们无法成功从中流式传输。需要进行更多调查。</para>
</listitem></itemizedlist>
</para>

<para>由于这些注意事项，JeVois 最适合与 Linux 主机一起使用。 </para>
    <section xml:id="_UserModes"><title>视频模式和映射用户指南</title>    </section>
<para>您的 JeVois 智能相机是一款非常灵活的嵌入式 Linux 计算机，可以运行各种机器视觉算法。</para>

<para>：运行哪种算法取决于以下两种情况：1）由通过 USB 链路连接到 JeVois 的主机选择；2）在不使用主机时使用命令行界面选择（例如，JeVois 仅连接到 Arduino）。</para>

<para>当使用主机时，通过在主机上选择特定的视频分辨率来实现特定机器视觉算法的选择。</para>

<para>：运行哪种算法可以通过 1) JeVois-Pro 的集成 GUI 或 2) 通过串行端口使用命令行界面进行选择。</para>

<para><itemizedlist>
<listitem>
<para>像素格式</para>
</listitem><listitem>
<para>视频映射</para>
</listitem></itemizedlist>
</para>

<para> </para>
    <section xml:id="_UserDemos"><title>捆绑视觉模块和演示的用户指南</title>    </section>
<para>新用户请务必查看 <link xlink:href="/start/start.html#demo-section">JeVois Start</link> 上的模块列表和相应的视频分辨率。</para>

<para>高级用户和程序员，这些模块的完整文档和源代码位于 <link xlink:href="http://jevois.org/basedoc/">JeVoisBase 文档</link>。</para>

<para>只需<emphasis role="bold">单击下面每个视觉模块的图标</emphasis>即可查看其文档。 </para>
    <section xml:id="_UserLighting"><title>优化不同光照条件下的性能</title>    </section>
<para>JeVois 智能相机中的传感器功能非常强大，但有时需要进行一些调整才能在低光照条件下正常运行。</para>

<para>这些技巧主要针对，因为 配备了高端 Starvis 背光（即超灵敏）传感器，在低光条件下表现非常出色。不过， 用户可能仍对以下一些技巧感兴趣。</para>

<para>所捕获视频的亮度取决于（至少）：</para>

<para><itemizedlist>
<listitem>
<para>曝光时间。曝光时间越长，收集的光子越多，视频就越亮。曝光时间受帧速率限制，也就是说，更快的帧速率会限制最大可能的曝光时间，因为需要将帧发送出去进行处理。</para>
</listitem><listitem>
<para>传感器增益，即对来自感光器的原始信号进行放大。增益越高，图像越亮，但噪声也越大。</para>
</listitem><listitem>
<para>伽马曲线，这是在后期处理中应用的校正曲线，用于调整像素值，可能使它们更亮或更暗。除了伽马曲线之外，JeVois 图像传感器还具有可编程颜色矩阵，它指定如何将像素值从原始像素阵列（BAYER 格式；参见 PixelFormats）转换为给定的传感器图像格式（例如 YUYV）。通过在该颜色矩阵中输入更高的值，可以实现图像的整体更高亮度。</para>
</listitem></itemizedlist>
</para>

<para>默认设置 - - - - - - - -</para>

<para>默认情况下，JeVois 会尝试保持给定视频映射中指定的帧速率。这样做的原因是，连接到 JeVois 的某些下游计算机可能需要指定的帧速率才能实现流畅的实时操作。对于与 JeVois 捆绑在一起的一些机器视觉模块，帧速率很高，例如 的帧速率为 60 帧/秒甚至 120 帧/秒。</para>

<para>在较高的帧速率下，可用于曝光的时间非常短。</para>

<para>在弱光下操作 -------------------&#8212;</para>

<para>让我们将 JeVois-A33 与专业摄像机（索尼 FDR-AX1，价格约为 JeVois-A33 的 100 倍）以及廉价的 USB 摄像机（小型子弹头摄像机）进行比较。</para>

<para></para>

<para>当光线较暗时（此处，我们在日落前但日落后不久关掉了灯），所有摄像头拍摄的图像都会变暗，如下所示。此处，我们可以看到子弹头摄像头通过将帧速率降低到 4 帧/秒来适应，以便获得更多曝光时间（子弹头摄像头的图片显示在计算机屏幕上，用于显示帧的 guvcview 报告 4.12 帧/秒）。</para>

<para></para>

<para>昂贵的索尼相机在这里被设置为以固定的 60 fps 进行拍摄，我们可以在该相机的小型 LCD 屏幕上看到，尽管成本高得多，但该相机在低光和高帧率下也难以产生明亮的图像。</para>

<para>让我们仔细看看 JeVois 相机。在低光照条件下，使用高帧率时，视频会变得非常非常暗，如下所示。</para>

<para></para>

<para>JeVois 提供了几种方法来解决这个问题：</para>

<para>亮度控制 - - - - - - - - -</para>

<para>首先要尝试的是，JeVois 提供了用于亮度、对比度等的标准 USB 摄像头控件。这些控件会影响颜色矩阵。您可能希望先在视频捕获软件中尝试使用这些控件，看看在您的照明条件下是否可以获得足够好的图像质量。</para>

<para>允许自动降低帧速率 -------------------------------------&#8212;</para>

<para><note><title>Note</title>

<para>以下提示适用于默认 传感器（Omnivision ov9653）。某些控件可能不适用于其他传感器（例如，Aptina AR0135 全局快门；请参阅“帮助”以列出可用的控件）。</para>
</note>
如果亮度控制不够，一种策略是允许在低光下使用 JeVois 时降低帧速率，以延长曝光时间。这可以使用 JeVois 命令行界面中提供的 <computeroutput>presetwb</computeroutput> 相机参数来实现（参见 UserCli）。不幸的是，USB 视频类规范中似乎不存在此类控件，因此我们无法将它们公开给主机，以便它们在视频捕获软件中显示为可用控件。因此，您必须使用 JeVois 命令行界面修改这些控件。让我们切换到夜间模式（在 Video4Linux2 规范中称为 <emphasis role="bold">shade）：</emphasis> </para>

<para><computeroutput>setcam presetwb 9</computeroutput></para>

<para>（<computeroutput>help</computeroutput> 报告的可用值为：0:manual 1:auto 2:incandescent 3:fluorescent 4:fluorescent_h 5:horizo​​n 6:daylight 7:flash 8:cloudy 9:shade）。</para>

<para></para>

<para>请随意尝试其他预设。预设 9 允许最大程度地自动降低帧速率，最多可降低 8 倍。其他一些预设仅允许较小程度的降低，或者在低光条件下不自动调整帧速率。</para>

<para><note><title>Note</title>

<para>修改摄像机预设时存在滞后现象，即从预设 1 切换到 9 然后再切换回 1 会使摄像机处于与原始状态不同的状态。只需关闭 JeVois 电源然后再打开即可恢复到原始状态。</para>
</note>
使用较低的固定帧速率 --------------------------&#8212;</para>

<para>在与 JeVois 捆绑的演示中，我们经常使用 60 帧/秒来展示 JeVois 动态处理视频的速度。</para>

<para>但是，如果您不需要以 60 帧/秒的速度使用 ObjectTracker 模块检测彩色物体，并且您的应用程序以 15 帧/秒的速度运行就足够了，那么只需编辑相应的视频映射并降低 <emphasis role="bold">videomappings.cfg</emphasis> 文件中的 USB 输出帧速率和摄像头帧速率（参见 VideoMapping）。</para>

<para>JeVois 启动时，默认使用自动曝光和增益控制，较低的帧速率将允许更大范围的自动曝光和增益调整，从而使 JeVois 在低光照条件下更好地运行。</para>

<para>手动曝光和增益 ---------------------&#8212;</para>

<para>另一个选择是转向手动控制。这里有两个控制措施值得关注：</para>

<para><itemizedlist>
<listitem>
<para>曝光：光传感器收集光线的时间。曝光时间受帧速率限制（即曝光时间不能超过帧周期）。曝光时间越长，视频就越亮，但也更容易出现运动模糊。</para>
</listitem><listitem>
<para>增益：表示从光传感器接收到的模拟信号在数字化之前应被放大到何种程度。较高的增益会使视频更亮，但也会放大噪音。</para>
</listitem></itemizedlist>
</para>

<para>首先将视频查看器中的<emphasis role="bold">曝光、自动</emphasis>控件设置为<emphasis role="bold">手动模式</emphasis>，然后开始设置<emphasis role="bold">曝光（绝对）</emphasis>和<emphasis role="bold">增益</emphasis>控件。请注意，尽管曝光控制的范围从 0 到 1000，但根据帧速率，只有该范围的一小部分可用（即，曝光时间不能增加到比帧周期更长的时间。如果尝试将曝光时间设置为比帧周期更长，曝光将自动限制在略低于帧周期的水平）。</para>

<para>一般来说，应该在增益和曝光值之间找到一个折衷点。如果运动模糊不是问题，那么尽可能高的曝光和尽可能低的增益将产生较少噪声和颗粒感的图像。</para>

<para><note><title>Note</title>

<para>由于自动增益在 USB 视频类规范中未定义为相机控制，因此在 JeVois 中我们将自动曝光和自动增益设置结合在一起：当您选择手动曝光时，它也会选择手动增益，当您选择自动曝光时，它也会选择自动增益。</para>
</note>
</para>

<para>增益越高，图像看起来就越粗糙，如果必须保持较高的帧速率，则看起来就越不美观。</para>

<para>但这对于机器视觉算法来说不一定是个问题。</para>

<para>例如，在上图中，我们将增益调得非常高，以便在非常暗的条件下仍能以 30 帧/秒的速度运行。JeVois 捕获的视频中明显存在明显的像素噪声。但是……JeVois 内部运行的 算法似乎没有受到影响，并且运行良好，可以轻松检测和解码场景中存在的两个 ArUco 标记！</para>

<para>这是一个更极端的例子，在几乎完全黑暗的环境下，将曝光和增益调到最大。图像质量很糟糕（参见标记黑色区域上的非常高的像素噪声）。但 ArUco 标记检测得很好……</para>

<para>\图片 html 低光之夜.jpg</para>

<para>进一步探索 ----------------&#8212;</para>

<para>JeVois 允许您通过 <computeroutput>setcamreg</computeroutput> 和 <computeroutput>getcamreg</computeroutput> 命令来访问相机传感器寄存器（必须先将参数 <computeroutput>camreg</computeroutput> 设置为 true，作为防止意外使用这些命令的额外保护）。请注意，更改与像素时钟和图像格式细节、脉冲极性等有关的任何寄存器都可能导致传感器崩溃，您必须关闭 JeVois 才能恢复。</para>

<para>您可能想要探索将不同的伽马曲线、不同的颜色矩阵等加载到传感器中，看看是否可以获得更好的低光性能。 </para>
    <section xml:id="_MicroSD"><title>MicroSD 卡组织和文件</title>    </section><section xml:id="_MicroSD_1autotoc_md68">
<title>MicroSD 卡的组织方式</title>

<para>JeVois 智能相机中的 MicroSD 卡包含智能相机处理器上运行的所有软件。其中包括：</para>

<para><itemizedlist>
<listitem>
<para>启动和配置低级硬件元素所需的文件，例如 DDR3 内存和 microSD 卡驱动程序以及 Linux 内核。</para>
</listitem><listitem>
<para>Linux 操作系统，包括标准 Linux 命令行实用程序，以及许多库，如 OpenCV、boost、Eigen3 等。</para>
</listitem><listitem>
<para>JeVois 机器视觉模块和数据。</para>
</listitem></itemizedlist>
</para>
</section>
<section xml:id="_MicroSD_1autotoc_md69">
<title>在桌面或笔记本电脑上使用 MicroSD 卡</title>

<para>修改 MicroSD 卡的内容（例如添加新的机器视觉模块或获取 JeVois 录制的视频文件）可以通过将 MicroSD 卡从 JeVois 智能相机中取出并将其连接到台式机或笔记本电脑来实现。</para>

<para><warning><title>Warning</title>

<para>您的 JeVois 智能相机具有 <emphasis role="bold">push-push</emphasis> MicroSD 卡槽。将卡推入直至卡入卡槽发出咔嗒声以装入卡槽，然后再次推入直至卡入卡槽并弹出以卸载卡槽。您是否尝试将 MicroSD 卡拉出，否则可能会损坏 JeVois 智能相机的 MicroSD 卡槽。</para>
</warning>
</para>
<section xml:id="_MicroSD_1autotoc_md70">
<title>JeVois-A33 MicroSD</title>

<para>  </para>
</section>
<section xml:id="_MicroSD_1autotoc_md71">
<title>JeVois-Pro MicroSD</title>

<para>  </para>
</section>
<section xml:id="_MicroSD_1autotoc_md72">
<title>在计算机上使用 MicroSD 卡</title>

<para>在台式机或笔记本电脑上访问 MicroSD 卡有两种基本方法：</para>

<para><itemizedlist>
<listitem>
<para>使用大多数计算机商店出售的 USB 读卡器，并将其连接到台式机或笔记本电脑的 USB 端口</para>
</listitem></itemizedlist>
</para>

<para></para>

<para><itemizedlist>
<listitem>
<para>使用 Micro-SD 至 SD 卡适配器，并将 SD 卡插入计算机（如果计算机有插槽）（例如 Mac 笔记本电脑）：</para>
</listitem></itemizedlist>
</para>

<para></para>

<para></para>
</section>
</section>
<section xml:id="_MicroSD_1autotoc_md73">
<title>MicroSD 分区和分区类型</title>

<para>该卡分为三个分区（逻辑卷）：</para>

<para><itemizedlist>
<listitem>
<para><emphasis role="bold">BOOT（DOS/Windows</emphasis> FAT32 格式）：包含启动所需的文件，包括 Linux 内核</para>
</listitem><listitem>
<para><emphasis role="bold">LINUX（Linux</emphasis> ext4 格式，在 Windows 和 Mac 电脑上读取 MicroSD 卡时可能不会显示）：包含 Linux 操作系统和程序</para>
</listitem><listitem>
<para><emphasis role="bold">JEVOIS（DOS/Windows</emphasis> FAT32 格式）：包含所有 JeVois 机器视觉模块和数据文件，包括智能相机可能创建的文件（例如，将视频保存到 microSD 时）。</para>
</listitem></itemizedlist>
</para>

<para>由于 LINUX 分区的类型为 ext4，这是 Linux 的原生文件系统，但在 Windows 和 Mac 上默认无法识别，因此当您在 Windows 或 Mac 计算机上读取 MicroSD 卡时，您可能无法看到或访问它。这通常不是问题，因为只有高级黑客（将在 Linux 计算机上编程）才需要修改 LINUX 分区的内容。</para>

<para>对于普通用户，您需要的只是 JEVOIS 分区，如下所述。</para>

<para>以下是插入 MicroSD 卡后 Mac 笔记本电脑上发生的情况的示例：出现两个卷，BOOT 和 JEVOIS，可以浏览这两个卷中的文件。LINUX 卷未出现在这台 Mac 上（但请注意，第三方应用程序也可用于允许 Mac 读取 ext4 分区）。</para>

<para><warning><title>Warning</title>

<para>MicroSD 卡还具有额外的和必要的 &quot;files&quot; ，这些文件直接存储在卡上的特定扇区（物理闪存盘位置）上。这些是引导加载程序（系统启动）文件，是 JeVois 嵌入式处理器启动时加载的第一个文件。由于处理器在早期启动阶段还不知道分区、文件系统等，因此它所知道的全部操作就是从 SD 卡读取原始扇区。您通常不需要修改这些特殊文件。但请注意，如果您想将一张 JeVois MicroSD 卡的内容复制到新卡，则需要进行完整的物理逐扇区复制。有关如何执行此操作的说明，请参阅 NewMicroSD。</para>
</warning>
</para>
</section>
<section xml:id="_MicroSD_1autotoc_md74">
<title>MicroSD 卡内容</title>

<para>以下是典型的 microSD 卡上的文件简图树（ 类似但不完全相同）：</para>

<para><literallayout><computeroutput>├── BOOT  ########## (16 MB FAT32 partition)
│   ├── README.txt               # information file for Windows users who may not see the JEVOIS partition
│   ├── script.bin               # low-level hardware configuration file
│   ├── uEnv.txt                 # optional command-line arguments for the Linux Kernel
│   └── uImage                   # Linux kernel


├── LINUX ########## (1 GB Linux ext4 partition)
│   ├── bin                      ### Directory for standard Unix commands
│   │   ├── ash                  # some Unix command
│   │   ├── bash                 # some other Unix command
│   │   ├── busybox              # ...
│   │   ├── cat

...

│   ├── etc                      ### Directory for Unix configuration files
│   │   ├── fstab
│   │   ├── group
│   │   ├── hostname
│   │   ├── hosts

...

│   ├── lib                      ### Directory for Unix system libraries
│   │   ├── ld-2.23.so
│   │   ├── ld-linux-armhf.so.3
│   │   ├── libatomic.so.1.2.0
│   │   ├── libc-2.23.so
│   │   ├── libcrypt-2.23.so
│   │   ├── libc.so.6
│   │   ├── libdl-2.23.so
│   │   ├── libgcc_s.so
│   │   ├── libm-2.23.so
│   │   ├── libm.so.6
│   │   ├── libnsl-2.23.so

...

│   ├── sbin                     ### Directory for system administration Unix commands
│   │   ├── arp
│   │   ├── blkid
│   │   ├── devmem
│   │   ├── fdisk
│   │   ├── freeramdisk
│   │   ├── fsck

...

│   ├── tmp                      ### Scratch directory for temporary files
│   ├── usr                      ### Directory for user Unix commands and shared data
│   │   ├── bin
│   │   │   ├── ar
│   │   │   ├── attr
│   │   │   ├── awk
│   │   │   ├── basename
│   │   │   ├── bunzip2
│   │   │   ├── bzcat

...

│   │   ├── lib                  ### Directory for Unix user libraries
│   │   │   ├── libattr.so.1.1.0
│   │   │   ├── libavcodec.so.56.60.100
│   │   │   ├── libavdevice.so.56.4.100
│   │   │   ├── libavfilter.so.5.40.101
│   │   │   ├── libavformat.so.56.40.101
│   │   │   ├── libavheap.so
│   │   │   ├── libavresample.so.2.1.0
│   │   │   ├── libavutil.so.54.31.100
│   │   │   ├── libbfd-2.25.51.so
│   │   │   ├── libbfd-2.26.1.so
│   │   │   ├── libblas.so
│   │   │   ├── libboost_atomic.so.1.61.0
│   │   │   ├── libboost_chrono.so.1.61.0
│   │   │   ├── libboost_container.so.1.61.0

...

│   │   ├── sbin
│   │   │   ├── addgroup         ### Directory for more Unix system administration commands
│   │   │   ├── adduser
│   │   │   ├── arping
│   │   │   ├── chroot

...

│   │   └── share                ### Directory for shared data used by Unix commands
│   │       ├── awk
│   │       │   ├── assert.awk
│   │       │   ├── bits2str.awk
│   │       │   ├── cliff_rand.awk
│   │       │   ├── ctime.awk
│   │       │   ├── ftrans.awk
│   │       │   ├── getopt.awk
│   │       │   ├── gettime.awk

...
│   └── var                      ### Directory for Unix system log files and other volatile files
│       ├── cache
│       ├── lib
│       │   └── misc
│       ├── lock
│       ├── log
│       ├── run
│       ├── spool
│       └── tmp



├── JEVOIS ########## (6+ GB FAT32 partition)
│   ├── config                   ### Directory for JeVois engine configuration file
│   │   ├── initscript.cfg
│   │   ├── JeVois.cmake
│   │   ├── jevois_config.cmake
│   │   ├── params.cfg
│   │   └── videomappings.cfg
│   ├── data                     ### Directory for optional user data, some JeVois modules also save outputs into it
│   ├── lib                      ### Directory for JeVois libraries, i.e., collections of shared vision algorithms
│   │   └── JeVois               # One sub-directory for each JeVois &quot;Vendor&quot; (provider of JeVois modules)
│   │       └── libjevoisbase.so.1.0
│   ├── modules                  ### Directory for JeVois machine vision modules
│   │   └── JeVois               # One sub-directory for each JeVois &quot;Vendor&quot; (provider of JeVois modules)
│   │       ├── Convert          # One directory for each module
│   │       │   ├── Convert.so   # The compiled module code that will be loaded when that module is selected
│   │       │   ├── icon.png     # Extra data about the module
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   └── screenshot1.png
│   │       ├── DemoArUco
│   │       │   ├── calibration.yaml
│   │       │   ├── DemoArUco.so
│   │       │   ├── icon.png
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   ├── screenshot1.png
│   │       │   └── screenshot2.png
│   │       ├── DemoGPU
│   │       │   ├── DemoGPU.so
│   │       │   ├── icon.png
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   ├── screenshot1.png
│   │       │   ├── shaders      # This module uses auxiliary files for GPU shader code
│   │       │   │   ├── blurfragshader.glsl
│   │       │   │   ├── dilatefragshader.glsl
│   │       │   │   ├── erodefragshader.glsl
│   │       │   │   ├── medianfragshader.glsl
│   │       │   │   ├── multfragshader.glsl
│   │       │   │   ├── simplefragshader.glsl
│   │       │   │   ├── simplevertshader.glsl
│   │       │   │   ├── sobelfragshader.glsl
│   │       │   │   ├── threshfragshader.glsl
│   │       │   │   ├── twirlfragshader.glsl
│   │       │   │   └── yuvfragshader.glsl
│   │       │   └── video1.mkv

...

│   │       ├── DemoSalGistFaceObj
│   │       │   ├── DemoSalGistFaceObj.so
│   │       │   ├── facedetector
│   │       │   │   ├── haarcascade_eye_tree_eyeglasses.xml
│   │       │   │   └── haarcascade_frontalface_alt.xml
│   │       │   ├── icon.png
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   ├── movie.avi
│   │       │   ├── screenshot1.png
│   │       │   └── tiny-dnn     # 该模块使用神经网络数据的辅助文件 
│   │       │       ├── CIFAR10
│   │       │       │   ├── batches.meta.txt
│   │       │       │   ├── data_batch_1.bin
│   │       │       │   ├── data_batch_2.bin
│   │       │       │   ├── data_batch_3.bin
│   │       │       │   ├── data_batch_4.bin
│   │       │       │   ├── data_batch_5.bin
│   │       │       │   ├── readme.html
│   │       │       │   ├── test_batch.bin
│   │       │       │   └── weights.tnn
│   │       │       └── MNIST
│   │       │           ├── t10k-images.idx3-ubyte
│   │       │           ├── t10k-labels.idx1-ubyte
│   │       │           ├── train-images.idx3-ubyte
│   │       │           ├── train-labels.idx1-ubyte
│   │       │           └── weights.tnn

...

│   │       ├── SaliencySURF
│   │       │   ├── icon.png
│   │       │   ├── images       # Images of the things this module can recognize
│   │       │   │   ├── books.png
│   │       │   │   ├── doorframe.png
│   │       │   │   ├── doorlock2.png
│   │       │   │   ├── doorlock.png
│   │       │   │   ├── lightswitch2.png
│   │       │   │   ├── lightswitch.png
│   │       │   │   ├── spot25.png
│   │       │   │   ├── spot26.png
│   │       │   │   └── usbbatt.png
│   │       │   ├── modinfo.html
│   │       │   ├── modinfo.yaml
│   │       │   ├── params.cfg
│   │       │   ├── SaliencySURF.so
│   │       │   └── screenshot1.png

...

│   ├── packages                 ### Simply copy downloaded .jvpkg files here and JeVois will unpack and install them
│   └── scripts
│       ├── astylerc
│       ├── docinstall.sh
│       ├── extract-code-snippets.pl
│       ├── jevois-modinfo.pl
│       └── list-sources.sh

...</computeroutput></literallayout></para>
</section>
<section xml:id="_MicroSD_1autotoc_md75">
<title>MicroSD 分区大小调整</title>

<para>如果您的卡大于我们提供的图像尺寸，您可能需要调整 JEVOIS 或 JEVOISPRO 分区的大小以使用卡上所有可用的空间。</para>

<para>JEVOIS 或 JEVOISPRO 分区使用 VFAT/FAT32 文件系统，以实现与各种主机的最大兼容性。要在 Linux 下调整其大小，请使用 <computeroutput>gparted</computeroutput> （您可能必须先使用 <computeroutput>sudo apt install gparted</computeroutput> 安装它）。</para>
</section>
<section xml:id="_MicroSD_1autotoc_md76">
<title>JeVois-A33：在 JeVois 运行时访问和修改 MicroSD</title>

<para></para>

<para>当卡位于 JeVois 智能相机内时，您可以访问 microSD 上 <emphasis role="bold">JEVOIS</emphasis> 分区的内容。JeVois 可以（根据需要）使 <emphasis role="bold">JEVOIS</emphasis> 分区作为虚拟 USB 闪存驱动器通过 USB 向连接的主机计算机显示。</para>

<para>要启用此功能，请连接到 JeVois 命令行界面（参见 UserCli）并发出命令：</para>

<para><literallayout><computeroutput>usbsd
</computeroutput></literallayout></para>

<para>您会注意到主机检测到了一个新的 USB 闪存驱动器。</para>

<para></para>

<para><note><title>Note</title>

<para>由于能够在更改 microSD 内容的同时切换各种视觉模块会带来一些潜在的数据一致性问题，因此目前，我们已限制通过 USB 的文件访问，仅在不流式传输视频时才有效。同样，需要重新启动 JeVois 相机才能允许它使用主机上的任何新文件或修改过的文件。</para>
</note>
在 Linux 上，使用 及更高版本，您可以使用主机命令 <computeroutput>jevois-usbsd start</computeroutput> 指示连接的 JeVois 相机开始导出其 microSD，而无需打开串行终端应用程序并连接到 JeVois。同样，您可以发出 <computeroutput>jevois-usbsd stop</computeroutput> 来释放卡并重新启动 JeVois。</para>

<para>典型的工作流程如下：</para>

<para><itemizedlist>
<listitem>
<para>将 JeVois 连接到主机并让其启动。</para>
</listitem><listitem>
<para>确保您没有从 JeVois 捕获视频。</para>
</listitem><listitem>
<para>连接到 JeVois 命令行界面（使用硬件串行端口或 USB 串行；参见 UserCli）。</para>
</listitem><listitem>
<para>当你想修改 JeVois 内部 microSD 的内容时，请发出 <computeroutput>usbsd</computeroutput> 命令。虚拟 USB 闪存驱动器将出现在主机上。</para>
</listitem><listitem>
<para>使用 及更高版本，您不需要打开串行终端并在其中输入，而是可以直接从任何 Linux shell 使用新的主机命令 <computeroutput>jevois-usbsd start</computeroutput> 。</para>
</listitem><listitem>
<para>添加/修改/删除文件。这包括：<itemizedlist>
<listitem>
<para>修改 <emphasis role="bold">JEVOIS:/config</emphasis> 中的配置或参数文件</para>
</listitem><listitem>
<para>编辑 <emphasis role="bold">JEVOIS:/modules</emphasis> 下用 Python 编写的模块</para>
</listitem><listitem>
<para>添加任何数据，例如 ObjectDetect 模块的训练图像</para>
</listitem><listitem>
<para>检索任何数据，例如 JeVois 录制的视频文件</para>
</listitem><listitem>
<para>将使用 <computeroutput>./rebuild-platform.sh</computeroutput> 编译的新 C++ 模块的 .jvpkg 包复制到 JEVOIS:/packages/</para>
</listitem></itemizedlist>
</para>
</listitem><listitem>
<para>完成后，正确弹出虚拟 USB 驱动器（拖到垃圾箱、单击弹出按钮等）。JeVois 将检测到此情况并自动重新启动，然后可以使用新文件或修改后的文件。您应该在 JeVois LED 上看到以下内容：<itemizedlist>
<listitem>
<para>闪烁 - 关机完成</para>
</listitem><listitem>
<para>常亮绿色 - 重新启动</para>
</listitem><listitem>
<para>橙色闪烁 - 检测到摄像头传感器</para>
</listitem><listitem>
<para>常亮橙色：准备就绪 </para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>
</section>
    <section xml:id="_NewMicroSD"><title>如何为 JeVois 格式化新的 MicroSD 卡</title>    </section>
<para>JeVois 要求在其 MicroSD 上对分区（逻辑卷）和文件进行非常具体的组织。此外，MicroSD 卡上的特定物理位置（扇区）必须有两个低级引导加载程序（硬件启动）“文件”。出于这个原因，在准备用于 JeVois 的 MicroSD 卡时必须小心谨慎。</para>
<section xml:id="_NewMicroSD_1newmicrosd1">
<title>简单方法：下载并刷新 JeVois 磁盘映像</title>

<para>最简单的方法是下载并刷新预配置的 JeVois 磁盘映像。这些可在 jevois.org 上找到，其中包含所有操作系统、支持数据和核心 JeVois 软件。使用 JeVois 磁盘映像准备新的 MicroSD 卡后，您将能够使用笔记本电脑或台式电脑非常轻松地向其中添加新的机器视觉模块。</para>
<section xml:id="_NewMicroSD_1使用">
<title>resin.io 的 Etcher 轻松为 Windows/Mac/Linux 刷入 microSD</title>

<para>Etcher 是一个免费的开源程序，用于将磁盘映像刻录到 USB 驱动器和 SD 卡，它是跨平台的，并提供了在 Windows、Mac 和 Linux 上看起来相同的简单图形界面。</para>

<para><itemizedlist>
<listitem>
<para>下载并安装免费开源的 <link xlink:href="https://etcher.io/">Etcher</link></para>
</listitem><listitem>
<para>从 <link xlink:href="http://jevois.org/start/">JeVois Start</link> 下载 JeVois MicroSD 映像文件。使用 Etcher 时无需解压文件，它可以接受压缩文件。如果您的计算机自动解压文件（例如，在某些 Mac 上），那没问题，您只需在以下步骤中使用生成的解压文件，该文件应命名为 jevois-image-1.0-8G.img 或类似名称。</para>
</listitem><listitem>
<para>使用 USB 转 microSD 适配器或其他方法（例如，带有 SD 插槽的 Mac 上的 microSD 转 SD 适配器）将您的 microSD 卡连接到您的计算机。</para>
</listitem><listitem>
<para>启动 Etcher。</para>
</listitem><listitem>
<para>选择您下载的 .zip 图像文件（或从下载中解压的 .img 文件）。</para>
</listitem><listitem>
<para>选择与您的 microSD 卡对应的驱动器。</para>
</listitem><listitem>
<para>单击“闪存”并等待完成。您的卡已准备好插入 JeVois 智能相机。</para>
</listitem></itemizedlist>
</para>

<para></para>
</section>
<section xml:id="_NewMicroSD_1newmicrosdlinux">
<title>更传统的刷入 JeVois 磁盘映像：Linux</title>

<para>如果使用 Etcher 轻松刷新（如上所述）对您不起作用，请使用这些说明。</para>

<para>在 Linux 上，最简单的方法是在终端中使用 <computeroutput>dd。首先，识别分配给</computeroutput> SD 卡的设备。在 Ubuntu 上，转到 Ubuntu 菜单并输入 <computeroutput>disks，然后启动</computeroutput> <emphasis role="bold">Disks</emphasis> 程序。</para>

<para></para>

<para>单击最有可能是您的 MicroSD 卡的图标，然后仔细检查显示的信息，例如大小、品牌名称等。一旦您确定这是您的新 MicroSD 卡，请注意底部显示的设备名称。这里是 <computeroutput>/dev/sdf，这是我们将用来写入</computeroutput> JeVois 磁盘映像的名称。</para>

<para><note><title>Note</title>

<para>确保解压下载的文件。不要尝试将 .zip 文件刷入 microSD，否则将无法正常工作。</para>
</note>
<literallayout><computeroutput>cd Downloads
wget http://jevois.org/data/jevois-image-latest-8G.zip
unzip jevois-image-latest-8G.zip
sudo dd if=jevois-image-1.0-8G.img of=/dev/sdX bs=1M  # exact .img file name may vary
sync
</computeroutput></literallayout></para>

<para>您应该将上面的 <computeroutput>sdX</computeroutput> 替换为您在上一步中记下的设备名称。请确保等到 <computeroutput>sync</computeroutput> 命令（刷新磁盘缓存）完成，否则可能尚未将所有磁盘映像数据提交到您的 MicroSD。现在您可以弹出 MicroSD 卡并将其插入 JeVois 智能相机。</para>

<para>对于 <computeroutput>dd</computeroutput> 命令，<computeroutput>if</computeroutput> 指定源文件（或设备），<computeroutput>of</computeroutput> 指定目标文件（或设备），<computeroutput>bs</computeroutput> 是要使用的块大小。</para>

<para><warning><title>Warning</title>

<para>请务必仔细检查您使用的设备名称。一个小小的拼写错误就可能毁掉您计算机硬盘上的内容。</para>
</warning>
</para>
</section>
<section xml:id="_NewMicroSD_1newmicrosdwindows">
<title>更传统的刷入 JeVois 磁盘映像：Windows</title>

<para>如果使用 Etcher 轻松刷新（如上所述）对您不起作用，请使用这些说明。</para>

<para><note><title>Note</title>

<para>确保解压下载的文件。不要尝试将 .zip 文件刷入 microSD，否则将无法正常工作。</para>
</note>
您可以使用 <link xlink:href="https://sourceforge.net/p/usbwriter/wiki/Documentation/">https://sourceforge.net/p/usbwriter/wiki/Documentation/</link> 中的 USBWriter</para>

<para>您还可以尝试 <link xlink:href="http://www.alexpage.de/usb-image-tool/download/">USB 映像工具</link> 或 <link xlink:href="https://sourceforge.net/projects/win32diskimager/">Win32 磁盘映像器</link></para>

<para>有关如何使用这些工具，请参阅<link xlink:href="http://www.runeaudio.com/documentation/quick-start/sd-card-setup-windows/">此处</link>的说明。</para>
</section>
<section xml:id="_NewMicroSD_1newmicrosdmac">
<title>更传统的刷入 JeVois 磁盘映像：Mac</title>

<para>如果使用 Etcher 轻松刷新（如上所述）对您不起作用，请使用这些说明。</para>

<para><note><title>Note</title>

<para>确保解压下载的文件。不要尝试将 .zip 文件刷入 microSD，否则将无法正常工作。</para>
</note>
在 Mac 上最简单的方法是在终端中使用 <computeroutput>dd。首先，确定分配给</computeroutput> SD 卡的设备。为此，打开终端（位于应用程序 -&gt; 实用程序 -&gt; 终端），然后输入：</para>

<para><literallayout><computeroutput>diskutil list
</computeroutput></literallayout></para>

<para>您应该会看到类似如下所示的内容，表明我们的 MicroSD 卡已分配给此特定 Mac 上的 <computeroutput>/dev/disk1：</computeroutput> </para>

<para></para>

<para>请务必检查名称和大小，因为这是我们现在要擦除的设备。在终端中，输入：</para>

<para><literallayout><computeroutput>diskutil unmountDisk /dev/diskX
cd Downloads
wget http://jevois.org/data/jevois-image-latest-8G.zip
unzip jevois-image-latest-8G.zip
sudo dd if=jevois-image-1.0-8G.img of=/dev/diskX bs=1M # exact .img file name may vary
sync
</computeroutput></literallayout></para>

<para>您应该将上面的 <computeroutput>diskX</computeroutput> 替换为您在上一步中记下的设备名称。请确保等到 <computeroutput>sync</computeroutput> 命令（刷新磁盘缓存）完成，否则可能尚未将所有磁盘映像数据提交到您的 MicroSD。您现在可以弹出 MicroSD 卡并将其插入 JeVois 智能相机。</para>

<para>对于 <computeroutput>dd</computeroutput> 命令，<computeroutput>if</computeroutput> 指定源文件（或设备），<computeroutput>of</computeroutput> 指定目标文件（或设备），<computeroutput>bs</computeroutput> 是要使用的块大小。</para>

<para><warning><title>Warning</title>

<para>请务必仔细检查您使用的设备名称。一个小小的拼写错误就可能毁掉您计算机硬盘上的内容。</para>
</warning>
在 Mac 上，您还可以尝试使用 <link xlink:href="https://alltheware.wordpress.com/2012/12/11/easiest-way-sd-card-setup/">RPi SD 卡生成器</link> 来刷新您的 SD 卡。</para>
</section>
</section>
<section xml:id="_NewMicroSD_1copymicrosd">
<title>将 JeVois MicroSD 复制到另一个</title>

<para>除了您可以看到的分区和文件之外，JeVois MicroSD 卡还有两个额外的基本“文件”，它们直接存储在卡上的特定扇区（物理闪存盘位置）上。这两个是引导加载程序（系统启动）文件，是 JeVois 嵌入式处理器启动时加载的前两个文件。由于处理器在早期启动阶段还不知道分区、文件系统等，因此它所知道的只是从 SD 卡读取原始扇区。您通常不需要修改这两个特殊文件。但请注意，如果您想将一张 JeVois MicroSD 卡的内容复制到新卡上，则需要进行完整的物理逐扇区复制。</para>

<para>如果您定制了 JeVois MicroSD 卡，例如在其上安装了许多机器视觉模块，并且想要将其复制到另一张新的 MicroSD 卡，请按以下步骤操作：</para>

<para>在 Linux 和 Mac 上，您可以再次使用 <computeroutput>dd，首先将现有的</computeroutput> MicroSD 转储到台式机或笔记本电脑上的文件中，然后我们将该文件写入新的 MicroSD 卡：</para>

<para><literallayout><computeroutput>#&#32;Insert&#32;source&#32;card:

sudo&#32;dd&#32;if=/dev/sdX&#32;of=mycard.img&#32;bs=1M

sync

#&#32;Properly&#32;eject&#32;source&#32;card.

#&#32;Insert&#32;destination&#32;(blank)&#32;card:

sudo&#32;dd&#32;if=mycard.img&#32;of=/dev/sdX&#32;bs=1M

sync
</computeroutput></literallayout></para>

<para>对于 <computeroutput>dd</computeroutput> 命令，<computeroutput>if</computeroutput> 指定源文件（或设备），<computeroutput>of</computeroutput> 指定目标文件（或设备），<computeroutput>bs</computeroutput> 是要使用的块大小。</para>

<para>在 Windows 上，再次使用 USBWriter。</para>
</section>
<section xml:id="_NewMicroSD_1newmicrosd2">
<title>更复杂的方法：使用完整的 JeVois 从源代码构建过程编写新的 MicroSD 卡</title>

<para>为 JeVois 创建 MicroSD 卡的另一种方法是使用 JeVois 开发环境提供的编译和安装脚本。</para>

<para>这允许您安装自定义内核、自定义硬件配置、自定义 Linux 安装（可能还有新的系统库和程序）等。</para>

<para>不建议新手使用，仅适用于 Linux。此过程在程序员手册中有详细说明。</para>

<para>有关更多信息，请参阅 <link linkend="_Programmer">程序员指南</link> 以及特别是 ProgrammerSDK。 </para>
</section>
    <section xml:id="_UserSerial"><title>串口使用指南</title>    </section>
<para>JeVois 智能相机上的硬件串行端口（UART 端口）是 TTL 电平（不是 RS-232 电平），并且支持 3.3V 和 5V 逻辑。</para>

<para>使用的逻辑电压由连接的微控制器提供给智能相机（红线，IOREF 电压）。此电压应由您的微控制器提供，并且应是 RX 和 TX 信号工作的电压）。Arduino 开发板为此目的提供了 IOREF 引脚。IOREF 是 JeVois 的输入。因此，5V Arduino 将向 IOREF 输出 5V，并将使用 5V 电平进行 RX 和 TX。相比之下，3.3V Arduino 将向 IOREF 输出 3.3V，并将使用 3.3V 电平进行 RX 和 TX。</para>

<para>要连接到 Arduino 开发板，通常需要执行以下操作（显示，引脚排列与 相同）：</para>

<para>  </para>

<para>请注意连接器的方向和彩色电线的顺序，上面的 和下面的：</para>

<para>  </para>

<para><note><title>Note</title>

<para>确保所有引脚上的电压不要超过 5.5V，否则可能会损坏 JeVois 设备。</para>

<para>串行端口（所有引脚合计）的功耗小于 1mA。因此，直接将任何 Arduino 的 IOREF 引脚（通常额定为 50mA 或更低）与 JeVois 一起使用是合适的。</para>

<para>JeVois 不通过 4 针串行连接器上的针脚供电。IOREF 是 JeVois 的输入，仅提供电压参考来确定 RX 和 TX 针脚上应使用哪些电压，但 IOREF 不以任何方式连接到 JeVois 的主电源。 仅通过 mini-USB 连接器供电，而 仅通过其筒式插孔电源连接器供电。</para>
</note>
</para>
<section xml:id="_UserSerial_1autotoc_md144">
<title>更改串行端口设置</title>

<para>您可以通过编辑 microSD 卡上的文件 <emphasis role="bold">JEVOIS:/config/params.cfg</emphasis>（来源为 <emphasis role="bold">~/jevois/Config/params.cfg</emphasis>）自定义串行端口的设置以匹配微控制器可以支持的设置。支持以下选项（请参阅 <link linkend="_JeVoisDaemon">jevois-daemon 可执行文件</link> 了解启动时支持的更多配置选项，并参阅 <link linkend="_classjevois_1_1Serial">jevois::Serial</link> 了解串行接口的完整文档）：</para>

<para><itemizedlist>
<listitem>
<para><emphasis role="bold">serialdev</emphasis> - 串行设备的名称。4 针连接器的硬件串行端口在 JeVois 平台上始终为 <emphasis role="bold">/dev/ttyS0</emphasis>。</para>
</listitem><listitem>
<para><emphasis role="bold">serial:mode</emphasis> - 输入的终端仿真模式，应为 <emphasis role="bold">Plain</emphasis> 或 <emphasis role="bold">VT100。默认为</emphasis> <emphasis role="bold">Plain。</emphasis> </para>
</listitem><listitem>
<para><emphasis role="bold">serial:baudrate</emphasis> - 要使用的波特率。应为 110、300、600、1200、2400、4800、9600、14400、19200、38400、57600、115200、230400、380400、460800、921600、1000000、1152000、1500000、2000000、2500000、3000000、3500000、 4000000 之一。默认值为 <emphasis role="bold">115200。请注意，此处列出的某些值理论上受硬件支持，但似乎不起作用。可能需要对</emphasis> Linux 内核中 Allwinner 芯片的串行驱动程序进行一些调整。已确认值 <emphasis role="bold">9600、<emphasis role="bold">115200</emphasis> 和</emphasis> <emphasis role="bold">1500000（1</emphasis>.5 Mbps）可以正常工作。如果通过蓝牙 BLE 链路传输串行数据，则应使用 <emphasis role="bold">9600。</emphasis> </para>
</listitem><listitem>
<para><emphasis role="bold">serial:linestyle</emphasis> - 行尾样式：应为</para>
</listitem><listitem>
<para><emphasis role="bold">LF</emphasis> 表示 0x0a [\n];</para>
</listitem><listitem>
<para><emphasis role="bold">CR</emphasis> 表示 0x0d [\r];</para>
</listitem><listitem>
<para><emphasis role="bold">CRLF</emphasis> 表示 0x0d 0x0a [\r\n];</para>
</listitem><listitem>
<para><emphasis role="bold">Zero</emphasis> 表示 0x00 [\0];</para>
</listitem><listitem>
<para><emphasis role="bold">Sloppy</emphasis> 表示 CR、LF、CRLF、0xd0（由某些键盘发出，而不是 Return）中的任何一个，或 Zero 作为输入，CRLF 作为输出。<emphasis role="bold">Sloppy</emphasis> 是默认值。</para>
</listitem><listitem>
<para><emphasis role="bold">serial:format</emphasis> - 数据格式。应为包含 3 个字符的字符串：</para>
</listitem><listitem>
<para>数据位数：<emphasis role="bold">5</emphasis> 至 <emphasis role="bold">8，默认为</emphasis> <emphasis role="bold">8</emphasis> </para>
</listitem><listitem>
<para>奇偶校验：<emphasis role="bold">N</emphasis> 表示无，<emphasis role="bold">O</emphasis> 表示奇数，<emphasis role="bold">E</emphasis> 表示偶数。默认为 <emphasis role="bold">N</emphasis> </para>
</listitem><listitem>
<para>停止位：<emphasis role="bold">1</emphasis> 或 <emphasis role="bold">2。默认为</emphasis> <emphasis role="bold">1</emphasis> </para>
</listitem><listitem>
<para>示例：<emphasis role="bold">8N1（默认）</emphasis> </para>
</listitem></itemizedlist>
</para>

<para>例如，在将串行数据传输到蓝牙 BLE 发射器时，为了将串行速率降低到 9600 波特，<emphasis role="bold">params.cfg</emphasis> 应包含：</para>

<para><literallayout><computeroutput>serialdev=/dev/ttyS0 serial:baudrate=9600 serial:linestyle=LF </computeroutput></literallayout></para>

<para><note><title>Note</title>

<para>第一行 (serialdev=/dev/ttyS0) 是其他选项被接受所必需的。这是因为，否则，串行端口在解析 <emphasis role="bold">params.cfg</emphasis> 之前将保持未定义状态（<emphasis role="bold">serialdev</emphasis> 默认为空），并且稍后在 jevois-engine 启动其操作时将为其分配一个默认值 /dev/ttyS0。</para>
</note>
</para>
</section>
<section xml:id="_UserSerial_1autotoc_md145">
<title>使用低功耗蓝牙（BLE）的无线串行</title>

<para>我们已成功使用 Adafruit Feather 32u4 Bluefruit LE 通过蓝牙传输 JeVois 串行数据。使用此功能，您可以通过运行蓝牙串行应用程序（例如 BlueFruit 应用程序）的平板电脑控制 JeVois。</para>

<para>我们将其串行引脚连接到 JeVois 的串行端口，并编写了一段简单的代码，该代码只会在串行引脚和 Feather 的 BLE 模块之间转发串行数据。它在 9600 波特下工作良好，但在 115200 波特下会卡住。看起来 BLE 上的串行传输限制为 9600 波特。查看 <emphasis role="bold">JEVOIS:/config/params.cfg</emphasis> 以了解我们在通过蓝牙传输串行数据时使用的配置选项。其他串行到 BLE 模块可用并且应该也可以正常工作，但我们尚未测试。Feather 32u4 Bluefruit LE 的主要缺点是它的价格（30 美元）。 </para>
</section>
    <section xml:id="_UserSerialStyle"><title>标准化串行消息格式</title>    </section>
<para></para>

<para>JeVois 提供了一组标准化的串行输出消息，目的是协调多个机器视觉模块之间的串行消息，以便不同的视觉模块能够以相同的方式控制 Arduino 或类似的嵌入式控制器。然后，用户可以尝试使用不同的机器视觉模块，而无需重写和重新刷新他们的 Arduino 代码。例如，电动平移/倾斜云台可以直接由基于颜色的物体跟踪器、基于显着性的视觉注意模块、物体识别模块或 ArUco 虚拟现实标记检测模块控制，使用相同的 Arduino 代码接收来自 JeVois 的控制消息并启动平移/倾斜电机。</para>

<para>标准化串行消息重点（至少目前）是发送 JeVois 检测到的事物的位置和身份信息（1D、2D 或 3D）。</para>

<para>希望发送如下定义的标准化消息的模块应该从 <link linkend="_classjevois_1_1StdModule">jevois::StdModule</link> 派生，而不是从 <link linkend="_classjevois_1_1Module">jevois::Module</link> 派生。jevois::StdModule 类添加了允许最终用户控制串行消息格式的参数，以及帮助程序员发出标准化消息的附加成员函数。</para>

<para><link linkend="_classjevois_1_1StdModule">jevois::StdModule</link> 的参数 <computeroutput>serstyle</computeroutput> 和 <computeroutput>serprec</computeroutput> 定义以下标准化串行消息样式。参数 <computeroutput>serstamp</computeroutput> 允许使用帧编号、日期和/或时间对每条消息进行额外的标记。</para>

<para><note><title>Note</title>

<para>请注意，每次加载视觉处理模块时，<computeroutput>serstyle</computeroutput> 和 <computeroutput>serprec</computeroutput> 都会重置为默认值。因此，您应该在加载模块后设置它们。参数 <computeroutput>sertamp</computeroutput> 不受模块更改的影响，因为它归 JeVois 引擎所有。</para>
</note>
坐标约定和精度 ========================================</para>

<para>所有 1D 和 2D 坐标均使用 JeVois 标准坐标（介于 -1000 和 1000 之间），如 <link linkend="_group__coordhelpers">用于将坐标从相机分辨率转换为标准坐标的辅助函数</link> 中所定义。</para>

<para>所有 3D 坐标均假定来自经过校准的相机，并以真实世界空间的毫米为单位表示。</para>

<para>参数 <computeroutput>serprec</computeroutput> 定义这些坐标通过串行发送的精度，即小数点后的小数位数。例如：</para>

<para><itemizedlist>
<listitem>
<para>当 <computeroutput>serprec</computeroutput> 为 0 时，坐标将以整数形式发送，例如 123（无尾随小数点）。</para>
</listitem><listitem>
<para>当 <computeroutput>serprec</computeroutput> 为 1 时，坐标将以 1 位小数发送，例如 123.4</para>
</listitem><listitem>
<para>当 <computeroutput>serprec</computeroutput> 为 2 时，坐标将以 2 位小数发送，例如 123.45</para>
</listitem><listitem>
<para>依此类推。</para>
</listitem></itemizedlist>
</para>

<para>鉴于 <link linkend="_group__coordhelpers">用于将坐标从相机分辨率转换为标准坐标的辅助函数</link> 为 1D 和 2D 坐标提供的 -1000 到 1000 的范围已经很大，或者 3D 坐标的精度相当高（毫米），因此预期 <computeroutput>serprec</computeroutput> 仅在特殊情况下才为非零。大多数 Arduino 控制软件可以合理地预期仅支持 <computeroutput>serprec=0。</computeroutput> </para>

<para>一维（1D）位置消息======================================</para>

<para>1D 位置消息用于传达某物在 1D 轴（通常是水平轴）上的位置。例如， 模块中消失点的 <emphasis>x</emphasis> 坐标。</para>

<para>来自机器视觉模块的输入：</para>

<para><itemizedlist>
<listitem>
<para><emphasis>x</emphasis> 报告对象中心的标准化一维位置。</para>
</listitem><listitem>
<para><emphasis>id</emphasis> 描述所报告对象是什么的文本字符串（例如，它具有哪个 ArUco 标记 ID）。为了便于接收 Arduino 解析，ID 中不应有空格。任何空格都将被下划线替换。</para>
</listitem><listitem>
<para><emphasis>size</emphasis> 报告对象的标准化 1D 大小（因此，对象从 x-size/2 延伸到 x+size/2）。请注意，size 将以与坐标相同的精度输出。</para>
</listitem><listitem>
<para><emphasis>extra</emphasis> 有关报告对象的任何附加文本字符串。</para>
</listitem><listitem>
<para><emphasis>xmin</emphasis> 和 <emphasis>xmax</emphasis> 报告对象两个边缘的标准化 1D 位置。对于 1D 对象，指定 <emphasis>xmin</emphasis> 和 <emphasis>xmax</emphasis> 相当于指定 <emphasis>x</emphasis> 和 <emphasis>size（但在</emphasis> 2D、3D 等中并非总是如此）。</para>
</listitem></itemizedlist>
</para>

<para>串行消息：</para>

<para>serstyle | 消息 ------&#8212;|--------------------------------------------------------------------------------------------------------------&#8212; Terse | <computeroutput>T1 x</computeroutput> Normal | <computeroutput>N1 id x size</computeroutput> Detail | <computeroutput>D1 id xmin xmax extra</computeroutput> Fine | N/A - 将改为发出 <computeroutput>D1D</computeroutput> 消息。</para>

<para>二维（2D）位置消息======================================</para>

<para>2D 位置消息用于传达 2D 空间中某物的位置（通常是相机图像的平面）。例如， 模块检测到的对象的 <emphasis>x</emphasis>,y 标准化坐标。</para>

<para>来自机器视觉模块的输入：</para>

<para><itemizedlist>
<listitem>
<para><emphasis>x,y</emphasis> 报告对象中心的标准化二维位置。</para>
</listitem><listitem>
<para><emphasis>id</emphasis> 描述所报告对象是什么的文本字符串（例如，它具有哪个 ArUco 标记 ID）。为了便于接收 Arduino 解析，ID 中不应有空格。任何空格都将被下划线替换。</para>
</listitem><listitem>
<para><emphasis>w,h</emphasis> 报告对象的标准化宽度和高度（因此，对象水平方向从 x-w/2 延伸到 x+w/2，垂直方向从 y-h/2 延伸到 y+h/2）。请注意，尺寸数据将以与坐标数据相同的精度输出。</para>
</listitem><listitem>
<para><emphasis>extra</emphasis> 有关报告对象的任何附加文本字符串。</para>
</listitem><listitem>
<para><emphasis>x1,y1</emphasis> ... <emphasis>x4,y4</emphasis> 报告对象周围边界矩形的 4 个角的标准化 x,y 坐标。</para>
</listitem><listitem>
<para><emphasis>x1,y1</emphasis> ... <emphasis>xn,yn</emphasis> 报告对象周围边界多边形的 <emphasis>n</emphasis> 个顶点的标准化 x,y 坐标。请注意，n 可能因对象而异。</para>
</listitem></itemizedlist>
</para>

<para>串行消息：</para>

<para>塞尔风格|留言------&#8212;|-------------------------------------&#8212; -----------------------------------------------&#8212; -------------&#8212; 简洁| <computeroutput>T2 x y</computeroutput> 正常 | <computeroutput>N2 id x y w h</computeroutput> 详细信息 | <computeroutput>D2 id x1 y1 x2 y2 x3 y3 x4 y4 额外</computeroutput> <computeroutput>F2 id n x1 y1 ... xn yn 额外</computeroutput></para>

<para><note><title>Note</title>

<para><emphasis role="bold">Normal</emphasis> 和 <emphasis role="bold">Detail</emphasis> 消息的边界框的紧密度取决于机器视觉模块生成的信息。通常，机器视觉模块将使用定义形状（多边形轮廓）的 2D 顶点列表调用 <link linkend="_classjevois_1_1StdModule">jevois::StdModule</link> 的串行消息函数。在 <emphasis role="bold">Normal</emphasis> 样式中，垂直边界矩形适合这些顶点以生成消息，旋转矩形适合顶点以生成 <emphasis role="bold">Detail</emphasis> 消息。</para>
</note>
三维（3D）位置消息========================================</para>

<para><warning><title>Warning</title>

<para>这尚未完全测试！</para>
</warning>
3D 位置消息用于传达现实世界 3D 空间中某物的位置，通常可从已校准相机且相机观察到已知现实世界大小的物体的模块获得。例如，ArUco 模块可以恢复已知现实世界大小的标记的完整 3D 位置和姿势。</para>

<para>我们使用 <link xlink:href="https://en.wikipedia.org/wiki/Right-hand_rule">右手定则</link> 来表示 3D 坐标，因为它是机器人学中的主导惯例。我们还遵循机器人操作系统 (ROS) 的 <link xlink:href="http://www.ros.org/reps/rep-0103.html">REP-0103</link> 中关于相机框架（称为<emphasis>后缀框架</emphasis>）的惯例，以简化互操作性，但我们以毫米而不是米为单位报告距离：</para>

<para><itemizedlist>
<listitem>
<para>X 轴指向右</para>
</listitem><listitem>
<para>Y 轴指向下</para>
</listitem><listitem>
<para>Z 轴指向前</para>
</listitem></itemizedlist>
</para>

<para>来自机器视觉模块的输入：</para>

<para><itemizedlist>
<listitem>
<para><emphasis>x,y,z</emphasis> 报告物体中心的实际 3D 位置（以毫米为单位），距离相机的光学中心。</para>
</listitem><listitem>
<para><emphasis>id</emphasis> 描述所报告对象是什么的文本字符串（例如，它具有哪个 ArUco 标记 ID）。为了便于接收 Arduino 解析，ID 中不应有空格。任何空格都将被下划线替换。</para>
</listitem><listitem>
<para><emphasis>w,h,d</emphasis> 报告物体的宽度（X 轴）、高度（Y 轴）和深度（Z 轴），单位为毫米（因此，物体水平方向从 x-w/2 延伸到 x+w/2，垂直方向从 y-h/2 延伸到 y+h/2，沿相机光轴方向从 z-d/2 延伸到 z+d/2）。请注意，尺寸数据将以与坐标数据相同的精度输出。</para>
</listitem><listitem>
<para><emphasis>extra</emphasis> 有关报告对象的任何附加文本字符串。</para>
</listitem><listitem>
<para><emphasis>q1,q2,q3,q4</emphasis> 一个将物体的框架与相机的框架相关联的四元数（如果合适）。</para>
</listitem><listitem>
<para><emphasis>x1,y1,zn</emphasis> ... <emphasis>xn,yn,zn</emphasis> 定义对象周围 3D 多面体的 <emphasis>n</emphasis> 个顶点的 3D 坐标。</para>
</listitem></itemizedlist>
</para>

<para>串行消息：</para>

<para>塞尔风格|留言------&#8212;|-------------------------------------&#8212; -----------------------------------------------&#8212; -------------&#8212; 简洁| <computeroutput>T3 x y z</computeroutput> 正常 | <computeroutput>N3 id x y z w h d</computeroutput> 详细信息 | <computeroutput>D3 id x y z w h d q1 q2 q3 q4 额外</computeroutput> <computeroutput>F3 id n x1 y1 z1 ... xn yn zn 额外</computeroutput></para>

<para>新的机器视觉模块可以使用 <link linkend="_classjevois_1_1StdModule">jevois::StdModule</link> 类中提供的便捷函数来发送标准化串行消息。</para>

<para><note><title>Note</title>

<para>如果您将使用四元数数据（<emphasis role="bold">详细消息样式），您可能应该将</emphasis> <computeroutput>serprec</computeroutput> 参数设置为非零值以获得四元数值的足够精度。</para>
</note>
物体识别消息 ==============================</para>

<para></para>

<para>、 等多个模块可识别可能属于给定类别集的对象。这些模块会为每个检测到的对象发送对象识别消息。</para>

<para>识别由多个类别：分数对组成，其中 <emphasis>类别是对象类别（对象类型）的名称，<emphasis>分数是此类别的识别分数，范围为</emphasis> 0.0</emphasis> ... 100.0</para>

<para>请注意，许多算法都会提供此类配对的列表作为其结果，以涵盖可能出现的模糊识别。例如，<emphasis role="bold">cat:77.2 dog:27.3</emphasis> 表示算法非常确信它正在看一只猫，但是，如果置信度较低，它认为它也可能正在看一只狗。</para>

<para>serstyle | 消息 ------&#8212;|--------------------------------------------------------------------------------------------------------------&#8212; 简洁 | <computeroutput>TO topcateg</computeroutput> 正常 | <computeroutput>NO topcateg:topscore</computeroutput> 详细信息 | <computeroutput>DO topcateg:topscore categ2:score2 ... categN:scoreN</computeroutput> 精细 | <computeroutput>FO topcateg:topscore categ2:score2 ... categN:scoreN</computeroutput></para>

<para>其中 <emphasis>topcateg</emphasis> 是得分最高的类别的类别名称，<emphasis>topscore</emphasis> 是其得分，而 <emphasis>categ2</emphasis> 是得分第二高的类别，依此类推。2...N 次级识别的数量可能因消息而异，也可能为零，但 <emphasis>topcateg</emphasis> 和 <emphasis>topscore</emphasis> 始终保证存在（如果没有结果，则不会发送任何消息）。</para>

<para>请注意，某些对象类别名称可能包含空格，例如 <emphasis role="bold">dining table</emphasis>；构造消息时，任何空格都会被下划线替换（例如 <emphasis role="bold">dining_table</emphasis>），以便 Arduino 和类似程序更容易解析消息。</para>

<para>物体检测 + 识别消息 ===========================================</para>

<para>一些模块，如、 和 首先检测可能包含对象的一个​​或多个边界框，然后识别每个框中可能存在哪个对象。</para>

<para>这些模块发送如上所述的二维（2D）位置消息（T2、N2、D2、F2 消息），并在 <emphasis>id</emphasis> 和 <emphasis>extra</emphasis> 字段中包含以下信息：</para>

<para>serstyle | id | extra ------&#8212;|-------------------------------------&#8212;|------------------------------------------------------------&#8212; 简洁 | <computeroutput>topcateg</computeroutput> | (无额外) 正常 | <computeroutput>topcateg:topscore</computeroutput> | (无额外) 详细信息 | <computeroutput>topcateg:topscore</computeroutput> | <computeroutput>categ2:score2 ... categN:scoreN</computeroutput> 精细 | <computeroutput>topcateg:topscore</computeroutput> | <computeroutput>categ2:score2 ... categN:scoreN</computeroutput></para>

<para>其中 <emphasis>topcateg</emphasis> 是得分最高的类别的类别名称，<emphasis>topscore</emphasis> 是其得分，而 <emphasis>categ2</emphasis> 是得分第二高的类别，依此类推。与对象识别消息相同的注释也适用。</para>

<para>可选地在串行消息上标记帧号、日期和时间 ============================================================================</para>

<para></para>

<para>参数 <computeroutput>serstamp</computeroutput> 允许选择性地按日期、时间或帧号标记标准化串行消息。</para>

<para>请注意，JeVois 没有电池，因此每次通电时，其内部时钟都会重置为 1970 年 1 月 1 日 UTC。但是，外部计算机可以使用 JeVois <computeroutput>date</computeroutput> 命令设置日期。有关 <computeroutput>date 命令</computeroutput> 以及如何设置/检索 JeVois 的日期和时间的更多信息，请参阅 UserCli。</para>

<para>标记被添加到标准化串行消息的前面，后面跟着一个空格。请注意，使用标记将在每个标准化串行消息的开头添加一个字段（用于标记）。如果 Arduino 被编程为响应 T2 消息，那么如果接收以日期或帧号开头的消息，它可能会感到困惑，因此 Arduino 代码应该进行相应调整。</para>

<para>冲压方式：</para>

<para>|serstamp | 邮票格式 | 帧 769 的示例，于 2017 年 12 月 24 日 15:52:42 | |------------&#8212;|---------------------------&#8212;|-------------------------------------&#8212;| |无 | 无邮票 | | |帧 | FRAME | 769 | |时间 | hh:mm:ss | 15:52:42 | |FrameTime | FRAME/hh:mm:ss | 769/15:52:42 | |FrameDateTime | FRAME/YYYY-MM-DD/hh:mm:ss | 769/2017-12-24/15:52:42 |</para>

<para>因此，如果 <computeroutput>serstyle</computeroutput> 为 <emphasis role="bold">Terse，且检测到</emphasis> x=123、y=456 处的目标，则消息将从默认的 <computeroutput>serstamp</computeroutput> 变为 <emphasis role="bold">None：</emphasis> </para>

<para>\逐字 T2 123 456 \end逐字</para>

<para>到，使用 <emphasis role="bold">FrameDateTime</emphasis> 的 <computeroutput>serstamp：</computeroutput> </para>

<para>\逐字 769/2017-12-24/15:52:42 T2 123 456 \end逐字</para>

<para>可选框架标记 ========================</para>

<para></para>

<para>参数 <computeroutput>sermark</computeroutput> 允许发送以下消息，要么在处理来自摄像机传感器的视频帧之前（开始标记消息），要么在处理之后（停止标记消息），或者两者兼而有之：</para>

<para>|sermark | 开始标记消息 | 停止标记消息 | |--------&#8212;|-----------------&#8212;|----------------&#8212;| |无 | (无消息) | (无消息) | |开始 | 标记开始 | (无消息) | |停止 | (无消息) | 标记停止 | |两者 | 标记开始 | 标记停止 |</para>

<para>请注意，可能会在标记之前发送一个戳记，具体取决于参数 <computeroutput>serstamp</computeroutput> 的值。</para>

<para>限制每个视频帧的串行消息数量 ===========================================================</para>

<para></para>

<para>JeVois Engine 的参数 <computeroutput>serlimit</computeroutput> 可以设置为限制每个视频帧上发送的串行消息数量，以避免串行链路过载。例如，如果模块为每个检测到的项目发送一条消息，但存在许多项目，则可以使用 <computeroutput>serlimit</computeroutput> 来限制将通过串行端口报告的项目数量。</para>

<para>请注意，如果模块使用来自异步线程的 sendSerial() 发送消息，则无法严格执行每帧的限制。 <computeroutput>serlimit</computeroutput> 的基本工作方式是，对于 sendSerial() 或其派生函数（如 SendSerialImg2D() 等）发送的每条消息，都会增加一个（线程安全）计数器，并且每次调用模块的 process() 函数（无论是正常完成还是异常）完成后，计数器都会重置为零。</para>

<para>嵌入式控制器和机器人的建议 =======================================================</para>

<para><itemizedlist>
<listitem>
<para>只能沿着一个轴朝向某物（例如，机器人汽车的转向）的机器人通常会期待 <computeroutput>T1</computeroutput> 消息。</para>
</listitem><listitem>
<para>只能朝向 2D 图像平面中的某个物体（例如，电动平移/倾斜云台）的机器人通常会期待 <computeroutput>T2</computeroutput> 消息。</para>
</listitem><listitem>
<para>可以将末端执行器移向 3D 空间中的物体的机器人（例如，没有夹持器的机械臂）通常会期待 <computeroutput>T3</computeroutput> 消息。</para>
</listitem><listitem>
<para>机器人会根据物体采取不同的动作，通常会期望 <computeroutput>N1、<computeroutput>N2</computeroutput> 或</computeroutput> <computeroutput>N3</computeroutput> 消息，然后解码 <emphasis>id</emphasis> 字段来决定要做什么。</para>
</listitem><listitem>
<para>机器人还需要在受控环境中了解物体的尺寸（例如，检查机器人可能会弹出传送带上的有缺陷的物品，摄像机放置在传送带上方固定距离处并向下观察它）通常会期望 <computeroutput>D1、<computeroutput>D2</computeroutput> 或</computeroutput> <computeroutput>D3</computeroutput> 消息，或者，如果形状很重要，则期望 <computeroutput>F2</computeroutput> 或 <computeroutput>F3</computeroutput> 消息。</para>
</listitem><listitem>
<para>可以将末端执行器移向 3D 空间中的物体并抓住该物体的机器人（例如，带有夹持器的机械臂）通常会期望 <computeroutput>N3、<computeroutput>D3</computeroutput> 或</computeroutput> <computeroutput>F3</computeroutput> 消息。 </para>
</listitem></itemizedlist>
</para>
    <section xml:id="_ProConnectors"><title>JeVois-Pro 辅助连接器</title>    </section>
<para>6 针 AUX 电源连接器 ===========================</para>

<para>此连接器（位于相机顶部的两个 USB 端口之间，请参阅 ProHardware）为您可能想要连接到 JeVois-Pro 的辅助设备提供电源。此电源来自 JeVois-Pro 的主 6-24VDC 筒形插孔输入。</para>

<para>  </para>

<para>注意连接器的方向和上面彩色电线的顺序。</para>

<para>引脚排列如下：</para>

<para>引脚 | 电线颜色 | 功能 -&#8212;|---------&#8212;|-----------------------------------------------------------------------------------------------------&#8212; 1 | 黑色 | GND 2 | 红色 | 5V / 1A（与 USB 主机 1 共享，从 JeVois-Pro 后面看时连接器位于左侧） 3 | 橙色 | 5V / 1A（与 USB 主机 2 共享，从 JeVois-Pro 后面看时连接器位于右侧） 4 | 黄色 | 3.3V / 750mA 5 | 蓝色 | 1.8V / 500mA 6 | 黑色 | GND</para>

<para>配对连接器零件编号：JST SHR-06V-S-B，间距 1.0mm，6 针 JST-SH 系列。</para>

<para>这些连接器的针脚几乎不可能用手压接，除非您有 JST 出售的 1000 美元以上的特殊工具。因此，请妥善保管 JeVois-Pro 相机附带的电缆。延长电线，而不是将它们剪得很短……</para>

<para>请注意，此连接器每个引脚的额定电流为 1A。由于只有两个 GND 引脚，因此请尽量不要在其他 4 个引脚上消耗超过 2A 的电流。</para>

<para>8 针 GPIO 连接器 =====================</para>

<para>此连接器（位于微型 HDMI 连接器旁边，请参阅 ProHardware）提供 6 个通用输入/输出引脚 (GPIO)。这些引脚可以以多种方式配置，如下所述。</para>

<para>与 4 针串行端口一样，此端口需要在第 6 针（IOREF）上提供输入电压。这是 JeVois-Pro 的输入，您必须提供该输入以告诉 JeVois-Pro 您希望 GPIO 针以哪个电压水平运行：3.3V 或 5V。有关更多信息，请参阅 UserSerial。</para>

<para>  </para>

<para>注意连接器的方向和上面彩色电线的顺序。</para>

<para>引脚排列如下：</para>

<para>引脚 | 电线颜色 | 功能 | A311D SoC | 内核 GPIO -&#8212;|---------&#8212;|-------------------------------------------------------------&#8212;|--------&#8212;|----------&#8212; 1 | 紫色 | JVGPIO0 / SPI MOSI / SPDIF_OUT / UART_RTS | GPIOH_4 | 431 2 | 橙色 | JVGPIO1 / SPI MISO / SPDIF_IN / UART_CTS / PWM_F | GPIOH_5 | 432 3 | 白色 | JVGPIO2 / SPI SS / UART_RX / IR_OUT / ONEWIRE / ISO7816_CLK | GPIOH_6 | 433 4 | 蓝色 | JVGPIO3 / SPI SCLK / UART_TX / ISO7816_DATA | GPIOH_7 | 434 5 | 绿色 | JVGPIO4 / I2C SDA | GPIOZ_14 | 425 6 |黄色 | JVGPIO5 / I2C SCL | GPIOZ_15 | 426 7 | 红色 | IOREF（您提供 GPIO 工作的电压：3.3V 或 5V）| - | - 8 | 黑色 | GND | - | -</para>

<para>配对连接器零件编号：JST SHR-08V-S-B，间距 1.0mm，8 针 JST-SH 系列。</para>

<para>这些连接器的针脚几乎不可能用手压接，除非您有 JST 出售的 1000 美元以上的特殊工具。因此，请妥善保管 JeVois-Pro 相机附带的电缆。延长电线，而不是将它们剪得很短……</para>

<para><warning><title>Warning</title>

<para>应始终提供 IOREF，并且与 GPIO 的工作电压相匹配。如果您要使用 6 针 AUX 电源连接器为小工具供电，您可以方便地从该连接器获取它。因此，例如，如果您使用 6 针 AUX 电源连接器的黄色线为 3.3V 小工具供电，则还可以将相同的 3.3V 电压馈送到 8 针 GPIO 连接器的 IOREF（红色）线。</para>
</warning>
\警告 IOREF 和所有 GPIO 应在 3.3V 至 5V 之间的电压下工作。如果超过 5.5V，可能会损坏 JeVois-Pro 上的 GPIO 缓冲芯片。</para>

<para><note><title>Note</title>

<para>我们最初认为我们可以在此连接器上支持 1.8V - 5V。然而，最近我们在用于此连接器电压转换的 NXP NTB0104GU,115 数据表中看到了一个脚注，其中说连接器上的电压不应低于 CPU 芯片上的电压（在我们的设计中为 3.3V）。因此，请考虑 1.8V 不受官方支持，尽管在我们执行的基本测试中它似乎运行良好。从长远来看，它可能会损坏 NBT0104 芯片。</para>
</note>
具有自动方向感应的电压转换 --------------------------------------------&#8212;</para>

<para>JVGPIO0 到 JVGPIO3 通过电压电平转换器（NXP NTB0104GU,115 芯片）连接。该芯片会自动检测输入或输出方向。这是一个很棒的功能，因为我们不需要为每个 GPIO 增加一个额外的引脚来指示它当前是用作输入还是输出，并相应地设置转换器的方向。但它也有一些注意事项：如果您使用引脚作为输出，但将其连接到可以提供电流的设备，例如因为设备的输入端有一个上拉电阻，NTB0104 芯片可能会反转其方向。通常这不会损坏您的硬件，但可能会导致意外结果。</para>

<para>例如，我们尝试使用 SPI 总线将 Sparkfun ICM20948 外部 IMU 连接到 JeVois-Pro 的 GPIO 连接器。我们无法让它工作，并且总是从设备读取垃圾，并且无法使用示波器看到 Sparkfun 板引脚上的 SPI 传输。事实证明，Sparkfun 板有自己的一组电压转换器，所有引脚上都有大约 2.2k 上拉电阻。这可能足以让我们的 NTB0104 认为 Sparkfun 板的所有引脚都是输出，因此它将自身配置为通过所有 4 个 SPI 引脚将数据从 Sparkfun 板发送到 JeVois-Pro 的 A311D。这是一个问题，因为 MOSI、SS 和 SCLK 实际上应该将数据从 A311D 发送到 Sparkfun 板。为了解决这个问题，您可能需要在 Sparkfun IMU 前面插入一些单向缓冲区（例如，74HC125 或类似产品，其中 3 个缓冲区连接 A311D-&gt;Sparkfun（MOSI、SS、SCLK）和一个连接 Sparkfun-&gt;A311D（MISO）；请注意，我们还没有尝试过这个，但我们很快就会尝试）。</para>

<para><note><title>Note</title>

<para>根据 NTB0104 数据表，如果您确实需要在某些输入上使用上拉电阻，请确保其值为 50k 欧姆或更大，以避免方向反转。</para>
</note>
由于 NBT0104，当用作输入时，JVGPIO0 至 JVGPIO3 也具有“粘性”，因为 NTB0104 将保持当前驱动状态，直到主动更改为止。例如：</para>

<para><itemizedlist>
<listitem>
<para>将 JVGPIO0（紫色线）配置为输入（见下文）</para>
</listitem><listitem>
<para>将 IOREF 设置为 5V 并保持</para>
</listitem><listitem>
<para>将 5V 施加到紫色线，JVGPIO0 将读为“1”</para>
</listitem><listitem>
<para>将紫色线与 5V 断开，仍将读为“1”</para>
</listitem><listitem>
<para>将 0V（GND）施加到紫色线，现在 JVGPIO0 将读为“0”</para>
</listitem><listitem>
<para>将紫色线与 GND 断开，仍将读为“0”</para>
</listitem></itemizedlist>
</para>

<para>JVGPIO4 和 JVGPIO5 使用简单的 MOSFET 进行电压转换，并使用 2k 上拉电阻连接到 IOREF。配置为输入时（见下文），这些引脚会因为上拉电阻而默认读取“1”，除非您主动将它们驱动至 0V（GND），在这种情况下它们将读取“0”。</para>

<para>欲了解更多信息，请查看以下原理图：<link linkend="_HardwareFiles">硬件：原理图、机壳 STL 文件等 \tableofcontents</link></para>

<para>基本 GPIO 使用 -----------&#8212;</para>

<para>要激活给定的 GPIO，请从上表的最后一列查找其内核 GPIO 编号，然后在 Linux shell 中以 root 身份发出这些命令（或在 JeVois 控制台中，使用 <computeroutput>shell</computeroutput> 作为前缀），将下面的 <emphasis>431</emphasis> 替换为您要使用的内核 GPIO 编号：</para>

<para><literallayout><computeroutput>echo&#32;431&#32;&gt;&#32;/sys/class/gpio/export&#32;#&#32;声明&#32;GPIO&#32;编号&#32;431&#32;=&#32;GPIOH_4&#32;/&#32;JVGPIO0&#32;/&#32;紫线&#32;echo&#32;out&#32;&gt;&#32;/sys/class/gpio/gpio431/direction&#32;#&#32;用作输出，或&#32;&apos;in&apos;&#32;用作输入&#32;echo&#32;1&#32;&gt;&#32;/sys/class/gpio/gpio431/value&#32;#&#32;开启，或&#32;&apos;0&apos;&#32;禁用&#32;cat&#32;/sys/class/gpio/gpio431/value&#32;#&#32;查看当前值&#32;
</computeroutput></literallayout></para>

<para>对于方向，您还可以使用 <emphasis>low</emphasis> 设置为输出并立即以无故障的方式将输出级别设置为低，或者使用 <emphasis>high</emphasis> 设置为输出并立即将输出级别设置为无故障的高。</para>

<para>如果您想在声明该 GPIO 后释放它：</para>

<para><literallayout><computeroutput>echo&#32;431&#32;&gt;&#32;/sys/class/gpio/unexport&#32;
</computeroutput></literallayout></para>

<para>使用 JVGPIO0 - JVGPIO5 作为输入 ------------------------------&#8212;</para>

<para>JVGPIO0 的示例：</para>

<para><literallayout><computeroutput>&#32;echo&#32;431&#32;&gt;&#32;/sys/class/gpio/export&#32;#&#32;声明&#32;GPIO&#32;编号&#32;431&#32;=&#32;GPIOH_4&#32;/&#32;JVGPIO0&#32;/&#32;紫线&#32;echo&#32;in&#32;&gt;&#32;/sys/class/gpio/gpio431/direction

#&#32;对紫色线施加与&#32;IOREF&#32;相同的电压

cat&#32;/sys/class/gpio/gpio431/value&#32;#查看当前值，应该显示“1”

#&#32;将紫色线连接到GND

cat&#32;/sys/class/gpio/gpio431/value&#32;#&#32;查看当前值，现在应该显示“0”&#32;
</computeroutput></literallayout></para>

<para>使用 JVGPIO0 - JVGPIO3 作为输出 -------------------------------&#8212;</para>

<para>JVGPIO0 的示例：</para>

<para><literallayout><computeroutput>&#32;echo&#32;431&#32;&gt;&#32;/sys/class/gpio/export&#32;#&#32;声明&#32;GPIO&#32;编号&#32;431&#32;=&#32;GPIOH_4&#32;/&#32;JVGPIO0&#32;/&#32;紫色线&#32;echo&#32;out&#32;&gt;&#32;/sys/class/gpio/gpio431/direction
#&#32;确保紫色线上没有上拉、下拉等，请参阅上面的注释。
#&#32;将&#32;IOREF&#32;连接到&#32;3.3V&#32;或&#32;5V。将电压表连接到紫色线&#32;echo&#32;1&#32;&gt;&#32;/sys/class/gpio/gpio431/value&#32;#&#32;电压表应读取与您提供给&#32;IOREF&#32;的电压相同的电压&#32;echo&#32;0&#32;&gt;&#32;/sys/class/gpio/gpio431/value&#32;#&#32;电压表应读取&#32;0V&#32;
</computeroutput></literallayout></para>

<para>使用 JVGPIO4 - JVGPIO5 作为输出 -------------------------------&#8212;</para>

<para>我们可能犯了一个错误，使用了 A311D 无法克服的过强上拉电阻。或者可能存在特定问题，因为这些引脚在 A311D 上有特殊的 OD（开漏）驱动器，但我们在 A311D 数据表中找不到太多相关信息。在我们尝试解决这个问题时，请使用此技巧：</para>

<para>JVGPIO4 示例：</para>

<para><literallayout><computeroutput>&#32;echo&#32;425&#32;&gt;&#32;/sys/class/gpio/export&#32;#&#32;声明&#32;GPIO&#32;编号&#32;425&#32;=&#32;GPIOZ_14&#32;/&#32;JVGPIO4&#32;/&#32;绿线
#&#32;将&#32;IOREF&#32;连接到&#32;3.3V&#32;或&#32;5V。将电压表连接到绿线&#32;echo&#32;low&#32;&gt;&#32;/sys/class/gpio/gpio431/direction&#32;#&#32;电压表应读取&#32;0V&#32;echo&#32;in&#32;&gt;&#32;/sys/class/gpio/gpio431/direction&#32;#&#32;电压表应读取与您提供给&#32;IOREF&#32;的电压相同的电压&#32;
</computeroutput></literallayout></para>

<para>事实上，将 1 写入 <emphasis>值似乎没有任何效果，输出始终为低。通过将引脚的方向切换为</emphasis> <emphasis></emphasis> ，我们基本上将其断开，并让我们的上拉电阻将其驱动为高电平。</para>

<para>使用 JeVois-Pro GPIO 作为 SPI、UART、I2C 等 ------------------------------------------&#8212;</para>

<para><note><title>Note</title>

<para>请耐心等待，因为这项工作仍在进行中。我们将在测试特定外围设备时很快发布更详细的教程。我们列表中的第一个是 SPI 和 I2C OLED 显示器。</para>
</note>
编辑 microSD 的 BOOT 分区上的文件 <emphasis role="bold">env.txt（当</emphasis> JeVois-Pro 在控制台模式下运行时，文件位于 <emphasis role="bold">/boot/env.txt</emphasis>）。最后，找到内核覆盖列表并附加所需的内核覆盖（将其添加到 <emphasis>覆盖中，用空格分隔）。这样做将在启动时声明特定功能的引脚，并在这些引脚上加载和启动该功能的相应内核驱动程序：</emphasis> </para>

<para><literallayout><computeroutput>#&#32;设备树覆盖&#32;#
#&#32;aux-i2c&#32;--&#32;在&#32;AUX&#32;引脚&#32;5&#32;(SDA)&#32;和&#32;6&#32;(SCL)&#32;上启用&#32;I2C&#32;驱动程序。
#&#32;aux-onewire&#32;--&#32;在&#32;AUX&#32;引脚&#32;3&#32;上启用&#32;OneWire&#32;驱动程序。
#&#32;aux-spi&#32;--&#32;在&#32;AUX&#32;引脚&#32;1&#32;(MOSI)、2&#32;(MISO)、3&#32;(SS)、4&#32;(SCLK)&#32;上启用&#32;SPI&#32;驱动程序。
#&#32;aux-uart&#32;--&#32;在&#32;AUX&#32;引脚&#32;1&#32;(RTS)、2&#32;(CTS)、3&#32;(RX)、4&#32;(TX)&#32;上启用&#32;UART&#32;驱动程序。
#&#32;icm20948&#32;--&#32;在&#32;JeVois&#32;M.2&#32;传感器连接器上启用&#32;ICM-20948&#32;IMU（位于&#32;IMX290&#32;摄像头板上）。
#&#32;imx290&#32;--&#32;在&#32;JeVois&#32;M.2&#32;传感器连接器上启用&#32;Sony&#32;IMX290&#32;摄像头传感器。
#&#32;wifi-bt&#32;--&#32;启用&#32;WIFI/BT&#32;M.2&#32;PCIe&#32;卡，而不是默认的&#32;Myriad-X&#32;或&#32;Coral-TPU&#32;M.2&#32;PCIe&#32;卡。
#&#32;emmc&#32;--&#32;启用自定义&#32;eMMC，仅适用于&#32;JeVois&#32;双&#32;TPU&#32;+&#32;eMMC&#32;板。
#&#32;sdio&#32;--&#32;在&#32;M.2&#32;PCIe&#32;端口上启用&#32;SDIO&#32;功能，与&#32;SDIO&#32;wifi&#32;卡和其他卡一起使用。
#&#32;wdt&#32;--&#32;启用看门狗定时器。
#&#32;remote&#32;--&#32;启用红外遥控输入（可在&#32;JeVois-Pro&#32;主板上的测试板上使用）。

覆盖=icm20948&#32;imx290&#32;
</computeroutput></literallayout></para>

<para>然后重新启动，新的内核设备就会出现。例如，当您激活 <emphasis>aux-spi</emphasis> 覆盖时，您应该会得到一个新设备 <emphasis role="bold">/dev/spidev1.0</emphasis>（除了 JeVois-Pro 板载 IMU 内部使用的 /dev/spidev32766.0）。</para>

<para>请注意上面解释的自动感应电压转换注意事项。</para>

<para>有关 GPIO 的更多信息 -------------------------&#8212;</para>

<para>在 JeVois-Pro 使用的 Amlogic A311D 芯片上，GPIO 被组织成两个 <emphasis>组，每个组由不同的控制器处理。第一个组是</emphasis> AO（始终开启）组，由 CPU 无法关闭的电源供电。此组通常用于内部 GPIO，例如为 CPU 核心组启用电源、调试 UART 等。第二个组用于在正常运行中使用的更通用的 GPIO，例如 I2C 和 SPI 外设等。</para>

<para>负责各个bank的Linux内核设备如下：</para>

<para>内核设备 | 银行 ---------------&#8212;|---------------&#8212; pinctrl@ff800014 | AO (始终开启) pinctrl@ff634480 | 标准</para>

<para>每个银行都由多个 <emphasis>引脚组成。您可以在此处获取引脚列表：</emphasis> </para>

<para><literallayout><computeroutput>cat&#32;/sys/kernel/debug/pinctrl/pinctrl@ff800014/pins&#32;#&#32;列出&#32;AO&#32;库中的引脚&#32;cat&#32;/sys/kernel/debug/pinctrl/pinctrl@ff634480/pins&#32;#&#32;列出标准库中的引脚&#32;
</computeroutput></literallayout></para>

<para>就内核驱动程序而言，这些列表建立了银行引脚号（例如，引脚 15）与 A311D 芯片上相应的物理引脚（例如，标准银行中的引脚 15 是芯片上的物理引脚 GPIOZ_14）之间的映射。</para>

<para>通过为每个库添加偏移量到该库中的给定引脚，两个库的引脚进一步组合并重新映射到单个 GPIO <emphasis>范围。您可以在此处获取偏移量：</emphasis> </para>

<para><literallayout><computeroutput>cat&#32;/sys/kernel/debug/pinctrl/pinctrl@ff800014/gpio-ranges&#32;#&#32;AO&#32;库&#32;cat&#32;/sys/kernel/debug/pinctrl/pinctrl@ff634480/gpio-ranges&#32;#&#32;标准库&#32;
</computeroutput></literallayout></para>

<para>因此事情安排如下：</para>

<para>银行 | 银行偏移 | 引脚数 | GPIO 范围 ------&#8212;|----------&#8212;|-------------&#8212;|---------&#8212; AO | 496 | 16 | 496 - 511 标准 | 410 | 86 | 410 - 495</para>

<para>这就是我们在本节开头的表格中得出内核 GPIO列的方法：例如，紫色线是芯片上的 GPIOH_4，它是标准控制器的引脚 21，其基数为 410。因此，410 + 21 = 431 是 GPIOH_4 的最终 GPIO 编号。</para>

<para>欲了解更多信息，请查看以下原理图：<link linkend="_HardwareFiles">硬件：原理图、机壳 STL 文件等 \tableofcontents</link> </para>
    <section xml:id="_UserProFan"><title>JeVois-Pro 调整风扇速度</title>    </section>
<para> 上的风扇采用具有两种状态和滞后的简单算法进行控制：</para>

<para><itemizedlist>
<listitem>
<para>只要温度低于 <emphasis>temp_max，风扇速度就会降低</emphasis> </para>
</listitem><listitem>
<para>当温度超过 <emphasis>temp_max</emphasis> 时，风扇速度会切换至高速</para>
</listitem><listitem>
<para>风扇速度将保持高速，直到温度降至 <emphasis>temp_min</emphasis> 以下，此时风扇速度会切换回低速。</para>
</listitem></itemizedlist>
</para>

<para>在我们的测试中，这远没有斜坡调制那么烦人，斜坡调制会随着温度的升高而增加风扇速度，从而让人分心。</para>

<para>调整风扇参数=============================</para>

<para> 上的风扇由一个小程序控制，该程序可控制 CPU、Coral TPU（如果已安装）和 Hailo-8 SPU（如果已安装）的温度，并使用上述算法调整风扇速度。要更改设置，请转到 GUI 中的“配置”选项卡，然后在文件列表底部选择“浏览/创建文件...”</para>

<para>  </para>

<para>导航到并打开：<emphasis role="bold">/lib/systemd/system/jevoispro-fan.service</emphasis></para>

<para>然后，您可以按照顶部注释块中所述将选项添加到 <computeroutput>ExecStart</computeroutput> 行。</para>

<para>  </para>

<para>例如：</para>

<para>ExecStart=/sbin/jevoispro-fan -d 4.8 </para>

<para>当相机的 CPU 负载不高时，可以使风扇更安静，从而使 CPU 温度较低。如果为 <computeroutput>-d</computeroutput> 选择的值太低，风扇可能根本不会旋转，这是不推荐的。</para>

<para>编辑文件后，保存它，然后在 GUI 的控制台选项卡中输入：</para>

<para><literallayout><computeroutput>!systemctl restart jevoispro-fan </computeroutput></literallayout></para>

<para>（或重新启动相机）。启动时风扇全速运转几秒钟，然后算法接管。 </para>
    <section xml:id="_UserProUSBserial"><title>JeVois-Pro 串行 USB 通信</title>    </section>
<para>从 开始，您可以启用将日志和模块输出消息发送到 的 mini-USB 端口的功能。只需在 GUI 的“系统”选项卡中选中该选项即可，如下所示：</para>

<para>  </para>

<para>并重新启动相机。</para>

<para>然后使用常规 USB 转 mini-USB 电缆将 JeVois Pro 的 mini-USB 端口连接到主机上的标准 USB 端口。当 启动时，您的主机将检测到 USB 串行设备。然后您可以连接到它以与 通信。例如，在 Linux 主机上，当 连接时，主机上会出现一个新设备 <emphasis role="bold">/dev/ttyACM0。然后您可以使用</emphasis> <computeroutput>screen</computeroutput> 程序进行连接：</para>

<para><literallayout><computeroutput>sudo screen /dev/ttyACM0 115200 </computeroutput></literallayout></para>

<para>然后按照 <link linkend="_UserCli">命令行界面用户指南</link> 中所述向 发出命令</para>

<para> 增强了 JeVois 软件中的串行驱动程序，使其能够应对电缆断开/重新连接。但是，仍然存在一些注意事项，因为似乎没有正确的方法可以从 Linux 用户空间真正知道电缆是否已连接。但是，如果 正在发送消息并且电缆未连接，则与串行端口关联的小缓冲区最终会溢出。在这种情况下， 将关闭串行设备并尝试重新打开它。这通常会在电缆重新连接后成功。请注意，如果您的模块没有写入大量消息，您将不会在相机上知道电缆已断开连接，直到您尝试输出足够的消息以导致该缓冲区溢出。 </para>
    <section xml:id="_UserCli"><title>命令行界面用户指南</title>    </section>
<para><formalpara><title></title></formalpara>
</para>
<section xml:id="_UserCli_1cmdline">
<title>命令行界面概述</title>

<para>除了通过视频捕捉软件与 JeVois 相机交互之外，您还可以使用两个可用串行端口中的任意一个：</para>

<para><itemizedlist>
<listitem>
<para>通过智能相机上的 4 针连接器的硬件串行端口（见上文）。</para>
</listitem><listitem>
<para>当摄像机出现在串行总线上时，USB 串行端口也会同时出现在主机上。</para>
</listitem><listitem>
<para>在 上，图形用户界面的控制台。</para>
</listitem></itemizedlist>
</para>

<para>您或其他机器（例如 Arduino）可以连接到 JeVois 并向智能相机发出简单命令。这些命令允许调整相机参数、视觉处理参数以及 JeVois 智能相机的一般操作。</para>

<para>您可以使用 JeVois 命令行界面执行的操作包括：<itemizedlist>
<listitem>
<para>调整相机传感器的对比度、曝光度、增益、白平衡等。</para>
</listitem><listitem>
<para>显示有关 JeVois 的基本信息，例如可用 RAM 内存、CPU 频率、CPU 温度。</para>
</listitem><listitem>
<para>根据当前加载和运行的视觉模块调整机器视觉参数。许多机器视觉模块会公开阈值、操作模式等参数，您可以使用 JeVois 命令行界面进行调整。</para>
</listitem><listitem>
<para>运行包含任意数量有效命令的脚本。</para>
</listitem><listitem>
<para>决定将输出和日志串行消息发送到何处（发送到硬件串行端口、发送到 serial-ver-USB、发送到两者或不发送到任何位置）。</para>
</listitem><listitem>
<para>检查可用的视频模式和机器视觉算法，然后选择特定的一种。</para>
</listitem><listitem>
<para>可能执行特定机器视觉模块可能提供的自定义命令。</para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>请注意，默认情况下，命令回显处于关闭状态，这意味着，当您通过串行链路连接到 JeVois 时，您将看不到您输入的内容。这是为了避免将所有可能要发送到 JeVois 相机的命令发回 Arduino。大多数串行通信软件都有一个 &quot;turn on local echo&quot; 选项，这将允许您查看您输入的内容，但将由您的串行终端程序处理，而不是让 JeVois 发回您输入的所有字符。</para>

<para>由于命令行界面主要用于机器对机器通信，因此目前不提供编辑功能。这意味着如果您输入了错误的字符并尝试删除它，则错误字符和删除字符都将发送到 JeVois，您的命令将失败。如果您在输入时容易出现许多拼写错误，只需在您选择的任何编辑器中输入命令，然后将其复制并粘贴到 JeVois 命令行界面中即可。</para>
</note>
按照以下说明使用串行 USB 连接到 JeVois：</para>

<para><itemizedlist>
<listitem>
<para><link linkend="_USBserialLinux">使用串行 USB 连接到 JeVois：Linux 主机</link></para>
</listitem><listitem>
<para><link linkend="_USBserialWindows">使用 USB 串行连接到 JeVois：Windows 主机</link></para>
</listitem><listitem>
<para><link linkend="_USBserialMac">使用 USB 串行连接到 JeVois：Mac 主机</link></para>
</listitem><listitem>
<para><link linkend="_UserProUSBserial">JeVois-Pro 串行 USB 通信</link></para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>在 <emphasis role="bold">host</emphasis> 模式下运行 JeVois 软件时，您只需在启动 jevois-daemon 的终端窗口中直接输入命令即可与 JeVois 进行交互。有关更多详细信息，请参阅 <link linkend="_JeVoisDaemon">jevois-daemon 可执行文件</link> 。</para>
</note>
<formalpara><title></title></formalpara>
</para>
</section>
<section xml:id="_UserCli_1cmdlinestart">
<title>命令行界面入门</title>

<para>连接后，您可以使用命令行界面。支持的命令、常规操作参数和相机传感器控制如下（以下部分将进一步详细说明）：</para>

<para><literallayout><computeroutput>help - print help message
info - show system information including CPU speed, load and temperature
setpar &lt;name&gt; &lt;value&gt; - set a parameter value
getpar &lt;name&gt; - get a parameter value(s)
runscript &lt;filename&gt; - run script commands in specified file
setcam &lt;ctrl&gt; &lt;val&gt; - set camera control &lt;ctrl&gt; to value &lt;val&gt;
getcam &lt;ctrl&gt; - get value of camera control &lt;ctrl&gt;
listmappings - list all available video mappings
setmapping &lt;num&gt; - select video mapping &lt;num&gt;, only possible while not streaming
setmapping2 &lt;CAMmode&gt; &lt;CAMwidth&gt; &lt;CAMheight&gt; &lt;CAMfps&gt; &lt;Vendor&gt; &lt;Module&gt; - set no-USB-out video mapping defined on the fly, while not streaming
ping - returns &apos;ALIVE&apos;
serlog &lt;string&gt; - forward string to the serial port(s) specified by the serlog parameter
serout &lt;string&gt; - forward string to the serial port(s) specified by the serout parameter
usbsd - export the JEVOIS partition of the microSD card as a virtual USB drive
sync - commit any pending data write to microSD
restart - restart the JeVois smart camera

常规选项：
  --tracelevel (无符号整数) 默认值为 [0] 
    设置要显示的最低跟踪级别 
       导出者：引擎

--nickname (string) 默认=[jevois] 
  与此相机关联的昵称，当多个 JeVois 相机连接到同一个 USB 总线时很有用 
     导出者：engine

--help (bool) default=[false] 
  打印此帮助消息 
     导出者：引擎值=[true]

--loglevel (jevois::manager::LogLevel) default=[info] List:[fatal|error|info] 
  设置要显示的最低日志级别 
     导出者：engine


Engine Options: 
  --videoerrors (bool) 默认=[true] 
    显示视频流中的任何机器视觉模块错误（异常）。仅在将视频流式传输到 USB 时生效。
       导出者：引擎

--cpumode (jevois::engine::CPUmode) default=[Performance] List:[PowerSave|Conservative|OnDemand|Interactive|Performance] 
  CPU 频率调节模式 
     由 engine 导出

--videomapping (int) default=[-1] 
  要使用的视频映射索引，或 -1 使用默认映射 
     导出者：engine

--cpumax (无符号整数) 默认值 = [1344] 列表：[120|240|312|408|480|504|600|648|720|816|912|1008|1044|1056|1080|1104|1116|1152|1200|1224|1248|1296|1344] 
  CPU 最大频率（MHz） 
     导出者：engine

--serialdev (字符串) 默认值 = [stdio] 
  硬件（4 针连接器）串行设备名称，或 &apos;stdio&apos; 以使用控制台，或为空以表示没有硬件串行端口 
     导出者：引擎

--serlog (jevois::engine::SerPort) default=[None] List:[None|All|Hard|USB] 
  显示选定串行端口上的日志和调试消息 
     导出者：engine

--serout (jevois::engine::SerPort) default=[None] List:[None|All|Hard|USB] 将模块串行消息发送到选定的串行端口 导出者：engine

--camturbo (bool) default=[false] 通过放宽对 DMA 相干视频缓冲内存的需求来启用相机 turbo 模式。这可以将对捕获的图像数据的访问速度提高几倍，但也可能会在某些模块（如 PassThrough）中产生条纹​​伪影。条纹是缓存中的不正确数据。您应该尝试每个特定模块。不建议将 Turbo 模式用于任何生产级应用程序。导出者：引擎值=[true]

--usbserialdev (字符串) 默认值=[] USB 串行设备名称，或为空 导出者：引擎

--camreg (bool) default=[false] 通过 setcamreg 和 getcamreg 启用对相机寄存器的原始访问 导出者：engine

--python (bool) 默认值为 [true] 为 true 时，启用对用 Python 编写的模块的支持。否则，尝试加载 Python 模块将引发异常。禁用 Python 可节省大量内存，在使用运行大型深度神经网络的 C++ 模块时可能很有用。导出者：引擎

--cameradev (字符串) 默认=[/dev/video0] 相机设备名称（如果以 /dev/v... 开头），或电影文件名（例如 movie.mpg）或图像序列（例如 im%02d.jpg，用于读取帧 im00.jpg、im01.jpg 等）。导出者：引擎

--cameranbuf (无符号整数) 默认值=[0] 视频输入（摄像头）缓冲区的数量，或 0 表示自动。导出者：引擎

--gadgetdev (字符串) 默认=[] 小工具设备名称。这仅在平台硬件上使用。在主机硬件上，除非 gadgetdev 为 None（用于基准测试）或不是以 /dev/ 开头的电影文件的文件词干（并且应该包含单个 int 参数的 printf 样式指令，即电影编号），否则将使用显示窗口。导出者：引擎

--serlimit (无符号长整型) 默认值=[0] 模块使用 sendSerial() 可以发送的最大串行消息数，对于每个视频帧，或 0 表示无限制。模块发送的任何超过第一个 serlimit 的消息都将被丢弃。这有利于避免串行链路过载，例如，在运行 ArUco 检测器并且 JeVois 的视野中存在大量 ArUco 标签的情况下。导出者：引擎

--gadgetnbuf (无符号整数) 默认值=[0] 视频输出 (USB 视频) 缓冲区的数量，或 0 表示自动 导出者：引擎

--multicam (bool) default=[false] 允许一个 USB 总线上最多 3 个 JeVois 摄像头。启用此选项可减少每个 JeVois 摄像头使用的 USB 带宽量，从每个 USB 同步微帧 3kb 减少到 1kb。所有 3 个 JeVois 摄像头都必须启用此选项，并且 JeVois Linux 内核模块也应该已加载多摄像头。导出者：引擎

--quietcmd (bool) 默认值=[false] 设置为 true 时，在命令行界面收到每个正确命令后不发出“OK”消息。仅推荐高级用户使用。导出者：engine

可用的相机控制：

- 亮度 [int] 最小值=-3 最大值=3 步长=1 默认值=0 curr=0
- 对比度 [int] 最小值=0 最大值=6 步长=1 默认值=3 curr=3
- 饱和度 [int] 最小值=0 最大值=4 步长=1 默认值=2 curr=2
- autowb [bool] 默认值=1 curr=0
- dowb [int] 最小值=0 最大值=1 步长=1 默认值=0 curr=1
- redbal [int] 最小值=0 最大值=255 步长=1 默认值=128 curr=125
- bluebal [int] 最小值=0 最大值=255 步长=1 默认值=128 curr=151
- autogain [bool] 默认值=1 curr=1
- gain [int] 最小值=16 最大值=1023 步长=1 默认值=16 curr=58
- hflip [bool] 默认值=0 curr=0
- vflip [bool] 默认值=0 curr=0
- powerfreq [菜单] 值 0：禁用 1：50hz 2：60hz curr=2
- 锐度 [int] 最小值=0 最大值=32 步长=1 def=6 curr=6
- autoexp [菜单] 值 0：自动 1：手动 curr=0
- absexp [int] 最小值=1 最大值=1000 步长=1 def=1000 curr=500
- presetwb [菜单] 值 0：手动 1：自动 2：白炽灯 3：荧光灯 4：荧光灯_h 5：地平线 6：日光 7：闪光 8：多云 9：阴影 curr=1</computeroutput></literallayout></para>

<para>根据当前加载的机器视觉模块，可能会有其他参数和其他命令可用。例如，<emphasis role="bold">SaveVideo</emphasis> 模块允许两个新命令，“start”（开始将视频录制到磁盘）和“stop”（停止将视频录制到磁盘）。它还带来了一些特定于视频编码的新选项。加载此模块时（通过在相机查看器软件中选择相应的视频分辨率），输入“help”将显示以下新部分：</para>

<para><literallayout><computeroutput>PARAMETERS:

Video Saving Options:  
  --fourcc（字符串）默认值=[MJPG] Regex:[^\w{4}$] 
    要使用的编解码器的 FourCC。OpenCV VideoWriter 文档未明确说明支持哪些编解码器。据推测，ffmpeg 库在 OpenCV 内部使用。因此，ffmpeg 支持的任何视频编码器都应该可以使用。经过测试的编解码器包括：MJPG、MP4V、AVC1。请确保您还选择了正确的文件扩展名（例如，MJPG 为 .avi，MP4V 为 .mp4，等等）
        导出者：SaveVideo

  --fps (双精度) 默认值=[30] 
    文件中存储的视频帧/秒，用于播放期间
       导出者：SaveVideo

--filename (string) default=[video%06d.avi] 
  要写入的视频文件的名称。如果路径不是绝对路径，则将在其前面添加 /jevois/data/savevideo/。名称应包含一个 int 参数的类似 printf 的指令，该指令将从 0 开始，并在每个 streamoff 命令上递增。
     导出者：SaveVideo 
</computeroutput></literallayout></para>

<para>和 <literallayout><computeroutput>MODULE-SPECIFIC COMMANDS:

start - start saving video
stop - stop saving video and increment video file number
</computeroutput></literallayout></para>

<para>您还可以使用 <computeroutput>help2</computeroutput> 仅显示当前加载模块的参数和命令。</para>

<para><formalpara><title></title></formalpara>
</para>
</section>
<section xml:id="_UserCli_1cmdline2">
<title>命令行界面使用</title>

<para>命令区分大小写，必须完全按照此处所示输入。由于命令行界面主要供机器（例如 Arduino）使用，并且为了优化速度，如上所述，对于拼写错误和其他与所需命令格式的偏差，我们只能容忍极小的宽容。</para>
<section xml:id="_UserCli_1cmdsertype">
<title>串行通信类型</title>

<para>JeVois 区分两种类型的串行通信：</para>

<para>1) <emphasis role="bold">serlog：</emphasis>用于日志消息（错误消息、用户通知等）。日志消息按严重性等级分类，并且始终以“DBG”（调试级别）、“INF”（信息级别）、“ERR”（错误级别）或“FTL”（致命错误级别）开头。</para>

<para>2）<emphasis role="bold">serout：</emphasis>用于机器使用的基于文本的输出（例如，JeVois 检测到的物体的坐标，发送到 Arduino）。</para>

<para>实际端口（例如硬件 4 针连接器与 USB 串行端口）到 <computeroutput>serlog</computeroutput> 和 <computeroutput>serout</computeroutput> 的分配由参数控制，详情如下。分配非常灵活，例如，您可以决定将 <computeroutput>serlog</computeroutput> 消息发送到 4 针硬件串行端口和 USB 串行端口，或者不发送到任何端口，或者只发送到一个端口等，而将 <computeroutput>serout</computeroutput> 消息仅发送到硬件 4 针串行端口，或者发送到所有端口，不发送到任何端口等。</para>

<para>请注意，可以设置参数 <computeroutput>serlimit</computeroutput> 来限制每个视频帧上发送的串行消息数量，以避免串行链路过载。例如，如果模块为每个检测到的项目发送一条消息，但存在许多项目，则可以使用 <computeroutput>serlimit</computeroutput> 来限制将通过串行端口报告的项目数量。</para>
</section>
<section xml:id="_UserCli_1cmdbehavior">
<title>命令行一般行为</title>

<para>当 JeVois 引擎在给定的串行端口上收到命令时，就会执行该命令并将任何输出发送回同一串行端口。</para>

<para>所有成功的命令都以最后一行结束，内容是 <literallayout><computeroutput>OK
</computeroutput></literallayout></para>

<para>失败的命令会发出一些错误消息，该消息始终以“ERR”开头，例如： <literallayout><computeroutput>ERR Unsupported command
</computeroutput></literallayout></para>

<para>许多命令不会产生任何额外的输出，因此只返回一行“OK”或以“ERR”开头的行。</para>
</section>
<section xml:id="_UserCli_1cmdeol">
<title>命令行行尾标记</title>

<para>JeVois 的默认行尾行为是 <emphasis>sloppy，其包括：</emphasis> </para>

<para><itemizedlist>
<listitem>
<para>在输入（发送到 JeVois 的字符串）时，CR（0x0d 或 [\r]）、LF（0x0a 或 [\n]）、CRLF、0xd0（由某些键盘发出而不是 Return）或 0x00 [\0] 中的任何一个都被接受为有效的行尾标记。 接收到的行尾标记之前且不包括行尾标记的字符将被视为一个将被解析和执行的命令。</para>
</listitem><listitem>
<para>对于输出（JeVois 发送的字符串），JeVois 相机发出 CRLF 行尾字符。</para>
</listitem></itemizedlist>
</para>

<para>这是在 JeVois 智能相机启动时可配置的。有关详细信息，请参阅 <link linkend="_classjevois_1_1Serial">jevois::Serial</link> 的 jevois::serial::linestyle 参数。但请注意，此参数在 JeVois 启动后变为隐藏。因此，您只能通过 JeVois 智能相机启动时执行的 initscript.cfg 脚本更改串行行尾行为。有关详细信息，请参阅 JeVoisDaemon。</para>
</section>
<section xml:id="_UserCli_1cmdgeneral">
<title>命令行通用命令和参数</title>

<para>这里描述了无论加载哪个视觉模块始终可用的通用命令。</para>
<section xml:id="_UserCli_1cmdhelp">
<title>帮助 - 打印帮助信息</title>

<para>打印帮助信息。帮助信息仅发送到发出帮助命令的串行端口。</para>
</section>
<section xml:id="_UserCli_1cmdinfo">
<title>info - 显示系统信息，包括 CPU 速度、负载和温度</title>

<para>显示有关 JeVois 智能相机的一些重要信息：<literallayout><computeroutput>INFO: JeVois 1.1
INFO: Linux version 3.4.39
INFO: CPU: 1344MHz, 32C, load: 1.02 1.01 0.86 1/50 83
INFO: MemTotal: 238452 kB, MemFree: 194292 kB
INFO: OUT: YUYV 640x300 @ 60fps CAM: YUYV 320x240 @ 60fps MOD: JeVois:DemoSaliency
OK
</computeroutput></literallayout></para>
</section>
<section xml:id="_UserCli_1cmdsetpar">
<title>setpar &lt;name&gt; &lt;val&gt; - 设置参数值</title>

<para>例如，命令<literallayout><computeroutput>setpar cpumax 1200
</computeroutput></literallayout> returns <literallayout><computeroutput>OK
</computeroutput></literallayout> and a subsequent command <literallayout><computeroutput>info
</computeroutput></literallayout> would show the updated CPU frequency of 1200 MHz: <literallayout><computeroutput>INFO: JeVois 1.1
INFO: Linux version 3.4.39
INFO: CPU: 1200MHz, 31C, load: 1.00 1.01 0.89 1/50 83
INFO: MemTotal: 238452 kB, MemFree: 194292 kB
INFO: OUT: YUYV 640x300 @ 60fps CAM: YUYV 320x240 @ 60fps MOD: JeVois:DemoSaliency
OK
</computeroutput></literallayout></para>
</section>
<section xml:id="_UserCli_1cmdgetpar">
<title>getpar &lt;name&gt; - 获取参数值</title>

<para>此命令的答案由参数名称和当前参数值组成。例如，命令</para>

<para><literallayout><computeroutput>getpar cpumax
</computeroutput></literallayout> returns (assuming the parameter has just been set to 1200 as above) <literallayout><computeroutput>cpumax 1200
OK
</computeroutput></literallayout></para>
</section>
<section xml:id="_UserCli_1cmdrunscript">
<title>runscript &lt;filename&gt; - 在指定文件中运行脚本命令</title>

<para>运行脚本，该脚本只是一个文件，其中包含的命令格式与通过命令行界面交互输入的命令格式完全相同。如果文件名不是绝对的（不以 / 符号开头），则假定文件名相对于当前加载的视觉模块的位置。</para>
</section>
<section xml:id="_UserCli_1cmdsetcam">
<title>setcam &lt;ctrl&gt; &lt;val&gt; - 将相机控制 &lt;ctrl&gt; 设置为值 &lt;val&gt;</title>

<para>设置相机控制。帮助消息提供了可用相机控制及其允许值的列表。请注意，某些控制在某些模式下无效，例如，在尝试将值设置为 <computeroutput>absexp（手动曝光值）之前，您应该关闭</computeroutput> <computeroutput>autoexp（自动曝光控制）。</computeroutput> </para>

<para>例如<literallayout><computeroutput>setcam autogain 0
setcam gain 232
</computeroutput></literallayout></para>
</section>
<section xml:id="_UserCli_1cmdgetcam">
<title>getcam &lt;ctrl&gt; - 获取相机控制 &lt;ctrl&gt; 的值</title>

<para>例如，在上述 <computeroutput>setcam</computeroutput> 命令之后，发出</para>

<para><literallayout><computeroutput>getcam gain
</computeroutput></literallayout></para>

<para>would return <literallayout><computeroutput>gain 232
OK
</computeroutput></literallayout></para>

<para>请注意，有时相机传感器硬件会修改通过 <computeroutput>setcam</computeroutput> 给出的值，例如对其进行四舍五入、剪切等，而 <computeroutput>getcam</computeroutput> 允许您取回实际设置到传感器芯片中的值。</para>
</section>
<section xml:id="_UserCli_1cmdlistmappings">
<title>listmappings - 列出所有可用的视频映射</title>

<para>列出所有视频映射，定义相机图像大小、帧速率和像素格式、USB 输出图像大小、帧速率和像素格式以及要运行的机器视觉模块之间的关联。映射的定义位于 videomappings.cfg 文件中。<computeroutput>listmappings</computeroutput> 命令允许您获取列表中给定映射的数字索引，稍后您可以使用 <computeroutput>setmapping</computeroutput> 命令使用它。例如：</para>

<para><literallayout><computeroutput>listmappings
</computeroutput></literallayout></para>

<para>可能会返回类似的列表（取决于 videomappings.cfg 的内容）</para>

<para><literallayout><computeroutput>AVAILABLE VIDEO MAPPINGS:

    0 - OUTPUT: NONE 0x0 @ 0fps CAMERA: YUYV 320x240 @ 60fps) MODULE: SaveVideo
    1 - OUTPUT: NONE 0x0 @ 0fps CAMERA: YUYV 320x240 @ 30fps) MODULE: RoadNavigation
    2 - OUTPUT: NONE 0x0 @ 0fps CAMERA: YUYV 320x240 @ 30fps) MODULE: SaveVideo
    3 - OUTPUT: NONE 0x0 @ 0fps CAMERA: YUYV 176x144 @ 120fps) MODULE: SaveVideo
    4 - OUTPUT: RGGB 640x480 @ 30fps CAMERA: RGGB 640x480 @ 30fps) MODULE: PassThrough
    5 - OUTPUT: RGGB 352x288 @ 60fps CAMERA: RGGB 352x288 @ 60fps) MODULE: PassThrough
    6 - OUTPUT: RGGB 176x144 @ 120fps CAMERA: RGGB 176x144 @ 120fps) MODULE: PassThrough
    7 - OUTPUT: MJPG 352x288 @ 60fps CAMERA: RGGB 352x288 @ 60fps) MODULE: Convert
    8 - OUTPUT: MJPG 320x240 @ 60fps CAMERA: RGBP 320x240 @ 60fps) MODULE: Convert
    9 - OUTPUT: MJPG 176x144 @ 120fps CAMERA: RGGB 176x144 @ 120fps) MODULE: Convert
   10 - OUTPUT: RGBP 320x240 @ 22fps CAMERA: YUYV 320x240 @ 22fps) MODULE: DemoGPU
   11 - OUTPUT: YUYV 960x240 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: DemoNeon
   12 - OUTPUT: YUYV 640x312 @ 50fps CAMERA: YUYV 320x240 @ 50fps) MODULE: DemoSalGistFaceObj
   13 - OUTPUT: YUYV 640x300 @ 60fps CAMERA: YUYV 320x240 @ 60fps) MODULE: DemoSaliency
   14 - OUTPUT: YUYV 640x300 @ 10fps CAMERA: YUYV 320x240 @ 10fps) MODULE: BurnTest
   15 - OUTPUT: YUYV 352x288 @ 60fps CAMERA: YUYV 352x288 @ 60fps) MODULE: SaveVideo
   16 - OUTPUT: YUYV 320x288 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: SaliencySURF
   17 - OUTPUT: YUYV 320x286 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: DemoQRcode
   18 - OUTPUT: YUYV 320x260 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: DemoArUco
   19 - OUTPUT: YUYV 320x256 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: RoadNavigation
   20 - OUTPUT: YUYV 320x254 @ 60fps CAMERA: YUYV 320x240 @ 60fps) MODULE: ObjectTracker
   21 - OUTPUT: YUYV 320x252 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: ObjectDetect
   22 - OUTPUT: YUYV 320x240 @ 60fps CAMERA: YUYV 320x240 @ 60fps) MODULE: SaveVideo
   23 - OUTPUT: YUYV 320x240 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: SaveVideo
   24 - OUTPUT: YUYV 320x120 @ 30fps CAMERA: YUYV 160x120 @ 30fps) MODULE: DemoBackgroundSubtract
   25 - OUTPUT: YUYV 176x160 @ 120fps CAMERA: YUYV 176x144 @ 120fps) MODULE: RoadNavigation
   26 - OUTPUT: YUYV 176x144 @ 120fps CAMERA: YUYV 176x144 @ 120fps) MODULE: SaveVideo
   27 - OUTPUT: YUYV 160x120 @ 60fps CAMERA: YUYV 160x120 @ 60fps) MODULE: SaveVideo
   28 - OUTPUT: YUYV 88x72 @ 120fps CAMERA: YUYV 88x72 @ 120fps) MODULE: SaveVideo
   29 - OUTPUT: YUYV 64x192 @ 25fps CAMERA: YUYV 320x240 @ 25fps) MODULE: SalientRegions
   30 - OUTPUT: GREY 320x960 @ 45fps CAMERA: YUYV 320x240 @ 45fps) MODULE: EdgeDetectionX4
   31 - OUTPUT: GREY 320x240 @ 59fps CAMERA: YUYV 320x240 @ 59fps) MODULE: EdgeDetection
   32 - OUTPUT: GREY 320x240 @ 30fps CAMERA: YUYV 320x240 @ 30fps) MODULE: SuperPixelSeg
   33 - OUTPUT: GREY 176x288 @ 100fps CAMERA: YUYV 176x144 @ 100fps) MODULE: OpticalFlow
   34 - OUTPUT: GREY 176x144 @ 120fps CAMERA: YUYV 176x144 @ 120fps) MODULE: DemoEyeTracker
   35 - OUTPUT: GREY 176x144 @ 119fps CAMERA: YUYV 176x144 @ 119fps) MODULE: EdgeDetection
   36 - OUTPUT: GREY 160x495 @ 60fps CAMERA: YUYV 160x120 @ 60fps) MODULE: DemoCPUGPU
   37 - OUTPUT: GREY 128x117 @ 5fps CAMERA: YUYV 160x120 @ 5fps) MODULE: DenseSift
   38 - OUTPUT: GREY 120x25 @ 60fps CAMERA: YUYV 320x240 @ 60fps) MODULE: SaliencyGist
OK
</computeroutput></literallayout></para>

<para>有关视频映射的更多信息，请参阅 UserModes。</para>
</section>
<section xml:id="_UserCli_1cmdsetmapping">
<title>setmapping &lt;num&gt; - 选择视频映射 &lt;num&gt;，仅在非流媒体时可用</title>

<para><note><title>Note</title>

<para><emphasis role="bold">请注意，此命令仅在某些特殊情况下有用，并且可能会造成混淆。在大多数情况下，选择在</emphasis> JeVois 上运行哪个机器视觉模块可以通过以下方式完成：1) 通过在连接到 JeVois 的主机上运行的视频捕获软件上选择视频分辨率（这是带有流式视频输出的操作），或 2) 使用下面详述的 <computeroutput>setmapping2</computeroutput> 命令（对于嵌入式机器人，没有流式视频输出的操作）。</para>
</note>
通常，视频映射由主机通过选择给定的视频分辨率、帧速率和像素格式来选择。但是，在某些情况下，<computeroutput>setmapping</computeroutput> 很有用：</para>

<para><orderedlist>
<listitem>
<para>如果当前映射的 USB 输出像素格式为“NONE”，即当前没有通过 USB 传输视频。</para>
</listitem><listitem>
<para>如果主机当前没有从 JeVois 相机流式传输，并且主机（或 Arduino）想要选择特定的映射（通常，选择无 USB 输出的映射很有用，因为无论如何在主机上启动摄像机软件时都会选择通过 USB 流式传输视频的映射）。</para>
</listitem></orderedlist>
</para>

<para>例子：</para>

<para><literallayout><computeroutput>setmapping 0
</computeroutput></literallayout></para>

<para>will return <literallayout><computeroutput>OK
</computeroutput></literallayout></para>

<para>如果主机当前没有通过 USB 从 JeVois 流式传输视频，则映射将更改为 0。但如果视频正在流式传输到主机，答案将是： <literallayout><computeroutput>ERR Command error [setmapping 0]: Cannot set mapping while streaming: Stop your webcam program on the host computer first.
</computeroutput></literallayout></para>

<para>只需关闭主机上的相机捕捉软件并重试即可。</para>

<para><note><title>Note</title>

<para>如果您发出 <emphasis role="bold">setmapping</emphasis> 命令，然后在主机上打开视频观看软件，则该软件很可能会覆盖您刚刚使用 <emphasis role="bold">setmapping</emphasis> 执行的操作，并且无论如何都会选择其自己的映射。因此，实际上，<emphasis role="bold">setmapping</emphasis> 通常仅适用于选择无 USB 输出的模式。另请参阅 <emphasis role="bold">setmapping2，它可能在避免通过索引设置映射时可能出现的混淆方面更好，因为该索引可能会随着</emphasis> <emphasis role="bold">videomapping.cfg</emphasis> 文件的编辑而发生变化。</para>

<para>对于通过 USB 流式传输输出视频的映射，主机还确定何时开始流式传输（当您在主机上启动相机捕获软件时）以及何时停止流式传输（当您退出该程序时）。但是，对于 USB 输出为 NONE 的映射，主机上没有运行相机捕获软件，因此需要指示 JeVois 相机开始或停止流式传输（请参阅下面的 <computeroutput>streamon</computeroutput> 和 <computeroutput>streamoff</computeroutput> 命令）。</para>

<para>当选择无 USB 输出模式时，我们不会自动开始流式传输，因为用户可能希望在流式传输之前先进行其他配置。例如，用户可能选择带有 SaveVideo 模块的模式，该模块会将摄像机帧保存到磁盘，然后设置该模块的参数以选择给定的文件名和视频编码格式，然后才开始流式传输。</para>
</note>
当选择 USB 输出类型为 NONE 的模式时，将有两个附加命令可用：<emphasis role="bold">streamon</emphasis> 和 <emphasis role="bold">streamoff，详情如下。</emphasis> </para>
</section>
<section xml:id="_UserCli_1cmdsetmapping2">
<title>setmapping2 &lt;CAMmode&gt; &lt;CAMwidth&gt; &lt;CAMheight&gt; &lt;CAMfps&gt; &lt;Vendor&gt; &lt;Module&gt; - 设置非 USB 输出视频映射，在非流式传输时进行动态定义</title>

<para>这允许人们动态定义和设置没有 USB 输出的新视频映射。</para>

<para>此命令对于从 Arduino 等嵌入式系统配置 JeVois 智能相机非常有用，因为它可能不知道 <emphasis role="bold">videomappings.cfg</emphasis> 中它希望使用的特定映射的映射号。</para>

<para>详情请参阅 UserModes。这里因为没有 USB 输出，我们只需要指定相机格式、分辨率和帧速率，以及要使用哪个机器视觉模块。</para>

<para>例如：</para>

<para><literallayout><computeroutput>setmapping2 YUYV 640 480 20.0 JeVois DemoArUco
</computeroutput></literallayout> 将加载 <emphasis role="bold">DemoArUco</emphasis> 模块并使用配置为 640x480 @ 20fps YUYV 视频图像的相机运行它。</para>

<para><note><title>Note</title>

<para>无法使用类似的命令进行 USB 输出映射，因为 JeVois 智能相机必须在首次连接到主机时向主机公布可以通过 USB 传输的所有支持视频分辨率的完整列表。</para>

<para>对于没有通过 USB 进行视频流传输的映射（使用 <computeroutput>setmmapping2</computeroutput> 设置），主机上没有运行摄像头捕获软件来指示 JeVois 开始视频流传输。因此，需要指示 JeVois 摄像头开始或停止流传输（请参阅下面的 <computeroutput>streamon</computeroutput> 和 <computeroutput>streamoff</computeroutput> 命令）。这是手动完成的，以便用户可以决定何时开始和停止流传输。</para>

<para><computeroutput>setmapping2</computeroutput> 应仅与支持无 USB 输出处理的机器视觉模块一起使用。这些模块的源代码中将有一个 <emphasis role="bold">process(InputFrame &amp;&amp; inframe)</emphasis> 函数。如果您的 JeVois 智能相机在给定的 <computeroutput>setmapping2</computeroutput> 命令后似乎无法工作，请尝试 <computeroutput>setpar serlog USB</computeroutput> 并使用终端和串行 USB 连接连接到 JeVois。如果您看不到任何消息，可能是您忘记了 <computeroutput>streamon</computeroutput> 命令。如果您看到错误消息，可能是您的模块不支持无 USB 输出处理。</para>
</note>
</para>
</section>
<section xml:id="_UserCli_1cmdstreamon">
<title>streamon - 启动摄像头视频流</title>

<para>仅当当前视频映射具有 NONE 类型的 USB 输出（包括使用 <computeroutput>setmapping2</computeroutput> 选择的模式）时，此命令才会存在。</para>

<para>它将指示 JeVois 智能相机开始从相机传感器流式传输视频帧。选择没有 USB 输出的视频模式后，需要发出 <computeroutput>streamon</computeroutput> 命令。否则，智能相机将无限期地等待此命令。</para>
</section>
<section xml:id="_UserCli_1cmdstreamoff">
<title>streamoff - 停止摄像头视频流</title>

<para>此命令仅在当前视频映射具有 NONE 类型的 USB 输出时才会存在（包括使用 <computeroutput>setmapping2</computeroutput> 选择的模式）。它将指示 JeVois 智能相机停止从相机传感器流式传输视频帧。</para>

<para>当使用类型为 NONE 的 USB 输出映射时，必须手动发出 <computeroutput>streamoff</computeroutput> 命令，然后才能发出下一个 <computeroutput>setmapping</computeroutput> 或 <computeroutput>setmapping2</computeroutput> 命令。</para>
</section>
<section xml:id="_UserCli_1cmdping">
<title>ping - 返回‘ALIVE’</title>

<para>该命令的目的是检查 JeVois 智能相机是否崩溃，例如在测试当前正在开发和调试的新机器视觉模块时。</para>
</section>
<section xml:id="_UserCli_1cmdserlog">
<title>serlog &lt;string&gt; - 将字符串转发到 serlog 参数指定的串行端口</title>

<para>它与 <computeroutput>serlog</computeroutput> 参数配合使用，该参数确定哪个串行端口用于日志消息。<computeroutput>serlog</computeroutput> 命令只是将给定的字符串转发到 <computeroutput>serlog</computeroutput> 参数选择的串行端口。</para>

<para>例如，这很有用，允许连接到 JeVois 硬件串行端口的 Arduino 发送调试消息，这些消息可以被连接到 JeVois 的串行 USB 端口的人读取。</para>

<para>例如，连接到 JeVois 硬件 4 针连接器的 Arduino 可能会通过其串行端口发出：</para>

<para><literallayout><computeroutput>setpar serlog USB
serlog Arduino started
serlog Arduino compass calibrated
</computeroutput></literallayout></para>

<para>然后使用串行 USB 端口连接到 JeVois 相机的人（或其他机器）将看到：</para>

<para><literallayout><computeroutput>Arduino started
Arduino compass calibrated
</computeroutput></literallayout></para>

<para>请记住，JeVois 相机本身发出的日志消息（例如错误消息）也会发送到 <computeroutput>serlog</computeroutput> 参数选择的端口。</para>
</section>
<section xml:id="_UserCli_1cmdserout">
<title>serout &lt;string&gt; - 将字符串转发到 serout 参数指定的串行端口</title>

<para>其操作类似于 <computeroutput>serlog</computeroutput> 命令，但使用 <computeroutput>serout</computeroutput> 参数选择的串行端口。</para>

<para>例如，要以交互方式调试某些 Arduino 代码，可能需要手动输入 JeVois 机器视觉模块会发出的字符串类型，以确保 Arduino 始终正确解释它们。假设我们正在调试 JeVois 提供的平移/倾斜 Arduino 代码。可能需要尝试手动发出一些“T2 targetx targety”消息，以检查平移/倾斜摄像头是否以正确的方式移动。将 Arduino 连接到 JeVois 的 4 针硬件串行端口，并通过串行 USB 端口与 JeVois 交互，人类可以输入：</para>

<para><literallayout><computeroutput>setpar serout Hard
serout T2 0 0
serout T2 1000 1000
serout T2 -1000 -1000
serout T2 &amp;^%$@ try to crash arduino by using buggy T2 command
</computeroutput></literallayout></para>

<para>然后，“T2 x y”字符串将被转发到 Arduino，Arduino 应相应地移动平移/倾斜电机。对于最后一个（格式错误的）T2 命令，Arduino 应正确拒绝它并且不移动电机。</para>

<para>请记住，JeVois 相机本身发出的模块数据输出消息（例如，检测到的目标物体的坐标）也会发送到 <computeroutput>serout</computeroutput> 参数选择的端口。</para>
</section>
<section xml:id="_UserCli_1cmdusbsd">
<title>usbsd - 将 microSD 卡的 JEVOIS 分区导出为虚拟 USB 驱动器</title>

<para></para>

<para>此命令允许通过 USB 访问 JeVois 内部 microSD 卡的 JEVOIS 分区，就像它是连接到主机的 USB 拇指驱动器一样。此命令仅在不流式传输视频时有效。</para>

<para>在 JeVois 内部使用 microSD 进行写入时，会出现数据缓存和同步问题，目前已按如下方式解决：</para>

<para><itemizedlist>
<listitem>
<para>在命令行界面上发出 <computeroutput>usbsd</computeroutput> 命令时，microSD 的 JEVOIS 分区首先对 JeVois 处理器变为只读。这意味着 JeVois 将无法再保存数据（例如，某些模块保存的视频文件），并且无法执行需要写入 microSD 的其他操作，例如在加载 Python 模块时自动编译它们。然后，JEVOIS 分区将作为虚拟 USB 闪存驱动器导出到主机，具有读写访问权限。</para>
</listitem><listitem>
<para>用户随后可以自由浏览 microSD 的内容、添加文件、删除文件和修改文件。不过 JeVois 不会立即知道这些更改。</para>
</listitem><listitem>
<para>然后用户应该正确弹出虚拟 USB 驱动器。JeVois 将检测到此情况并重新启动以便能够使用用户所做的修改。</para>
</listitem></itemizedlist>
</para>
</section>
<section xml:id="_UserCli_1cmdsync">
<title>sync - 将任何待处理的数据写入 microSD</title>

<para></para>

<para>发出此命令以确保写入 microSD 的数据已提交到卡中，例如在您重新启动或断开 JeVois 之前。</para>
</section>
<section xml:id="_UserCli_1cmddate">
<title>日期 [日期和时间] - 获取或设置系统日期和时间</title>

<para></para>

<para>JeVois 平台硬件没有用于实时时钟的电池。因此，每次重启时，其时间都会重置为纪元（1970 年 1 月 1 日 UTC）。使用此命令设置日期和时间或获取日期和时间。语法与 Unix <computeroutput>date</computeroutput> 命令相同。这很有用，例如，在录制视频时获取准确的时间戳。由于 JeVois 没有电池供电的时钟，因此下次断电时任何日期设置都将丢失。</para>

<para>例如，请参阅<link xlink:href="http://man7.org/linux/man-pages/man1/date.1.html">此处</link> 了解有关 Unix date 命令的更多信息。用于设置日期的格式为：</para>

<para><literallayout><computeroutput>MMDDhhmm[[CC]YY][.ss]]
</computeroutput></literallayout></para>

<para>其中方括号表示可选字段，<emphasis role="bold">MM</emphasis> 是月份，<emphasis role="bold">DD</emphasis> 是日期，<emphasis role="bold">hh</emphasis> 是小时，<emphasis role="bold">mm</emphasis> 是分钟，<emphasis role="bold">CC</emphasis> 是年份的前两位（世纪）数字，<emphasis role="bold">YY</emphasis> 是年份的后两位数字，<emphasis role="bold">ss</emphasis> 是秒。</para>

<para>例如，在连接到 JeVois 的串行终端中向 JeVois 发出以下“date”命令：</para>

<para><literallayout><computeroutput>date 0504153018
</computeroutput></literallayout></para>

<para>returns</para>

<para><literallayout><computeroutput>date now Fri May  4 15:30:00 UTC 2018
OK
</computeroutput></literallayout></para>

<para>在 Linux 主机上，要将 JeVois 相机上的日期和时间设置为与主机相同，您只需将 Linux date 命令的输出转发为 JeVois date 命令的输入：在 Linux 主机的终端窗口中，输入：</para>

<para><literallayout><computeroutput>jevois-cmd&#32;date&#32;`date&#32;+%m%d%H%M%Y.%S`
</computeroutput></literallayout></para>
</section>
<section xml:id="_UserCli_1cmdrestart">
<title>restart - 重新启动 JeVois 智能相机</title>

<para></para>

<para>此命令只是重新启动 JeVois 智能相机。</para>
</section>
<section xml:id="_UserCli_1cmdquit">
<title>quit – 退出该程序</title>

<para></para>

<para>在主机模式下运行时，只需在启动它的终端中输入“quit”即可退出 <computeroutput>jevois-daemon。</computeroutput> </para>
</section>
<section xml:id="_UserCli_1cmdshell">
<title>shell &lt;command&gt; - 在 JeVois 上执行 Unix 命令</title>

<para>请谨慎使用此功能，因为您可能会破坏 JeVois 的操作系统。这主要用于调试。例如，尝试：</para>

<para><literallayout><computeroutput>shell dmesg
</computeroutput></literallayout></para>

<para>查看 JeVois 的启动日志。</para>
</section>
<section xml:id="_UserCli_1moreclicmds">
<title>可能有更多命令可用</title>

<para>由于该文档可能落后于 JeVois 上运行的实际软件，请检查 JeVois 控制台中的“帮助”以查找任何尚未在此处记录的新命令。</para>
</section>
</section>
<section xml:id="_UserCli_1cmdpar">
<title>命令行上可用的常规参数</title>

<para>如上所述，不同的机器视觉模块将添加用户可通过命令行使用的参数（可能还有新命令）。这里我们描述了引擎导出的参数。无论当前加载了哪个机器视觉模块，这些参数始终可用：</para>
<section xml:id="_UserCli_1parloglevel">
<title>loglevel (jevois::manager::LogLevel) default=[info] List:[fatal|error|info|debug] - 设置要显示的最低日志级别</title>

<para>JeVois 代码使用提供的命令 <link linkend="_group__debugging_1ga136d9d772791ddd40a7781b0f6b01dd6">LDEBUG()</link>、LINFO()、LERROR() 和 <link linkend="_group__debugging_1ga07fea0c726b5acfbb6c0d5483dd15d0d">LFATAL()</link> 发出日志消息。loglevel 参数允许用户在运行时选择日志详细程度。将显示所选级别或更严重的消息。例如，当选择 <computeroutput>loglevel</computeroutput> 为 <computeroutput>info</computeroutput> 时，将显示 <link linkend="_group__debugging_1gadf127ca2262cc160830da49c37d04e85">LINFO()</link>、LERROR() 和 <link linkend="_group__debugging_1ga07fea0c726b5acfbb6c0d5483dd15d0d">LFATAL()</link> 消息。</para>

<para><note><title>Note</title>

<para>作为速度优化，可以在编译时禁用 DEBUG 级别日志消息，从而避免浪费一些 CPU 来测试日志级别的当前值，然后决定是否发出调试消息。在 JeVois 编译期间关闭 JEVOIS_LDEBUG_ENABLE 时，这些测试将在编译时被绕过，并且所有 <link linkend="_group__debugging_1ga136d9d772791ddd40a7781b0f6b01dd6">LDEBUG()</link> 命令都只是无操作（它们不执行任何操作，也不使用任何 CPU，就像它们刚刚被删除一样）。</para>

<para>因此，如果在编译 JeVois 期间 JEVOIS_LDEBUG_ENABLE 处于关闭状态，则可能的值 <computeroutput>debug</computeroutput> 将不会作为可能的 <computeroutput>loglevel</computeroutput> 值之一出现。</para>
</note>
</para>
</section>
<section xml:id="_UserCli_1partracelevel">
<title>tracelevel (unsigned int) default=[0] - 设置要显示的最低跟踪级别</title>

<para>程序员可以使用 <link linkend="_group__debugging_1ga9061a9b1a920652dd863efb219c0d9d4">JEVOIS_TRACE()</link> 宏发出调试消息，告知用户某个特定函数何时执行。JEVOIS_TRACE() 将在函数启动时发出一条消息，在函数结束时发出另一条消息。这对于检测正在开发的模块可能在哪里锁定并应进行修复非常有用。</para>

<para>JEVOIS_TRACE 接受一个参数，即一个整数，称为 <computeroutput>level。然后可以调整</computeroutput> <computeroutput>tracelevel</computeroutput> 参数以仅显示级别低于 <computeroutput>tracelevel</computeroutput> 当前值的跟踪消息。跟踪级别越高，您将看到的消息越多。程序员决定在各种函数中使用哪个跟踪级别。</para>

<para><note><title>Note</title>

<para>因为 <link linkend="_group__debugging_1ga9061a9b1a920652dd863efb219c0d9d4">JEVOIS_TRACE()</link> 使用 <link linkend="_group__debugging_1ga136d9d772791ddd40a7781b0f6b01dd6">LDEBUG()</link> 发出其跟踪消息，所以除非 JeVois 在编译时启用了 JEVOIS_LDEBUG_ENABLE（默认情况下并非如此），否则这些消息不会出现。这样做的原因是为了避免在生产模型中运行时浪费时间进行测试以确定我们是否应该发出调试消息。同样，JeVois 必须在启用 JEVOIS_TRACE_ENABLE 的情况下进行编译，跟踪消息才能正常工作。</para>
</note>
</para>
</section>
<section xml:id="_UserCli_1parserout">
<title>serout (jevois::engine::SerPort) default=[None] List:[None|All|Hard|USB] - 将模块串行消息发送到选定的串行端口</title>

<para>此参数的值表示 serout 类型的消息将被发送到哪个串行端口。</para>

<para>参见上面关于 <computeroutput>serout</computeroutput> 命令的讨论。</para>
</section>
<section xml:id="_UserCli_1parserlog">
<title>serlog (jevois::engine::SerPort) default=[None] List:[None|All|Hard|USB] - 显示选定串行端口上的日志和调试消息</title>

<para>此参数的值表示 serlog 类型的消息将被发送到哪个串行端口。</para>

<para>参见上面关于 <computeroutput>serlog</computeroutput> 命令的讨论。</para>
</section>
<section xml:id="_UserCli_1parcpumax">
<title>cpumax (无符号整数) 默认值=[1344] 列表:[120|240|312|408|480|504|600|648|720|816|912|1008|1044|1056|1080|1104|1116|1152|1200|1224|1248|1296|1344] - CPU 最大频率（MHz）</title>

<para>允许用户（或 Arduino）设置 JeVois CPU 的最大运行频率。这在某些情况下可能有助于限制 CPU 速度，例如当使用电量不足的电池为 JeVois 供电时。</para>
</section>
<section xml:id="_UserCli_1parcpumode">
<title>cpumode (jevois::engine::CPUmode) default=[Performance] List:[PowerSave|Conservative|OnDemand|Interactive|Performance] - CPU 频率调制模式</title>

<para>允许用户选择不同的方案，以便在运行过程中动态调整 JeVois CPU 频率。这在 Linux 社区中也称为频率调节器。</para>

<para>默认情况下，假设 JeVois 智能相机将始终以最大可能速度处理视频。因此，默认情况下 <computeroutput>cpumode</computeroutput> 设置为 <computeroutput>Performance。当</computeroutput> CPU 使用率不高时，其他模式会降低 CPU 速度，例如当 CPU 正在等待相机的下一张图像时。</para>

<para><note><title>Note</title>

<para>一般而言，除非您在某些极端情况下使用 JeVois 相机，否则我们建议将 <computeroutput>cpumode</computeroutput> 保持为其默认设置 <computeroutput>Performance，因为这将提供最可靠的帧速率。使用其他模式时，帧速率可能会出现较大波动。</computeroutput> </para>
</note>
</para>
</section>
<section xml:id="_UserCli_1parcamreg">
<title>camreg (bool) default=[false] - 通过 setcamreg 和 getcamreg 启用对相机寄存器的原始访问</title>

<para>此命令允许直接访问 JeVois 智能相机传感器芯片上的低级寄存器。默认情况下，此功能处于关闭状态。此功能仅适用于低级黑客，他们试图通过尝试低级相机传感器寄存器的不同设置来提高图像质量。</para>

<para><warning><title>Warning</title>

<para>当你摆弄低级寄存器时，你的 JeVois 智能相机很容易崩溃。你已收到警告。一个错误的值会导致整个智能相机崩溃。</para>
</warning>
当参数 <computeroutput>camreg</computeroutput> 设置为 true 时，两个新命令变得可用：</para>

<para><itemizedlist>
<listitem>

<para>setcamreg <computeroutput>reg</computeroutput> <computeroutput>val</computeroutput> - 将原始相机寄存器 <computeroutput>reg</computeroutput> 设置为值 <computeroutput>val</computeroutput> </para>
</listitem>
<listitem>

<para>getcamreg <computeroutput>reg</computeroutput> - 获取原始相机寄存器的值 <computeroutput>reg</computeroutput> </para>
</listitem>
</itemizedlist>
</para>

<para>在这两种情况下，<computeroutput>reg</computeroutput> 和 <computeroutput>val</computeroutput> 都是无符号的 8 位值。为方便起见，十进制值和十六进制值（使用前缀 <computeroutput>0x</computeroutput> 表示十六进制）均受支持。</para>

<para>在配备 AR0135 全局快门和 ICM-20948 IMU 的改进型 JeVois 装置上，以下命令也可用：<itemizedlist>
<listitem>
<para>setimureg <computeroutput>reg</computeroutput> <computeroutput>val</computeroutput> - 将原始 IMU 寄存器 <computeroutput>reg</computeroutput> 设置为值 <computeroutput>val</computeroutput> </para>
</listitem><listitem>
<para>getimureg <computeroutput>reg</computeroutput> - 获取原始 IMU 寄存器的值 <computeroutput>reg</computeroutput> </para>
</listitem><listitem>
<para>setimuregs <computeroutput>reg</computeroutput> <computeroutput>num</computeroutput> <computeroutput>val1</computeroutput> ... <computeroutput>valn</computeroutput> - 设置原始 IMU 寄存器值数组</para>
</listitem><listitem>
<para>getimuregs <computeroutput>reg</computeroutput> <computeroutput>num</computeroutput> - 获取原始 IMU 寄存器值数组</para>
</listitem><listitem>
<para>setdmpreg <computeroutput>reg</computeroutput> <computeroutput>val</computeroutput> - 将原始 DMP 寄存器 <computeroutput>reg</computeroutput> 设置为值 <computeroutput>val</computeroutput> </para>
</listitem><listitem>
<para>getdmpreg <computeroutput>reg</computeroutput> - 获取原始 DMP 寄存器的值 <computeroutput>reg</computeroutput> </para>
</listitem><listitem>
<para>setdmpregs <computeroutput>reg</computeroutput> <computeroutput>num</computeroutput> <computeroutput>val1</computeroutput> ... <computeroutput>valn</computeroutput> - 设置原始 DMP 寄存器值数组</para>
</listitem><listitem>
<para>getdmpregs <computeroutput>reg</computeroutput> <computeroutput>num</computeroutput> - 获取原始 DMP 寄存器值数组</para>
</listitem></itemizedlist>
</para>

<para><formalpara><title></title></formalpara>
</para>
</section>
</section>
</section>
<section xml:id="_UserCli_1cmdscr">
<title>命令行脚本</title>

<para>有时，在加载模块时设置一些参数或执行一些命令很有用。</para>

<para>JeVois 允许您将参数设置和命令存储在模块目录中名为 <emphasis role="bold">script.cfg</emphasis> 的文件中。文件 <emphasis role="bold">script.cfg</emphasis> 可能包含任何命令序列，就像您在 JeVois 命令行界面中以交互方式输入它们一样。</para>

<para>以下是 ObjectTracker 模块的示例，该模块根据颜色跟踪对​​象。对于此模块，最好将 JeVois 相机传感器设置为全手动模式，因为自动增益、曝光和白平衡会影响同一物体在不同视点和光源位置下的 RGB 像素值。由于 ObjectTracker 中的跟踪基于传感器返回的颜色值，因此全手动相机模式可以提供更可靠的跟踪。</para>

<para><literallayout><computeroutput>#&#32;Demo&#32;configuration&#32;script&#32;for&#32;ObjectTracker&#32;module.

#&#32;Set&#32;camera&#32;to&#32;fixed&#32;color&#32;balance,&#32;gain,&#32;and&#32;exposure,&#32;so&#32;that&#32;we&#32;get&#32;more&#32;reliable&#32;colors&#32;than&#32;we&#32;would&#32;obtain&#32;under
#&#32;automatic&#32;mode:
setcam&#32;autowb&#32;0
setcam&#32;autogain&#32;0
setcam&#32;autoexp&#32;0
setcam&#32;redbal&#32;110
setcam&#32;bluebal&#32;170
setcam&#32;gain&#32;16
setcam&#32;absexp&#32;500

#&#32;Detect&#32;a&#32;light&#32;blue&#32;flash&#32;drive&#32;by&#32;setting&#32;the&#32;appropriate&#32;value&#32;ranges&#32;for&#32;Hue,&#32;Saturation,&#32;and&#32;Value&#32;in&#32;the
#&#32;ObjectTracker&#32;module:
setpar&#32;hrange&#32;95...110
setpar&#32;srange&#32;100...255
setpar&#32;vrange&#32;60...253
</computeroutput></literallayout></para>

<para>ObjectTracker 的 <emphasis role="bold">script.cfg</emphasis> 文件存储在您的 microSD 上的 <emphasis role="bold">JEVOIS:/modules/JeVois/ObjectTracker/script.cfg</emphasis> 源中，位于 <emphasis role="bold">~/jevoisbase/src/Modules/ObjectTracker/script.cfg</emphasis>。 </para>
</section>
    <section xml:id="_USBserialLinux"><title>使用串行 USB 连接到 JeVois：Linux 主机</title>    </section>
<para>该功能目前在 上还不可用，但很快就会可用……</para>
<section xml:id="_USBserialLinux_1serusblinuxgen">
<title>在 Linux 主机上查找串行 USB 设备</title>

<para>在 Linux 上，首先查找插入 JeVois 智能相机时创建的端口。除非您已经有其他调制解调器设备连接到主机，否则最有可能的是 <emphasis role="bold">/dev/ttyACM0。要找出答案，请在连接</emphasis> JeVois 智能相机后，在 Linux 终端中输入“dmesg”时检查显示的消息。等待至少 10 秒钟让智能相机启动并被主机检测到。“dmesg”命令的输出应包含一些有关检测 JeVois 智能相机（包括其视频组件和串行端口组件）的消息：</para>

<para><literallayout><computeroutput>[...] [4768736.704777] usb 1-1.3：使用 xhci_hcd 的新高速 USB 设备编号 13 [4768736.809464] usb 1-1.3：发现新 USB 设备，idVendor=1d6b，idProduct=0102 [4768736.809470] usb 1-1.3：新 USB 设备字符串：Mfr=1，Product=2，SerialNumber=0 [4768736.809473] usb 1-1.3：产品：JeVois-A33 智能相机 [4768736.809476] usb 1-1.3：制造商：JeVois Inc [4768736.847915] uvcvideo：发现 UVC 1.00 设备JeVois-A33 智能摄像头 (1d6b:0102) [4768736.849892] 输入：JeVois-A33 智能摄像头为 /devices/pci0000:00/0000:00:1c.6/0000:09:00.0/usb1/1-1/1-1.3/1-1.3:1.0/input/input29 [4768736.851499] cdc_acm 1-1.3:1.2: ttyACM0: USB ACM 设备 </computeroutput></literallayout></para>

<para>在上面的例子中，JeVois 智能相机被检测为 UVC（USB 视频类）设备，并在 <emphasis role="bold">/devices/pci</emphasis>... 中创建了相应的视频设备条目，该条目通常也会被别名为 <emphasis role="bold">/dev/video0</emphasis> 以方便访问。此外，JeVois 相机的串行 USB 端口被检测为 CDC-ACM 串行端口，并在此示例中分配了设备名称 <emphasis role="bold">ttyACM0。</emphasis> </para>

<para>要使用串行 USB 链接连接到您的 JeVois 智能相机，请启动终端程序。默认配置为 115200 8N1。</para>
</section>
<section xml:id="_USBserialLinux_1serusblinuxperm">
<title>权限问题</title>

<para>在 Ubuntu 上，会默认安装并运行一个名为 ModemManager 的程序。它将尝试连接到任何新的串行 USB 设备，并通过向其发送调制解调器配置命令来探测它。JeVois 将忽略这些命令，但 ModemManager 会在 JeVois 连接后继续向 JeVois 发送字符串长达一分钟。因此，最好直接删除 ModemManager：</para>

<para><literallayout><computeroutput>sudo apt purge modemmanager # 彻底删除它，以后如果需要，您可以随时重新安装它 </computeroutput></literallayout></para>

<para>在 Linux 上，默认情况下，您可能没有权限访问 JeVois 串行 USB 端口。您可以通过两种方式解决此问题：<itemizedlist>
<listitem>
<para>将您的用户添加到 <emphasis role="bold">dialout</emphasis> 组，方法是发出<literallayout><computeroutput>sudo usermod -aG dialout $USER groups $USER # 检查您现在是否在 dialout 组中 </computeroutput></literallayout> 并重新启动您的机器以使设置生效。</para>
</listitem><listitem>
<para>或者只是更改端口的访问权限（但请注意，每次插入 JeVois 相机时都必须这样做）：<literallayout><computeroutput>sudo chmod 777 /dev/ttyACM0 </computeroutput></literallayout></para>
</listitem></itemizedlist>
</para>

<para>要测试连接，最好使用 <link linkend="_JeVoisInventor">JeVois-A33：JeVois Inventor 图形用户界面</link></para>
</section>
<section xml:id="_USBserialLinux_1serusblinuxscreen">
<title>使用 screen 命令</title>

<para><literallayout><computeroutput>sudo apt-get install screen # 如果尚未安装 sudo screen /dev/ttyACM0 115200 </computeroutput></literallayout></para>

<para><note><title>Note</title>

<para>据我们所知，“screen”程序不提供命令回显选项（查看您正在输入的内容）。因此，当您输入时，您将看不到您输入的内容。这是正常的。</para>

<para>要在使用“屏幕”时向上滚动，请键入 <computeroutput>CTRL-A</computeroutput> <computeroutput>ESC，然后可以使用箭头键或鼠标滚轮向上滚动。当您准备返回交互模式时，请键入</computeroutput> <computeroutput>RETURN</computeroutput> 两次。</para>
</note>
</para>
</section>
<section xml:id="_USBserialLinux_1serusblinuxminicom">
<title>使用 minicom 软件</title>

<para>您还可以使用 <computeroutput>minicom</computeroutput> 或其他串行通信软件。Minicom 很不错，因为它允许您启用本地回显（这样您就可以看到您输入的内容）：</para>

<para><literallayout><computeroutput>sudo apt-get install minicom # 如果尚未安装 sudo minicom -D /dev/ttyACM0 </computeroutput></literallayout></para>

<para>要启用本地回显，请键入以下按键：<computeroutput>CTRL-A</computeroutput> <computeroutput>Z（用于配置菜单），然后</computeroutput> <computeroutput>E（本地回显打开/关闭）。请注意，尽管</computeroutput> minicom 让您看起来可以纠正拼写错误，但您仍然不能；例如，键入“helx”然后 <computeroutput>BACKSPACE</computeroutput> 然后“p”（将 helx 更正为 help）将传输消息“helx”后跟 <computeroutput>BACKSPACE</computeroutput> 字符，后跟“p”，而这对于 JeVois 来说仍然是一个错误命令。</para>
</section>
<section xml:id="_USBserialLinux_1serusblinuxbeware">
<title>警惕 Linux 上的 ModemManager 或类似程序</title>

<para>许多 Linux 发行版（包括 Ubuntu）都会监控调制解调器的连接，以便能够以即插即用的方式检测到它们。由于 JeVois 串行 USB 端口在主机看来就像一个新的调制解调器（这样就不需要驱动程序了），因此当您连接 JeVois 时，主机可能会尝试向 JeVois 发送调制解调器配置命令。</para>

<para>JeVois 将安全地忽略这些命令，但主机可能需要几分钟才能放弃尝试将 JeVois 初始化为可以通过电话线拨号的调制解调器。当您的主机尝试将 JeVois 配置为调制解调器时，它发送的命令将干扰您可能输入的任何命令。为了避免这种情况并允许您在主机检测到串行 USB 端口后立即使用它，请关闭 Linux 主机的调制解调器管理器功能。例如，在 Ubuntu 上：</para>

<para><literallayout><computeroutput>sudo Killall ModemManager </computeroutput></literallayout></para>

<para>使用快捷 shell 命令 jevois-cmd ==========================================</para>

<para></para>

<para>在 Linux 下，<emphasis role="bold">jevois</emphasis> 软件包在主机的 <emphasis role="bold">/usr/bin</emphasis> 中提供了命令 <computeroutput>jevois-cmd</computeroutput>（源代码位于 <emphasis role="bold">~/jevois/scripts</emphasis>），可以直接在主机的任何终端中执行（而不是在打开某个串行终端后在 JeVois 命令行界面中运行）。使用方法如下：</para>

<para><literallayout><computeroutput>jevois-cmd 帮助 </computeroutput></literallayout></para>

<para>使用串行 USB 端口连接到 JeVois，向 jevois 发出命令“help”，收集并显示 JeVois 返回的结果。</para>

<para>可以发送任何有效的 JeVois 命令行命令。例如：</para>

<para><literallayout><computeroutput>jevois-cmd 设置 cpumax 1200 </computeroutput></literallayout></para>

<para>应该返回</para>

<para><literallayout><computeroutput>确定 </computeroutput></literallayout></para>

<para>以及随后的</para>

<para><literallayout><computeroutput>jevois-cmd 信息 </computeroutput></literallayout></para>

<para>应显示更新后的 CPU 频率 1200 MHz，如下所示：</para>

<para><literallayout><computeroutput>INFO：JeVois 1.3.0 INFO：Linux 版本 3.4.39 INFO：CPU：1200MHz，28C，负载：0.98 0.53 0.22 1/59 86 INFO：MemTotal：238452 kB，MemFree：170188 kB INFO：OUT：YUYV 640x300 @ 60fps CAM：YUYV 320x240 @ 60fps MOD：JeVois：DemoSaliency OK </computeroutput></literallayout></para>

<para><note><title>Note</title>

<para>如果 JeVois 抱怨错误，但您知道您的命令是正确的，那么 Linux <emphasis role="bold">ModemManager</emphasis> 可能正在您的主机上运行，​​并试图将 JeVois 配置为调制解调器，向其发送 JeVois 不感兴趣的各种命令。见上文。 </para>
</note>
</para>
</section>
    <section xml:id="_USBserialWindows"><title>使用 USB 串行连接到 JeVois：Windows 主机</title>    </section>
<para>该功能目前在 上还不可用，但很快就会可用……</para>
<section xml:id="_USBserialWindows_1serusbwingen">
<title>在 Windows 主机上查找串行 USB 设备</title>

<para><emphasis role="bold">这应该只会影响部分 Windows 7 和 Windows 8 用户。如果您没有看到下面显示的故障 CDC 串行设备，则无需执行任何操作。</emphasis></para>

<para>在某些版本的 Windows 上，JeVois 的串行 USB 端口将被自动检测和配置。但是，在其他版本上，可能需要安装“inf”文件。</para>

<para><itemizedlist>
<listitem>
<para>首先，查看您的<emphasis role="bold">设备管理器</emphasis>，检查<emphasis role="bold">其他设备</emphasis>下是否有错误的<emphasis role="bold">CDC 串行</emphasis>设备。如果没有，JeVois 串行-over-USB 可能已被检测和配置，您可以继续下一部分。 </para>
</listitem><listitem>
<para>如果您看到错误设备，请通过右键单击下载此文件，然后通过以下链接<emphasis role="bold">将目标另存为...</emphasis>：http://jevois.org/data/jevois-serial.inf <note><title>Note</title>

<para>确保文件确实以文件扩展名 <emphasis role="bold"></emphasis>.inf 保存，否则 Windows 将无法在下一步中检测到它。在某些版本的 Windows 中，文件最终被保存为 <emphasis role="bold">jevois-serial.inf.txt，然后您应该将其重命名为</emphasis> <emphasis role="bold">jevois-serial.inf</emphasis> </para>
</note>
</para>
</listitem><listitem>
<para>在设备管理器中，右键单击有错误的 CDC 序列，并选择 <emphasis role="bold">属性。</emphasis> </para>
</listitem><listitem>
<para>单击<emphasis role="bold">更新驱动程序</emphasis>，然后单击<emphasis role="bold">浏览我的计算机以查找驱动程序软件</emphasis>。</para>
</listitem><listitem>
<para>选择您保存 <emphasis role="bold">jevois-serial.inf</emphasis> 文件的文件夹（可能是您的 <emphasis role="bold">下载文件夹，请确保其中没有任何其他</emphasis> <emphasis role="bold"></emphasis>.inf 文件）。当 Windows 抱怨此驱动程序不受信任时，选择仍然安装。</para>
</listitem><listitem>
<para>您的设备管理器应从显示 <emphasis role="bold">CDC 串行</emphasis> 设备更新为 <emphasis role="bold">JeVois-A33 Serial-over-USB</emphasis> 或 <emphasis role="bold">Gadget Serial</emphasis>，并且 Windows 应告诉您驱动程序已成功安装。在下面的示例中，JeVois serial-over-USB 端口配置为 <emphasis role="bold">COM6</emphasis> - 这是您应该与串行终端程序一起使用的端口。</para>
</listitem></itemizedlist>
</para>

<para>\图像 html windows-cdc-安装.png</para>
</section>
<section xml:id="_USBserialWindows_1serusbwinusing">
<title>连接到 JeVois</title>

<para>我们已经成功使用 <link xlink:href="https://ttssh2.osdn.jp/index.html.en">Tera Term</link> 和 <link xlink:href="https://www.compuphase.com/software_termite.htm">Termite</link> 进行连接。打开使用 115200 8N1 创建的 COM 端口。</para>

<para>Termite 与 JeVois 配合使用效果非常好，因为它允许您键入和编辑单个命令行（在屏幕底部），当您按回车键时，它会将最后编辑的行发送给 JeVois。因此，它比其他一些串行终端程序更易于输入错误。</para>

<para></para>

<para> </para>
</section>
    <section xml:id="_USBserialMac"><title>使用 USB 串行连接到 JeVois：Mac 主机</title>    </section>
<para>该功能目前在 上还不可用，但很快就会可用……</para>
<section xml:id="_USBserialMac_1serusbmacgen">
<title>在 Mac 主机上查找串行 USB 设备</title>

<para>当 JeVois 智能相机连接到 Mac OSX 主机时，会自动检测到新的串行 USB。其名称的形式为：</para>

<para><literallayout><computeroutput>/dev/tty.usbmodemXXXX </computeroutput></literallayout> 其中上面显示的“XXXX”字符将替换为取决于您的 Mac 电脑的 4 位数字。</para>

<para>要找出您机器上的确切名称，请打开 <emphasis role="bold">终端窗口（在</emphasis> <emphasis role="bold">应用程序中，然后是</emphasis> <emphasis role="bold">实用程序中），然后输入：</emphasis> </para>

<para><literallayout><computeroutput>ls /dev/tty.usbmodem* </computeroutput></literallayout></para>

<para>它应该返回设备名称。</para>
</section>
<section xml:id="_USBserialMac_1serusbmacscreen">
<title>使用 screen 命令</title>

<para>您可以使用内置的“屏幕”程序连接到您的 JeVois 相机：</para>

<para><literallayout><computeroutput>screen /dev/tty.usbmodemXXXX 115200 </computeroutput></literallayout> 其中将“XXXX”替换为上面“ls”命令返回的数字。</para>

<para>一旦连接，您就可以发出“help”，“info”等命令</para>

<para><note><title>Note</title>

<para>据我们所知，“screen”程序不提供命令回显选项（查看您正在输入的内容）。因此，当您输入时，您将看不到您输入的内容。这是正常的。</para>

<para>要在使用“屏幕”时向上滚动，请键入“CTRL-A”“ESC”，然后可以使用箭头键或鼠标滚轮向上滚动。当您准备返回交互模式时，请键入 <computeroutput>RETURN</computeroutput> 两次。</para>
</note>
</para>
</section>
<section xml:id="_USBserialMac_1serusbmacother">
<title>使用其他串行终端程序</title>

<para>还有其他适用于 Mac 的程序比“screen”更易于使用。例如，我们在使用 <link xlink:href="https://www.emtec.com/zoc/">ZOC 7</link> 时取得了良好的效果。 </para>
</section>
    <section xml:id="_UserProUSBserial"><title>JeVois-Pro 串行 USB 通信</title>    </section>
<para>从 开始，您可以启用将日志和模块输出消息发送到 的 mini-USB 端口的功能。只需在 GUI 的“系统”选项卡中选中该选项即可，如下所示：</para>

<para>  </para>

<para>并重新启动相机。</para>

<para>然后使用常规 USB 转 mini-USB 电缆将 JeVois Pro 的 mini-USB 端口连接到主机上的标准 USB 端口。当 启动时，您的主机将检测到 USB 串行设备。然后您可以连接到它以与 通信。例如，在 Linux 主机上，当 连接时，主机上会出现一个新设备 <emphasis role="bold">/dev/ttyACM0。然后您可以使用</emphasis> <computeroutput>screen</computeroutput> 程序进行连接：</para>

<para><literallayout><computeroutput>sudo screen /dev/ttyACM0 115200 </computeroutput></literallayout></para>

<para>然后按照 <link linkend="_UserCli">命令行界面用户指南</link> 中所述向 发出命令</para>

<para> 增强了 JeVois 软件中的串行驱动程序，使其能够应对电缆断开/重新连接。但是，仍然存在一些注意事项，因为似乎没有正确的方法可以从 Linux 用户空间真正知道电缆是否已连接。但是，如果 正在发送消息并且电缆未连接，则与串行端口关联的小缓冲区最终会溢出。在这种情况下， 将关闭串行设备并尝试重新打开它。这通常会在电缆重新连接后成功。请注意，如果您的模块没有写入大量消息，您将不会在相机上知道电缆已断开连接，直到您尝试输出足够的消息以导致该缓冲区溢出。 </para>
    <section xml:id="_ArduinoTutorial"><title>教程：如何编写与 JeVois 交互的 Arduino 代码</title>    </section>
<para><formalpara><title>使用 JeVois 和 Arduino 控制伺服器</title></formalpara>
</para>

<para><formalpara><title>JeVois 模块输出的串行字符串</title></formalpara>
</para>

<para>在这个简单的示例中，我们创建一个 Arduino 程序，它将监听来自、、、 或其他模块的消息，这些模块通过串行端口输出包含目标位置信息的消息。这些模块输出以下形式的字符串：</para>

<para><literallayout><computeroutput>T1 &lt;target_x&gt;
</computeroutput></literallayout></para>

<para>用于一维导航（例如 中消失点的方向），或</para>

<para><literallayout><computeroutput>T2 &lt;target_x&gt; &lt;target_y&gt;
</computeroutput></literallayout></para>

<para>用于二维坐标。有关自定义串行消息的信息，请参阅 UserSerialStyle。</para>

<para>为了使输出独立于视频图像分辨率，所有模块始终将坐标标准化为 -1000（全左或全上）到 1000（全右或全下）的范围。</para>

<para>每个视频帧通常输出一个字符串，也就是说，这些字符串以每秒 30 个、每秒 60 个或更高的速率从 JeVois 相机输出。</para>

<para><formalpara><title>Arduino 伺服控制</title></formalpara>
</para>

<para>这是一段简单的 Arduino 代码，可以解析 JeVois 发送的字符串并将其转换为控制伺服电机角度的脉冲。此代码可用于控制无线电遥控汽车的转向，或控制安装 JeVois 相机的伺服电动云台的 pan 和 titl 角度。</para>

<para><literallayout><computeroutput>//&#32;JeVois&#32;control&#32;steering&#32;or&#32;a&#32;pan/tilt&#32;head&#32;from&#32;the&#32;output&#32;of&#32;JeVois&#32;modules
//
//&#32;We&#32;handle&#32;messages&#32;&quot;T2&#32;&lt;targetx&gt;&#32;&lt;targety&gt;&quot;,&#32;&quot;T1&#32;&lt;targetx&gt;&quot;,&#32;&quot;PANGAIN&#32;&lt;gain&gt;&quot;,&#32;and&#32;&quot;TILTGAIN&#32;&lt;gain&gt;&quot;.
//&#32;targetx&#32;and&#32;targety&#32;are&#32;assumed&#32;to&#32;be&#32;in&#32;the&#32;-1000&#32;...&#32;1000&#32;range&#32;as&#32;output&#32;by&#32;the&#32;JeVois&#32;Kalman&#32;filters.
//&#32;Here&#32;we&#32;only&#32;do&#32;simple&#32;PD&#32;control&#32;under&#32;the&#32;assumption&#32;that&#32;target&#32;coordinates&#32;have&#32;already&#32;been&#32;filtered&#32;upstream.

#include&#32;&lt;Servo.h&gt;

//&#32;Pin&#32;for&#32;LED,&#32;blinks&#32;as&#32;we&#32;receive&#32;serial&#32;commands:
#define&#32;LEDPIN&#32;13

//&#32;Serial&#32;port&#32;to&#32;use:&#32;on&#32;chips&#32;with&#32;USB&#32;(e.g.,&#32;32u4),&#32;that&#32;usually&#32;is&#32;Serial1.&#32;On&#32;chips&#32;without&#32;USB,&#32;use&#32;Serial:
#define&#32;SERIAL&#32;Serial1

//&#32;Pins&#32;for&#32;up&#32;to&#32;two&#32;servos:
Servo&#32;panservo;
#define&#32;PANPIN&#32;3
Servo&#32;tiltservo;
#define&#32;TILTPIN&#32;5

//&#32;Initial&#32;servo&#32;values&#32;in&#32;degrees:
#define&#32;PANZERO&#32;90
#define&#32;TILTZERO&#32;90

//&#32;With&#32;updates&#32;typically&#32;coming&#32;in&#32;at&#32;60Hz&#32;or&#32;up&#32;to&#32;120Hz,&#32;we&#32;will&#32;often&#32;need&#32;to&#32;move&#32;by&#32;a&#32;fraction&#32;of&#32;a
//&#32;degree.&#32;Hence&#32;we&#32;keep&#32;track&#32;of&#32;the&#32;pan&#32;and&#32;tilt&#32;values&#32;multiplied&#32;by&#32;SCALE.&#32;For&#32;the&#32;gains,&#32;a&#32;gain&#32;of&#32;100
//&#32;means&#32;we&#32;will&#32;update&#32;servo&#32;angle&#32;by&#32;the&#32;0.1*(target&#32;value/SCALE)&#32;degrees&#32;on&#32;each&#32;update.&#32;Higher&#32;gains&#32;mean
//&#32;larger&#32;angular&#32;updates.
#define&#32;SCALE&#32;100
long&#32;pangain&#32;=&#32;100;
long&#32;tiltgain&#32;=&#32;100;
long&#32;panval&#32;=&#32;PANZERO&#32;*&#32;SCALE;
long&#32;tiltval&#32;=&#32;TILTZERO&#32;*&#32;SCALE;

//&#32;Buffer&#32;for&#32;received&#32;serial&#32;port&#32;bytes:
#define&#32;INLEN&#32;128
char&#32;instr[INLEN&#32;+&#32;1];

void&#32;setup()
{
&#32;&#32;SERIAL.begin(115200);
&#32;&#32;SERIAL.setTimeout(1000000);

&#32;&#32;pinMode(LEDPIN,&#32;OUTPUT);
&#32;&#32;digitalWrite(LEDPIN,&#32;LOW);
&#32;&#32;
&#32;&#32;panservo.attach(PANPIN);
&#32;&#32;panservo.write(panval&#32;/&#32;SCALE);

&#32;&#32;tiltservo.attach(TILTPIN);
&#32;&#32;tiltservo.write(tiltval&#32;/&#32;SCALE);

&#32;&#32;//&#32;We&#32;are&#32;ready&#32;to&#32;rock,&#32;disable&#32;logs&#32;and&#32;turn&#32;on&#32;serial&#32;outputs&#32;on&#32;JeVois&#32;platform:
&#32;&#32;SERIAL.println(&quot;setpar&#32;serlog&#32;None&quot;);
&#32;&#32;SERIAL.println(&quot;setpar&#32;serout&#32;Hard&quot;);
}

void&#32;loop()
{
&#32;&#32;digitalWrite(LEDPIN,&#32;LOW);
&#32;&#32;byte&#32;len&#32;=&#32;SERIAL.readBytesUntil(&apos;\n&apos;,&#32;instr,&#32;INLEN);
&#32;&#32;instr[len]&#32;=&#32;0;
&#32;&#32;digitalWrite(LEDPIN,&#32;HIGH);

&#32;&#32;char&#32;*&#32;tok&#32;=&#32;strtok(instr,&#32;&quot;&#32;\r\n&quot;);
&#32;&#32;int&#32;state&#32;=&#32;0;&#32;int&#32;targx&#32;=&#32;0,&#32;targy&#32;=&#32;0;
&#32;&#32;while&#32;(tok)
&#32;&#32;{
&#32;&#32;&#32;&#32;//&#32;State&#32;machine:
&#32;&#32;&#32;&#32;//&#32;0:&#32;start&#32;parsing
&#32;&#32;&#32;&#32;//&#32;1:&#32;T2&#32;command,&#32;parse&#32;targx
&#32;&#32;&#32;&#32;//&#32;2:&#32;T2&#32;command,&#32;parse&#32;targy
&#32;&#32;&#32;&#32;//&#32;3:&#32;T2&#32;command&#32;complete
&#32;&#32;&#32;&#32;//&#32;4:&#32;T1&#32;command,&#32;parse&#32;targx
&#32;&#32;&#32;&#32;//&#32;5:&#32;T1&#32;command&#32;complete
&#32;&#32;&#32;&#32;//&#32;6:&#32;PANGAIN&#32;command,&#32;parse&#32;pangain
&#32;&#32;&#32;&#32;//&#32;7:&#32;PANGAIN&#32;command&#32;complete
&#32;&#32;&#32;&#32;//&#32;8:&#32;TILTGAIN&#32;command,&#32;parse&#32;tiltgain
&#32;&#32;&#32;&#32;//&#32;9:&#32;TILTGAIN&#32;command&#32;complete
&#32;&#32;&#32;&#32;//&#32;1000:&#32;unknown&#32;command
&#32;&#32;&#32;&#32;switch&#32;(state)
&#32;&#32;&#32;&#32;{
&#32;&#32;&#32;&#32;&#32;&#32;case&#32;0:
&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;if&#32;(strcmp(tok,&#32;&quot;T2&quot;)&#32;==&#32;0)&#32;state&#32;=&#32;1;
&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;else&#32;if&#32;(strcmp(tok,&#32;&quot;T1&quot;)&#32;==&#32;0)&#32;state&#32;=&#32;4;
&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;else&#32;if&#32;(strcmp(tok,&#32;&quot;PANGAIN&quot;)&#32;==&#32;0)&#32;state&#32;=&#32;6;
&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;else&#32;if&#32;(strcmp(tok,&#32;&quot;TILTGAIN&quot;)&#32;==&#32;0)&#32;state&#32;=&#32;8;
&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;else&#32;state&#32;=&#32;1000;
&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;break;
&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;
&#32;&#32;&#32;&#32;&#32;&#32;case&#32;1:&#32;targx&#32;=&#32;atoi(tok);&#32;state&#32;=&#32;2;&#32;break;
&#32;&#32;&#32;&#32;&#32;&#32;case&#32;2:&#32;targy&#32;=&#32;atoi(tok);&#32;state&#32;=&#32;3;&#32;break;
&#32;&#32;&#32;&#32;&#32;&#32;case&#32;4:&#32;targx&#32;=&#32;atoi(tok);&#32;state&#32;=&#32;5;&#32;break;
&#32;&#32;&#32;&#32;&#32;&#32;case&#32;6:&#32;pangain&#32;=&#32;atoi(tok);&#32;state&#32;=&#32;7;&#32;break;
&#32;&#32;&#32;&#32;&#32;&#32;case&#32;8:&#32;tiltgain&#32;=&#32;atoi(tok);&#32;state&#32;=&#32;9;&#32;break;

&#32;&#32;&#32;&#32;&#32;&#32;default:&#32;break;&#32;//&#32;Skip&#32;any&#32;additional&#32;tokens
&#32;&#32;&#32;&#32;}
&#32;&#32;&#32;&#32;tok&#32;=&#32;strtok(0,&#32;&quot;&#32;\r\n&quot;);
&#32;&#32;}

&#32;&#32;//&#32;Target&#32;coordinates&#32;are&#32;in&#32;range&#32;-1000&#32;...&#32;1000.&#32;Servos&#32;want&#32;0&#32;...&#32;180.
&#32;&#32;//&#32;We&#32;also&#32;need&#32;to&#32;negate&#32;as&#32;needed&#32;so&#32;that&#32;the&#32;servo&#32;turns&#32;to&#32;cancel&#32;any&#32;offset&#32;from&#32;center:
&#32;&#32;if&#32;(state&#32;==&#32;3&#32;||&#32;state&#32;==&#32;5)
&#32;&#32;{
&#32;&#32;&#32;&#32;panval&#32;-=&#32;(targx&#32;*&#32;pangain)&#32;/&#32;1000;
&#32;&#32;&#32;&#32;if&#32;(panval&#32;&lt;&#32;5&#32;*&#32;SCALE)&#32;panval&#32;=&#32;5&#32;*&#32;SCALE;&#32;else&#32;if&#32;(panval&#32;&gt;&#32;175&#32;*&#32;SCALE)&#32;panval&#32;=&#32;175&#32;*&#32;SCALE;
&#32;&#32;&#32;&#32;panservo.write(panval&#32;/&#32;SCALE);
&#32;&#32;}
&#32;&#32;
&#32;&#32;if&#32;(state&#32;==&#32;3)
&#32;&#32;{
&#32;&#32;&#32;&#32;tiltval&#32;+=&#32;(targy&#32;*&#32;tiltgain)&#32;/&#32;1000;
&#32;&#32;&#32;&#32;if&#32;(tiltval&#32;&lt;&#32;5&#32;*&#32;SCALE)&#32;tiltval&#32;=&#32;5&#32;*&#32;SCALE;&#32;else&#32;if&#32;(tiltval&#32;&gt;&#32;175&#32;*&#32;SCALE)&#32;tiltval&#32;=&#32;175&#32;*&#32;SCALE;
&#32;&#32;&#32;&#32;tiltservo.write(tiltval&#32;/&#32;SCALE);
&#32;&#32;}
}
</computeroutput></literallayout></para>

<para><formalpara><title>在 JeVois 平台上使用 script.cfg 文件</title></formalpara>
</para>

<para>有时，在加载模块时设置一些参数或执行一些命令很有用。</para>

<para>JeVois 允许您将参数设置和命令存储在模块目录中名为 <computeroutput>script.cfg</computeroutput> 的文件中。文件 <computeroutput>script.cfg</computeroutput> 可能包含任何命令序列，就像您在 JeVois 命令行界面中以交互方式输入它们一样。</para>

<para>以下是 ObjectTracker 模块的一个示例。如下所示，此处的命令不仅会设置 JeVois 上的参数，还会设置 Arduino 控制的云台的平移和倾斜增益：</para>

<para><literallayout><computeroutput>#&#32;Demo&#32;configuration&#32;script&#32;for&#32;ObjectTracker&#32;module.

#&#32;Set&#32;camera&#32;to&#32;fixed&#32;color&#32;balance,&#32;gain,&#32;and&#32;exposure,&#32;so&#32;that&#32;we&#32;get&#32;more&#32;reliable&#32;colors&#32;than&#32;we&#32;would&#32;obtain&#32;under
#&#32;automatic&#32;mode:
setcam&#32;autowb&#32;0
setcam&#32;autogain&#32;0
setcam&#32;autoexp&#32;0
setcam&#32;redbal&#32;110
setcam&#32;bluebal&#32;170
setcam&#32;gain&#32;16
setcam&#32;absexp&#32;500

#&#32;Detect&#32;a&#32;light&#32;blue&#32;flash&#32;drive:
setpar&#32;hrange&#32;95...110
setpar&#32;srange&#32;100...255
setpar&#32;vrange&#32;60...253

#&#32;Send&#32;info&#32;log&#32;messages&#32;to&#32;None,&#32;send&#32;serial&#32;strings&#32;from&#32;module&#32;to&#32;Hard&#32;serial&#32;port:
setpar&#32;serlog&#32;None
setpar&#32;serout&#32;Hard

#&#32;Apply&#32;high&#32;gain&#32;to&#32;our&#32;pan/tilt&#32;servos,&#32;sending&#32;the&#32;commands&#32;below&#32;to&#32;our&#32;Arduino&#32;over&#32;the&#32;Hard&#32;serial&#32;port&#32;that&#32;we
#&#32;configured&#32;above&#32;to&#32;handle&#32;the&#32;serout&#32;messages.&#32;The&#32;Arduino&#32;controlling&#32;the&#32;pan/tilt&#32;servos&#32;will&#32;receive&#32;and&#32;parse
#&#32;these&#32;commands,&#32;and&#32;will&#32;set&#32;the&#32;servo&#32;gains:
serout&#32;PANGAIN&#32;400
serout&#32;TILTGAIN&#32;300
</computeroutput></literallayout> </para>
    <section xml:id="_CaseMounting"><title>JeVois-A33 外壳安装指南</title>    </section>
<para>JeVois 智能相机提供 4 个孔，可安全地安装到机器人或其他设备上。</para>

<para>\警告 孔在工厂时未带螺纹。当您将螺钉拧入其中时，外壳的塑料将被螺钉形成螺纹。建议您只用螺钉安装 JeVois 智能相机一次。多次这样做可能会磨损相机外壳孔的塑料并导致螺钉松动。</para>

<para>\警告 JeVois 相机外壳上的孔深度略大于 5 毫米。请规划最大 5 毫米的螺丝长度，以避免碰到外壳上螺丝孔的底部。</para>

<para>\图像 html 案例安装.png</para>

<para>您可以下载 <link xlink:href="http://jevois.org/data/jevois-dimensions.pdf">JeVois Dimensions Scan - PDF</link> 或 <link xlink:href="http://jevois.org/data/jevois-dimensions.png">JeVois Dimensions Scan - 600-DPI PNG</link> 并以 100% 比例打印以获得安装图案。</para>

<para>\图像 html jevois-dimensions-thumb.png</para>

<para>自定义安装由 JeVois 用户 DrRickDaglessMD 贡献 ----------------------------------------------------&#8212;</para>

<para>看看这个很棒的适配器，你可以用 3D 打印机制作它，将 JeVois 安装在普通三脚架上：https://www.thingiverse.com/thing:2358684</para>

<para>\图片 html 三脚架适配器.png </para>
    <section xml:id="_ProCaseMounting"><title>JeVois-Pro 外壳安装指南</title>    </section>
<para> 提供 2 个螺纹孔（公制螺丝 M2.5x0.45）用于牢固地安装到机器人或其他设备上。</para>

<para>更多信息即将发布...</para>

<para>\警告 JeVois-Pro 相机外壳上的孔深度略大于 5 毫米。计划最大螺丝长度为 5 毫米，以避免碰到外壳内的电子设备！ </para>
    <section xml:id="_HardwareFiles"><title>硬件：原理图、机壳 STL 文件等 \tableofcontents</title>    </section>
<para>JeVois-A33 示意图 ======================</para>

<para><itemizedlist>
<listitem>
<para><link xlink:href="http://jevois.org/data/JeVois-A33-CPU-Board-Schematics.pdf">JeVois-A33 CPU 板</link></para>
</listitem><listitem>
<para><link xlink:href="http://jevois.org/data/JeVois-A33-Power-Board-Schematics.pdf">JeVois-A33 电源板</link></para>
</listitem></itemizedlist>
</para>

<para>JeVois-A33 塑料外壳 STL 文件 ====================================</para>

<para>请注意，这些在基于长丝的 3D 打印机上打印效果不佳。它们在激光烧结打印机上打印效果不错，尽管您可能会丢失挤出徽标中的许多细节。</para>

<para>标准情况 ----------&#8212;</para>

<para><itemizedlist>
<listitem>
<para><link xlink:href="http://jevois.org/data/JeVois-A33-Case-Top.STL">JeVois-A33 顶壳 STL</link></para>
</listitem><listitem>
<para><link xlink:href="http://jevois.org/data/JeVois-A33-Case-Bottom.STL">JeVois-A33 底壳 STL</link></para>
</listitem></itemizedlist>
</para>

<para>无风扇机箱 ---------&#8212;</para>

<para>此机箱专为 30x20mm 尺寸的散热器而设计。请注意，在我们的测试中，30x20x6mm 的散热器太小，无法提供足够的冷却。JeVois 在负载下会立即过热。这就是我们决定在生产中使用风扇的原因。有关无风扇改装的更多信息，请参阅 Fanless。</para>

<para><itemizedlist>
<listitem>
<para><link xlink:href="http://jevois.org/data/fanless/JeVoisA33-fanless-case-top.STL">JeVois-A33 无风扇顶壳 STL</link></para>
</listitem><listitem>
<para><link xlink:href="http://jevois.org/data/fanless/JeVoisA33-fanless-case-bottom.STL">JeVois-A33 无风扇底壳 STL</link></para>
</listitem></itemizedlist>
</para>

<para>带有 AR0135 全局快门传感器的改装单元的外壳 ------------------------------------------------------&#8212;</para>

<para><itemizedlist>
<listitem>
<para><link xlink:href="http://jevois.org/data/JeVois-A33-AR0135-Case-Top.STL">JeVois-A33-AR0135 顶壳 STL</link></para>
</listitem><listitem>
<para><link xlink:href="http://jevois.org/data/JeVois-A33-AR0135-Case-Bottom.STL">JeVois-A33-AR0135 底壳 STL</link></para>
</listitem></itemizedlist>
</para>

<para>JeVois-Pro 示意图 ======================</para>

<para><itemizedlist>
<listitem>
<para><link xlink:href="http://jevois.org/data/JeVois-Pro-Main-Schematics.pdf">JeVois-Pro 主板原理图</link></para>
</listitem><listitem>
<para><link xlink:href="http://jevois.org/data/JeVoisPro-Main-ASSEMBLY.pdf">JeVois-Pro 主板组件</link></para>
</listitem><listitem>
<para><link xlink:href="http://jevois.org/data/JeVois-Pro-Daughter-Schematics.pdf">JeVois-Pro 子板原理图</link></para>
</listitem><listitem>
<para><link xlink:href="http://jevois.org/data/JeVoisPro-Daughter-ASSEMBLY.pdf">JeVois-Pro 子板组件</link></para>
</listitem></itemizedlist>
</para>

<para>JeVois-Pro 塑料外壳 STL 文件 ====================================</para>

<para>请注意，这些在基于长丝的 3D 打印机上打印效果不佳。它们在激光烧结打印机上打印效果不错，尽管您可能会丢失挤出徽标中的许多细节。</para>

<para>标准情况 ----------&#8212;</para>

<para><itemizedlist>
<listitem>
<para><link xlink:href="http://jevois.org/data/JeVoisPro-Case-Front.STL">JeVois-Pro 前壳 STL</link></para>
</listitem><listitem>
<para><link xlink:href="http://jevois.org/data/JeVoisPro-Case-Back.STL">JeVois-Pro 后壳 STL</link> </para>
</listitem></itemizedlist>
</para>
    <section xml:id="_Lenses"><title>JeVois-A33 镜头选项</title>    </section>
<para>截至 2018 年 4 月， 有几种不同的镜头可供选择：</para>

<para></para>

<para>点击 <link xlink:href="/i/jevois-lenses.png">此处查看上图的较大版本</link>。</para>
<section xml:id="_Lenses_1autotoc_md62">
<title>概述</title>

<para>以下是快速比较：</para>

<para><informaltable frame="all">
    <tgroup cols="4" align="left" colsep="1" rowsep="1">
      <colspec colname='c1'/>
      <colspec colname='c2'/>
      <colspec colname='c3'/>
      <colspec colname='c4'/>
<thead>
      <row >
<entry>
<para>Lens </para>
</entry><entry>
<para>Horizontal field of view </para>
</entry><entry>
<para>Infrared-cut (IR) filter </para>
</entry><entry>
<para>Adjustable focus  </para>
</entry></row>
</thead><tbody>
      <row >
<entry>
<para>Standard </para>
</entry><entry>
<para>60 degrees </para>
</entry><entry>
<para>Yes </para>
</entry><entry>
<para>No (dot of glue on threads)  </para>
</entry></row>
      <row >
<entry>
<para>NoIR </para>
</entry><entry>
<para>60 degrees </para>
</entry><entry>
<para>No </para>
</entry><entry>
<para>Yes  </para>
</entry></row>
      <row >
<entry>
<para>90deg </para>
</entry><entry>
<para>90 degrees, no distortion </para>
</entry><entry>
<para>Yes </para>
</entry><entry>
<para>Yes  </para>
</entry></row>
      <row >
<entry>
<para>120deg </para>
</entry><entry>
<para>120 degrees fisheye </para>
</entry><entry>
<para>Yes </para>
</entry><entry>
<para>Yes  </para>
</entry></row>
    </tbody>
    </tgroup>
</informaltable>
</para>

<para><emphasis role="bold">红外截止 (IR-cut) 滤光片</emphasis>可阻挡红外光，使传感器仅接收可见光。这非常适合白天使用。没有这种滤光片的 <emphasis role="bold">NoIR</emphasis> 镜头非常适合夜间使用。然后，您需要提供红外光源（通常是红外 LED 阵列），它可以使用人眼不可见的光波长照亮您的场景。这样，即使在人类看来完全黑暗的环境中，JeVois 仍能通过反射的红外光“看见”。许多安全摄像头都使用此功能提供夜间监控。</para>

<para><emphasis role="bold">无畸变镜头</emphasis>的特点是视野更宽广，但图像的空间畸变非常小，使得世界上的直线在摄像机拍摄的视频中看起来也是直线。</para>

<para>相比之下，超广角<emphasis role="bold">鱼眼镜头</emphasis>会遭受所谓的桶形失真，之所以这样命名，是因为相机会将垂直线阵列成像为弯曲的，就像在桶表面上一样。与传统镜头相比，这是鱼眼镜头获得更宽视野的反面。JeVois 提供了一种校正桶形失真的算法，该算法在 JeVois 内部的 GPU 上运行，例如，请参阅 JeVois 模块。</para>

<para>请注意，除标准镜头外，所有镜头均已在工厂调整为 30 厘米至无穷远的对焦距离。此外，我们要求工厂在对焦后不要粘合镜头。因此，您只需转动镜头即可轻松改变焦距。找到最佳设置后，您应该使用螺纹上的一小滴胶水、油漆、指甲油等固定镜头（就像 JeVois 中预装的标准镜头一样）。</para>
</section>
<section xml:id="_Lenses.dox_1autotoc_md63">
<title>建议和使用场景</title>

<para><itemizedlist>
<listitem>
<para><emphasis role="bold">标准镜头：</emphasis>用途最广泛，无失真，固定焦距为 40cm 至无穷远。提供相对较窄的视野，但这意味着物体看起来更大，目标上的像素更多，可能使它们更容易被 JeVois 理解（例如，解码二维码或 ArUco 标记）。</para>
</listitem><listitem>
<para><emphasis role="bold">无红外镜头</emphasis>：无失真，视野与标准镜头相同，可调焦距，无红外截止滤镜。主要用于夜视应用，使​​用红外照明器作为光源。</para>
</listitem><listitem>
<para><emphasis role="bold">90 度镜头</emphasis>：视野比标准镜头更宽，无失真，可调整焦距。由于没有失真，使用此镜头不需要任何镜筒校正，而使用视野更宽的镜头时则需要镜筒校正。如果您需要比原始镜头更宽的视野，请使用此镜头，而无需校正图像失真。请注意，与原始镜头相比，使用此镜头时 JeVois 前方的物体会显得更小。但作为交换，您将看到光轴两侧更宽广的区域。</para>
</listitem><listitem>
<para><emphasis role="bold">120 度镜头</emphasis>：最宽视野、桶形失真、可调焦距。如果您想要比原始镜头更宽的视野，请使用此镜头，但请注意，您可能需要花费一些 CPU 或 GPU 资源来消除桶形失真。请注意，使用此镜头时，JeVois 前方的物体与原始镜头相比会显得更小。但作为交换，您将看到光轴两侧更宽广的视野。</para>
</listitem></itemizedlist>
</para>

<para>这些传感器和镜头可在 <link xlink:href="https://jevoisinc.com">https://jevoisinc.com</link> 上找到。</para>
</section>
<section xml:id="_Lenses.dox_1autotoc_md64">
<title>在没有镜头胶的特殊 JeVois 装置上调整或更换镜头</title>

<para>无需镜头胶水且配备 ov9653 或 ov7725 传感器的特殊 JeVois 装置可在 <link xlink:href="https://jevoisinc.com">https://jevoisinc.com</link> 上购买</para>

<para>这些设备包含在一套安装有标准镜头以及额外的 90 度、120 度和 NoIR 镜头的套件中。</para>

<para>  </para>
</section>
<section xml:id="_Lenses_1autotoc_md65">
<title>在标准 JeVois 装置中安装新传感器和镜头</title>

<para>这需要一些技巧，但可以在不到 5 分钟的时间内完成。请观看下面的视频了解详细信息。</para>

<para></para>
</section>
<section xml:id="_Lenses_1autotoc_md66">
<title>矫正镜片</title>

<para>在某些情况下，在标准镜头前放置矫正镜片也很有用。例如，人们可能想要实现微观精度，或者想要阅读小文本，或者可能只需要聚焦在离相机很近的物体上。</para>

<para></para>

<para>上图是使用 15 倍镜头拍摄的一个例子，该镜头取自一副带有可更换镜头的珠宝商眼镜。使用这种矫正镜头（本例中没有很好地对准，因此出现扭曲），我们可以很好地聚焦在距离 JeVois 很近的 2.5 英寸硬盘上的微小文本上。</para>
</section>
<section xml:id="_Lenses_1autotoc_md67">
<title>镜头阴影/均匀性校正</title>

<para>不同的镜头具有不同的偏心阴影量。JeVois 相机传感器芯片提供了一些低级寄存器设置，以帮助改善不同镜头的图像均匀性。如果您在 JeVois 相机中使用了一些定制镜头，请继续阅读。</para>

<para>以下是使用 90 度无失真镜头和默认设置（适用于 60 度镜头）的示例。观察图像在画面角落附近如何变暗：</para>

<para></para>

<para>镜头阴影的调整是通过应用一些正增益来实现的，该正增益会随着偏心率（与图像中心的距离）的增加而增加，并且应用于中央无校正盘的外部。下图显示了校正区域的中心和中央无校正盘（图像的中心区域名称）：</para>

<para></para>

<para>相机寄存器 LCC1（0x62）和 LCC3（0x63）允许通过指定距离传感器中心点的偏移量（每个寄存器的第 7 位指定的方向，其余 6 位指定的幅度）来调整校正盘的位置。</para>

<para>以下是所有相关寄存器：</para>

<para></para>

<para>值得注意的是，寄存器 LCC3 (0x64) 设置增益（校正强度），而 LCC4 (0x65) 设置中央无校正盘的半径。除了单个增益参数，还可以通过寄存器 LCC5 (0x66) 为红色、绿色和蓝色指定 3 个不同的增益（然后使用寄存器 LLC3 (0x64) 为绿色、LCFCFB (0x9d) 为蓝色和 LCCFR (0x9e) 为红色）。</para>

<para>下面是一个简单的 Python 程序，它允许您以交互方式调整无校正区域的半径和 RGB 的单增益因子：</para>

<para><literallayout><computeroutput>#!/usr/bin/python

#&#32;Needed&#32;packages:&#32;sudo&#32;apt-get&#32;install&#32;python&#32;python-tk

#&#32;This&#32;tutorial&#32;is&#32;a&#32;simple&#32;program&#32;that&#32;allows&#32;one&#32;to&#32;play&#32;with&#32;two&#32;low-level&#32;camera&#32;sensor&#32;parameters&#32;that&#32;relate&#32;to
#&#32;correction&#32;for&#32;lens&#32;sensitivity&#32;fall-off&#32;with&#32;eccentricity.

serdev&#32;=&#32;&apos;/dev/ttyACM0&apos;&#32;#&#32;serial&#32;device&#32;of&#32;JeVois

from&#32;Tkinter&#32;import&#32;*
import&#32;serial
import&#32;time

####################################################################################################
#&#32;Send&#32;a&#32;command&#32;to&#32;JeVois&#32;and&#32;show&#32;response
def&#32;send_command(cmd):
&#32;&#32;&#32;&#32;print&#32;&quot;HOST&gt;&gt;&#32;&quot;&#32;+&#32;cmd
&#32;&#32;&#32;&#32;ser.write(cmd&#32;+&#32;&apos;\n&apos;)
&#32;&#32;&#32;&#32;out&#32;=&#32;&apos;&apos;
&#32;&#32;&#32;&#32;time.sleep(0.1)
&#32;&#32;&#32;&#32;while&#32;ser.inWaiting()&#32;&gt;&#32;0:
&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;out&#32;+=&#32;ser.read(1)
&#32;&#32;&#32;&#32;if&#32;out&#32;!=&#32;&apos;&apos;:
&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;print&#32;&quot;JEVOIS&gt;&gt;&#32;&quot;&#32;+&#32;out,&#32;#&#32;the&#32;final&#32;comma&#32;suppresses&#32;extra&#32;newline,&#32;since&#32;JeVois&#32;already&#32;sends&#32;one

####################################################################################################
#&#32;Callback&#32;when&#32;radius&#32;slider&#32;is&#32;moved
def&#32;update_radius(val):
&#32;&#32;&#32;&#32;send_command(&apos;setcamreg&#32;0x65&#32;{}&apos;.format(val))
&#32;&#32;&#32;&#32;
####################################################################################################
#&#32;Callback&#32;when&#32;factor&#32;slider&#32;is&#32;moved
def&#32;update_factor(val):
&#32;&#32;&#32;&#32;send_command(&apos;setcamreg&#32;0x64&#32;{}&apos;.format(val))
&#32;&#32;&#32;&#32;
####################################################################################################
#&#32;Main&#32;code
ser&#32;=&#32;serial.Serial(serdev,&#32;115200,&#32;timeout=1)
send_command(&apos;ping&apos;)&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;&#32;#&#32;should&#32;return&#32;ALIVE
send_command(&apos;setpar&#32;camreg&#32;true&apos;)&#32;&#32;&#32;&#32;&#32;#&#32;enable&#32;low-level&#32;access&#32;to&#32;camera&#32;sensor&#32;registers
send_command(&apos;setcamreg&#32;0x66&#32;1&apos;)&#32;&#32;&#32;&#32;&#32;&#32;&#32;#&#32;enable&#32;lens&#32;correction

master&#32;=&#32;Tk()

w1l&#32;=&#32;Label(master,&#32;text&#32;=&#32;&quot;Radius&quot;)
w1l.pack()

w1&#32;=&#32;Scale(master,&#32;from_=0,&#32;to=255,&#32;tickinterval=32,&#32;length=600,&#32;orient=HORIZONTAL,&#32;command=update_radius)
w1.set(0x80)
w1.pack()

w2l&#32;=&#32;Label(master,&#32;text&#32;=&#32;&quot;Correction&#32;factor&quot;)
w2l.pack()

w2&#32;=&#32;Scale(master,&#32;from_=0,&#32;to=255,&#32;tickinterval=32,&#32;length=600,&#32;orient=HORIZONTAL,&#32;command=update_factor)
w2.set(0x10)
w2.pack()

mainloop()
</computeroutput></literallayout></para>

<para>使用此代码，您应该能够改善图像的一致性，但请注意以下注意事项。在运行此 Python 代码之前，请确保您对串行 USB 设备具有写访问权限（例如，<computeroutput>sudo chmod 777 /dev/ttyACM0</computeroutput>，或以 root 身份运行 Python 程序）。</para>

<para></para>

<para>您可能需要调整代码以获得不同的效果。这里的关键元素是：</para>

<para><itemizedlist>
<listitem>
<para>请注意，在室内使用时，如果仅将 JeVois 指向空白墙壁，则可能无法正常工作，因为广角镜头、<link xlink:href="https://en.wikipedia.org/wiki/Diffuse_reflection">墙壁的非朗伯表面特性</link>和非均匀光源的组合可能会增加明显的阴影。您应该尝试在户外使用，或者使用小型照相亭，就像人们在 eBay 上拍摄想要出售的物品时使用均匀照明的照片一样。</para>
</listitem><listitem>
<para>首先向 JeVois 发送命令“setpar camreg true”，以启用对低级传感器寄存器的访问。</para>
</listitem><listitem>
<para>然后发出命令“setcamreg REG VAL”，其中 <computeroutput>REG</computeroutput> 是寄存器地址，<computeroutput>VAL</computeroutput> 是值。“setcamreg”命令可以理解十进制、八进制（如果以 0 开头）和十六进制（如果以 0x 开头）寄存器地址。</para>
</listitem></itemizedlist>
</para>

<para>一旦为特定镜头找到良好的设置，您可能希望在相机启动时发出这些命令，方法是将命令放在 microSD 卡上的 <emphasis role="bold">initscript.cfg</emphasis> 中。 </para>
</section>
    <section xml:id="_Sensors"><title>JeVois-A33 相机传感器选项</title>    </section>
<para> 智能相机默认使用 Omnivision ov9653 1.3MP 相机传感器。这是一款非常出色的整体传感器，与 JeVois 单元内处理器的可用计算能力完美匹配。</para>

<para>然而，在某些情况下，人们可能需要使用不同的光学器件或传感器。</para>

<para>以下选项可作为对现有 JeVois 智能相机的修改：</para>

<para><informaltable frame="all">
    <tgroup cols="6" align="left" colsep="1" rowsep="1">
      <colspec colname='c1'/>
      <colspec colname='c2'/>
      <colspec colname='c3'/>
      <colspec colname='c4'/>
      <colspec colname='c5'/>
      <colspec colname='c6'/>
<thead>
      <row >
<entry>
<para>Sensor </para>
</entry><entry>
<para>Resolution </para>
</entry><entry>
<para>Shutter </para>
</entry><entry>
<para>Pixel size </para>
</entry><entry>
<para>Lens type </para>
</entry><entry>
<para>JeVois name  </para>
</entry></row>
</thead><tbody>
      <row >
<entry>
<para>Omnivision ov9653 (standard) </para>
</entry><entry>
<para>1.3MP (1280x1024 max) </para>
</entry><entry>
<para>Rolling </para>
</entry><entry>
<para>3.18um x 3.18um </para>
</entry><entry>
<para>1/4 inch </para>
</entry><entry>
<para>ov9650  </para>
</entry></row>
      <row >
<entry>
<para>Omnivision ov7725 </para>
</entry><entry>
<para>0.3MP (640x480 max) </para>
</entry><entry>
<para>Rolling </para>
</entry><entry>
<para>6.00um x 6.00um </para>
</entry><entry>
<para>1/4 inch </para>
</entry><entry>
<para>ov7725  </para>
</entry></row>
      <row >
<entry>
<para>OnSemi AR0135 color </para>
</entry><entry>
<para>1.2MP (1280x960 max) </para>
</entry><entry>
<para>Global </para>
</entry><entry>
<para>3.75um x 3.75um </para>
</entry><entry>
<para>M12 (12mm, S-mount) </para>
</entry><entry>
<para>ar0135  </para>
</entry></row>
      <row >
<entry>
<para>OnSemi AR0135 monochrome </para>
</entry><entry>
<para>1.2MP (1280x960 max) </para>
</entry><entry>
<para>Global </para>
</entry><entry>
<para>3.75um x 3.75um </para>
</entry><entry>
<para>M12 (12mm, S-mount) </para>
</entry><entry>
<para>ar0135  </para>
</entry></row>
      <row >
<entry>
<para>Omnivision ov2640 </para>
</entry><entry>
<para>2.0MP (1600x1200 max) </para>
</entry><entry>
<para>Rolling </para>
</entry><entry>
<para>2.20um x 2.20um </para>
</entry><entry>
<para>1/4 inch </para>
</entry><entry>
<para>ov2640  </para>
</entry></row>
    </tbody>
    </tgroup>
</informaltable>
</para>

<para><note><title>Note</title>

<para>带有 M12 镜头座的传感器需要为您的 JeVois 智能相机配备一个新的塑料外壳。它们支持最广泛的镜头，从超广角到远摄。</para>

<para>全局快门意味着所有像素都在同一时间采样，而滚动快门则以光栅扫描方式逐个采样像素。全局快门传感器非常适合：<itemizedlist>
<listitem>
<para>无人机</para>
</listitem><listitem>
<para>快速移动的机器人</para>
</listitem><listitem>
<para>汽车</para>
</listitem><listitem>
<para>条形码扫描仪</para>
</listitem><listitem>
<para>3D 扫描</para>
</listitem><listitem>
<para>位置跟踪</para>
</listitem><listitem>
<para>虹膜扫描</para>
</listitem><listitem>
<para>增强现实</para>
</listitem><listitem>
<para>有关更多信息，请参阅 <link xlink:href="https://en.wikipedia.org/wiki/Rolling_shutter">https://en.wikipedia.org/wiki/Rolling_shutter</link>。</para>
</listitem></itemizedlist>
</para>

<para>通常，像素越大的传感器具有更好的低光性能。单色传感器通常也具有更好的低光性能。有关更多详细信息，请参阅给定传感器的数据表。</para>
</note>
</para>
<section xml:id="_Sensors_1autotoc_md109">
<title>镜头</title>

<para>对于镜头，请参阅 镜头</para>
</section>
<section xml:id="_Sensors_1autotoc_md110">
<title>安装</title>

<para>这需要一些技巧，但可以在不到 5 分钟的时间内完成。请观看下面的视频了解详细信息。</para>

<para></para>

<para>小心使用相机连接器，不要用力拉扯卡舌。卡舌只能滑出约 2 毫米。</para>

<para>  </para>
</section>
<section xml:id="_Sensors_1autotoc_md111">
<title>JeVois智能相机配置</title>

<para><note><title>Note</title>

<para>对于 JeVois 软件 及更高版本，这是可选的：传感器类型在启动时自动检测。但您可能仍希望按如下所述选择它，因为这将加快 JeVois 的启动时间，避免 JeVois 一个接一个地尝试所有已知传感器。</para>
</note>
为了让您的 JeVois 智能相机知道您已经安装了新传感器，您需要在 JeVois 设备的 microSD 上的特殊配置文件中指明传感器的名称。</para>

<para><itemizedlist>
<listitem>
<para>将 microSD 插入台式机或笔记本电脑</para>
</listitem><listitem>
<para>浏览 BOOT 分区</para>
</listitem><listitem>
<para>使用任何编辑器，在该目录中创建一个名为 <emphasis>sensor</emphasis> 的纯文本文件</para>
</listitem><listitem>
<para>在该文件中写入一行纯 ASCII 文本，并使用上面列出的 JeVois 名称。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para>例如（安装 ov7725 传感器后）：</para>

<para><itemizedlist>
<listitem>
<para><emphasis role="bold">Linux：<computeroutput>echo</emphasis> ov7725 &gt; /media/${USER}/BOOT/sensor</computeroutput></para>
</listitem><listitem>
<para><emphasis role="bold">Mac：<computeroutput>echo</emphasis> ov7725 &gt; /Volumes/BOOT/sensor</computeroutput></para>
</listitem><listitem>
<para><emphasis role="bold">Windows：使用记事本创建并保存文件。确保没有扩展名（即，它被命名为</emphasis> <emphasis>sensor</emphasis> 而不是 <emphasis>sensor.txt</emphasis>）。</para>
</listitem></itemizedlist>
</para>
</section>
<section xml:id="_Sensors_1autotoc_md112">
<title>我的 JeVois 相机有哪些传感器？</title>

<para>在 JeVois Inventor 的控制台中，输入：</para>

<para><literallayout><computeroutput>获取相机传感器&#32;
</computeroutput></literallayout></para>
</section>
<section xml:id="_Sensors_1autotoc_md113">
<title>传感器特定信息</title>
<section xml:id="_Sensors_1autotoc_md114">
<title>Omnivision ov7725</title>

<para>由于像素更大，该传感器比默认的 JeVois 传感器具有更好的低光性能。另一方面，它的分辨率较低。它也可以以 60fps 的速度在 640x480 下抓取（原始传感器在该分辨率下只能达到 30fps），但它被限制在 60fps，无法像原始传感器那样以 120fps 的速度抓取。</para>

<para>如果您觉得原始传感器在低光照条件下难以发挥作用，并且您想在低光照条件下维持高帧速率，请使用此传感器（否则，请参阅 <link linkend="_UserLighting">优化不同光照条件下的性能</link> 以获取有关如何在需要时通过动态调整原始 ov9653 传感器上的帧速率来增加曝光时间的提示）。</para>

<para>  </para>

<para>该传感器支持：YUYV、BAYER、RGB565<itemizedlist>
<listitem>
<para>VGA ( 640 x 480): up to 60 fps</para>
</listitem><listitem>
<para>CIF ( 352 x 288): up to 60 fps</para>
</listitem><listitem>
<para>QVGA ( 320 x 240): up to 60 fps</para>
</listitem><listitem>
<para>QCIF ( 176 x 144): up to 60 fps</para>
</listitem><listitem>
<para>QQVGA ( 160 x 120): up to 60 fps</para>
</listitem><listitem>
<para>QQCIF ( 88 x 72): up to 60 fps</para>
</listitem></itemizedlist>
</para>
</section>
<section xml:id="_Sensors_1autotoc_md115">
<title>OnSemi (Aptina) AR0135</title>

<para><note><title>Note</title>

<para>该传感器主要用于工业机器视觉，因此自动图像增强功能比消费级 Omnivision 传感器少。仅提供自动增益和自动曝光，无自动白平衡。</para>

<para>此传感器仅支持 <emphasis role="bold">RAW BAYER</emphasis> 或 <emphasis role="bold">GRAY</emphasis> 输出格式（取决于您使用的是彩色还是单色版本）。JeVois 核心软件 及更高版本能够即时从 BAYER 或 GRAY 转换为 YUYV，让您仍能运行绝大多数需要 YUYV 像素格式的 JeVois 模块。但是，这样做是有代价的（JeVois 处理器必须从 BAYER 或 GRAY 转换为 YUYV）。在无头模式下操作时（没有视频输出到 USB 端口），您可以通过使用 BAYER 作为相机像素格式并确保您的代码可以处理它来消除额外的成本（例如，如果您只对输入帧执行 <computeroutput>getCvBGR()</computeroutput> 或类似操作，则没有问题，该函数可以从任何内容（包括 BAYER）转换为 BGR）。</para>
</note>
此传感器需要为您的 JeVois 设备配备定制塑料外壳。说明大致与上面的安装视频相同，只需小心确保将传感器拉向外壳前部即可：</para>

<para>  </para>

<para>  </para>

<para>  </para>

<para>  </para>

<para>  </para>

<para>该传感器支持：BAYER 或 MONO（取决于您拥有的型号），使用 JeVois CPU 即时转换为 YUYV<itemizedlist>
<listitem>
<para>SXGA (1280 x 960): up to 54 fps</para>
</listitem><listitem>
<para>720p (1280 x 720): up to 60 fps</para>
</listitem><listitem>
<para>VGA ( 640 x 480): up to 54 fps (binned version of SXGA)</para>
</listitem><listitem>
<para>360p ( 640 x 360): up to 60 fps</para>
</listitem><listitem>
<para>QVGA ( 320 x 240): up to 54 fps (central crop of binned version of SXGA)</para>
</listitem><listitem>
<para>180p ( 320 x 180): up to 60 fps</para>
</listitem><listitem>
<para>QQVGA ( 160 x 120): up to 54 fps (central crop of binned version of SXGA)</para>
</listitem><listitem>
<para>90p ( 160 x 90): up to 60 fps</para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>截至撰写本文时，我们无法在所有分辨率下实现制造商宣传的最高帧速率。目前，计划 30fps 是更安全的选择。</para>
</note>
我们为该传感器添加了一个很棒的 IMU（惯性测量单元），即 TDK/InvenSense ICM-20948。</para>

<para>查看新模块 和。</para>

<para>该芯片的规格相当令人印象深刻：<itemizedlist>
<listitem>
<para>3 轴 16 位加速度计，全范围灵敏度可选为 +/-2g、+/-4g、+/-8g 和 +/-16g。</para>
</listitem><listitem>
<para>加速度计数据速率从 4 Hz 到 1125 Hz。</para>
</listitem><listitem>
<para>3 轴 16 位陀螺仪，全范围灵敏度可选为 +/-250dps（度/秒）、+/-500dps、+/-1000dps 和 +/-2000dps。</para>
</listitem><listitem>
<para>陀螺仪数据速率从 4 Hz 到 1125 Hz。</para>
</listitem><listitem>
<para>3 轴 16 位磁力计（指南针），范围宽达 +/-4900uT（微特斯拉）。</para>
</listitem><listitem>
<para>磁力计数据速率为 10 Hz、20 Hz、50 Hz 或 100 Hz。</para>
</listitem><listitem>
<para>16 位温度传感器，读出速率高达 8 kHz。</para>
</listitem><listitem>
<para>RAW 数据模式（随时获取当前传感器值）、缓冲 (FIFO) 数据模式（传感器值以固定速率累积到 FIFO 中）和数字运动处理模式 (DMP；原始数据在芯片上处理)。</para>
</listitem><listitem>
<para>片上数字运动处理器 (DMP) 可以在 IMU 芯片内部计算：<itemizedlist>
<listitem>
<para>四元数 6（使用加速度计 + 陀螺仪），</para>
</listitem><listitem>
<para>四元数 9（使用加速度计 + 陀螺仪 + 指南针），</para>
</listitem><listitem>
<para>geomag 四元数（使用加速度计 + 指南针），</para>
</listitem><listitem>
<para>翻转/拾取检测，</para>
</listitem><listitem>
<para>步数检测和计数，</para>
</listitem><listitem>
<para>基本活动识别：驾驶、行走、跑步、骑自行车、倾斜、静止。使用片上计算的四元数，使用以高精度、固定速率获取传感器数据并动态应用各种校准、漂移校正和补偿的算法，可以高度准确地实时估计传感器在 3D 世界中的姿势及其移动方式。</para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>

<para></para>

<para>请注意，与 IMU 的通信是通过 400kHz I2C 总线进行的，这可能会限制数据读出速率，具体取决于从 IMU 请求的数据。此 IMU 有 3 种基本操作模式（参数 <computeroutput>mode</computeroutput> 只能在 params.cfg 中设置）：<itemizedlist>
<listitem>
<para>RAW：可以使用 getRaw() 或 get() 函数随时访问最新的原始传感器数据。这是最简单的操作模式。一个缺点是，如果您没有以完全规则的间隔调用 get()，则读数中会出现一些时间抖动。IMU 不为其数据提供任何时间戳。</para>
</listitem><listitem>
<para>FIFO：在此模式下，来自传感器的数据以精确、恒定的速率堆积到 1 kbyte FIFO 缓冲区中（当加速度计、陀螺仪和磁力计全部开启时，陀螺仪速率决定 FIFO 缓冲速率）。主要优点是您可以读出数据，而不必担心以高精度间隔调用 getRaw() 或 get()。但您需要注意，当使用高传感器数据速率时，FIFO 可能会很快填满并溢出。</para>
</listitem><listitem>
<para>DMP：在此模式下，数据以精确、固定的速率从传感器捕获，并馈送到片上数字运动处理器 (DMP)。然后，DMP 计算四元数、活动识别等，并在这些算法的结果可用时将数据包推送到 FIFO。</para>
</listitem></itemizedlist>
</para>
</section>
<section xml:id="_Sensors_1autotoc_md116">
<title>Omnivision ov2640</title>

<para>该传感器的主要优势在于其分辨率较高。然而，这也有其代价：光敏度不够好，机器视觉处理速度可能较慢，高分辨率下帧速率可能受到 USB 2.0 传输速度的限制（视频数据最高为 24 MByte/s）。</para>

<para>如果您想要检测远处的小物体并且不需要很高的帧速率，请使用此传感器。例如，使用此传感器可以很好地检测条形码的 ArUco 标记。</para>

<para>该传感器支持：YUYV、BAYER、RGB565<itemizedlist>
<listitem>
<para>UXGA (1600 x 1200): up to 15 fps</para>
</listitem><listitem>
<para>SXGA (1280 x 1024): up to 15 fps</para>
</listitem><listitem>
<para>720p (1280 x 720): up to 15 fps</para>
</listitem><listitem>
<para>XGA (1024 x 768): up to 15 fps</para>
</listitem><listitem>
<para>SVGA ( 800 x 600): up to 40 fps</para>
</listitem><listitem>
<para>VGA ( 640 x 480): up to 40 fps</para>
</listitem><listitem>
<para>CIF ( 352 x 288): up to 60 fps</para>
</listitem><listitem>
<para>QVGA ( 320 x 240): up to 60 fps</para>
</listitem><listitem>
<para>QCIF ( 176 x 144): up to 60 fps</para>
</listitem><listitem>
<para>QQVGA ( 160 x 120): up to 60 fps</para>
</listitem><listitem>
<para>QQCIF ( 88 x 72): up to 60 fps</para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>此传感器的外壳比 ov9650 和 ov7725 大 1 毫米。因此，安装此传感器后，JeVois 智能相机外壳的前部不会完全关闭。这是可以预料的，塑料 JeVois 相机外壳的顶部和底部之间会有大约 1 毫米的间隙。</para>
</note>
</para>
</section>
<section xml:id="_Sensors_1autotoc_md117">
<title>哪一个是哪一个？</title>

<para>Omnivision 传感器模块看起来几乎一模一样。查找将传感器连接到 JeVois 电路板的扁平柔性电缆上的标记：</para>

<para><itemizedlist>
<listitem>
<para>HDF-25 或 HDF-7725：是 ov7725  </para>
</listitem><listitem>
<para>HDF-53：是 ov9653  </para>
</listitem><listitem>
<para>HDF3M：位于 ov2640  </para>
</listitem></itemizedlist>
</para>

<para>就镜头而言：</para>

<para><itemizedlist>
<listitem>
<para>Standard 和 NOIR 的镜头孔最小。NOIR 的镜头螺纹上没有胶水，而 Standard 有胶水。</para>
</listitem><listitem>
<para>90 度的孔比标准和 NOIR 的孔稍大一些。</para>
</listitem><listitem>
<para>120 度更大，更容易识别。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>您可能收到了额外的镜头，这些镜头有时会被拧入方形护罩中以提供保护。在尝试将镜头安装到 JeVois 相机上之前，您应该先拧下护罩。您可以丢弃护罩：</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para>   </para>
</section>
</section>
    <section xml:id="_Fanless"><title>JeVois-A33 无风扇操作</title>    </section>
<para>在某些情况下，冷却 的风扇声音太大或耗电量太大。JeVois 可以在没有风扇的情况下工作。这里我们向您展示如何将您的 JeVois 相机转换为使用散热器而不是风扇。</para>

<para>在开发 JeVois 的过程中，我们最初计划使用散热器进行被动冷却。但是，所需的散热器太大，而且温度太高，所以我们最终选择了风扇。</para>

<para>要求 =============</para>

<para>你会需要：</para>

<para><itemizedlist>
<listitem>
<para>一台能用的 JeVois 相机</para>
</listitem><listitem>
<para>一把大号平头螺丝刀</para>
</listitem><listitem>
<para>钢丝钳或剪刀</para>
</listitem><listitem>
<para>强力胶</para>
</listitem><listitem>
<para>散热器，这里我们使用 30x30x20mm，带尖刺式散热片，因为这种散热片效率更高</para>
</listitem><listitem>
<para>散热器（导热）胶，我们在 ebay 或 aliexpress 上买的</para>
</listitem><listitem>
<para>酒精垫</para>
</listitem><listitem>
<para>带软钳口的虎钳（例如橡胶）</para>
</listitem></itemizedlist>
</para>

<para>\警告 散热器会变得非常热，热到让人无法舒适地触摸。温度最高可达 80C (175F)。</para>

<para>转换为无风扇 =======================</para>

<para><itemizedlist>
<listitem>
<para>此修改当然会使您的保修失效。继续操作时风险自负。</para>
</listitem><listitem>
<para>使用大号平头螺丝刀打开外壳</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para></para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>剪断风扇电线。确保它们不会短路！</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>您可能需要使用强力胶将相机传感器粘在外壳底部。但请注意，强力胶产生的无形烟雾会永久损坏您的镜头。因此，在将胶水涂到外壳上之前，请确保镜头已盖好。在下图中，您需要将传感器从外壳中轻轻抬起，在传感器外壳上的外壳上涂上少量强力胶，然后将传感器放回原位。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>检查 CPU 周围的焊接工作。焊点不应高于 CPU。否则，散热器可能会造成短路。如果您担心焊点会与散热器接触，您可能需要用胶带覆盖一些焊点。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>现在准备粘合散热器。首先用酒精棉签清洁散热器、CPU 和 RAM 芯片，让酒精完全干燥。CPU 上有 <emphasis>A33</emphasis> 标记，RAM 芯片上有 <emphasis>Sa​​msung</emphasis> 标记。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>接下来，在 CPU 和 RAM 芯片上涂抹少量散热胶。请注意，RAM 芯片比 CPU 薄一点，因此与散热片的接触不会很好，但这没关系，因为 RAM 无论如何都不会变得很热。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>将散热器压在 CPU 上并用虎钳夹紧，不要太紧以免损坏电路板。让其干燥几个小时（建议干燥一整夜）。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>准备出发，看上去不太好，但让我们看看它是否可行。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>成功，在 20C 的办公室中，运行 30 分钟后，CPU 温度约为 63C，这使用了大约 375% 的 CPU（400% 意味着将所有 4 个 CPU 核心都加载到最大）。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para>两小时后，相机温度最终升至 66C。</para>

<para>如果 CPU 温度超过 75C，CPU 频率将自动从 1.34GHz 降低至 1.2GHz。</para>

<para>您还可以使用 JeVois 的参数 <computeroutput>cpumax</computeroutput> 降低最大 CPU 时钟。在 JeVois Inventor 的控制台中，输入“help”并查找参数 <computeroutput>cpumax，它将向您显示以</computeroutput> MHz 为单位的可能频率数。然后您可以选择其中一个并进行设置。例如，</para>

<para>\逐字设置 cpumax 1008 \end逐字</para>

<para>TensorFlow 预测时间从 25ms/推理增加到 33ms/推理，但在我们的测试相机上，CPU 温度从 66C 下降到 42C。</para>

<para>您还可以将此命令添加到相机的 <emphasis role="bold">initscript.cfg</emphasis> 文件中，以便在每次 JeVois 启动时运行它。</para>

<para><note><title>Note</title>

<para>使用我们在工厂测试摄像机时使用的 模块，我们最终达到了 75C，此时 CPU 频率自动降至 1.2GHz。然后温度在 72C 和 75C 之间波动，而 CPU 频率在 1.2GHz 和 1.34GHz 之间波动。 默认未启用，因为它是一个终端模块（您需要重新启动 JeVois 才能将其关闭）。如果您在 <emphasis role="bold">videomappings.cfg</emphasis> 中查找 BurnTest，您将找到一个注释掉的条目。删除注释字符并重新启动 JeVois 以启用它。如上所述，一旦启动 BurnTest，您将需要重新启动 JeVois 才能退出它。虽然系统保持稳定（没有崩溃），但我们怀疑在 75C 附近长时间运行会显著缩短 CPU 芯片的使用寿命。这也是我们最终决定在批量生产中使用风扇的原因之一。</para>
</note>
结论 ===========</para>

<para>它看上去很丑，体积很大，摸起来很烫，但可以进行无风扇改造。</para>

<para>  </para>

<para>如果您不介意以较低的频率运行，则可以使用较小的散热器。请参阅 <link xlink:href="http://jevois.org/start/software.html">http://jevois.org/start/software.html</link> 并查找“无风扇机箱”以下载可容纳 30x20mm 散热器的机箱的 STL 文件。然后您可以 3D 打印该机箱。在我们早期对 30x20x6mm 散热器的测试中，JeVois 在负载下几乎会立即过热。但是，如果您能找到高效且更高的 30x20mm 散热器并且可以在较低的 CPU 频率下工作，这可能是一个选择。不过，这必须经过测试。 </para>
    <section xml:id="_Multicam"><title>JeVois-A33 通过连接到一个 USB 总线的多个 JeVois 摄像机流式传输视频</title>    </section>
<para>默认情况下， 配置为使用所有 USB 等时带宽（isochronous bandwidth），以最大限度地减少延迟。</para>

<para>简而言之，等时传输可以保证实时数据传输，因此非常适合音频和视频。在 8kHz 时钟（125us 周期）上，每个连接设备都可以请求一些时隙（time slots），例如，一个设备可能请求每 8 个时钟周期（微帧 microframe）传输 1 KB，另一个设备可能请求每微帧传输 128 字节，等等。然后主机找到一种方法来满足所有连接设备的各种请求。JeVois 默认请求最大值，即每微帧 3 KB，目的是尽快将所有视频数据推送到主机以最大限度地减少延迟。</para>

<para>从 开始，提供了一个新的启动开关：通过将一个名为 <emphasis role="bold">multicam</emphasis> 的空文件写入 microSD 卡的 <emphasis role="bold">BOOT:</emphasis> 分区，可以将 JeVois 相机的带宽请求降低到 1 kbyte/microframe (8 MByte/s)。有关此特殊文件的更多信息，请参阅 <link linkend="_Debugging">调试 JeVois 软件</link> 和 MicroSD。使用此新选项，可以从连接到同一 USB 总线的 3 个 JeVois 相机进行流式传输。请注意，所有 3 个相机都必须启用 <emphasis role="bold">multicam</emphasis> 启动模式才能正常工作。</para>

<para></para>

<para>由于这会将每个 JeVois 相机的 USB 带宽限制为 8 MByte/s，因此默认情况下不启用此功能。请注意，它还可能限制某些模块可以运行的帧速率。在 YUYV 中，这意味着只有低分辨率才能以全帧速率通过。事实上，仅 640 x 480 x 2（bytes/pixel）x 30（fps）就已经是 18 Mbytes/s。</para>

<para>使用 PC 主机硬件时，可以使用扩展卡为每个端口提供专用的 USB 控制器。例如 StarTech PEXUSB400（4 个独立的 USB 2.0 端口，已停产，但可以在 eBay 上找到）或 PEXUSB3S44V（4 个独立的 USB 3.0 端口）。使用这样的卡，可以从 4 个 JeVois 摄像机以全帧速率（3kb/微帧）进行流式传输，或者从 12 个 JeVois 摄像机以多摄像机速率（1kb/微帧；需要将一个有源 3 端口 USB 集线器连接到扩展卡上的 4 个端口中的每一个）。 </para>
    <section xml:id="_UserDNNoverview"><title>在 JeVois-A33 和 JeVois-Pro 上运行神经网络</title>    </section>
<para>JeVois 模块提供了一个通用引擎，用于在 和 上运行神经网络推理。请注意，目前 JeVois 上还没有提供神经网络训练，因为训练通常需要大型服务器和大型 GPU。因此，我们假设您有一个已经训练好的模型，您想在 JeVois 相机上使用它来对实时视频流进行运行时推理。</para>

<para>虽然我们在这里重点介绍 JeVois 模块，但有几个较旧的模块提供了 DNN 功能：</para>

<para><itemizedlist>
<listitem>
<para>：使用 TensorFlow API 在 CPU 上进行 TensorFlow-Lite 对象分类</para>
</listitem><listitem>
<para>：Itti 等人 (1998) 显著性模型 + 使用 TensorFlow API 在 CPU 上进行 TensorFlow-Lite 对象分类</para>
</listitem><listitem>
<para>：使用 TensorFlow API 在 CPU 上进行 TensorFlow-Lite 对象分类</para>
</listitem><listitem>
<para>：使用 Darknet API 在 CPU 上进行 Darknet 对象识别</para>
</listitem><listitem>
<para>：Itti 等人(1998) 显著性模型 + CPU 上的 Darknet 对象识别，Darknet API</para>
</listitem><listitem>
<para>：CPU 上的 Darknet YOLO 对象检测，Darknet API</para>
</listitem><listitem>
<para>：使用 CPU 上的 OpenCV 进行对象检测</para>
</listitem><listitem>
<para>：使用 CPU 上的 OpenCV 进行对象检测，Python 版本</para>
</listitem><listitem>
<para>：使用 CPU 上的 OpenCV 进行对象分类，Python 版本</para>
</listitem><listitem>
<para>：Python 中的面部情绪识别网络</para>
</listitem><listitem>
<para>仅限：：使用 MediaPipe 的面部标志</para>
</listitem><listitem>
<para>仅限：：使用 MediaPipe 的手部标志</para>
</listitem><listitem>
<para>仅限：：使用 MediaPipe 的身体姿势标志</para>
</listitem><listitem>
<para>仅限：：并行运行多个神经网络，以象限显示</para>
</listitem><listitem>
<para>仅限：：并行运行多个神经网络，重叠显示</para>
</listitem><listitem>
<para>仅限：：使用 Coral Python API 在可选 Coral TPU 上运行分类模型</para>
</listitem><listitem>
<para>仅限：：使用 Coral Python API 在可选 Coral TPU 上运行检测模型</para>
</listitem><listitem>
<para>仅限：：使用 Coral Python API 在可选 Coral TPU 上运行分割模型</para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>在 上，其中一些模块位于图形界面中的 <emphasis role="bold">Legacy</emphasis> 模块列表下。</para>
</note>
</para>
<section xml:id="_UserDNNoverview_1autotoc_md140">
<title>JeVois-Pro DNN 与各种硬件加速器的基准测试</title>

<para>参见 <link linkend="_JeVoisProBenchmarks">JeVois-Pro 深度神经网络基准</link></para>
</section>
<section xml:id="_UserDNNoverview_1autotoc_md141">
<title>JeVois DNN 框架概述</title>

<para> 模块实现了一个 <link linkend="_classjevois_1_1dnn_1_1Pipeline">Pipeline</link> 组件，该组件作为总体推理协调器，同时还可作为三个子组件的工厂：</para>

<para><itemizedlist>
<listitem>
<para>预处理器：从摄像头传感器接收图像并准备进行网络推理（例如，调整大小、将 RGB 交换为 BGR、量化等）。
<literallayout>&#160;&#xa;</literallayout>
 可用变体：</para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1PreProcessorBlob">PreProcessorBlob</link> (C++)：应该适用于大多数需要一张图像作为输入的网络</para>
</listitem><listitem>
<para>按照 PreProcessor、PreProcessorPython 中描述的接口和 PyPreBlob.py 中的示例，用 Python 编写自己的程序</para>
</listitem><listitem>
<para>网络：接收预处理的图像并运行神经网络推理，产生一些输出。
<literallayout>&#160;&#xa;</literallayout>
 可用变体：<itemizedlist>
<listitem>
<para><link linkend="_classjevois_1_1dnn_1_1NetworkOpenCV">NetworkOpenCV</link> (C++)，适用于 OpenCV、OpenVino/Myriad-X 和 TIM-VX/NPU</para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1NetworkNPU">NetworkNPU</link> (C++)</para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1NetworkHailo">NetworkHailo</link> (C++)</para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1NetworkTPU">NetworkTPU</link> (C++)</para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1NetworkONNX">NetworkONNX</link> (C++)，适用于 ONNX Runtime（也提供 Python 版本）</para>
</listitem><listitem>
<para>按照 Network、NetworkPython 中的接口和 PyNetOpenCV.py 中的示例，用 Python 编写您自己的程序</para>
</listitem></itemizedlist>
</para>
</listitem><listitem>
<para>PostProcessor：接收原始网络输出并以人性化的方式呈现它们。例如，在运行对象检测网络后在实时摄像机视频上绘制框。
<literallayout>&#160;&#xa;</literallayout>
 可用变体：<itemizedlist>
<listitem>
<para><link linkend="_classjevois_1_1dnn_1_1PostProcessorClassify">PostProcessorClassify</link></para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1PostProcessorDetect">PostProcessorDetect</link></para>
</listitem><listitem>
<para>PostProcessorSegment（语义分割）</para>
</listitem><listitem>
<para>PostProcessorYuNet（用于面部检测框 + 眼睛、鼻子和嘴巴上的标记）</para>
</listitem><listitem>
<para>PostProcessorStub（在编写自己的预处理器之前，可用于测试模型的速度）</para>
</listitem><listitem>
<para>使用 PostProcessor、PostProcessorPython 中的接口和 PyPostClassify.py 中的示例编写自己的预处理器</para>
</listitem></itemizedlist>
</para>
</listitem></itemizedlist>
</para>

<para>管道的参数在 YAML 文件中指定，该文件描述了要使用哪个预处理器、哪种网络类型、哪种后处理器以及这些预处理器的各种参数，以及训练后的权重在 microSD 上的存储位置。这些 YAML 文件存储在 JEVOIS[PRO]:/share/dnn/ 中，可通过用户界面的 Config 选项卡在 上访问。</para>

<para>在 模块中，通过 <link linkend="_classjevois_1_1dnn_1_1Pipeline">Pipeline</link> 组件的 <computeroutput>pipe</computeroutput> 参数选择给定网络。该参数中描述的可用管道如下：</para>

<para><literallayout><computeroutput>&lt;ACCEL&gt;:&lt;TYPE&gt;:&lt;NAME&gt;
</computeroutput></literallayout></para>

<para>其中 ACCEL 是 (OpenCV、NPU、SPU、TPU、VPU、NPUX、VPUX、Python) 之一，TYPE 是 (Stub、Classify、Detect、Segment、YuNet、Python、Custom) 之一。</para>

<para>JeVois-Pro GUI（Pipeline 组件的 <computeroutput>管道参数）中使用了以下键：</computeroutput> </para>

<para><itemizedlist>
<listitem>
<para>**OpenCV：**由 OpenCV DNN 框架加载并在 CPU 上运行的网络。</para>
</listitem><listitem>
<para>**ORT：**由 ONNX Runtime 框架加载并在 CPU 上运行的网络。</para>
</listitem><listitem>
<para>**NPU：**在 JeVois-Pro 集成的 5-TOPS NPU（神经处理单元）上原生运行的网络。</para>
</listitem><listitem>
<para>**TPU：**在可选的 4-TOPS Google Coral TPU 加速器（张量处理单元）上运行的网络。</para>
</listitem><listitem>
<para>**SPU：**在可选的 26-TOPS Hailo8 SPU 加速器（流处理单元）上运行的网络。</para>
</listitem><listitem>
<para>**VPU：**在可选的 1-TOPS MyriadX VPU 加速器（矢量处理单元）上运行的网络。</para>
</listitem><listitem>
<para>**NPUX：**由 OpenCV 加载并通过 TIM-VX OpenCV 扩展在 NPU 上运行的网络。为了高效运行，网络应该量化为 int8，否则会出现一些基于 CPU 的缓慢仿真。</para>
</listitem><listitem>
<para>**VPUX：**针对 VPU 优化的网络，但如果 VPU 不可用，则在 CPU 上运行。请注意，如果未检测到 VPU 加速器，则通过扫描所有 VPU 条目并将其目标从 Myriad 更改为 CPU 来自动创建 VPUX 条目。如果检测到 VPU，则列出 VPU 模型，而不列出 VPUX 模型。VPUX 仿真在 JeVois-Pro CPU 上运行，使用 Arm Compute Library 来高效实现各种网络层和操作。例如：</para>
</listitem></itemizedlist>
</para>

<para><literallayout><computeroutput>%YAML&#32;1.0
---

#&#32;SqueezeNet&#32;v1.1&#32;from&#32;https://github.com/DeepScale/SqueezeNet
SqueezeNet:
&#32;&#32;preproc:&#32;Blob
&#32;&#32;nettype:&#32;OpenCV
&#32;&#32;postproc:&#32;Classify
&#32;&#32;model:&#32;&quot;opencv-dnn/classification/squeezenet_v1.1.caffemodel&quot;
&#32;&#32;config:&#32;&quot;opencv-dnn/classification/squeezenet_v1.1.prototxt&quot;
&#32;&#32;intensors:&#32;&quot;NCHW:32F:1x3x227x227&quot;
&#32;&#32;mean:&#32;&quot;0&#32;0&#32;0&quot;
&#32;&#32;scale:&#32;1.0
&#32;&#32;rgb:&#32;false
&#32;&#32;classes:&#32;&quot;classification/imagenet_labels.txt&quot;
&#32;&#32;classoffset:&#32;1
</computeroutput></literallayout></para>

<para>将在 模块中通过 <link linkend="_classjevois_1_1dnn_1_1Pipeline">Pipeline</link> 的 <computeroutput>管道参数以</computeroutput> <emphasis role="bold">OpenCV:Classify:SqueezeNet</emphasis> 形式提供</para>

<para>有关 YAML 文件中支持的键的最新列表，请参阅以下定义的所有参数（使用“JEVOIS_DECLARE_PARAMETER(...)”）：</para>

<para><itemizedlist>
<listitem>
<para><link linkend="_GUIhelper_8C_1a251ee9f915563bc8c09c1623b5e29e31">预处理器::H</link></para>
</listitem><listitem>
<para><link linkend="_GUIhelper_8C_1a251ee9f915563bc8c09c1623b5e29e31">网络::H</link></para>
</listitem><listitem>
<para><link linkend="_GUIhelper_8C_1a251ee9f915563bc8c09c1623b5e29e31">后处理器::H</link></para>
</listitem><listitem>
<para><link linkend="_GUIhelper_8C_1a251ee9f915563bc8c09c1623b5e29e31">管道::H</link></para>
</listitem></itemizedlist>
</para>

<para>从上面的链接中，点击<emphasis>转到此文件的源代码</emphasis>来查看参数定义。</para>
</section>
<section xml:id="_UserDNNoverview_1autotoc_md142">
<title>添加新网络的程序</title>

<para><itemizedlist>
<listitem>
<para>运行时所需的一切（完整的 OpenCV，包含所有可用的后端、目标等、OpenVino、Coral EdgeTPU 库、Hailo 库、NPU​​ 库等）都已预先安装在 JeVois 上，因此您无需在相机上安装任何其他软件即可使用这些框架运行您的自定义网络。</para>
</listitem><listitem>
<para>获得模型：训练您自己的模型，或下载预先训练的模型。</para>
</listitem><listitem>
<para>获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、RGB 或 BGR、打包（NWHC）或平面（NCHW）像素、输入和输出层的名称等）。</para>
</listitem><listitem>
<para>要在 上运行，请在您的 Linux 台式机上转换/量化模型，以便对其进行优化以在可用的神经加速器之一上运行，例如集成 NPU、Hailo8、Coral TPU 等。<itemizedlist>
<listitem>
<para>这将要求您在具有大量 RAM、磁盘空间以及可能具有大型 nVidia GPU 的快速 Linux 台式机上为每个目标加速器安装供应商提供的 SDK（例如，Amlogic NPU SDK、OpenVino SDK、Hailo SDK、Coral EdgeTPU 编译器）。</para>
</listitem><listitem>
<para>对于量化，您还需要一个<emphasis>代表性样本数据集</emphasis>。这通常是来自用于您的模型的验证集的大约 100 张图像。目标是通过原始网络（仅前向推理）运行此数据集并记录在每一层遇到的值的范围。然后，这些值的范围将用于以最佳精度量化各层。</para>
</listitem><listitem>
<para>使用您选择的加速器的供应商 SDK，在快速的 Linux 桌面上转换和量化模型。</para>
</listitem></itemizedlist>
</para>
</listitem><listitem>
<para>将模型复制到 JEVOIS[PRO]:/share/dnn/custom/ 下的 JeVois microSD 卡</para>
</listitem><listitem>
<para>为您的模型创建一个 JeVois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 JEVOIS[PRO]:/share/dnn/custom/ 下的 YAML 文件</para>
</listitem><listitem>
<para>在相机上，启动 JeVois 模块。它将扫描自定义目录以查找任何有效的 YAML 文件，并通过 DNN 模块的 <link linkend="_classjevois_1_1dnn_1_1Pipeline">Pipeline</link> 组件的 <computeroutput>管道参数使您的模型可用。选择该管道以运行您的模型。</computeroutput> </para>
</listitem><listitem>
<para>您可以在模型运行时调整许多参数（例如，置信度阈值、预处理平均值和比例、交换 RGB/BGR），而其他参数在运行时被冻结（例如，输入张量维度、后处理器类型）。一旦确定了在线可调参数的良好值，您就可以将这些值复制到 YAML 文件中。冻结的参数只能在 YAML 文件中更改。</para>
</listitem></itemizedlist>
</para>
</section>
<section xml:id="_UserDNNoverview_1autotoc_md143">
<title>可用框架的详细信息</title>

<para><itemizedlist>
<listitem>
<para> and: <link linkend="_UserDNNconv">为 JeVois-Pro 转换和量化深度神经网络</link></para>
</listitem><listitem>
<para> and: <link linkend="_UserDNNopencv">使用 OpenCV 在 JeVois-A33 或 JeVois-Pro 上运行神经网络</link></para>
</listitem><listitem>
<para> only: <link linkend="_UserDNNnpu">为 JeVois-Pro NPU 转换并运行神经网络</link></para>
</listitem><listitem>
<para> only: <link linkend="_UserDNNspu">为 Hailo-8 SPU 转换并运行神经网络</link></para>
</listitem><listitem>
<para> only: <link linkend="_UserDNNtpu">为 Coral TPU 转换并运行神经网络</link></para>
</listitem><listitem>
<para> only: <link linkend="_UserDNNvpu">转换并运行 Myriad-X VPU 的神经网络</link></para>
</listitem><listitem>
<para><link linkend="_UserDNNtips">运行自定义神经网络的技巧</link> </para>
</listitem></itemizedlist>
</para>
</section>
    <section xml:id="_UserDNNconv"><title>为 JeVois-Pro 转换和量化深度神经网络</title>    </section><section xml:id="_UserDNNconv_1autotoc_md131">
<title>转换过程概述</title>

<para>一些运行 的硬件加速器要求 DNN 模型经过优化、量化并转换为硬件支持的操作集，然后才能在相机中运行。在本教程中，我们探索以下运行时框架的转换：</para>

<para><itemizedlist>
<listitem>
<para>**OpenCV**：接受许多原样模型，与本机框架（例如 Caffe）相比，运行时速度相当快。但是，主要在 CPU 上运行，与专用神经加速器相比速度较慢。例外情况包括：</para>
</listitem><listitem>
<para><emphasis role="bold">OpenCV + Inference Engine 后端 + Myriad-X 目标 (1.4 TOPS)：</emphasis> 模型通过 OpenCV 和 OpenVino 框架在 Myriad-X VPU 上运行。这是在 上运行 Myriad-X 模型的主要方式。</para>
</listitem><listitem>
<para>**OpenCV + TIM-VX 后端 + NPU 目标 (5 TOPS)：**量化模型在集成到 处理器中的 Verisilicon NPU 上运行。在 NPU 上运行模型可能比专门为 NPU 转换模型更简单（见下文）。但是，模型仍然需要量化才能使用此后端，使用此方法加载和初始化模型非常慢，运行时性能可能不如运行与 NPU 本机相同的模型时。JeVois DNN 框架通过 <link linkend="_classjevois_1_1dnn_1_1NetworkOpenCV">NetworkOpenCV</link> 类支持带有 CPU、Myriad-X 和 TIM-VX 的 OpenCV。</para>
</listitem><listitem>
<para>**ONNX 运行时**：接受 ONNX 格式的模型，并直接在 CPU 上运行它们，无需进一步转换。可以从 C++ 和 Python 调用。</para>
</listitem><listitem>
<para><emphasis role="bold">Verisilicon / Amlogic A311D NPU 集成到 JeVois-Pro 处理器 (5 TOPS)：</emphasis> Verisilicon/Amlogic 提供的 NPU SDK 允许转换和量化模型，以便在 NPU 上进行本机操作。在运行时，NPU 直接连接到 JeVois-Pro 的主内存，因此提供最快的数据传输速率。JeVois 通过 <link linkend="_classjevois_1_1dnn_1_1NetworkNPU">NetworkNPU</link> 类支持 NPU。</para>
</listitem><listitem>
<para>**Hailo-8 (26 TOPS)：**首先使用 Hailo Dataflow Compiler 对模型进行量化和优化，然后使用 Hailo Runtime Library 提供的运行时接口运行。JeVois DNN 通过 <link linkend="_classjevois_1_1dnn_1_1NetworkHailo">NetworkHailo</link> 类支持 Hailo 网络。Hailo-8 通过 PICe 连接，速度非常快（5 GBits/s）。</para>
</listitem><listitem>
<para>**Google Coral Edge TPU（4 TOPS/芯片，可能采用双芯片板）：**使用 Tensorflow-Lite 对模型进行量化，然后使用 Coral EdgeTPU 编译器将其编译为硬件加速器支持的指令。JeVois DNN 通过 <link linkend="_classjevois_1_1dnn_1_1NetworkTPU">NetworkTPU</link> 类支持 Coral。使用 M.2 板时，Coral TPU 可以连接到 PCIe（5 GBits/s），也可以连接到 USB（JeVois-Pro 上仅提供 USB 2.0，因为 A311D 处理器只有一个 5 GBits/s 接口，我们将其用于 PCIe，速度仅为 480 Mbits/s）。</para>
</listitem></itemizedlist>
</para>
</section>
<section xml:id="_UserDNNconv_1autotoc_md132">
<title>量化</title>

<para>网络量化是将网络权重从通常在服务器级 GPU 上使用的 32 位浮点值转换为较小的表示（例如 8 位宽）的过程。这使得模型更小、加载速度更快，并且使用专门设计为使用 8 位权重运行的嵌入式硬件处理器执行速度更快。</para>

<para>量化时，目标是尽可能多地使用减少的可用位来表示原始浮点值。例如，如果已知浮点值在训练期间始终处于某个范围内，例如 [-12.4 .. 24.7]，那么人们会希望进行量化，使得 -12.4 量化为 0，而 24.7 量化为 255。这样，在缩减为 8 位的情况下，整个 8 位范围 [0..255] 将用于以最大精度表示原始浮点数。</para>

<para>因此，成功的量化要求对网络中每一层将要处理的值的范围有一个很好的了解。这可以在训练期间实现（通过使用所谓的<emphasis>量化感知训练</emphasis>，它将在训练期间跟踪每一层的值的范围），也可以在训练之后使用代表性样本数据集（<emphasis>训练后量化</emphasis>，其中样本数据集将通过已经训练过的网络，并且将记录每一层处理的值的范围）。</para>

<para>JeVois 支持以下量化方法：</para>
<section xml:id="_UserDNNconv_1autotoc_md133">
<title>仿射不对称（AA）</title>

<para>权重表示为无符号的 8 位值 [0..255]，加上比例和零点属性，描述如何将该 8 位值解释为浮点数：</para>

<para><literallayout><computeroutput>int_val&#32;=&#32;float_val&#32;/&#32;scale&#32;+&#32;zero_point&#32;//&#32;从浮点数量化为整数&#32;float_val&#32;=&#32;(int_val&#32;-&#32;zero_point)&#32;*&#32;scale&#32;//&#32;从整数反量化为浮点数&#32;
</computeroutput></literallayout></para>

<para>通常，整个网络层只使用一个尺度和零点，这样我们不必为网络中的每个权重携带这些额外的参数。</para>

<para>例如，假设网络最初预期浮点输入值为 [0.0 .. 1.0]。我们可以使用 scale = 1/255 和 zero_point = 0 来量化它。现在 0.0 映射到 0，1.0 映射到 255。</para>

<para>如果网络使用 [-1.0 .. 1.0] 中的输入，我们可以使用比例 = 1/127.5 和零点 = 127.5 进行量化。</para>
</section>
<section xml:id="_UserDNNconv_1autotoc_md134">
<title>动态定点（DFP）</title>

<para>权重表示为整数值（通常是有符号的 int8 或有符号的 int16），具有特殊的按位解释：<itemizedlist>
<listitem>
<para>最高有效位：符号（0 表示正数，1 表示负数）</para>
</listitem><listitem>
<para>接下来的 m 位：整数部分；例如，如果原始浮点值在 [-3.99 .. 3.99] 范围内，则 m=2 位足以表示绝对值在 [0 .. 3] 范围内的整数。</para>
</listitem><listitem>
<para>接下来的 fl 位：小数部分（以 2 为基数）。</para>
</listitem></itemizedlist>
</para>

<para>通常，动态定点规范仅指定 <computeroutput>fl</computeroutput> 值，其中 m 只是所选类型的位数（例如，8 位为 8）减去为符号保留的 1 位，再减去为小数部分保留的 fl 位。</para>

<para>DFP 也为整个层指定，因此我们不必为网络中的每个权重携带不同的 fl 值。</para>

<para><note><title>Note</title>

<para>使用哪种方法取决于您自己和/或框架支持的内容。例如，Coral TPU 和 Hailo SPU 使用 8 位非对称仿射。OpenCV 通常使用未量化的 float32。Myriad-X VPU 使用未量化的 float16。Verisilicon NPU 是最通用的，因为它支持 8 位非对称仿射以及 8 位和 16 位动态定点。Google 的 Tensorflow 团队通常推荐 uint8 非对称仿射。</para>
</note>
</para>
</section>
</section>
<section xml:id="_UserDNNconv_1autotoc_md135">
<title>JeVois Tensor 规范</title>

<para>JeVois 使用以下规范来描述神经网络的输入和输出张量：</para>

<para>\逐字 [NCHW:|NHWC:|NA:|AUTO:]类型：[NxCxHxW|NxHxWxC|...][:QNT[:fl|:scale:zero]] </para>

<para><itemizedlist>
<listitem>
<para>第一个字段（可选）：关于如何组织通道（通常，对于颜色输入张量，为红色、绿色和蓝色）的提示；要么：</para>
</listitem><listitem>
<para><emphasis role="bold">packed (NHWC)：</emphasis> 张量维度是批大小 N（一批中要处理的图像数量，到目前为止，JeVois 上始终为 1，因为我们希望尽快处理每个相机图像），然后是高度，然后是宽度，然后是通道。因此，通道是变化最快的索引，对于 3 个 RGB 通道，数据因此在内存中组织为 RGBRGBRGB...</para>
</listitem><listitem>
<para>**平面（NCHW）：**现在高度和宽度的变化速度比通道快，因此对于 3 个 RGB 通道，这会在内存中产生 3 个连续的单通道图像或平面：RRR...GGG...BBB...</para>
</listitem><listitem>
<para>如果输入不是 RGB 图像，则可能是其他内容。</para>
</listitem></itemizedlist>
</para>

<para>这主要因为一些网络确实需要平面排序（从网络设计者的角度来看这更容易使用，因为可以独立处理各种颜色平面；但这不是大多数图像格式如 JPEG、PNG 等或相机传感器所提供的），而其他网络则需要打包像素（这可能会使网络设计更加复杂，但优点是现在可以将原生打包格式的图像直接输入到网络）。</para>

<para><itemizedlist>
<listitem>
<para>**类型**：值类型，例如，32F 代表 float32，8U 代表 uint8，等等。</para>
</listitem><listitem>
<para>NxCxHxW（用值替换 N、C、H、W，例如 1x3x224x224）或 NxHxWxC 或任何其他张量大小规范</para>
</listitem><listitem>
<para>**QNT：**量化类型：可以是 <computeroutput>NONE（无量化，如果未给出量化规范则假定），<computeroutput>DFP：fl（动态定点，小数部分有</computeroutput> <computeroutput>fl</computeroutput> 位；例如，带有</computeroutput> DFP：7 的 int8 可以表示 [-0.99 .. 0.99] 中的数字，因为最高有效位用于符号，0 位用于整数部分，7 位用于小数部分），或 <computeroutput>AA：scale：zero_point（仿射非对称）。原则上，<computeroutput>APS（仿射每通道非对称）也是可能的，但我们还没有遇到它，因此目前不支持它（如果您需要它，请告诉我们）。</computeroutput>  在内部，JeVois</computeroutput> 使用 NPU SDK 中的 <computeroutput>vsi_nn_tensor_attr_t</computeroutput> 结构来表示这些规范，因为与 TensorFlow、OpenCV 等提供的等效结构相比，这是最通用的规范。此结构和量化类型等相关规范在 <link xlink:href="https://github.com/jevois/jevois/blob/master/Contrib/npu/include/ovxlib/vsi_nn_tensor.h">https://github.com/jevois/jevois/blob/master/Contrib/npu/include/ovxlib/vsi_nn_tensor.h</link> 中定义</para>
</listitem></itemizedlist>
</para>
</section>
<section xml:id="_UserDNNconv_1autotoc_md136">
<title>预处理及其对量化的影响</title>

<para>大多数 DNN 都使用某种形式的预处理，即将输入像素值准备到网络预期的范围内。这与量化是分开的，但我们将在下文中看到两者可以相互作用。</para>

<para>例如，DNN 设计者可能会认为 [-1.0 .. 1.0] 范围内的浮点输入像素值最容易训练，收敛性最好，性能最好。因此，当图像呈现给使用浮点的原始网络时，预处理包括首先将像素值从 [0 .. 255]（通常用于大多数图像格式，如 PNG、JPEG 等）转换为 [-1.0 .. 1.0] 范围。</para>

<para>大多数预训练网络应与预训练权重一起提供以下预处理信息：</para>

<para><itemizedlist>
<listitem>
<para>平均值：输入的平均值是多少（通常在训练期间学习）？</para>
</listitem><listitem>
<para>比例：应如何将像素值缩放为浮点值以输入到网络中？</para>
</listitem><listitem>
<para>stdev：输入值的标准差是多少？</para>
</listitem></itemizedlist>
</para>

<para>通常指定比例或标准差之一，但在极少数情况下也可以同时使用两者。平均值和标准差值是红、绿、蓝的三元组，而比例值是单个标量数。</para>

<para>然后，预处理根据图像或相机帧中的原始 uint8 值计算要输入到网络中的浮点像素值，如下所示：</para>

<para><literallayout><computeroutput>float_pix&#32;=&#32;(int_pix&#32;-&#32;平均值)&#32;*&#32;比例&#32;/&#32;标准差&#32;
</computeroutput></literallayout></para>

<para>预处理由设计网络以对浮点值进行操作的网络设计者指定。它最初与量化无关，量化是希望在硬件加速器上高效运行网络的人所需要的。然而，如上所述，两者可能会相互作用，有时实际上会相互抵消。例如：</para>

<para><itemizedlist>
<listitem>
<para>假设原始浮点网络使用 [0.0 .. 1.0] 范围内的输入，预处理平均值为 [0 0 0]，预处理比例为 1/255，预处理标准差为 [1 1 1]。</para>
</listitem><listitem>
<para>我们希望使用 uint8 非对称仿射对其进行量化，例如，在 Coral TPU 上运行。然后，我们将使用量化器零点 0 和量化器比例 1/255，以最大限度地将 [0.0 .. 1.0] 范围扩展到可用的 uint8 位。</para>
</listitem></itemizedlist>
</para>

<para>最后，首先进行预处理然后进行量化将导致无操作：</para>

<para><itemizedlist>
<listitem>
<para>输入像素值在 [0 .. 255] 之间</para>
</listitem><listitem>
<para>预处理：float_pix = (int_pix - preproc_mean) * preproc_scale / preproc_stdev；结果在 [0.0 .. 1.0] 之间</para>
</listitem><listitem>
<para>量化：quantized_int_val = float_pix / quantizer_scale + quantizer_zero_point；结果返回到 [0 .. 255]</para>
</listitem></itemizedlist>
</para>

<para>JeVois <link linkend="_classjevois_1_1dnn_1_1PreProcessorBlob">PreProcessorBlob</link> 检测诸如此类的特殊情况，并提供无操作或优化的实现。</para>

<para>完整的预处理涉及一些额外的步骤，例如调整输入图像的大小，可能将 RGB 交换为 BGR，以及可能将压缩 RGB 解包为平面 RGB，如 <link linkend="_classjevois_1_1dnn_1_1PreProcessorBlob">PreProcessorBlob</link> 文档中所述</para>
</section>
<section xml:id="_UserDNNconv_1autotoc_md137">
<title>后期处理和去量化</title>

<para>当量化网络运行时，它通常会输出量化表示。</para>

<para>因此，后处理将做两件事：</para>

<para><itemizedlist>
<listitem>
<para>使用量化网络的输出层规范所指定的 DFP、AA 等，将 uint8、int8 等反量化回浮点数，并使用量化操作的逆操作。</para>
</listitem><listitem>
<para>解释结果并产生人类可用的输出（例如，对于 YOLO，解码网络输出中的框，可以将其绘制到已处理的图像上）。</para>
</listitem></itemizedlist>
</para>

<para>有时，反量化是没有必要的；例如，语义分割网络通常只输出一个 uint8 值数组，其中的值直接是输入图像中每个像素分配的对象类别编号。</para>
</section>
<section xml:id="_UserDNNconv_1autotoc_md138">
<title>网络转换程序</title>

<para>以下页面描述了每个可用框架的一般程序和详细信息：</para>

<para><itemizedlist>
<listitem>
<para><link linkend="_UserDNNoverview">在 JeVois-A33 和 JeVois-Pro 上运行神经网络</link> - <link linkend="_UserDNNopencv">使用 OpenCV 在 JeVois-A33 或 JeVois-Pro 上运行神经网络</link> - <link linkend="_UserDNNnpu">为 JeVois-Pro NPU 转换并运行神经网络</link> - <link linkend="_UserDNNspu">为 Hailo-8 SPU 转换并运行神经网络</link> - <link linkend="_UserDNNtpu">为 Coral TPU 转换并运行神经网络</link> - <link linkend="_UserDNNvpu">转换并运行 Myriad-X VPU 的神经网络</link></para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>您可能不需要安装这些框架的完整转换工具包，而是想尝试 USC/iLab 在线模型转换器，这是一个简单的 Web 界面，可让您上传原始网络，然后将转换后的网络直接下载到您的 JeVois-Pro 相机上。</para>
</note>
</para>
</section>
<section xml:id="_UserDNNconv_1autotoc_md139">
<title>提示</title>

<para><itemizedlist>
<listitem>
<para>通常，预处理规模很小，例如 1/127.5 = 0.00784313</para>
</listitem><listitem>
<para>通常，预处理平均值为 [0 0 0] 或 [128 128 128] 左右</para>
</listitem><listitem>
<para>通常，预处理标准差是 [1 1 1] 或 [64 64 64] 左右</para>
</listitem><listitem>
<para>量化参数在模型转换过程中计算。对于使用 AA 的输入层，量化比例通常是一个较小的数字，如 1/127.5，而量化零点通常为 0 或 128 左右。 </para>
</listitem></itemizedlist>
</para>
</section>
    <section xml:id="_UserDNNopencv"><title>使用 OpenCV 在 JeVois-A33 或 JeVois-Pro 上运行神经网络</title>    </section>
<para>OpenCV 提供了一个 DNN 模块，允许在 和 上运行神经网络推理。这通常是运行神经网络最简单的方法，因为不需要转换、量化等。然而，这也是 最慢的方法，因为推理在 CPU 上运行，这比 上可用的一些专用硬件加速器要慢。</para>

<para>支持的神经网络框架====================================</para>

<para><itemizedlist>
<listitem>
<para>Caffe</para>
</listitem><listitem>
<para>TensorFlow</para>
</listitem><listitem>
<para>ONNX（以及通过转换为 ONNX 的 pyTorch）</para>
</listitem><listitem>
<para>Darknet</para>
</listitem></itemizedlist>
</para>

<para>程序 =========</para>

<para><itemizedlist>
<listitem>
<para>阅读并理解有关 <link linkend="_UserDNNoverview">在 JeVois-A33 和 JeVois-Pro 上运行神经网络</link> 的 JeVois 文档</para>
</listitem><listitem>
<para>查看 <link xlink:href="https://docs.opencv.org/4.x/d2/d58/tutorial_table_of_content_dnn.html">官方 OpenCV DNN 文档</link></para>
</listitem><listitem>
<para>运行时推理所需的一切（完整的 OpenCV，包括所有可用的后端、目标等）都已预先安装在您的 JeVois microSD 上。</para>
</listitem><listitem>
<para>获得模型：训练您自己的模型，或下载预先训练的模型。</para>
</listitem><listitem>
<para>获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、RGB 或 BGR、打包（NWHC）或平面（NCHW）像素等）。</para>
</listitem><listitem>
<para>将模型复制到 JEVOIS[PRO]:/share/dnn/custom/ 下的 JeVois microSD 卡</para>
</listitem><listitem>
<para>为您的模型创建一个 JeVois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 JEVOIS[PRO]:/share/dnn/custom/ 下的 YAML 文件</para>
</listitem><listitem>
<para>启动 JeVois 模块。它将扫描自定义目录以查找任何有效的 YAML 文件，并使您的模型作为 DNN 模块的 Pipeline 组件的 <computeroutput>管道参数的一个可用值。选择该管道以运行您的模型。</computeroutput> </para>
</listitem></itemizedlist>
</para>

<para>示例：使用 Caffe 中的 ResNet-18 进行图像分类 =======================================================</para>

<para>让我们运行 ResNet-18 图像分类模型。在这里，我们将只获得一个在 ImageNet 数据集上经过预训练的模型，但对于您在自己的自定义数据集上训练的模型，步骤应该非常相似。</para>

<para>在网上快速搜索“ResNet-18 Caffe”会出现这个链接，它似乎有我们需要的一切：https://github.com/HolmesShuan/ResNet-18-Caffemodel-on-ImageNet</para>

<para><orderedlist>
<listitem>
<para>获取模型并复制到microSD ---------------------------------&#8212;</para>
</listitem></orderedlist>
</para>

<para>首先我们下载模型。对于 Caffe，有两个文件：一个 <emphasis role="bold"></emphasis>.prototxt 文件，描述网络层；一个 <emphasis role="bold"></emphasis>.caffemodel 文件，包含训练后的权重。</para>

<para>在该 GitHub 链接上可用的文件中，我们需要 **deploy.prototxt**，它是用于运行时推理的文件；我们将它保存为 **JEVOIS[PRO]:/share/dnn/custom/resnet-18.prototxt**。然后我们获得训练后的权重并将其保存到 **JEVOIS[PRO]:/share/dnn/custom/resnet-18.caffemodel**。</para>

<para><note><title>Note</title>

<para>在 上，将数据保存到 microSD 的最简单方法是将其从相机中弹出并将其连接到您的桌面。在 上，您可能希望将相机连接到网络（请参阅 ProNetwork）并使用 <link linkend="_ProUserQuick">JeVois-Pro 快速入门用户指南</link> 中说明的方法，以获得更顺畅的工作流程：特别是，请参阅有关在控制台模式下启动的部分，这样就可以轻松地在运行 X 以浏览网页、下载文件等之间切换，然后返回控制台以启动 JeVois 软件。</para>

<para>在 运行时，microSD 的 JEVOISPRO：分区安装在 /jevoispro 上，因此文件进入 /jevoispro/share/dnn/custom/</para>
</note>
<orderedlist>
<listitem>
<para>获取一些有关预处理的信息 -----------------------------------------&#8212;</para>
</listitem></orderedlist>
</para>

<para>现在我们需要预处理参数，例如图像大小、均值和尺度等。我们查看**train.prototxt**来寻找任何线索，我们发现：</para>

<para><itemizedlist>
<listitem>
<para>**crop_size: 224**（这意味着模型需要 224x224 的输入图像）</para>
</listitem><listitem>
<para>**平均值：104；平均值：117；平均值：123**（我们将使用这些平均值；这里不清楚它们是按 RGB 顺序还是 BGR 顺序）。</para>
</listitem><listitem>
<para>目前尚不清楚模型是否需要 RGB 或 BGR、NCHW 或 NHWC，我们不知道输入的比例或标准差......模型运行后，我们可以研究这些。</para>
</listitem><listitem>
<para>要找出输入形状，我们可以使用 Lutz Roeder 出色的 <link xlink:href="https://netron.app/">Netron</link> 在线模型检查工具：</para>
</listitem><listitem>
<para>将浏览器指向 <link xlink:href="https://netron.app/">https://netron.app/</link></para>
</listitem><listitem>
<para>单击“打开模型...”</para>
</listitem><listitem>
<para>上传 resnet-18.prototxt</para>
</listitem><listitem>
<para>单击输入层和输出层的框以查看有关它们的一些信息</para>
</listitem><listitem>
<para>我们发现对于这个 resnet-18，输入形状为 1x3x224x224，即 NCHW 顺序（平面 RGB 颜色）</para>
</listitem><listitem>
<para>Intel OpenVino 员工非常擅长记录模型输入和输出。虽然我们在这里使用的特定模型可能与他们使用的模型不完全相同，但快速搜索“openvino resnet-18”会出现 <link xlink:href="https://docs.openvino.ai/latest/omz_models_model_resnet_18_pytorch.html">https://docs.openvino.ai/latest/omz_models_model_resnet_18_pytorch.html</link>，它为我们提供了有关原始模型的一些有趣信息：</para>
</listitem><listitem>
<para>输入形状 NCWH:1x3x224x224</para>
</listitem><listitem>
<para>平均值 [123.675, 116.28, 103.53]</para>
</listitem><listitem>
<para>比例 [58.395, 57.12, 57.375]</para>
</listitem><listitem>
<para>通道顺序 RGB</para>
</listitem></itemizedlist>
</para>

<para>让我们使用它们。如 <link linkend="_UserDNNconv">为 JeVois-Pro 转换和量化深度神经网络</link> 中所述，在 JeVois 中，预处理 <computeroutput>scale</computeroutput> 是一个通常很小的标量（如 0.0078125），但预处理 <computeroutput>stdev</computeroutput> 也可用，它通常是 [64 64 64] 左右的三元组；因此，为了我们的目的，这里给出的 scale 似乎应该被解释为 <computeroutput>stdev。</computeroutput> </para>

<para><note><title>Note</title>

<para>理想情况下，您将通过自己训练自己的自定义模型来了解所有这些参数，而不是像我们在这里一样仅仅下载通用的预训练模型。</para>
</note>
<orderedlist>
<listitem>
<para>创建一个 YAML zoo 文件，以便 JeVois 可以运行我们的模型 -------------------------------------------------------&#8212;</para>
</listitem></orderedlist>
</para>

<para>我们根据 上使用 Caffe 在 OpenCV 中运行的一些其他分类模型对我们的 YAML 文件进行建模。例如，在 <emphasis role="bold">opencv.yml</emphasis>（可在 的“配置”选项卡中找到）中，我们发现 SqueezeNet 也是一个 caffemodel。因此，我们受 SqueezeNet 的启发，创建了自己的 YAML 文件 **JEVOIS[PRO]:/share/dnn/custom/resnet-18.yml**：</para>

<para><literallayout><computeroutput>&#32;%YAML&#32;1.0&#32;---

ResNet-18：&#32;preproc：Blob&#32;nettype：OpenCV&#32;postproc：分类模型：“dnn/custom/resnet-18.caffemodel”配置：“dnn/custom/resnet-18.prototxt”强度：“NCHW：32F：1x3x224x224”平均值：“123.675&#32;116.28&#32;103.53”比例：1.0&#32;stdev：“58.395&#32;57.12&#32;57.375”#&#32;见下文，需要调整！&#32;rgb：true&#32;类：“coral/classification/imagenet_labels.txt”类偏移量：1&#32;
</computeroutput></literallayout></para>

<para><note><title>Note</title>

<para>对于 <computeroutput>类，我们使用已预加载到</computeroutput> microSD 上的现有 ImageNet 标签文件，因为上面使用的 GitHub 存储库未提供该文件。由于该标签文件的第一个条目为“background”，而这在许多模型中并未使用，因此如果我们的网络不使用该额外类名，我们可能必须使用 <computeroutput>classoffset</computeroutput> 1 来移动类标签。如果您使用自定义训练模型，您还应将文件 <emphasis role="bold">resnet-18.labels</emphasis> 复制到 microSD，该文件描述了您的类名（每行一个类标签），然后将 classes 参数设置为该文件。</para>
</note>
如果您想知道 YAML 文件中各个条目的含义，请查看 UserDNNoverview，每个条目都记录在使用它们的类中（jevois::dnn::PreProcessor、jevois::dnn::Network、jevois::dnn::PostProcessor、jevois::dnn::Pipeline）。</para>

<para><orderedlist>
<listitem>
<para>测试模型并调整任何参数 ----------------------------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>选择 机器视觉模块</para>
</listitem><listitem>
<para>将 <computeroutput>管道参数设置为</computeroutput> <emphasis role="bold">OpenCV:Classify:ResNet-18</emphasis></para>
</listitem><listitem>
<para>如果您没有看到预期的输出，请尝试在 JeVois GUI 中实时调整预处理器参数。例如，最初网络没有显示任何高于阈值的输出类别。由于我们不确定 <computeroutput>stdev，我们可以在</computeroutput> GUI 中将其设置为 [1 1 1]，现在我们看到了预期的输出！</para>
</listitem><listitem>
<para>如果您需要调整 YAML 文件设置，您可以在 的“配置”选项卡下找到该文件。因此，我们在这里编辑 YAML 文件以进行更改：<literallayout><computeroutput>stdev:&#32;&quot;1&#32;1&#32;1&quot;&#32;
</computeroutput></literallayout> 或者，由于 [1 1 1] 是默认值，我们可以删除 <emphasis role="bold">stdev:</emphasis> 行。</para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para>它成功了（此处显示在 JeVois-Pro 上）！由于它在 CPU 上运行，所以不是最快的，但模型导入成功。当将相机指向书架时，书柜/书店分类输出通常是我们在 ImageNet 上训练的分类模型所获得的结果。</para>

<para>也许我们对平均值的顺序（RGB 与 BGR）有误。一旦您确认模型需要的是 RGB 还是 BGR，以及 R、G 和 B 的平均值是多少，您就可以在 GUI 或 YAML 文件中实时调整平均值参数。</para>

<para><orderedlist>
<listitem>
<para>提示 ----&#8212;</para>
</listitem></orderedlist>
</para>

<para>请参阅 <link linkend="_UserDNNtips">运行自定义神经网络的技巧</link> </para>
    <section xml:id="_UserDNNnpu"><title>为 JeVois-Pro NPU 转换并运行神经网络</title>    </section>
<para> 包含一个 5-TOPS 神经处理单元 (NPU)，该单元集成在 Amlogic A311D 处理器中。该神经加速器与主内存的连接速度最快（直接 DMA 访问），因此数据传输和网络执行速度非常快。此外，它不会像其他一些加速器那样受到片上内存有限的困扰，因此相当大的网络可以在 NPU 上运行。</para>

<para><note><title>Note</title>

<para>仅限。 不支持此加速器。</para>
</note>
支持的神经网络框架====================================</para>

<para><itemizedlist>
<listitem>
<para>Caffe</para>
</listitem><listitem>
<para>TensorFlow</para>
</listitem><listitem>
<para>TensorFlow-Lite</para>
</listitem><listitem>
<para>ONNX（以及通过转换为 ONNX 的 pyTorch）</para>
</listitem><listitem>
<para>Darknet</para>
</listitem><listitem>
<para>Keras</para>
</listitem></itemizedlist>
</para>

<para>NPU 可以运行量化为 uint8、int8 或 int16 权重的模型。它不支持浮点权重，因此需要量化和转换。硬件支持的操作和层类型数量有限，这进一步限制了可以在其上运行的内容。但它比标准 CPU 快很多倍。</para>

<para>为了在 NPU 上执行，您的模型将被量化，然后在 Linux 桌面上转换为专有 blob 格式，然后可以将其传输到 JeVois-Pro microSD 进行执行。</para>

<para>程序 =========</para>

<para><itemizedlist>
<listitem>
<para>阅读并理解有关 <link linkend="_UserDNNoverview">在 JeVois-A33 和 JeVois-Pro 上运行神经网络</link> 的 JeVois 文档</para>
</listitem><listitem>
<para>确保你理解 <link linkend="_UserDNNconv">为 JeVois-Pro 转换和量化深度神经网络</link> 中的量化概念</para>
</listitem><listitem>
<para>查看 <link xlink:href="https://github.com/khadas/aml_npu_sdk/tree/master/docs">NPU SDK 文档</link>。特别值得关注的是 <link xlink:href="https://github.com/khadas/aml_npu_sdk/blob/master/docs/">模型转码和运行用户指南</link>。</para>
</listitem><listitem>
<para>NPU 仅支持一组特定的层类型。如果您尝试转换包含不受支持的层的网络，转换有时可能看似成功，但转换后的网络可能无法运行。在尝试转换网络之前，请先查看 <link xlink:href="https://github.com/khadas/aml_npu_sdk/blob/master/docs/">层和操作支持指南</link>。</para>
</listitem><listitem>
<para>您需要下载并安装 Amlogic NPU SDK 才能在运行 Linux Ubuntu 20.04 的台式计算机上转换/量化您的模型。</para>
</listitem><listitem>
<para>运行时所需的一切（NPU 运行时库）都已预先安装在您的 JeVois-Pro microSD 上。</para>
</listitem><listitem>
<para>获得模型：训练您自己的模型，或下载预先训练的模型。</para>
</listitem><listitem>
<para>获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、RGB 或 BGR、打包（NWHC）或平面（NCHW）像素等）。</para>
</listitem><listitem>
<para>将模型复制到 JEVOIS[PRO]:/share/dnn/custom/ 下的 JeVois-Pro microSD 卡</para>
</listitem><listitem>
<para>为您的模型创建一个 JeVois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 JEVOIS[PRO]:/share/dnn/custom/ 下的 YAML 文件</para>
</listitem><listitem>
<para>启动 JeVois 模块。它将扫描自定义目录以查找任何有效的 YAML 文件，并使您的模型作为 DNN 模块的 Pipeline 组件的 <computeroutput>管道参数的一个可用值。选择该管道以运行您的模型。</computeroutput> </para>
</listitem></itemizedlist>
</para>

<para>设置 NPU SDK ========================</para>

<para><note><title>Note</title>

<para>以下所有内容均应在运行 Ubuntu 20.04 Linux 的快速 x86_64 台式计算机上运行，​​而不是在您的 JeVois-Pro 相机上运行。最后，我们将转换后的模型复制到 microSD，然后使用该模型在 JeVois-Pro 上运行推理。</para>
</note>
Amlogic/VeriSilicon NPU SDK 由 Khadas 分发，该公司制造使用与 相同的 Amlogic A311D 处理器的开发板。</para>

<para><literallayout><computeroutput>git&#32;lfs&#32;clone&#32;--recursive&#32;https://github.com/khadas/aml_npu_sdk.git&#32;cd&#32;aml_npu_sdk/acuity-toolkit/demo&#32;
</computeroutput></literallayout></para>

<para>无需安装 Ubuntu 包或 Python wheels，所有内容都包含在该 git repo 中。</para>

<para>其中有 3 个脚本需要编辑，然后在桌面上按顺序运行：</para>

<para><itemizedlist>
<listitem>
<para>**0_import_model.sh**：从源框架（Caffe、TensorFlow 等）转换为中间表示，然后计算样本数据集上每一层遇到的值范围的一些统计数据。这些值范围将用于设置量化参数。</para>
</listitem><listitem>
<para>**1_quantize_model.sh**：使用非对称仿射 uint8 或动态定点 int8 或 int16 量化模型。这将生成我们将在 上运行的模型，采用 <emphasis role="bold">.nb</emphasis> 专有二进制 blob 格式。</para>
</listitem><listitem>
<para>**2_export_case_code.sh**：创建一些可以在目标平台（如 JeVois-Pro）上编译的 C 代码，以创建一个独立的应用程序，该应用程序将在一个图像上加载和运行模型。我们不会使用该代码，因为 JeVois 软件提供了自己的代码，可将模型直接链接到相机传感器和 GUI。但是，我们将对其进行检查，以便我们可以获取 YAML zoo 文件的输入和输出规范。</para>
</listitem></itemizedlist>
</para>

<para>对于第 2 步，我们需要一个有代表性的样本数据集，通常是来自训练或验证集的约 100 张图像。这非常重要，因为它将设置量化参数。</para>

<para>示例：使用 YOLOv7-tiny 进行对象检测 =============================================</para>

<para>我们选择 YOLOv7-tiny 作为本教程的原因是：</para>

<para><itemizedlist>
<listitem>
<para>它以 Darknet 格式提供，仅使用 NPU 支持的操作和层</para>
</listitem><listitem>
<para>JeVois 已经为其提供了后处理器</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>获取模型 -------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>前往 <link xlink:href="https://github.com/AlexeyAB/darknet">https://github.com/AlexeyAB/darknet</link></para>
</listitem><listitem>
<para>让我们下载在 416x416 输入上运行的 YOLOv7-tiny。单击最新版本，然后单击底部资产列表中的 <emphasis role="bold">yolov7-tiny.weights，或者运行以下命令：@code</emphasis> {.py} wget <link xlink:href="https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov7-tiny.weights">https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov7-tiny.weights</link> </para>
</listitem><listitem>
<para>我们还需要网络结构的描述，我们可以在 repo 的 <emphasis role="bold">cfg</emphasis> 文件夹中找到它：<literallayout><computeroutput>wget&#32;https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov7-tiny.cfg&#32;
</computeroutput></literallayout></para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>获取样本数据集 --------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>此模型在 <link xlink:href="https://cocodataset.org">COCO 数据集</link> 上进行训练。让我们下载 <link xlink:href="http://images.cocodataset.org/zips/val2017.zip">2017 年验证集</link>：<literallayout><computeroutput>wget&#32;http://images.cocodataset.org/zips/val2017.zip&#32;unzip&#32;val2017.zip&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>有 5,000 张图像，比我们需要的多。unix 命令“shuf”可以随机打乱名称列表并取前 <computeroutput>n，因此让我们使用它从数据集中抓取</computeroutput> 100 张随机图像。我们将这些文件路径的列表保存到 <emphasis role="bold">dataset.txt</emphasis>，供 <emphasis role="bold">0_import_model.sh</emphasis> 使用：<literallayout><computeroutput>ls&#32;./val2017/*.jpg&#32;|&#32;shuf&#32;-n&#32;100&#32;&gt;&#32;dataset.txt&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para><emphasis role="bold">dataset.txt</emphasis> 现在应包含 100 行（由于 shuf 是随机的，因此您的结果会有所不同）：<literallayout><computeroutput>./val2017/000000382030.jpg&#32;./val2017/000000436617.jpg&#32;./val2017/000000138550.jpg&#32;./val2017/000000226154.jpg&#32;./val2017/000000319369.jpg&#32;...&#32;
</computeroutput></literallayout></para>
</listitem></itemizedlist>
</para>

<para>3.编辑并运行0_import_model.sh ------------------------------&#8212;</para>

<para><itemizedlist>
<listitem>
<para>该文件包含各种框架的各种注释示例。在这里我们需要：</para>
</listitem><listitem>
<para>更改名称</para>
</listitem><listitem>
<para>启用 Darknet 简介，注释掉其他框架。注意：pegasus 运行两次，第一次用于导入，然后生成有关输入的元数据。我们只用我们要从中导入的框架替换第一个。</para>
</listitem></itemizedlist>
</para>

<para>+（Darknet 不需要，其他可能需要）将输入大小列表设置为我们的输入大小，根据 **yolov7-tiny.cfg**，这里是 1x3x416x416。 +我们需要知道输入预处理比例、平均值、标准差。Tiny YOLO v7 只期望像素值在 [0.0 .. 1.0] 内的 RGB 图像。因此我们将使用平均值 = [0 0 0]、标准差 = [1 1 1]、比例 = 1/255 = 0.0039215686、rgb = true。</para>

<para><itemizedlist>
<listitem>
<para>下面，**channel-mean-value** 需要 4 个值：3 个颜色通道的 3 个均值和 1 个比例。</para>
</listitem><listitem>
<para>我们最终得到这个修改后的 <emphasis role="bold">0_import_model.sh</emphasis>:<literallayout><computeroutput>&#32;#!/bin/bash

NAME=yolov7-tiny&#32;#&#32;JEVOIS&#32;编辑了&#32;ACUITY_PATH=../bin/

pegasus=${ACUITY_PATH}pegasus&#32;如果&#32;[&#32;!-e&#32;&quot;$pegasus&quot;&#32;];&#32;然后&#32;pegasus=${ACUITY_PATH}pegasus.py&#32;fi

$pegasus&#32;导入&#32;darknet\&#32;--模型&#32;${NAME}.cfg&#32;\&#32;--weights&#32;${NAME}.weights&#32;\&#32;--输出模型&#32;${NAME}.json&#32;\&#32;--输出数据&#32;${NAME}.data&#32;\&#32;$pegasus&#32;生成输入元数据&#32;\&#32;--模型&#32;${NAME}.json&#32;\&#32;--输入元数据输出&#32;${NAME}_inputmeta.yml&#32;\&#32;--通道平均值“0&#32;0&#32;0&#32;0.0039215686”&#32;\&#32;#&#32;JEVOIS&#32;编辑&#32;--源文件数据集.txt&#32;
</computeroutput></literallayout></para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>请勿剪切和粘贴上面的“# JEVOIS 编辑”注释，它们会破坏代码，请将其删除。</para>
</note>
<itemizedlist>
<listitem>
<para>运行它，它应该完成并且没有错误：<literallayout><computeroutput>./0_import_model.sh&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>您可以查看 yolov7-tiny_inputmeta.yml 了解输入参数的描述，查看 yolov7-tiny.json 了解模型图的描述。</para>
</listitem><listitem>
<para>如果此步骤出现错误，则可能是某些操作不受支持，这可能发生在网络末端。在这种情况下，请检查 Netron 中的网络并查看哪一层转换失败，然后添加 <emphasis role="bold">&#8211;outputs /some/layer</emphasis> 以将网络截断到该层。</para>
</listitem></itemizedlist>
</para>

<para>4.编辑并运行1_quantize_model.sh --------------------------------&#8212;</para>

<para><itemizedlist>
<listitem>
<para>因为我们的输入范围是[0.0 .. 1.0]，这需要 uint8 非对称仿射量化，以便我们的预处理和随后的量化将减少为无操作（参见 UserDNNconv）。</para>
</listitem><listitem>
<para>因此我们启用该功能并更改模型名称，最终得到修改后的 <emphasis role="bold">1_quantize_model.sh</emphasis>:<literallayout><computeroutput>&#32;#!/bin/bash

NAME=yolov7-tiny&#32;#&#32;JEVOIS&#32;编辑了&#32;ACUITY_PATH=../bin/

pegasus=${ACUITY_PATH}pegasus&#32;如果&#32;[&#32;!-e&#32;&quot;$pegasus&quot;&#32;];&#32;然后&#32;pegasus=${ACUITY_PATH}pegasus.py&#32;fi

$pegasus&#32;quantize&#32;\&#32;--quantizer&#32;asymmetric_affine&#32;\&#32;#&#32;JEVOIS&#32;编辑&#32;--qtype&#32;uint8&#32;\&#32;#&#32;JEVOIS&#32;编辑&#32;--rebuild&#32;\&#32;--with-input-meta&#32;${NAME}_inputmeta.yml&#32;\&#32;--model&#32;${NAME}.json&#32;\&#32;--model-data&#32;${NAME}.data&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>运行它，它应该会顺利完成：<literallayout><computeroutput>./1_quantize_model.sh&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>您可以查看 yolov7-tiny.quantize 以查看样本数据集上每个层的最小/最大值范围，以及每个层如何相应地量化。下一个脚本运行时，此文件将被删除。</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>编辑并运行2_export_case_code.sh ----------------------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>在这里，我们只需要设置模型名称，并选择正确的 NPU 模型，对于 中的 A311D 处理器，其为 **VIPNANOQI_PID0X88**。我们最终得到：<literallayout><computeroutput>&#32;#!/bin/bash

NAME=yolov7-tiny&#32;#&#32;JEVOIS&#32;编辑了&#32;ACUITY_PATH=../bin/

pegasus=$ACUITY_PATH/pegasus&#32;如果&#32;[&#32;!-e&#32;&quot;$pegasus&quot;&#32;];&#32;然后&#32;pegasus=$ACUITY_PATH/pegasus.py&#32;fi

$pegasus&#32;导出&#32;ovxlib&#32;\&#32;--model&#32;${NAME}.json&#32;\&#32;--model-data&#32;${NAME}.data&#32;\&#32;--model-quantize&#32;${NAME}.quantize&#32;\&#32;--with-input-meta&#32;${NAME}_inputmeta.yml&#32;\&#32;--dtype&#32;quantized&#32;\&#32;--optimize&#32;VIPNANOQI_PID0X88&#32;\&#32;#&#32;JEVOIS&#32;编辑&#32;--viv-sdk&#32;${ACUITY_PATH}vcmdtools&#32;\&#32;--pack-nbg-unify

rm&#32;-rf&#32;${名称}_nbg_unify

mv../*_nbg_unify${名称}_nbg_unify

cd&#32;${名称}_nbg_unify

mv&#32;network_binary.nb&#32;${NAME}.nb

光盘&#32;..

#&#32;保存正常情况演示导出.数据&#32;mkdir&#32;-p&#32;${NAME}_normal_case_demo&#32;mv&#32;*.h&#32;*.c&#32;.project&#32;.cproject&#32;*.vcxproj&#32;BUILD&#32;*.linux&#32;*.export.data&#32;${NAME}_normal_case_demo

#&#32;删除&#32;normal_case&#32;演示源&#32;#rm&#32;*.h&#32;*.c&#32;.project&#32;.cproject&#32;*.vcxproj&#32;BUILD&#32;*.linux&#32;*.export.data

rm&#32;*.数据&#32;*.量化&#32;*.json&#32;*_inputmeta.yml&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>运行它，它应该完成并且没有错误：<literallayout><computeroutput>./2_export_case_code.sh&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>好的，我们需要的一切都在 yolov7-tiny_nbg_unify/</para>
</listitem><listitem>
<para>转换后的模型：yolov7-tiny.nb</para>
</listitem><listitem>
<para>C 代码：vnn_yolov7tiny.c，我们将检查它以得出我们的输入和输出张量规范。</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>创建 YAML zoo 文件 --------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>我们从 JeVois microSD 中已有的 zoo 文件 npu.yml 中的 <emphasis role="bold">YoloV4</emphasis> 条目开始（并且可以在 GUI 的 Config 选项卡中使用）。</para>
</listitem><listitem>
<para>为了获取量化输入和输出的规格，我们检查 yolov7-tiny_nbg_unify/vnn_yolov7tiny.c 并查找张量定义。我们找到了这个（添加了注释来解释下一步）：<literallayout><computeroutput>&#32;/*-----------------------------------------&#32;Tensor&#32;Initialize&#32;-----------------------------------------*/&#32;attr.dtype.fmt&#32;=&#32;VSI_NN_DIM_FMT_NCHW;&#32;/*&#32;@input_0:out0&#32;*/&#32;attr.size[0]&#32;=&#32;416;&#32;//&#32;JEVOIS：最后一个维度（变化最快；此处为&#32;W）attr.size[1]&#32;=&#32;416;&#32;//&#32;JEVOIS：下一个维度（此处为&#32;H）attr.size[2]&#32;=&#32;3;&#32;//&#32;JEVOIS：下一个维度（此处为&#32;C）attr.size[3]&#32;=&#32;1;&#32;//&#32;JEVOIS：第一个维度（此处为&#32;N）attr.dim_num&#32;=&#32;4;&#32;//&#32;JEVOIS：输入应为&#32;4D&#32;张量&#32;attr.dtype.scale&#32;=&#32;0.003921568393707275;&#32;//&#32;JEVOIS：AA&#32;量化的比例&#32;attr.dtype.zero_point&#32;=&#32;0;&#32;//&#32;JEVOIS：AA&#32;量化的零点&#32;attr.dtype.qnt_type&#32;=&#32;VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;&#32;//&#32;JEVOIS：即&#32;AA&#32;量化&#32;NEW_NORM_TENSOR(norm_tensor[0],&#32;attr,&#32;VSI_NN_TYPE_UINT8);&#32;//&#32;JEVOIS：即&#32;8U&#32;类型

/*&#32;@output_90_198:out0&#32;*/&#32;attr.size[0]&#32;=&#32;52;&#32;attr.size[1]&#32;=&#32;52;&#32;attr.size[2]&#32;=&#32;255;&#32;attr.size[3]&#32;=&#32;1;&#32;attr.dim_num&#32;=&#32;4;&#32;attr.dtype.scale&#32;=&#32;0.0038335032295435667;&#32;attr.dtype.zero_point&#32;=&#32;0;&#32;attr.dtype.qnt_type&#32;=&#32;VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;&#32;NEW_NORM_TENSOR(norm_tensor[1],&#32;attr,&#32;VSI_NN_TYPE_UINT8);

/*&#32;@output_94_205:out0&#32;*/&#32;attr.size[0]&#32;=&#32;26;&#32;attr.size[1]&#32;=&#32;26;&#32;attr.size[2]&#32;=&#32;255;&#32;attr.size[3]&#32;=&#32;1;&#32;attr.dim_num&#32;=&#32;4;&#32;attr.dtype.scale&#32;=&#32;0.0038371747359633446;&#32;attr.dtype.zero_point&#32;=&#32;0;&#32;attr.dtype.qnt_type&#32;=&#32;VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;&#32;NEW_NORM_TENSOR(norm_tensor[2],&#32;attr,&#32;VSI_NN_TYPE_UINT8);

/*&#32;@output_98_212:out0&#32;*/&#32;attr.size[0]&#32;=&#32;13;&#32;attr.size[1]&#32;=&#32;13;&#32;attr.size[2]&#32;=&#32;255;&#32;attr.size[3]&#32;=&#32;1;&#32;attr.dim_num&#32;=&#32;4;&#32;attr.dtype.scale&#32;=&#32;0.003918845672160387;&#32;attr.dtype.zero_point&#32;=&#32;0;&#32;attr.dtype.qnt_type&#32;=&#32;VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;&#32;NEW_NORM_TENSOR(norm_tensor[3],&#32;attr,&#32;VSI_NN_TYPE_UINT8);

因此，我们有一个输入和三个输出（针对&#32;3&#32;个&#32;YOLO&#32;尺度），并且我们从上面生成的代码中得出它们的&#32;JeVois&#32;规格，如下所示（参见&#32;\ref&#32;UserDNNconv）：\code{.py}&#32;intensors：“NCHW：8U：1x3x416x416：AA：0.003921568393707275：0”&#32;outtensors：“8U：1x255x52x52：AA：0.0038335032295435667：0，&#32;8U：1x255x26x26：AA：0.0038371747359633446：0，&#32;8U：1x255x13x13：AA：0.003918845672160387：0”&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>对于 YOLO 后处理，我们需要锚点的定义。我们从 yolov7-tiny.cfg 中获取这些内容：<literallayout><computeroutput>anchors&#32;=&#32;10,13,&#32;16,30,&#32;33,23,&#32;30,61,&#32;62,45,&#32;59,119,&#32;116,90,&#32;156,198,&#32;373,326&#32;
</computeroutput></literallayout> 在下面的 YAML 文件中，我们将按 YOLO 尺度拆分此列表（此处，9 个 w,h 对对应 3 个尺度中的 3 对。我们在下面用分号分隔尺度）。</para>
</listitem><listitem>
<para>由于 YOLOv7 使用“新样式”的 YOLO 坐标，我们需要禁用后处理器 sigmoid 并将后处理器 scalexy 设置为 2.0。对于 YOLOv5/v7，您可能希望这样做，并将 sigmoid 设置为 true 并将 scalexy 设置为 0.0，以便为 YOLOv2/v3/v4 使用旧样式的框坐标。您可以在 jevois::dnn::PostProcessorDetectYOLO::yolo_one() 中查看差异</para>
</listitem><listitem>
<para>我们只需修改名称和文件位置，将所有全局定义放入我们的文件中（例如 preproc、nettype 等，它们在 npu.yml 中全局设置，因此对于我们正在复制的 YoloV4 条目不会重复），并最终得到以下 **yolov7-tiny.yml**（预处理器平均值和比例与我们在 0_import_model.sh 中使用的一样）：<literallayout><computeroutput>&#32;%YAML&#32;1.0&#32;---

yolov7-tiny：&#32;preproc：Blob&#32;平均值：“0&#32;0&#32;0”&#32;比例：0.0039215686&#32;nettype：NPU&#32;模型：“dnn/custom/yolov7-tiny.nb”&#32;张力：“NCHW：8U：1x3x416x416：AA：0.003921568393707275：0”&#32;输出张力：“8U：1x255x52x52：AA：0.0038335032295435667：0，8U：1x255x26x26：AA：0.0038371747359633446：0，8U：1x255x13x13：AA：0.003918845672160387：0”&#32;postproc：检测&#32;检测类型：&#32;RAWYOLO&#32;类：“npu/detection/coco-labels.txt”&#32;锚点：“10,13,&#32;16,30,&#32;33,23；30,61,&#32;62,45,&#32;59,119；116,90,&#32;156,198,&#32;373,326”&#32;sigmoid：false&#32;scalexy：2.0&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>我们将 yolov7-tiny.yml 和 yolov7-tiny.nb 复制到 JeVois-Pro 上的 /jevoispro/share/dnn/custom/ 然后尝试一下！</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>测试模型并调整任何参数 ----------------------------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>选择 机器视觉模块</para>
</listitem><listitem>
<para>将 <computeroutput>管道参数设置为</computeroutput> <emphasis role="bold">NPU:Detect:yolov7-tiny</emphasis></para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para>成功了！速度也相当快，仅网络推理（在 NPU 上运行的部分）就约为 55 fps。</para>

<para><note><title>Note</title>

<para>您可以在 <emphasis role="bold">1_quantize_model.sh</emphasis> 中使用 int8-DFP 量化重复本教程。然后，您只需将 YAML 中的 intensors 和 outtensors 规范更改为获得的 DFP 参数。我们做到了，网络运行良好，但速度大约减半（约 22.5 fps）。因此，AA 量化是此网络的正确选择。</para>
</note>
提示 ====</para>

<para><itemizedlist>
<listitem>
<para>如果您在尝试运行网络时收到“图形验证失败”提示，则可能是您输入的张量规格不正确。在 GUI 的“配置”选项卡下，您可以编辑 yolov7-tiny.yml 并修复它。</para>
</listitem><listitem>
<para>Khadas 有自己的文档，您可能想查看一下，因为他们的 VIM3 板使用与 JeVois-Pro 相同的 Amlogic A311D 处理器。但请注意，在 JeVois 上，我们跳过使用生成的 C 代码，因为 JeVois-Pro 已经提供了运行 NPU 模型所需的所有代码。</para>
</listitem><listitem>
<para><link xlink:href="https://docs.khadas.com/linux/vim3/NPUSDK.html">https://docs.khadas.com/linux/vim3/NPUSDK.html</link></para>
</listitem><listitem>
<para><link xlink:href="https://docs.khadas.com/linux/vim3/ConvertToUseNPU.html">https://docs.khadas.com/linux/vim3/ConvertToUseNPU.html</link></para>
</listitem><listitem>
<para><link xlink:href="https://docs.khadas.com/linux/vim3/NPUPerformanceUsage.html">https://docs.khadas.com/linux/vim3/NPUPerformanceUsage.html</link></para>
</listitem><listitem>
<para><link xlink:href="https://docs.khadas.com/linux/vim3/NPUOperationTimes.html">https://docs.khadas.com/linux/vim3/NPUOperationTimes.html</link></para>
</listitem><listitem>
<para>从 pyTorch 转换时，如果您收到一些奇怪的错误，例如<literallayout><computeroutput>RuntimeError: [enforce fail at inline_container.cc:208] . file not found: archive/constants.pkl </computeroutput></literallayout> 您的模型可能是使用比 NPU SDK 中包含的版本更新的 pyTorch 版本保存的。您可能需要将模型保存到 ONNX，然后尝试再次从 ONNX 转换。或者可能是模型使用了 NPU 不支持的层类型或操作，在这种情况下转换为 ONNX 将无济于事。您需要将网络更改为仅包含可以映射到 NPU 的层和操作。</para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>到目前为止，我们还无法使用 NPU SDK 直接从 pyTorch 成功转换，我们总是会遇到某种错误。但首先将源模型导出到 ONNX，然后在其上运行 NPU SDK 就可以正常工作，只要在源模型中仅使用 NPU 支持的操作即可。</para>
</note>
<itemizedlist>
<listitem>
<para>有关我们有时如何跳过不受支持的最后一层（例如，执行重塑、检测框解码、非最大框抑制等）的示例，请参阅 <link linkend="_UserDNNvpu">转换并运行 Myriad-X VPU 的神经网络</link> 和 UserDNNspu。</para>
</listitem><listitem>
<para>另请参阅 <link linkend="_UserDNNtips">运行自定义神经网络的技巧</link></para>
</listitem></itemizedlist>
</para>

<para>另一个示例：使用 YOLOv10n 进行对象检测 ==================================================</para>

<para><itemizedlist>
<listitem>
<para>YOLOv10n 的流程几乎相同。我们必须对一些事情进行微调：</para>
</listitem><listitem>
<para>从 <link xlink:href="https://github.com/THU-MIG/yolov10/tree/main">https://github.com/THU-MIG/yolov10/tree/main</link> 获取代码</para>
</listitem><listitem>
<para>完成其安装步骤，包括创建 conda 环境和获取所有依赖项。</para>
</listitem><listitem>
<para>您还可以在此阶段使用自定义数据集进行重新训练。</para>
</listitem><listitem>
<para>要导出到 ONNX，使用 opset 13 会出现一些转换错误，因此我们使用 opset 12。我们还可以在该步骤中使用“imgsz”参数设置自定义图像分辨率：<literallayout><computeroutput>yolo&#32;export&#32;model=jameslahm/yolov10n&#32;format=onnx&#32;opset=12&#32;simply&#32;imgsz=288,512&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>网络末端的一些层出现大小错误，可能是因为不同的 opset。无论如何，我们想要原始的 YOLO 输出。因此，我们在 Netron 中检查了网络，并决定在 <emphasis role="bold">0_import_model.sh</emphasis> 中使用 <computeroutput>/model.23/Transpose_output_0</computeroutput> 作为输出层：<literallayout><computeroutput>#...#Onnx&#32;$pegasus&#32;import&#32;onnx\&#32;--model&#32;${NAME}.onnx&#32;\&#32;--output-model&#32;${NAME}.json&#32;\&#32;--outputs&#32;/model.23/Transpose_output_0&#32;\&#32;--output-data&#32;${NAME}.data
#...
</computeroutput></literallayout></para>
</listitem><listitem>
<para>转换正常。但是，它没有在显示屏上生成任何框。检查输出张量后，所有类的置信度值始终为零。查看转换过程中生成的 yolov10n-512x288.quantize 显示输出张量中的值范围为 [-108.24 .. 611.29]。实际上，在该输出张量中，对于输入 1x3x288x512，其为 1x3024x84，4 个框坐标（可以在 512x288 内变化，如果框部分超出输入图像，则变化更多）和 80 个类置信度（在 [0..1] 中）被连接在一起。这意味着，使用 8 位量化，[0..1] 中的任何类置信度将始终映射到相同的数字（量化的零点）...</para>
</listitem><listitem>
<para>因此我们将量化改为 dynamic_fixed_point 和 int16。结果使用 5 位表示小数部分，这足以合理地表示类别准确度。</para>
</listitem><listitem>
<para>效果很好，并且 NPU 的 YOLOv10n 现在包含在 JeVois 发行版和 microSD 图像中。 </para>
</listitem></itemizedlist>
</para>
    <section xml:id="_UserDNNspu"><title>为 Hailo-8 SPU 转换并运行神经网络</title>    </section>
<para> 支持 <link xlink:href="https://hailo.ai/products/hailo-8-m2-module/">26-TOPS Hailo-8</link> 流处理单元 (SPU)，作为使用 PCIe 接口的 M.2 2230 A+E 板上的可选附加神经加速器。到目前为止，这是此规格中速度最快的加速器。</para>

<para><note><title>Note</title>

<para>仅限。 不支持此加速器。</para>
</note>
支持的神经网络框架====================================</para>

<para><itemizedlist>
<listitem>
<para>TensorFlow / TensorFlow-Lite</para>
</listitem><listitem>
<para>ONNX</para>
</listitem><listitem>
<para>pyTorch（通过导出到 ONNX）</para>
</listitem></itemizedlist>
</para>

<para>程序 =========</para>

<para><itemizedlist>
<listitem>
<para>阅读并理解有关 <link linkend="_UserDNNoverview">在 JeVois-A33 和 JeVois-Pro 上运行神经网络</link> 的 JeVois 文档</para>
</listitem><listitem>
<para>确保你理解 <link linkend="_UserDNNconv">为 JeVois-Pro 转换和量化深度神经网络</link> 中的量化概念</para>
</listitem><listitem>
<para>您需要下载并安装 Hailo Software Suite docker，以便在运行 Linux Ubuntu 20.04 的台式计算机上转换/压缩您的模型。<emphasis>需要注册和密码。Hailo 保留接受或拒绝您的开发者注册请求的权利。</emphasis></para>
</listitem><listitem>
<para>运行时推理所需的一切（HailoRT 运行时库、Hailo PCIe 内核驱动程序）都已预先安装在您的 JeVois microSD 上。</para>
</listitem><listitem>
<para>获得模型：训练您自己的模型，或下载预先训练的模型。</para>
</listitem><listitem>
<para>获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、RGB 或 BGR、打包（NWHC）或平面（NCHW）像素等）。</para>
</listitem><listitem>
<para>转换模型如下：</para>
</listitem><listitem>
<para>使用 <computeroutput>hailo parser</computeroutput> 将源模型转换为 Hailo 存档 (.har)</para>
</listitem><listitem>
<para>使用 <computeroutput>hailo optimize</computeroutput> 为 Hailo-8 优化模型并量化为 int8。</para>
</listitem><listitem>
<para>使用 <computeroutput>hailo compilation</computeroutput> 将模型转换为可在 JeVois-Pro 上运行的二进制 blob (.hef)</para>
</listitem><listitem>
<para>可以使用其他命令来可视化您的模型、检查其在验证集上的性能等。</para>
</listitem><listitem>
<para>尝试使用 <computeroutput>hailo tutorial</computeroutput> 获取 Hailo 的 jupyter 教程。</para>
</listitem><listitem>
<para>将转换后的模型复制到 JEVOISPRO:/share/dnn/custom/ 下的 JeVois microSD 卡</para>
</listitem><listitem>
<para>为您的模型创建一个 JeVois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 JEVOISPRO:/share/dnn/custom/ 下的 YAML 文件</para>
</listitem><listitem>
<para>启动 JeVois 模块。它将扫描自定义目录以查找任何有效的 YAML 文件，并使您的模型作为 DNN 模块的 Pipeline 组件的 <computeroutput>管道参数的一个可用值。选择该管道以运行您的模型。</computeroutput> </para>
</listitem></itemizedlist>
</para>

<para>设置 Hailo 软件套件 ======================================</para>

<para><note><title>Note</title>

<para>以下所有内容均应在运行 Ubuntu 20.04 Linux 的快速 x86_64 台式计算机上运行，​​而不是在您的 JeVois-Pro 相机上运行。最后，我们将转换后的模型复制到 microSD，然后使用该模型在 JeVois-Pro 上运行推理。</para>

<para>我们在下面使用的是 HailoRT-4.8.1，但更高版本也应该可以正常工作。为了获得最佳兼容性，请下载与相机上安装的版本相同的版本（在相机的控制台中输入 <computeroutput>!dpkg --list | grep hailo</computeroutput>）。</para>
</note>
<itemizedlist>
<listitem>
<para>查看 <link xlink:href="https://hailo.ai/developer-zone/documentation/sw-suite-2022-07-1">官方文档</link></para>
</listitem><listitem>
<para><link xlink:href="https://hailo.ai/products/hailo-software-suite/model-zoo/">Hailo 模型库</link> 有许多可以在 Hailo-8 上运行的模型。您还可以在 <link xlink:href="https://github.com/hailo-ai/hailo_model_zoo">GitHub</link> 上查看其他文件和模型再训练代码。</para>
</listitem><listitem>
<para>在 hailo.ai 申请开发者账户，登录，然后转到 <link xlink:href="https://hailo.ai/developer-zone/sw-downloads/">https://hailo.ai/developer-zone/sw-downloads/</link></para>
</listitem><listitem>
<para>下载 <emphasis role="bold">Hailo 软件套件 - Docker</emphasis></para>
</listitem><listitem>
<para>下载 <emphasis role="bold">HailoRT – Ubuntu 软件包 (deb) for amd64</emphasis></para>
</listitem><listitem>
<para>下载 <emphasis role="bold">HailoRT – PCIe 驱动程序 Ubuntu 软件包 (deb)</emphasis></para>
</listitem><listitem>
<para>安装 PCIe 驱动程序和运行时库。这不是绝对必要的，但它会在我们继续进行时消除许多警告（对 DKMS 说 Y，它将通过内核更新携带驱动程序；如果失败也不要担心，也许你需要安装 dkms、内核头文件等）：<literallayout><computeroutput>sudo&#32;dpkg&#32;-i&#32;~/Downloads/hailort-pcie-driver_4.8.1_all.deb&#32;sudo&#32;dpkg&#32;-i&#32;~/Downloads/hailort_4.8.1_amd64.deb&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>如果尚未安装 docker，请安装：<literallayout><computeroutput>sudo&#32;apt&#32;install&#32;docker.io&#32;sudo&#32;usermod&#32;-aG&#32;docker&#32;${USER}&#32;#&#32;需要重启才能生效
</computeroutput></literallayout></para>
</listitem><listitem>
<para>解压您下载的 Hailo 软件套件：<literallayout><computeroutput>mkdir&#32;hailodev&#32;cd&#32;hailodev&#32;unzip&#32;~/Downloads/hailo_sw_suite_2022-07.zip&#32;./hailo_sw_suite_docker_run.sh&#32;
</computeroutput></literallayout> 您应该看到以下内容：<literallayout><computeroutput>&#32;欢迎使用&#32;Hailo&#32;软件套件容器&#32;要列出可用的命令，请输入：

--------------------------------------------------&#32;--

HailoRT：hailortcli&#32;-h&#32;数据流编译器：hailo&#32;-h&#32;Hailo&#32;模型动物园：hailomz&#32;-h&#32;TAPPAS：hailo_run_app&#32;-h

--------------------------------------------------&#32;--

（hailo_virtualenv）hailo@mypc:/local/workspace$&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>此时，您可以按照 Hailo 文档从 Hailo Model Zoo 获取模型并重新训练它，获取您自己的模型并进行转换等。我们在下面展示了一个示例。</para>
</listitem><listitem>
<para>完成后，只需“退出”docker 容器。</para>
</listitem><listitem>
<para>要稍后恢复，请输入“./hailo_sw_suite_docker_run.sh &#8211;resume”。</para>
</listitem><listitem>
<para>要重新启动并用新容器替换旧容器，请输入<computeroutput>./hailo_sw_suite_docker_run.sh --override</computeroutput></para>
</listitem><listitem>
<para>要在主机和 Hailo docker 之间复制文件，请在主机上（而不是在容器中）输入以下内容：</para>
</listitem><listitem>
<para><computeroutput>sudo docker container ls -a</computeroutput> 显示容器的 ID，例如 <emphasis role="bold">4f6342fbc915</emphasis></para>
</listitem><listitem>
<para><computeroutput>sudo docker cp myfile 4f6342fbc915:/local/workspace/</computeroutput> 从主机复制到容器</para>
</listitem><listitem>
<para><computeroutput>sudo docker cp 4f6342fbc915:/local/workspace/myfile .</computeroutput> 从容器复制到主机</para>
</listitem><listitem>
<para>请参阅 <link xlink:href="https://hailo.ai/developer-zone/documentation/sw-suite-2022-07-1?sp_referrer=working_with_dockers.html">https://hailo.ai/developer-zone/documentation/sw-suite-2022-07-1?sp_referrer=working_with_dockers.html</link> 了解更多信息（需要登录您的 Hailo 帐户）。</para>
</listitem></itemizedlist>
</para>

<para>示例：YOLOv7 物体检测 ==================================</para>

<para>我们下面运行的所有内容都来自我们上面启动的 docker 容器内部。</para>

<para><orderedlist>
<listitem>
<para>获取模型 -------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>前往 <link xlink:href="https://github.com/WongKinYiu/yolov7">https://github.com/WongKinYiu/yolov7</link> 查看</para>
</listitem><listitem>
<para>我们将使用基础版 YOLOv7 完整版来查看 Hailo 板在大型模型上运行速度有多快：<literallayout><computeroutput>wget&#32;https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt&#32;
</computeroutput></literallayout></para>
</listitem></itemizedlist>
</para>

<para>2.由于我们的模型是pyTorch，所以先将其转换为ONNX ----------------------------------------------------&#8212;</para>

<para><itemizedlist>
<listitem>
<para>该模型在 pyTorch 中，但 YOLOv7 团队提供了一个“export.py”，可以将其导出到 onnx，最近的模型通常都是这样：<literallayout><computeroutput>git&#32;clone&#32;https://github.com/WongKinYiu/yolov7.git&#32;cd&#32;yolov7&#32;pip&#32;install&#32;--upgrade&#32;pip&#32;pip&#32;install&#32;-r&#32;requirements.txt&#32;python3&#32;export.py&#32;--weights&#32;../yolov7.pt&#32;--simplify&#32;--img-size&#32;640&#32;--batch-size&#32;1&#32;cd&#32;..
</computeroutput></literallayout> <note><title>Note</title>

<para>安装要求会卸载 hailo 提供的 torch，然后安装看似相同的版本。这可能会干扰 Hailo 软件套件的其他方面。因此，您可能需要在不同的虚拟环境或本机主机上执行此操作，然后将结果复制到容器中，如上所示。</para>
</note>
</para>
</listitem><listitem>
<para>我们现在有 <emphasis role="bold">yolov7.onnx</emphasis></para>
</listitem><listitem>
<para>要使用 Netron 进行可视化，请运行 **google-chrome <link xlink:href="https://netron.app">https://netron.app</link>**（仍在容器内），选择“打开模型...”，然后选择模型，该模型位于容器中的 <emphasis role="bold">/local/workspace/yolov7.onnx</emphasis> 中。具体来说，我们看到 3 个输出，1x3x80x80x85、1x3x40x40x85、1x3x20x20x85，这是通常的 3 个 YOLO 尺度（形状不寻常，我们稍后会修复）。请注意，原始模型包含一些额外的后处理，但已从导出中删除，这很好，因为它可能不受硬件加速器支持。JeVois 软件将提供后处理。输入是 1x3x640x640（NCHW）。</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>运行 Hailo 解析器 --------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para><link xlink:href="https://hailo.ai/developer-zone/documentation/?type=application-and-release-notes">Hailo 下载部分</link> 中的 Hailo Model Zoo 用户指南有详细的说明。</para>
</listitem><listitem>
<para>我们还查看了 <link xlink:href="https://hailo.ai/developer-zone/documentation/dataflow-compiler-v3-19-0">Hailo Dataflow Compiler 文档</link></para>
</listitem><listitem>
<para>首先，将 ONNX 中的模型解析为 Hailo 存档 (HAR)：<literallayout><computeroutput>hailo&#32;parser&#32;onnx&#32;yolov7.onnx&#32;
</computeroutput></literallayout> 我们收到一些关于不支持的层 298、299、301、302、304、305 的错误，并建议重试，“使用这些最终节点名称：Conv_297、Conv_300、Conv_303”。这些是最终重塑之前的输出，例如，conv_303（Netron 中图形底部的最后一个 Conv 块）为 1x255x20x20，然后重塑为 1x3x20x20x85。事实上，我们应该使用 Conv_303，因为这是 <link linkend="_classjevois_1_1dnn_1_1PostProcessorDetect">jevois::dnn::PostProcessorDetect</link> 可以处理的 YOLO 输出形状。因此我们再试一次（运行 <emphasis role="bold">hailo parser onnx yolov7.onnx &#8211;help</emphasis> 以获取帮助后）：<literallayout><computeroutput>hailo&#32;parser&#32;onnx&#32;yolov7.onnx&#32;--end-node-names&#32;Conv_297&#32;Conv_300&#32;Conv_303&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>成功，我们现在有了**yolov7.har**</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>获取样本数据集 --------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>我们需要一个样本数据集来量化模型。它将通过模型进行处理（仅前向推理），以确定每一层遇到的值的范围。然后这些范围将用于量化。</para>
</listitem><listitem>
<para>如果您在自定义数据集上训练了模型，请将验证集中的大约 100 张图像复制到此处的新目录中。</para>
</listitem><listitem>
<para>我们的模型是在 <link xlink:href="https://cocodataset.org">COCO 数据集</link> 上训练的。让我们下载 <link xlink:href="http://images.cocodataset.org/zips/val2017.zip">2017 年验证集</link>：<literallayout><computeroutput>wget&#32;http://images.cocodataset.org/zips/val2017.zip&#32;unzip&#32;val2017.zip&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>有 5,000 张图像，比我们需要的多。unix 命令 <computeroutput>shuf</computeroutput> 可以随机打乱名称列表并取前 <computeroutput>n</computeroutput> 个，因此让我们使用它从数据集中抓取 100 张随机图像并将它们复制到新目录 <emphasis role="bold">sampledata</emphasis>:<literallayout><computeroutput>mkdir&#32;sampledata&#32;cp&#32;`ls&#32;./val2017/*.jpg&#32;|&#32;shuf&#32;-n&#32;100`&#32;sampledata/&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para><emphasis role="bold">sampledata/</emphasis> 现在应该包含 100 个 jpeg 图像。</para>
</listitem><listitem>
<para>Hailo 希望将样本数据集作为 <emphasis>“.npy 文件，其中包含形状为 (calib_size, h, w, c) 的预处理图像的 numpy 数组”</emphasis>（通过运行 **hailo optimize &#8211;help**）。因此，我们需要编写一个小的 python 脚本 <emphasis role="bold">numpy_sampledata.py</emphasis> 来执行此操作：<literallayout><computeroutput>&#32;import&#32;numpy&#32;as&#32;np&#32;import&#32;os&#32;from&#32;PIL&#32;import&#32;Image

dir&#32;=&#32;&apos;sampledata&apos;&#32;宽度&#32;=&#32;640&#32;高度&#32;=&#32;640&#32;图像数量&#32;=&#32;100

数据集&#32;=&#32;np.ndarray((numimages,&#32;height,&#32;width,&#32;3),&#32;np.float32)&#32;idx&#32;=&#32;0

for&#32;path&#32;in&#32;os.listdir(dir):&#32;fname&#32;=&#32;os.path.join(dir,&#32;path)&#32;if&#32;os.path.isfile(fname):&#32;image&#32;=&#32;Image.open(fname).resize((width,&#32;height));&#32;arr&#32;=&#32;np.array(image).astype(np.float32)&#32;arr&#32;=&#32;(arr&#32;-&#32;0.0)&#32;/&#32;255.0&#32;#&#32;预处理。这里：mean=[0&#32;0&#32;0],&#32;scale=1/255&#32;但因模型而异&#32;dataset[idx,&#32;:]&#32;=&#32;arr&#32;idx&#32;+=&#32;1&#32;with&#32;open(&apos;sampledata.npy&apos;,&#32;&apos;wb&apos;)&#32;as&#32;f:&#32;np.save(f,&#32;dataset)&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>我们运行脚本并得到**sampledata.npy**</para>
</listitem></itemizedlist>
</para>

<para>5.优化模型------------------&#8212;</para>

<para><itemizedlist>
<listitem>
<para>在我们的模型上启动 Hailo 优化器并使用我们的样本数据集。这将量化模型：<literallayout><computeroutput>hailo&#32;optimize&#32;yolov7.har&#32;--calib-set-path&#32;sampledata.npy&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>我们得到**yolov7_quantized.har**</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>编译模型 -----------------&#8212;</para>
</listitem></orderedlist>
</para>

<para><literallayout><computeroutput>hailo&#32;编译器&#32;yolov7_quantized.har&#32;
</computeroutput></literallayout></para>

<para>我们得到**yolov7.hef**，将其复制到 的 microSD 中。</para>

<para>编译器预测此模型的 FPS 为 12.27，考虑到其大小，这个数字听起来相当不错。请注意，它的目标是计算利用率达到 75，而且确实实现了这一目标。也许可以通过一些参数来提高这一数字。为了获得更快的 FPS，可以使用 yolov7-tiny，或者可以减小输入大小。</para>

<para><orderedlist>
<listitem>
<para>创建 JeVois-Pro YAML zoo 文件 -------------------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>我们从 JeVois microSD 中已有的动物园文件 spu.yml 中的任何 YOLO 条目开始（并且可以在 GUI 的“配置”选项卡中使用）。</para>
</listitem><listitem>
<para>对于 YOLO 后处理，我们需要定义锚点（用于预测对象框的原型框形状）。我们从 <link xlink:href="https://github.com/WongKinYiu/yolov7/blob/main/cfg/deploy/yolov7.yaml">https://github.com/WongKinYiu/yolov7/blob/main/cfg/deploy/yolov7.yaml</link> 中获取这些内容，位于顶部：<literallayout><computeroutput>&#32;锚点：
-&#32;[12,16,&#32;19,36,&#32;40,28]&#32;#&#32;P3/8
-&#32;[36,75,&#32;76,55,&#32;72,146]&#32;#&#32;P4/16
-&#32;[142,110,&#32;192,243,&#32;459,401]&#32;#&#32;P5/32&#32;
</computeroutput></literallayout> 在下面的 YAML 文件中，我们将用分号分隔 3 个 YOLO 尺度的 3 组锚点。</para>
</listitem><listitem>
<para>由于 YOLOv7 使用“新样式”的 YOLO 坐标，我们需要禁用后处理器 sigmoid 并将后处理器 scalexy 设置为 2.0。对于 YOLOv5/v7，您可能希望这样做。相反，将 sigmoid 设置为 true 并将 scalexy 设置为 0.0（默认值）以使用 YOLOv2/v3/v4 的旧样式框坐标。您可以在 jevois::dnn::PostProcessorDetectYOLO::yolo_one() 中查看差异</para>
</listitem><listitem>
<para>实际上，我们用于输出的这 3 个 Conv 层在该特定模型中似乎具有线性激活（请在 Netron 中查看）。因此我们需要将 sigmoid 设置为 true，因为后处理器将需要它来进行 YOLO 解码。</para>
</listitem><listitem>
<para>我们只需修改名称和文件位置，将 spu.yml 中的所有全局定义放入我们的文件中（例如 preproc、nettype 等，它们在 spu.yml 中全局设置，因此不会在我们要复制的条目中重复），最后得到以下 **yolov7.yml**：<literallayout><computeroutput>&#32;%YAML&#32;1.0&#32;---

yolov7：preproc：Blob&#32;平均值：“0&#32;0&#32;0”&#32;比例：0.0039215686&#32;nettype：SPU&#32;模型：“dnn/custom/yolov7.hef”&#32;postproc：检测&#32;检测类型：RAWYOLO&#32;锚点：“12,16、19,36、40,28；36,75、76,55、72,146；142,110、192,243、459,401”&#32;类：“npu/detection/coco-labels.txt”&#32;sigmoid：true&#32;scalexy：2.0&#32;
</computeroutput></literallayout></para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>我们不需要（也不能）使用 Hailo 模型指定 <emphasis role="bold">intensors</emphasis> 和 **outtensors**，这些规格嵌入在 HEF 文件中。</para>
</note>
<itemizedlist>
<listitem>
<para>我们将 yolov7.yml 和 yolov7.hef 复制到 JeVois-Pro 上的 /jevoispro/share/dnn/custom/ 然后尝试一下！</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>测试模型并调整任何参数 ----------------------------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>选择 机器视觉模块</para>
</listitem><listitem>
<para>将 <computeroutput>管道参数设置为</computeroutput> <emphasis role="bold">SPU:Detect:yolov7</emphasis></para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para>成功了！正如编译器所承诺的那样，网络推理的速度确实达到了 12.2 FPS。这是一个大型模型，并且使用 640x640 输入。如果您需要更高的帧速率，请尝试较小的输入或 yolov7-tiny。或者尝试 Hailo 团队提供的 YOLOv5m-640，它在 JeVois-Pro 上的运行速度超过 45 FPS。</para>

<para>提示 ====</para>

<para><itemizedlist>
<listitem>
<para>您可能希望从 <link xlink:href="https://hailo.ai/products/hailo-software-suite/model-zoo/">Hailo Model Zoo</link> 中的模型开始。这些模型应该转换得很好，而且您还可以通过查看 GFLOPS 数字预先了解它们的速度。但请注意，一些检测模型已使用非常不寻常的输出集进行转换，JeVois PostProcessor 可能不支持这些输出集。</para>
</listitem><listitem>
<para>Hailo Model Zoo Github 上有多个 docker 和关于如何重新训练其中一些模型的说明：https://github.com/hailo-ai/hailo_model_zoo/tree/master/training</para>
</listitem><listitem>
<para>另请参阅 <link linkend="_UserDNNtips">运行自定义神经网络的技巧</link> </para>
</listitem></itemizedlist>
</para>
    <section xml:id="_UserDNNtpu"><title>为 Coral TPU 转换并运行神经网络</title>    </section>
<para> 支持 <link xlink:href="https://coral.ai">Google Coral</link> 4-TOPS 张量处理单元 (TPU) 作为可选的硬件神经加速器。可以使用标准 <link xlink:href="https://coral.ai/products/m2-accelerator-ae/">Coral M.2 2230 A+E PCIe 板</link>、包含 2 个 Coral TPU + 一个 eMMC 闪存盘（安装在单个 M.2 2230 板上）的定制 JeVois 板或任意数量的 <link xlink:href="https://coral.ai/products/accelerator/">Coral USB 加密狗</link>。请注意，与 480 Mbits/s 的 USB 2.0 相比，PCIe 的数据传输速度更快（5 Gbits/s，而 JeVois-Pro 处理器只有一个 5 GBits/s 接口，我们将其用于 PCIe）。</para>

<para><note><title>Note</title>

<para>仅限。 不支持此加速器。</para>
</note>
支持的神经网络框架====================================</para>

<para>-TensorFlow / TensorFlow-Lite</para>

<para>TPU 可以运行量化为 int8 权重的模型。它不支持浮点权重，因此需要量化和转换。硬件支持的操作和层类型数量有限，这进一步限制了可以在其上运行的内容。此外，加速器上只有少量 RAM，这进一步限制了可以有效运行的网络规模。但它比标准 CPU 快很多倍。</para>

<para>为了在 TPU 上执行，您的模型将被量化，然后在 Linux 桌面上转换为 blob 格式，然后可以将其传输到 JeVois-Pro microSD 进行执行。</para>

<para>程序 =========</para>

<para><itemizedlist>
<listitem>
<para>阅读并理解有关 <link linkend="_UserDNNoverview">在 JeVois-A33 和 JeVois-Pro 上运行神经网络</link> 的 JeVois 文档</para>
</listitem><listitem>
<para>确保你理解 <link linkend="_UserDNNconv">为 JeVois-Pro 转换和量化深度神经网络</link> 中的量化概念</para>
</listitem><listitem>
<para>查看 <link xlink:href="https://coral.ai/docs/">官方 Google Coral 文档</link></para>
</listitem><listitem>
<para>TPU 仅支持一组特定的层类型。如果您尝试转换包含不受支持的层的网络，转换有时似乎会成功，但转换后的网络可能无法运行，或者使用基于 CPU 的模拟运行非常缓慢。在尝试转换网络之前，请检查 <link xlink:href="https://coral.ai/docs/edgetpu/models-intro/">兼容性概述</link>。特别要注意 Coral 文档中的以下声明：<emphasis>注意：目前，Edge TPU 编译器无法多次对模型进行分区，因此一旦发生不受支持的操作，该操作及其后的所有内容都会在 CPU 上执行，即使稍后发生受支持的操作也是如此。</emphasis></para>
</listitem><listitem>
<para>你需要下载并安装 <link xlink:href="https://coral.ai/docs/edgetpu/compiler/">EdgeTPU 编译器</link>，以便在运行 Linux Ubuntu 20.04 的台式计算机上转换/量化你的模型。</para>
</listitem><listitem>
<para>运行时推理所需的一切（EdgeTPU 运行时库、内核驱动程序、PyCoral）都已预先安装在您的 JeVois microSD 上。</para>
</listitem><listitem>
<para>获得模型：训练您自己的模型，或下载预先训练的模型。</para>
</listitem><listitem>
<para>请注意，TPU 仅有大约 6.5 MB 的板载 RAM 可用于存储模型参数，这充当了伪缓存（请参阅 <link xlink:href="https://coral.ai/docs/edgetpu/compiler/">https://coral.ai/docs/edgetpu/compiler/</link>）。因此，较小的模型可以一次性装入较小的 RAM 中，从而获得最佳性能。较大的模型需要通过 PCIe 或 USB 链路不断加载/卸载权重。较大的模型在 JeVois-Pro 集成 NPU 上运行得更好，它可以直接访问主 RAM（JeVois-Pro 上为 4 GB）。</para>
</listitem><listitem>
<para>Google 建议从 <link xlink:href="https://coral.ai/models/">https://coral.ai/models/</link> 上的一个模型开始，然后使用你自己的数据对其进行重新训练，如 <link xlink:href="https://github.com/google-coral/tutorials">https://github.com/google-coral/tutorials</link> 中所述</para>
</listitem><listitem>
<para>获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、RGB 或 BGR、打包（NWHC）或平面（NCHW）像素等）。</para>
</listitem><listitem>
<para>将模型复制到 JEVOIS[PRO]:/share/dnn/custom/ 下的 JeVois microSD 卡</para>
</listitem><listitem>
<para>为您的模型创建一个 JeVois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 JEVOIS[PRO]:/share/dnn/custom/ 下的 YAML 文件</para>
</listitem><listitem>
<para>启动 JeVois 模块。它将扫描自定义目录以查找任何有效的 YAML 文件，并使您的模型作为 DNN 模块的 Pipeline 组件的 <computeroutput>管道参数的一个可用值。选择该管道以运行您的模型。</computeroutput> </para>
</listitem></itemizedlist>
</para>

<para>设置 EdgeTPU 编译器 =================================</para>

<para><note><title>Note</title>

<para>以下所有内容均应在运行 Ubuntu 20.04 Linux 的快速 x86_64 台式计算机上运行，​​而不是在您的 JeVois-Pro 相机上运行。最后，我们将转换后的模型复制到 microSD，然后使用该模型在 JeVois-Pro 上运行推理。</para>
</note>
按照 <link xlink:href="https://coral.ai/docs/edgetpu/compiler/">https://coral.ai/docs/edgetpu/compiler/</link> 上的说明进行操作</para>

<para><literallayout><computeroutput>&#32;curl&#32;https://packages.cloud.google.com/apt/doc/apt-key.gpg&#32;|&#32;sudo&#32;apt-key&#32;add&#32;-

回显“deb&#32;https://packages.cloud.google.com/apt&#32;coral-edgetpu-stable&#32;main”|&#32;sudo&#32;tee&#32;/etc/apt/sources.list.d/coral-edgetpu.list

sudo&#32;apt-get&#32;更新

sudo&#32;apt-get&#32;安装&#32;edgetpu-编译器

edgetpu_compiler&#32;--help&#32;
</computeroutput></literallayout></para>

<para>示例：使用 NASNetMobile 进行对象分类 ====================================================</para>

<para><itemizedlist>
<listitem>
<para>许多预先训练的模型可在 <link xlink:href="https://coral.ai/models/">https://coral.ai/models/</link> 上找到</para>
</listitem><listitem>
<para>这里，我们使用 NASNetMobile，因为它还不在列表中。</para>
</listitem><listitem>
<para>让我们尝试使用 NASNetMobile 对 <link xlink:href="https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb">Coral colab 进行分类模型再训练</link> 进行改进。另请查看 <link xlink:href="https://github.com/google-coral/tutorials">其他 Coral 教程</link>。</para>
</listitem><listitem>
<para>这里我们跳过训练部分，只使用 ImageNet 上的预训练模型，专注于量化和转换到 Edge TPU。</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>安装 TensorFlow ------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>首选方法是通过 conda，详情见https://www.tensorflow.org/install/pip</para>
</listitem><listitem>
<para>在这里，我们将在 python3 虚拟环境中获取 tensorflow wheel，这样步骤更少：</para>
</listitem></itemizedlist>
</para>

<para><literallayout><computeroutput>python3&#32;-m&#32;venv&#32;tf_for_tpu&#32;source&#32;tf_for_tpu/bin/activate&#32;pip&#32;install&#32;--upgrade&#32;pip&#32;pip&#32;install&#32;tensorflow&#32;python3&#32;-c&#32;&quot;import&#32;tensorflow&#32;as&#32;tf;&#32;print(tf.reduce_sum(tf.random.normal([1000,&#32;1000])))&quot;&#32;#&#32;测试安装&#32;
</computeroutput></literallayout></para>

<para>您可能会看到一些关于缺少 GPU 库的警告，我们在这里忽略这些警告（CPU 足以转换模型），最后是类似 <emphasis role="bold">tf.Tensor(-337.86047, shape=(), dtype=float32)</emphasis> 的东西，这是我们的测试命令的结果（值 -337.86047 会有所不同，因为它是随机的）。</para>

<para><orderedlist>
<listitem>
<para>获取训练好的模型 ---------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>我们在 <link xlink:href="https://keras.io/api/applications/">https://keras.io/api/applications/</link> 上找到了在 ImageNet 上预先训练的 Keras/Tensorflow NASNetMobile</para>
</listitem><listitem>
<para>我们将按照 <link xlink:href="https://keras.io/api/applications/nasnet/#nasnetmobile-function">https://keras.io/api/applications/nasnet/#nasnetmobile-function</link> 中的说明将其加载到 TensorFlow 中</para>
</listitem><listitem>
<para>因此我们开始一个小的**convert.py**脚本，如下所示：<literallayout><computeroutput>&#32;import&#32;tensorflow&#32;as&#32;tf&#32;import&#32;numpy&#32;as&#32;np

模型&#32;=&#32;tf.keras.applications.NASNetMobile()

-&#32;这将使用所有默认值：224x224x3&#32;输入、ImageNet&#32;权重、包括最后的全连接层、包括最终的&#32;softmax&#32;激活。

-&#32;您可以在此阶段重新训练模型。这里我们将按原样使用它。

-&#32;如果我们现在运行**convert.py**，它只会下载模型并退出。

2.&#32;获取量化的样本数据集&#32;----------------------------------------

-&#32;由于我们使用的是&#32;ImageNet，我们可以从一些内置的&#32;TensorFlow&#32;函数中获取该数据集，但让我们手动执行此操作以查看如何在自定义数据集上执行此操作。

-&#32;我们仍然希望数据能够代表我们的训练数据，因此让我们下载&#32;ImageNet&#32;验证集：

+&#32;我们访问&#32;https://image-net.org，但即使创建了帐户，也只能通过请求进行下载&#32;
+&#32;因此，我们从&#32;http://academictorrents.com/details/5d6d0df7ed81efd49ca99ea4737e0ae5e3a5f2e5&#32;获取一个&#32;torrent&#32;文件，并使用“transmission-gtk”（Ubuntu&#32;上预装）下载数据集。

+&#32;我们获得&#32;ILSVRC2012_img_val.tar，解压后：\code{.py}&#32;mkdir&#32;dataset&#32;cd&#32;dataset&#32;tar&#32;xvf&#32;~/Downloads/ILSVRC2012_img_val.tar&#32;cd&#32;..&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>我们需要了解预处理的工作原理，以及应该将平均值、标准差和比例应用于原始像素值，以便我们稍后可以设置正确的预处理参数。我们在 <link xlink:href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/nasnet/preprocess_input">NASNetMobile 的 TensorFlow 文档</link> 中找到了一些信息，这些信息表明 nasnet.preprocess_input() 将缩放到 [-1 .. 1]。但没有提到方法......进一步查看[源代码]（https://github.com/keras-team/keras/blob/v2.9.0/keras/applications/nasnet.py::L817-L819），nasnet.preprocess_input（）调用[此处]（https://github.com/keras-team/keras/blob/07e13740fd181fc3ddec7d9a594d8a08666645f6/keras/applications/imagenet_utils.py#L101）定义的 imagenet_utils.preprocess_input（），后者调用定义的 _preprocess_numpy_input（） [这里]（https://github.com/keras-team/keras/blob/07e13740fd181fc3ddec7d9a594d8a08666645f6/keras/applications/imagenet_utils.py#L168）我们最终了解到，在 &apos;tf&apos; 模式下，我们将使用 mean=[127.5 127.5 127.5] 和 scale=1/127.5</para>
</listitem><listitem>
<para>我们将以下内容添加到我们的 <emphasis role="bold">convert.py</emphasis> 中，以我们正在关注的 colab 为蓝本，部分“转换为 TFLite”（我们只需要更改图像文件的位置和预处理）：<literallayout><computeroutput>&#32;IMAGE_SIZE&#32;=&#32;224

#&#32;提供代表性数据集的生成器&#32;def&#32;representative_data_gen():&#32;dataset_list&#32;=&#32;tf.data.Dataset.list_files(&apos;dataset/*&apos;)&#32;#&#32;修改后的&#32;JEVOIS&#32;for&#32;i&#32;in&#32;range(100):&#32;image&#32;=&#32;next(iter(dataset_list))&#32;image&#32;=&#32;tf.io.read_file(image)&#32;image&#32;=&#32;tf.io.decode_jpeg(image,&#32;channels=3)&#32;image&#32;=&#32;tf.image.resize(image,&#32;[IMAGE_SIZE,&#32;IMAGE_SIZE])&#32;image&#32;=&#32;tf.cast((image&#32;-&#32;127.5)&#32;/&#32;127.5,&#32;tf.float32)&#32;#&#32;修改后的&#32;JEVOIS&#32;image&#32;=&#32;tf.expand_dims(image,&#32;0)&#32;Yield&#32;[image]&#32;
</computeroutput></literallayout></para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>量化模型并转换为 TFLite -------------------------------------------&#8212;</para>
</listitem></orderedlist>
</para>

<para>我们再次将以下内容添加到我们的 <emphasis role="bold">convert.py</emphasis> 中，以我们关注的 colab 中的“转换为 TFLite”部分为蓝本：</para>

<para><literallayout><computeroutput>&#32;转换器&#32;=&#32;tf.lite.TFLiteConverter.from_keras_model(模型)

#&#32;这将启用量化转换器。优化&#32;=&#32;[tf.lite.Optimize.DEFAULT]

#&#32;这设置了量化的代表性数据集&#32;converter.representative_dataset&#32;=&#32;representative_data_gen

#&#32;这确保如果任何操作无法量化，转换器就会抛出错误&#32;converter.target_spec.supported_ops&#32;=&#32;[tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

#&#32;对于完整的整数量化，虽然支持的类型默认仅为&#32;int8，但为了清楚起见，我们明确声明了它。converter.target_spec.supported_types&#32;=&#32;[tf.int8]

#&#32;将输入和输出张量设置为&#32;uint8（在&#32;r2.3&#32;中添加）converter.inference_input_type&#32;=&#32;tf.uint8&#32;converter.inference_output_type&#32;=&#32;tf.uint8&#32;tflite_model&#32;=&#32;converter.convert()

使用&#32;open(&apos;NASNetMobile_quant.tflite&apos;,&#32;&apos;wb&apos;)&#32;作为&#32;f:&#32;#&#32;JEVOIS&#32;修改&#32;f.write(tflite_model)&#32;
</computeroutput></literallayout></para>

<para>我们运行完整的**convert.py**（整理上面的 3 个片段）：</para>

<para><literallayout><computeroutput>python3&#32;转换.py&#32;
</computeroutput></literallayout></para>

<para>这需要一段时间（也许我们应该安装 GPU 支持），但最终我们得到了 <emphasis role="bold">NASNetMobile_quant.tflite</emphasis>，它是我们原始模型的量化版本。</para>

<para>让我们快速检查一下，并将我们的量化模型上传到 Lutz Roeder 的出色 <link xlink:href="https://netron.app/">Netron</link> 在线模型检查工具。上传 <emphasis role="bold">NASNetMobile_quant.tflite</emphasis> 并检查各个层。特别是，如果您展开任何 Conv 层的输入、权重、偏差和输出详细信息，您将看到数据是如何通过一些相关的量化参数进行 int8 处理的。</para>

<para><orderedlist>
<listitem>
<para>将量化的TFLite模型转换为EdgeTPU -----------------------------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>要从量化的 TFLite 转换为 EdgeTPU，我们只需运行：<literallayout><computeroutput>edgetpu_compiler&#32;NASNetMobile_quant.tflite&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>这将移植尽可能多的层和操作以在 TPU 上执行。我们看到这个：<literallayout><computeroutput>&#32;Edge&#32;TPU&#32;编译器版本&#32;16.0.384591198&#32;启动了&#32;180&#32;秒的编译超时计时器。

模型在&#32;5841&#32;毫秒内成功编译。

输入模型：NASNetMobile_quant.tflite&#32;输入大小：6.21MiB&#32;输出模型：NASNetMobile_quant_edgetpu.tflite&#32;输出大小：8.15MiB&#32;用于缓存模型参数的片上内存：6.31MiB&#32;用于缓存模型参数的剩余片上内存：0.00B&#32;用于流式传输未缓存模型参数的片外内存：635.12KiB&#32;Edge&#32;TPU&#32;子图数量：1&#32;操作总数：669&#32;操作日志：NASNetMobile_quant_edgetpu.log&#32;有关单个操作的详细信息，请参阅操作日志文件。&#32;编译子进程在超时期限内完成。&#32;编译成功！&#32;
</computeroutput></literallayout></para>
</listitem><listitem>
<para>我们得到了 **NASNetMobile_quant_edgetpu.tflite**，我们会将其复制到 JeVois-Pro microSD。<note><title>Note</title>

<para>有点太大了！从上面的消息来看，我们正在最大限度地利用板载 RAM，除了将图像流式传输到 TPU 之外，每次推理时都需要在该 RAM 和主处理器的 RAM 之间交换 635 KB 的模型参数。</para>
</note>
</para>
</listitem><listitem>
<para>我们可以检查生成的 NASNetMobile_quant_edgetpu.log 以确认在这种情况下所有层都已移植到 TPU：<literallayout><computeroutput>&#32;Edge&#32;TPU&#32;编译器版本&#32;16.0.384591198&#32;输入：NASNetMobile_quant.tflite&#32;输出：NASNetMobile_quant_edgetpu.tflite

操作员计数状态

PAD&#32;20&#32;映射到边缘&#32;TPU&#32;ADD&#32;84&#32;映射到边缘&#32;TPU&#32;MAX_POOL_2D&#32;4&#32;映射到边缘&#32;TPU&#32;MEAN&#32;1&#32;映射到边缘&#32;TPU&#32;QUANTIZE&#32;86&#32;映射到边缘&#32;TPU&#32;CONV_2D&#32;196&#32;映射到边缘&#32;TPU&#32;CONCATENATION&#32;20&#32;映射到边缘&#32;TPU&#32;FULLY_CONNECTED&#32;1&#32;映射到边缘&#32;TPU&#32;RELU&#32;48&#32;映射到边缘&#32;TPU&#32;MUL&#32;4&#32;映射到边缘&#32;TPU&#32;SOFTMAX&#32;1&#32;映射到边缘&#32;TPU&#32;STRIDED_SLICE&#32;4&#32;映射到边缘&#32;TPU&#32;AVERAGE_POOL_2D&#32;40&#32;映射到边缘&#32;TPU&#32;DEPTHWISE_CONV_2D&#32;160&#32;映射到边缘&#32;TPU&#32;
</computeroutput></literallayout></para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>为我们的新模型创建一个 zoo YAML 文件 -------------------------------------------&#8212;</para>
</listitem></orderedlist>
</para>

<para>现在我们需要让 JeVois 了解我们的模型，方法是创建一个描述模型和文件位置的小型 YAML 文件。我们只需从预加载的 JeVois **tpu.yml**（在 GUI 的配置选项卡中）中获取一个条目即可获得灵感，并创建我们的新 **NASNetMobile.yml**：</para>

<para><literallayout><computeroutput>&#32;%YAML&#32;1.0&#32;---

NASNetMobile：预处理：Blob&#32;网络类型：TPU&#32;后处理：分类模型：“dnn/custom/NASNetMobile_quant_edgetpu.tflite”&#32;强度：“NHWC：8U：1x224x224x3：AA：0.0078125：128”&#32;平均值：“127.5&#32;127.5&#32;127.5”&#32;比例：0.0078125&#32;类：“coral/classification/imagenet_labels.txt”&#32;类别偏移量：1&#32;
</computeroutput></literallayout></para>

<para><note><title>Note</title>

<para>对于 <computeroutput>类，我们使用已预加载到</computeroutput> microSD 上的现有 ImageNet 标签文件，因为我们没有从 Keras 获取该文件。由于该标签文件的第一个条目为“背景”，而我们的模型未使用此条目，因此我们使用 <computeroutput>classoffset</computeroutput> 1 来移动类标签。如果标签似乎不正确，您可以在运行时调整它。如果您使用自定义训练的模型，您还应该将文件 <emphasis role="bold">NASNetMobile.labels</emphasis> 复制到 microSD，该文件描述了您的类名（每行一个类标签），然后将 classes 参数设置为该文件。</para>
</note>
<orderedlist>
<listitem>
<para>复制到 microSD 并运行 -----------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>将 <emphasis role="bold">NASNetMobile_quant_edgetpu.tflite</emphasis> 和 <emphasis role="bold">NASNetMobile.yml</emphasis> 复制到 JeVois-Pro microSD 上的 /jevoispro/share/dnn/custom/。</para>
</listitem><listitem>
<para>启动 模块并选择 <computeroutput>pipe</computeroutput> <emphasis role="bold">TPU:Classify:NASNetMobile</emphasis></para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para><itemizedlist>
<listitem>
<para>成功了！请注意，此屏幕截图使用的是连接到 USB 2.0 的 TPU，使用 PCIe TPU 板时速度更快。</para>
</listitem></itemizedlist>
</para>

<para>提示 ====</para>

<para><itemizedlist>
<listitem>
<para>权重大于 6.5 MB 的模型可以在 TPU 上运行得很好，但速度会更慢。缓存对用户完全透明，并且运行良好。</para>
</listitem><listitem>
<para>在 JeVois-Pro 上，可以同时为多个不同的模型实例化多个 Coral TPU 管道。这些模型将自动且透明地在硬件加速器上进行时间复用。例如，在 JeVois 模块 或 中，您可以将多个管道（在模块的 params.cfg 文件中）设置为 TPU 模型，即使您只有一个 TPU，也不会出现任何冲突或问题。</para>
</listitem><listitem>
<para>如果您有多个 TPU，则可以使用 YAML 参数 <emphasis role="bold">tpunum</emphasis> 在给定的 TPU 上运行给定的模型。</para>
</listitem><listitem>
<para>另请参阅 <link linkend="_UserDNNtips">运行自定义神经网络的技巧</link> </para>
</listitem></itemizedlist>
</para>
    <section xml:id="_UserDNNvpu"><title>转换并运行 Myriad-X VPU 的神经网络</title>    </section>
<para> 支持 <link xlink:href="https://www.intel.com/content/www/us/en/products/details/processors/movidius-vpu/movidius-myriad-x.html">Intel Movidius Myriad-X</link> 矢量处理单元 (VPU) 作为可选的附加神经加速器。</para>

<para><note><title>Note</title>

<para>仅限。 不支持此加速器。</para>
</note>
支持的神经网络框架====================================</para>

<para><itemizedlist>
<listitem>
<para>Caffe</para>
</listitem><listitem>
<para>TensorFlow</para>
</listitem><listitem>
<para>ONNX</para>
</listitem><listitem>
<para>pyTorch（通过导出到 ONNX）</para>
</listitem><listitem>
<para>MXNet</para>
</listitem><listitem>
<para>PaddlePaddle</para>
</listitem><listitem>
<para>Kaldi</para>
</listitem></itemizedlist>
</para>

<para>VPU 可以运行具有 float16（16 位浮点）权重的模型。它不支持标准 32 位浮点权重，因此需要进行转换或压缩。</para>

<para>为了在 VPU 上执行，您的模型将在 Linux 桌面上转换为专有 blob 格式，然后可以将其传输到 JeVois-Pro microSD 进行执行。</para>

<para>在 JeVois-Pro 上，我们通过作为 OpenCV 后端安装的 OpenVino 运行 VPU 模型。因此，加载和在 VPU 模型上运行推理的基本机制是 OpenCV，就像在 CPU 上运行的模型一样。</para>

<para>可以使用仿真模式，通过 <link xlink:href="https://github.com/ARM-software/ComputeLibrary">ARM 计算库</link> 和 <link xlink:href="https://github.com/openvinotoolkit/openvino_contrib/blob/master/modules/arm_plugin/README.md">OpenVino ARM CPU 插件</link>，使用 JeVois-Pro CPU 运行针对 VPU 优化的模型。不过，速度要慢得多。当 VPU 未连接到 JeVois-Pro 时，所有 VPU 网络仍可用作 <emphasis role="bold">VPUX</emphasis> 来发出仿真模式信号。对于最终用户来说，这是完全透明的（无需修改任何设置）。</para>

<para>程序 =========</para>

<para><itemizedlist>
<listitem>
<para>阅读并理解有关 <link linkend="_UserDNNoverview">在 JeVois-A33 和 JeVois-Pro 上运行神经网络</link> 的 JeVois 文档</para>
</listitem><listitem>
<para>确保你理解 <link linkend="_UserDNNconv">为 JeVois-Pro 转换和量化深度神经网络</link> 中的量化概念</para>
</listitem><listitem>
<para>查看 <link xlink:href="https://docs.openvino.ai/latest/index.html">官方 OpenVino 文档</link>。具体来说，我们将使用 <link xlink:href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">模型优化器</link> 将自定义模型转换为 VPU。</para>
</listitem><listitem>
<para>OpenVino 文档非常出色，提供了很多 <link xlink:href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_tutorials.html">转换教程</link></para>
</listitem><listitem>
<para><link xlink:href="https://docs.openvino.ai/latest/model_zoo.html">Open Model Zoo</link> 提供了许多可下载并转换为 VPU（或已转换）的模型。</para>
</listitem><listitem>
<para>VPU 仅支持一组特定的层类型。如果您尝试转换包含不受支持的层的网络，转换有时似乎成功，但转换后的网络可能无法运行。请查看 <link xlink:href="https://docs.openvino.ai/latest/openvino_docs_OV_UG_supported_plugins_VPU.html">支持的插件</link> 和 <link xlink:href="https://github.com/openvinotoolkit/openvino/blob/master/docs/ops/opset9.md">opset9</link> 了解相关信息。</para>
</listitem><listitem>
<para>您需要下载并安装 OpenVino SDK 才能在运行 Linux Ubuntu 20.04 的台式计算机上转换/压缩您的模型。</para>
</listitem><listitem>
<para>运行时推理所需的一切（OpenVino 运行时库、OpenCV 绑定、OpenVino ARM CPU 插件）都已预先安装在您的 JeVois microSD 上。</para>
</listitem><listitem>
<para>获得模型：训练您自己的模型，或下载预先训练的模型。</para>
</listitem><listitem>
<para>获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、RGB 或 BGR、打包（NWHC）或平面（NCHW）像素等）。</para>
</listitem><listitem>
<para>将模型复制到 JEVOIS[PRO]:/share/dnn/custom/ 下的 JeVois microSD 卡</para>
</listitem><listitem>
<para>为您的模型创建一个 JeVois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 JEVOIS[PRO]:/share/dnn/custom/ 下的 YAML 文件</para>
</listitem><listitem>
<para>启动 JeVois 模块。它将扫描自定义目录以查找任何有效的 YAML 文件，并使您的模型作为 DNN 模块的 Pipeline 组件的 <computeroutput>管道参数的一个可用值。选择该管道以运行您的模型。</computeroutput> </para>
</listitem></itemizedlist>
</para>

<para>设置 OpenVino SDK =============================</para>

<para><note><title>Note</title>

<para>以下所有内容均应在运行 Ubuntu 20.04 Linux 的快速 x86_64 台式计算机上运行，​​而不是在您的 JeVois-Pro 相机上运行。最后，我们将转换后的模型复制到 microSD，然后使用该模型在 JeVois-Pro 上运行推理。</para>
</note>
我们按照<link xlink:href="https://docs.openvino.ai/latest/openvino_docs_install_guides_install_dev_tools.html#doxid-openvino-docs-install-guides-install-dev-tools">官方 OpenVino 安装说明</link>在 Ubuntu 20.04 桌面上安装 OpenVino SDK：</para>

<para><itemizedlist>
<listitem>
<para>创建一个 python 虚拟环境并获取 OpenVino 开发工具：</para>
</listitem></itemizedlist>
</para>

<para><literallayout><computeroutput>python3&#32;-m&#32;venv&#32;openvino_env&#32;source&#32;openvino_env/bin/activate&#32;python&#32;-m&#32;pip&#32;install&#32;--upgrade&#32;pip&#32;pip&#32;install&#32;openvino-dev[tensorflow2,onnx,caffe,kaldi,mxnet,pytorch]&#32;#&#32;删除不需要的&#32;mo&#32;-h&#32;#&#32;验证安装&#32;
</computeroutput></literallayout></para>

<para>示例：使用 YOLOv5s 进行对象检测 ========================================</para>

<para><orderedlist>
<listitem>
<para>获取模型 -------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>前往 <link xlink:href="https://github.com/ultralytics/yolov5">https://github.com/ultralytics/yolov5</link></para>
</listitem><listitem>
<para>让我们下载在 640x640 输入上运行的 YOLOv5s。单击最新版本，然后单击底部资产列表中的 <emphasis role="bold">yolov5s.pt，或者运行以下命令：</emphasis> </para>
</listitem></itemizedlist>
</para>

<para><literallayout><computeroutput>wget&#32;https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt&#32;
</computeroutput></literallayout></para>

<para><itemizedlist>
<listitem>
<para>你将获得 pyTorch 格式的 **yolov5s.pt**。</para>
</listitem><listitem>
<para>与 NPU 或 TPU 不同，我们不需要 VPU 的样本数据集，因为我们只是将 32 位浮点数截断为 16 位浮点数，这不需要详细了解每一层在运行时会遇到的值范围。</para>
</listitem></itemizedlist>
</para>

<para>2.由于我们的模型是pyTorch，所以先将其转换为ONNX ----------------------------------------------------&#8212;</para>

<para><itemizedlist>
<listitem>
<para><link xlink:href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_PyTorch.html">OpenVino 的 pyTorch 转换文档</link> 要求首先将 pyTorch 模型导出到 ONNX，然后在其上运行 OpenVino 模型优化器。</para>
</listitem><listitem>
<para>与许多最近的网络一样，yolov5 repo 提供了一个 export.py 脚本来将模型导出为 ONNX 和其他格式。</para>
</listitem><listitem>
<para>因此，我们按如下方式进行（另请参阅https://github.com/violet17/yolov5_demo）：</para>
</listitem></itemizedlist>
</para>

<para><literallayout><computeroutput>&#32;git&#32;clone&#32;https://github.com/ultralytics/yolov5.git&#32;cd&#32;yolov5&#32;pip&#32;install&#32;-r&#32;requirements.txt&#32;python3&#32;export.py&#32;--weights&#32;../yolov5s.pt&#32;--include&#32;onnx&#32;--simplify&#32;--img&#32;640&#32;--batch&#32;1
#&#32;测试转换后的模型：python&#32;detect.py&#32;--weights&#32;../yolov5s.onnx&#32;
#&#32;检查&#32;runs/detect/exp/&#32;中的结果&#32;cd&#32;..&#32;
</computeroutput></literallayout></para>

<para><itemizedlist>
<listitem>
<para>我们现在有 <emphasis role="bold">yolov5s.onnx</emphasis></para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>运行OpenVino模型优化器 --------------------------------&#8212;</para>
</listitem></orderedlist>
</para>

<para>默认情况下，网络输出单个输出张量，该张量连接 3 个 YOLO 尺度，而大多数 YOLO 后处理器需要 3 个单独的输出。因此，让我们将 <emphasis role="bold">yolov5s.onnx</emphasis> 加载到 <link xlink:href="https://netron.app">https://netron.app</link> 中，以在最终重塑和连接之前找到最后 3 个 Conv 层。我们发现 Conv_198 输出 1x255x80x80，Conv_232 输出 1x255x40x40，Conv_266 输出 1x255x20x20。因此，我们将使用这些输出，JeVois PostProcessorDetect 可以处理这些输出。</para>

<para>点击下图放大。如果你点击 Netron 中的每个蓝色 Conv 层，你会看到它们的名称。</para>

<para>  </para>

<para>另外还可以看看 <link xlink:href="https://github.com/violet17/yolov5_demo">https://github.com/violet17/yolov5_demo</link>，他做了类似的事情。</para>

<para>我们将模型转换为 float16 (FP16)，以便在 Myriad-X VPU 上运行：</para>

<para><literallayout><computeroutput>mo&#32;--input_model&#32;yolov5s.onnx&#32;-s&#32;255&#32;--data_type&#32;FP16&#32;--output&#32;Conv_198,Conv_232,Conv_266&#32;
</computeroutput></literallayout></para>

<para>参数 <emphasis role="bold">-s 255</emphasis> 将在设备上将输入像素除以 255，因此我们可以直接将未缩放的输入像素输入到网络。更多选项请参阅“mo &#8211;help”。</para>

<para>我们获得了**yolov5s.bin**和**yolov5s.xml**，可以在JeVois-Pro上运行。</para>

<para><orderedlist>
<listitem>
<para>创建YAML zoo文件 --------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>我们从 JeVois microSD 中已有的 zoo 文件 vpu.yaml 中的类似条目开始（并且可以在 GUI 的 Config 选项卡中使用）。</para>
</listitem><listitem>
<para>对于 YOLO 后处理，我们需要定义锚点（用于预测对象框的原型框形状）。我们从 <link xlink:href="https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml">https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml</link> 获取这些，位于顶部：<literallayout><computeroutput>&#32;锚点：
-&#32;[10,13,&#32;16,30,&#32;33,23]&#32;#&#32;P3/8
-&#32;[30,61,&#32;62,45,&#32;59,119]&#32;#&#32;P4/16
-&#32;[116,90,&#32;156,198,&#32;373,326]&#32;#&#32;P5/32&#32;
</computeroutput></literallayout> 在下面的 YAML 文件中，我们将用分号分隔 3 个 YOLO 尺度的 3 组锚点。</para>
</listitem><listitem>
<para>由于 YOLOv5 使用“新样式”的 YOLO 坐标，我们需要禁用后处理器 sigmoid 并将后处理器 scalexy 设置为 2.0。对于 YOLOv5/v7，您通常会希望这样做。相反，将 sigmoid 设置为 true 并将 scalexy 设置为 0.0（默认值）以使用 YOLOv2/v3/v4 的旧样式框坐标。您可以在 jevois::dnn::PostProcessorDetectYOLO::yolo_one() 中查看差异</para>
</listitem><listitem>
<para>实际上，我们用于输出的这 3 个 Conv 层在该特定模型中似乎具有线性激活。因此我们需要将 sigmoid 设置为 true，因为后处理器将需要它来进行 YOLO 解码。</para>
</listitem><listitem>
<para>我们只需修改名称和文件位置，将 spu.yml 中的所有全局定义放入我们的文件中（例如 preproc、nettype 等，它们在 spu.yml 中全局设置，因此不会在我们要复制的条目中重复），最后得到以下 **yolov5s.yml**：<literallayout><computeroutput>&#32;%YAML&#32;1.0&#32;---

yolov5s：&#32;preproc：Blob&#32;网络类型：OpenCV&#32;后端：InferenceEngine&#32;目标：Myriad&#32;模型：“dnn/custom/yolov5s.bin”&#32;配置：“dnn/custom/yolov5s.xml”&#32;强度：“NCHW：8U：1x3x640x640”&#32;postproc：检测&#32;检测类型：RAWYOLO&#32;锚点：“10,13、16,30、33,23；30,61、62,45、59,119；116,90、156,198、373,326”&#32;类：“npu/detection/coco-labels.txt”&#32;sigmoid：true&#32;scalexy：2.0&#32;
</computeroutput></literallayout></para>
</listitem></itemizedlist>
</para>

<para><note><title>Note</title>

<para>在这里，只需在规范末尾指定 <emphasis role="bold">intensors: &quot;NCHW:8U:1x3x640x640&quot;</emphasis> 而没有量化细节，我们指示 JeVois 预处理器仅提供原始输入像素，而不进行值缩放（即，平均值 = [0 0 0]，比例 = 1，标准差 = [1 1 1]），因此我们完全跳过指定平均比例和标准差。</para>
</note>
<itemizedlist>
<listitem>
<para>我们将 yolov5s.yml、yolo5s.xml、yolov5s.bin 复制到 JeVois-Pro 上的 /jevoispro/share/dnn/custom/ 然后尝试一下！</para>
</listitem></itemizedlist>
<orderedlist>
<listitem>
<para>测试模型并调整任何参数 ----------------------------------------&#8212;</para>
</listitem></orderedlist>
<itemizedlist>
<listitem>
<para>选择 机器视觉模块</para>
</listitem><listitem>
<para>将 <computeroutput>管道参数设置为</computeroutput> <emphasis role="bold">VPU:Detect:yolov5s</emphasis></para>
</listitem></itemizedlist>
</para>

<para>  </para>

<para>成功了！这个网络对于 Myriad-X 来说有点大，运行速度仅为 1.9 FPS。使用模型的微型版本或使用较小的输入尺寸将获得更高的帧/秒。</para>

<para>提示 ====</para>

<para><itemizedlist>
<listitem>
<para>另请参阅 <link linkend="_UserDNNtips">运行自定义神经网络的技巧</link> </para>
</listitem></itemizedlist>
</para>
    <section xml:id="_UserDNNtips"><title>运行自定义神经网络的技巧</title>    </section>
<para>YAML zoo 文件的提示 --------------------&#8212;</para>

<para><itemizedlist>
<listitem>
<para>YAML 文件中支持的键：每个键都记录在使用它们的类中，在每个头文件开头的 <computeroutput>JEVOIS_DECLARE_PARAMETER(...)</computeroutput> 指令中：</para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1PreProcessor">jevois::dnn::PreProcessor</link></para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1Network">jevois::dnn::Network</link></para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1PostProcessor">jevois::dnn::PostProcessor</link></para>
</listitem><listitem>
<para><link linkend="_classjevois_1_1dnn_1_1Pipeline">jevois::dnn::Pipeline</link></para>
</listitem><listitem>
<para>如果您创建自定义 python 预处理器、网络或后处理器并在其中定义 JeVois 参数，那么您也可以在 YAML 文件中设置这些参数。</para>
</listitem><listitem>
<para>顺序很重要：当一个组件被实例化时（例如，**preproc: Blob** 将实例化一个 jevois::dnn::PreProcessorBlob），它的参数就会被赋予存在，但它们之前并不存在。因此，例如，由于 <computeroutput>rgb</computeroutput> 是一个预处理器参数，因此应该在设置 <computeroutput>preproc</computeroutput> 之后在 YAML 文件中指定它。
<literallayout>&#160;&#xa;</literallayout>
 对于 Python pre/net/post 尤其如此：</para>
</listitem><listitem>
<para>首先选择您将使用 Python，例如，**preproc: Python**</para>
</listitem><listitem>
<para>这只会公开一个新参数 <computeroutput>pypre</computeroutput> 来选择要加载哪个 python 文件</para>
</listitem><listitem>
<para>然后当您设置时，例如，**pypre：“pydnn/pre/PyPreBlob.py”** 所选的 python 代码将被加载和初始化</para>
</listitem><listitem>
<para>在初始化期间，python 代码可能会创建新的 JeVois 参数；这里，<computeroutput>scale</computeroutput> 和 <computeroutput>mean</computeroutput> </para>
</listitem><listitem>
<para>因此，现在您只能设置 <emphasis role="bold">scale: 0.0078125</emphasis> 或类似值。</para>
</listitem><listitem>
<para>参数在其定义中指定了默认值（在 <link linkend="_classjevois_1_1dnn_1_1PreProcessor">jevois::dnn::PreProcessor</link> 等中）。您可以删除 YAML 文件中将参数设置为这些默认值的行（例如，可以删除 **rgb: true**，因为 <computeroutput>rgb</computeroutput> 的默认值为 true）。这将使您的 YAML 文件更简洁。</para>
</listitem></itemizedlist>
</para>

<para>预处理提示-------------------&#8212;</para>

<para><itemizedlist>
<listitem>
<para><computeroutput>classes</computeroutput> 是可选的。如果您只想检查模型在 JeVois 相机上的运行速度，但没有类列表，只需从 YAML 中删除 <computeroutput>classes</computeroutput> 参数即可。JeVois 只会显示类号而不是类名。</para>
</listitem><listitem>
<para>对于 <computeroutput>classoffset：您身边很可能有电脑键盘，而且这些键盘往往很容易被在</computeroutput> ImageNet 上训练的模型识别。因此，只需将您的相机对准键盘，并在 JeVois GUI 中使用 <computeroutput>classoffset</computeroutput> 即可，直到您得到“电脑键盘”作为输出。</para>
</listitem><listitem>
<para><computeroutput>平均值和</computeroutput> <computeroutput>stdev</computeroutput> 值应与模型的输入图像（RGB 或 BGR，由 <computeroutput>rgb</computeroutput> 参数指定）的顺序相同。</para>
</listitem></itemizedlist>
</para>

<para>后期处理技巧 ---------------------&#8212;</para>

<para><itemizedlist>
<listitem>
<para>分类是最简单的情况。检测通常需要更多工作，因为需要合适的后处理器将网络输出解码为屏幕上无法绘制的框。JeVois 为 YOLO 系列、SSD、FasterRCNN 等提供了标准后处理器，您也可以用 Python 编写自己的后处理器。</para>
</listitem><listitem>
<para>YOLOv2 锚点可能需要乘以 8 才能与 JeVois PostProcessor 配合使用。您可以在终端中按如下方式执行此操作（此处只需从 yolov2-voc.cfg 中剪切并粘贴锚点）：<literallayout><computeroutput>for&#32;x&#32;in&#32;1.3221,&#32;1.73145,&#32;3.19275,&#32;4.00944,&#32;5.05587,&#32;8.09892,&#32;9.47112,&#32;4.84053,&#32;11.2364,&#32;10.0071;&#32;do&#32;echo&#32;&quot;scale=4;&#32;${x/,/}&#32;*&#32;8&quot;&#32;|&#32;bc;&#32;echo&#32;&apos;,&apos;;&#32;done&#32;|&#32;xargs&#32;
</computeroutput></literallayout> 删除最后一个逗号并放置一些分号以分隔 YOLO 尺度（如果需要），然后就可以开始了。有关一些详细信息，请参阅https://medium.com/nerd-for-tech/yolo-v2-configuration-file-explained-879e2219191。模型转换技巧 ----------------------&#8212;</para>
</listitem><listitem>
<para>在转换模型时，我们可能会有一些疑问：我们的模型使用的是 NCHW 还是 NHWC？输入层和输出层的名称是什么？我们可以使用 Lutz Roeder 出色的 <link xlink:href="https://netron.app/">Netron</link> 在线模型检查工具来回答这些问题：</para>
</listitem><listitem>
<para>将浏览器指向 <link xlink:href="https://netron.app/">https://netron.app/</link></para>
</listitem><listitem>
<para>单击“打开模型...”</para>
</listitem><listitem>
<para>上传您的模型</para>
</listitem><listitem>
<para>单击输入层和输出层的框以查看有关它们的一些信息 </para>
</listitem></itemizedlist>
</para>
</section>
