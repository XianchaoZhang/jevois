/*! \page UserDNNvpu 转换并运行 Myriad-X VPU 的神经网络

\jvpro 支持 [Intel Movidius Myriad-X](https://www.intel.com/content/www/us/en/products/details/processors/movidius-vpu/movidius-myriad-x.html) 矢量处理单元 (VPU) 作为可选的附加神经加速器。

\note 仅限 \jvpro。\jva33 不支持此加速器。

支持的神经网络框架====================================

- Caffe
- TensorFlow
- ONNX
- pyTorch（通过导出到 ONNX）
- MXNet
- PaddlePaddle
- Kaldi

VPU 可以运行具有 float16（16 位浮点）权重的模型。它不支持标准 32 位浮点权重，因此需要进行转换或压缩。

为了在 VPU 上执行，您的模型将在 Linux 桌面上转换为专有 blob 格式，然后可以将其传输到 JeVois-Pro microSD 进行执行。

在 JeVois-Pro 上，我们通过作为 OpenCV 后端安装的 OpenVino 运行 VPU 模型。因此，加载和在 VPU 模型上运行推理的基本机制是 OpenCV，就像在 CPU 上运行的模型一样。

可以使用仿真模式，通过 [ARM 计算库](https://github.com/ARM-software/ComputeLibrary) 和 [OpenVino ARM CPU 插件](https://github.com/openvinotoolkit/openvino_contrib/blob/master/modules/arm_plugin/README.md)，使用 JeVois-Pro CPU 运行针对 VPU 优化的模型。不过，速度要慢得多。当 VPU 未连接到 JeVois-Pro 时，所有 VPU 网络仍可用作 **VPUX** 来发出仿真模式信号。对于最终用户来说，这是完全透明的（无需修改任何设置）。

程序 =========

- 阅读并理解有关 \ref UserDNNoverview 的 JeVois 文档

- 确保你理解 \ref UserDNNconv 中的量化概念

- 查看 [官方 OpenVino 文档](https://docs.openvino.ai/latest/index.html)。具体来说，我们将使用 [模型优化器](https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html) 将自定义模型转换为 VPU。

- OpenVino 文档非常出色，提供了很多 [转换教程](https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_tutorials.html)

- [Open Model Zoo](https://docs.openvino.ai/latest/model_zoo.html) 提供了许多可下载并转换为 VPU（或已转换）的模型。

- VPU 仅支持一组特定的层类型。如果您尝试转换包含不受支持的层的网络，转换有时似乎成功，但转换后的网络可能无法运行。请查看 [支持的插件](https://docs.openvino.ai/latest/openvino_docs_OV_UG_supported_plugins_VPU.html) 和 [opset9](https://github.com/openvinotoolkit/openvino/blob/master/docs/ops/opset9.md) 了解相关信息。

- 您需要下载并安装 OpenVino SDK 才能在运行 Linux Ubuntu 20.04 的台式计算机上转换/压缩您的模型。

- 运行时推理所需的一切（OpenVino 运行时库、OpenCV 绑定、OpenVino ARM CPU 插件）都已预先安装在您的 JeVois microSD 上。

- 获得模型：训练您自己的模型，或下载预先训练的模型。

- 获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、RGB 或 BGR、打包（NWHC）或平面（NCHW）像素等）。

- 将模型复制到 JEVOIS[PRO]:/share/dnn/custom/ 下的 JeVois microSD 卡

- 为您的模型创建一个 JeVois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 JEVOIS[PRO]:/share/dnn/custom/ 下的 YAML 文件

- 启动 JeVois \jvmod{DNN} 模块。它将扫描自定义目录以查找任何有效的 YAML 文件，并使您的模型作为 DNN 模块的 Pipeline 组件的 \p 管道参数的一个可用值。选择该管道以运行您的模型。

设置 OpenVino SDK =============================

\note 以下所有内容均应在运行 Ubuntu 20.04 Linux 的快速 x86_64 台式计算机上运行，​​而不是在您的 JeVois-Pro 相机上运行。最后，我们将转换后的模型复制到 microSD，然后使用该模型在 JeVois-Pro 上运行推理。

我们按照[官方 OpenVino 安装说明](https://docs.openvino.ai/latest/openvino_docs_install_guides_install_dev_tools.html#doxid-openvino-docs-install-guides-install-dev-tools)在 Ubuntu 20.04 桌面上安装 OpenVino SDK：

- 创建一个 python 虚拟环境并获取 OpenVino 开发工具：

\code{.py} python3 -m venv openvino_env source openvino_env/bin/activate python -m pip install --upgrade pip pip install openvino-dev[tensorflow2,onnx,caffe,kaldi,mxnet,pytorch] # 删除不需要的 mo -h # 验证安装 \endcode

示例：使用 YOLOv5s 进行对象检测 ========================================

1. 获取模型 ----------------

- 前往 https://github.com/ultralytics/yolov5

- 让我们下载在 640x640 输入上运行的 YOLOv5s。单击最新版本，然后单击底部资产列表中的 \b yolov5s.pt，或者运行以下命令：

\code{.py} wget https://github.com/ultralytics/yolov5/releases/download/v6.2/yolov5s.pt \endcode

- 你将获得 pyTorch 格式的 **yolov5s.pt**。

- 与 NPU 或 TPU 不同，我们不需要 VPU 的样本数据集，因为我们只是将 32 位浮点数截断为 16 位浮点数，这不需要详细了解每一层在运行时会遇到的值范围。

2.由于我们的模型是pyTorch，所以先将其转换为ONNX -------------------------------------------------------

- [OpenVino 的 pyTorch 转换文档](https://docs.openvino.ai/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_PyTorch.html) 要求首先将 pyTorch 模型导出到 ONNX，然后在其上运行 OpenVino 模型优化器。

- 与许多最近的网络一样，yolov5 repo 提供了一个 export.py 脚本来将模型导出为 ONNX 和其他格式。

- 因此，我们按如下方式进行（另请参阅https://github.com/violet17/yolov5_demo）：

\code{.py} git clone https://github.com/ultralytics/yolov5.git cd yolov5 pip install -r requirements.txt python3 export.py --weights ../yolov5s.pt --include onnx --simplify --img 640 --batch 1
# 测试转换后的模型：python detect.py --weights ../yolov5s.onnx 
# 检查 runs/detect/exp/ 中的结果 cd .. \endcode

- 我们现在有 **yolov5s.onnx**

3. 运行OpenVino模型优化器 -----------------------------------

默认情况下，网络输出单个输出张量，该张量连接 3 个 YOLO 尺度，而大多数 YOLO 后处理器需要 3 个单独的输出。因此，让我们将 **yolov5s.onnx** 加载到 https://netron.app 中，以在最终重塑和连接之前找到最后 3 个 Conv 层。我们发现 Conv_198 输出 1x255x80x80，Conv_232 输出 1x255x40x40，Conv_266 输出 1x255x20x20。因此，我们将使用这些输出，JeVois PostProcessorDetect 可以处理这些输出。

点击下图放大。如果你点击 Netron 中的每个蓝色 Conv 层，你会看到它们的名称。

\jvimg{yolov5s-last-conv.png, 25%}

另外还可以看看 https://github.com/violet17/yolov5_demo，他做了类似的事情。

我们将模型转换为 float16 (FP16)，以便在 Myriad-X VPU 上运行：

\code{.py} mo --input_model yolov5s.onnx -s 255 --data_type FP16 --output Conv_198,Conv_232,Conv_266 \endcode

参数 **-s 255** 将在设备上将输入像素除以 255，因此我们可以直接将未缩放的输入像素输入到网络。更多选项请参阅“mo --help”。

我们获得了**yolov5s.bin**和**yolov5s.xml**，可以在JeVois-Pro上运行。

4. 创建YAML zoo文件 -----------------------

- 我们从 JeVois microSD 中已有的 zoo 文件 vpu.yaml 中的类似条目开始（并且可以在 GUI 的 Config 选项卡中使用）。

- 对于 YOLO 后处理，我们需要定义锚点（用于预测对象框的原型框形状）。我们从 https://github.com/ultralytics/yolov5/blob/master/models/yolov5s.yaml 获取这些，位于顶部：\code{.py} 锚点：
- [10,13, 16,30, 33,23] # P3/8
- [30,61, 62,45, 59,119] # P4/16
- [116,90, 156,198, 373,326] # P5/32 \endcode 在下面的 YAML 文件中，我们将用分号分隔 3 个 YOLO 尺度的 3 组锚点。

- 由于 YOLOv5 使用“新样式”的 YOLO 坐标，我们需要禁用后处理器 sigmoid 并将后处理器 scalexy 设置为 2.0。对于 YOLOv5/v7，您通常会希望这样做。相反，将 sigmoid 设置为 true 并将 scalexy 设置为 0.0（默认值）以使用 YOLOv2/v3/v4 的旧样式框坐标。您可以在 jevois::dnn::PostProcessorDetectYOLO::yolo_one() 中查看差异

- 实际上，我们用于输出的这 3 个 Conv 层在该特定模型中似乎具有线性激活。因此我们需要将 sigmoid 设置为 true，因为后处理器将需要它来进行 YOLO 解码。

- 我们只需修改名称和文件位置，将 spu.yml 中的所有全局定义放入我们的文件中（例如 preproc、nettype 等，它们在 spu.yml 中全局设置，因此不会在我们要复制的条目中重复），最后得到以下 **yolov5s.yml**：\code{.py} %YAML 1.0 ---

yolov5s： preproc：Blob 网络类型：OpenCV 后端：InferenceEngine 目标：Myriad 模型：“dnn/custom/yolov5s.bin” 配置：“dnn/custom/yolov5s.xml” 强度：“NCHW：8U：1x3x640x640” postproc：检测 检测类型：RAWYOLO 锚点：“10,13、16,30、33,23；30,61、62,45、59,119；116,90、156,198、373,326” 类：“npu/detection/coco-labels.txt” sigmoid：true scalexy：2.0 \endcode

\note 在这里，只需在规范末尾指定 **intensors: "NCHW:8U:1x3x640x640"** 而没有量化细节，我们指示 JeVois 预处理器仅提供原始输入像素，而不进行值缩放（即，平均值 = [0 0 0]，比例 = 1，标准差 = [1 1 1]），因此我们完全跳过指定平均比例和标准差。

- 我们将 yolov5s.yml、yolo5s.xml、yolov5s.bin 复制到 JeVois-Pro 上的 /jevoispro/share/dnn/custom/ 然后尝试一下！

5. 测试模型并调整任何参数 -------------------------------------------

- 选择 \jvmod{DNN} 机器视觉模块

- 将 \p 管道参数设置为 **VPU:Detect:yolov5s**

\jvimg{vpu-yolov5s.png, 70%}

成功了！这个网络对于 Myriad-X 来说有点大，运行速度仅为 1.9 FPS。使用模型的微型版本或使用较小的输入尺寸将获得更高的帧/秒。

提示 ====

- 另请参阅 \ref UserDNNtips

*/

