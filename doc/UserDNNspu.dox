/*! \page UserDNNspu 为 Hailo-8 SPU 转换并运行神经网络

\jvpro 支持 [26-TOPS Hailo-8](https://hailo.ai/products/hailo-8-m2-module/) 流处理单元 (SPU)，作为使用 PCIe 接口的 M.2 2230 A+E 板上的可选附加神经加速器。到目前为止，这是此规格中速度最快的加速器。

\note 仅限 \jvpro。\jva33 不支持此加速器。

支持的神经网络框架====================================

- TensorFlow / TensorFlow-Lite
- ONNX
- pyTorch（通过导出到 ONNX）

程序 =========

- 阅读并理解有关 \ref UserDNNoverview 的 JeVois 文档

- 确保你理解 \ref UserDNNconv 中的量化概念

- 您需要下载并安装 Hailo Software Suite docker，以便在运行 Linux Ubuntu 20.04 的台式计算机上转换/压缩您的模型。<em>需要注册和密码。Hailo 保留接受或拒绝您的开发者注册请求的权利。</em>

- 运行时推理所需的一切（HailoRT 运行时库、Hailo PCIe 内核驱动程序）都已预先安装在您的 JeVois microSD 上。

- 获得模型：训练您自己的模型，或下载预先训练的模型。

- 获取有关模型的一些参数（例如，预处理平均值、标准差、比例、预期输入图像大小、RGB 或 BGR、打包（NWHC）或平面（NCHW）像素等）。

- 转换模型如下：
+ 使用 `hailo parser` 将源模型转换为 Hailo 存档 (.har)
+ 使用 `hailo optimize` 为 Hailo-8 优化模型并量化为 int8。
+ 使用 `hailo compilation` 将模型转换为可在 JeVois-Pro 上运行的二进制 blob (.hef)
+ 可以使用其他命令来可视化您的模型、检查其在验证集上的性能等。
+ 尝试使用 `hailo tutorial` 获取 Hailo 的 jupyter 教程。
- 将转换后的模型复制到 JEVOISPRO:/share/dnn/custom/ 下的 JeVois microSD 卡

- 为您的模型创建一个 JeVois 模型动物园条目，在其中指定模型参数和复制模型文件的位置。通常，这是 JEVOISPRO:/share/dnn/custom/ 下的 YAML 文件

- 启动 JeVois \jvmod{DNN} 模块。它将扫描自定义目录以查找任何有效的 YAML 文件，并使您的模型作为 DNN 模块的 Pipeline 组件的 \p 管道参数的一个可用值。选择该管道以运行您的模型。

设置 Hailo 软件套件 ======================================

\note 以下所有内容均应在运行 Ubuntu 20.04 Linux 的快速 x86_64 台式计算机上运行，​​而不是在您的 JeVois-Pro 相机上运行。最后，我们将转换后的模型复制到 microSD，然后使用该模型在 JeVois-Pro 上运行推理。

\note 我们在下面使用的是 HailoRT-4.8.1，但更高版本也应该可以正常工作。为了获得最佳兼容性，请下载与相机上安装的版本相同的版本（在相机的控制台中输入 `!dpkg --list | grep hailo`）。

- 查看 [官方文档](https://hailo.ai/developer-zone/documentation/sw-suite-2022-07-1)

- [Hailo 模型库](https://hailo.ai/products/hailo-software-suite/model-zoo/) 有许多可以在 Hailo-8 上运行的模型。您还可以在 [GitHub](https://github.com/hailo-ai/hailo_model_zoo) 上查看其他文件和模型再训练代码。

- 在 hailo.ai 申请开发者账户，登录，然后转到 https://hailo.ai/developer-zone/sw-downloads/
+ 下载 **Hailo 软件套件 - Docker**
+ 下载 **HailoRT – Ubuntu 软件包 (deb) for amd64**
+ 下载 **HailoRT – PCIe 驱动程序 Ubuntu 软件包 (deb)**

- 安装 PCIe 驱动程序和运行时库。这不是绝对必要的，但它会在我们继续进行时消除许多警告（对 DKMS 说 Y，它将通过内核更新携带驱动程序；如果失败也不要担心，也许你需要安装 dkms、内核头文件等）：\code{.py} sudo dpkg -i ~/Downloads/hailort-pcie-driver_4.8.1_all.deb sudo dpkg -i ~/Downloads/hailort_4.8.1_amd64.deb \endcode

- 如果尚未安装 docker，请安装：\code{.py} sudo apt install docker.io sudo usermod -aG docker ${USER} # 需要重启才能生效\endcode

- 解压您下载的 Hailo 软件套件：\code{.py} mkdir hailodev cd hailodev unzip ~/Downloads/hailo_sw_suite_2022-07.zip ./hailo_sw_suite_docker_run.sh \endcode 您应该看到以下内容：\code{.unparsed} 欢迎使用 Hailo 软件套件容器 要列出可用的命令，请输入：

-------------------------------------------------- --

HailoRT：hailortcli -h 数据流编译器：hailo -h Hailo 模型动物园：hailomz -h TAPPAS：hailo_run_app -h

-------------------------------------------------- --

（hailo_virtualenv）hailo@mypc:/local/workspace$ \endcode

- 此时，您可以按照 Hailo 文档从 Hailo Model Zoo 获取模型并重新训练它，获取您自己的模型并进行转换等。我们在下面展示了一个示例。

- 完成后，只需“退出”docker 容器。

- 要稍后恢复，请输入“./hailo_sw_suite_docker_run.sh --resume”。

- 要重新启动并用新容器替换旧容器，请输入`./hailo_sw_suite_docker_run.sh --override`

- 要在主机和 Hailo docker 之间复制文件，请在主机上（而不是在容器中）输入以下内容：
+ `sudo docker container ls -a` 显示容器的 ID，例如 **4f6342fbc915**
+ `sudo docker cp myfile 4f6342fbc915:/local/workspace/` 从主机复制到容器
+ `sudo docker cp 4f6342fbc915:/local/workspace/myfile .` 从容器复制到主机
+ 请参阅 https://hailo.ai/developer-zone/documentation/sw-suite-2022-07-1?sp_referrer=working_with_dockers.html 了解更多信息（需要登录您的 Hailo 帐户）。

示例：YOLOv7 物体检测 ==================================

我们下面运行的所有内容都来自我们上面启动的 docker 容器内部。

1. 获取模型 ----------------

- 前往 https://github.com/WongKinYiu/yolov7 查看

- 我们将使用基础版 YOLOv7 完整版来查看 Hailo 板在大型模型上运行速度有多快：\code{.py} wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt \endcode

2.由于我们的模型是pyTorch，所以先将其转换为ONNX -------------------------------------------------------

- 该模型在 pyTorch 中，但 YOLOv7 团队提供了一个“export.py”，可以将其导出到 onnx，最近的模型通常都是这样：\code{.py} git clone https://github.com/WongKinYiu/yolov7.git cd yolov7 pip install --upgrade pip pip install -r requirements.txt python3 export.py --weights ../yolov7.pt --simplify --img-size 640 --batch-size 1 cd ..\endcode \note 安装要求会卸载 hailo 提供的 torch，然后安装看似相同的版本。这可能会干扰 Hailo 软件套件的其他方面。因此，您可能需要在不同的虚拟环境或本机主机上执行此操作，然后将结果复制到容器中，如上所示。

- 我们现在有 **yolov7.onnx**

- 要使用 Netron 进行可视化，请运行 **google-chrome https://netron.app**（仍在容器内），选择“打开模型...”，然后选择模型，该模型位于容器中的 <b>/local/workspace/yolov7.onnx</b> 中。具体来说，我们看到 3 个输出，1x3x80x80x85、1x3x40x40x85、1x3x20x20x85，这是通常的 3 个 YOLO 尺度（形状不寻常，我们稍后会修复）。请注意，原始模型包含一些额外的后处理，但已从导出中删除，这很好，因为它可能不受硬件加速器支持。JeVois 软件将提供后处理。输入是 1x3x640x640（NCHW）。

3. 运行 Hailo 解析器 -----------------------

- [Hailo 下载部分](https://hailo.ai/developer-zone/documentation/?type=application-and-release-notes) 中的 Hailo Model Zoo 用户指南有详细的说明。

- 我们还查看了 [Hailo Dataflow Compiler 文档](https://hailo.ai/developer-zone/documentation/dataflow-compiler-v3-19-0)

- 首先，将 ONNX 中的模型解析为 Hailo 存档 (HAR)：\code{.py} hailo parser onnx yolov7.onnx \endcode 我们收到一些关于不支持的层 298、299、301、302、304、305 的错误，并建议重试，“使用这些最终节点名称：Conv_297、Conv_300、Conv_303”。这些是最终重塑之前的输出，例如，conv_303（Netron 中图形底部的最后一个 Conv 块）为 1x255x20x20，然后重塑为 1x3x20x20x85。事实上，我们应该使用 Conv_303，因为这是 jevois::dnn::PostProcessorDetect 可以处理的 YOLO 输出形状。因此我们再试一次（运行 **hailo parser onnx yolov7.onnx --help** 以获取帮助后）：\code{.py} hailo parser onnx yolov7.onnx --end-node-names Conv_297 Conv_300 Conv_303 \endcode

- 成功，我们现在有了**yolov7.har**

4. 获取样本数据集 -----------------------

- 我们需要一个样本数据集来量化模型。它将通过模型进行处理（仅前向推理），以确定每一层遇到的值的范围。然后这些范围将用于量化。

- 如果您在自定义数据集上训练了模型，请将验证集中的大约 100 张图像复制到此处的新目录中。

- 我们的模型是在 [COCO 数据集](https://cocodataset.org) 上训练的。让我们下载 [2017 年验证集](http://images.cocodataset.org/zips/val2017.zip)：\code{.py} wget http://images.cocodataset.org/zips/val2017.zip unzip val2017.zip \endcode

- 有 5,000 张图像，比我们需要的多。unix 命令 `shuf` 可以随机打乱名称列表并取前 \p n 个，因此让我们使用它从数据集中抓取 100 张随机图像并将它们复制到新目录 <b>sampledata</b>:\code{.py} mkdir sampledata cp `ls ./val2017/*.jpg | shuf -n 100` sampledata/ \endcode

- <b>sampledata/</b> 现在应该包含 100 个 jpeg 图像。

- Hailo 希望将样本数据集作为 <em>“.npy 文件，其中包含形状为 (calib_size, h, w, c) 的预处理图像的 numpy 数组”</em>（通过运行 **hailo optimize --help**）。因此，我们需要编写一个小的 python 脚本 <b>numpy_sampledata.py</b> 来执行此操作：\code{.py} import numpy as np import os from PIL import Image

dir = 'sampledata' 宽度 = 640 高度 = 640 图像数量 = 100

数据集 = np.ndarray((numimages, height, width, 3), np.float32) idx = 0

for path in os.listdir(dir): fname = os.path.join(dir, path) if os.path.isfile(fname): image = Image.open(fname).resize((width, height)); arr = np.array(image).astype(np.float32) arr = (arr - 0.0) / 255.0 # 预处理。这里：mean=[0 0 0], scale=1/255 但因模型而异 dataset[idx, :] = arr idx += 1 with open('sampledata.npy', 'wb') as f: np.save(f, dataset) \endcode

- 我们运行脚本并得到**sampledata.npy**

5.优化模型---------------------

- 在我们的模型上启动 Hailo 优化器并使用我们的样本数据集。这将量化模型：\code{.py} hailo optimize yolov7.har --calib-set-path sampledata.npy \endcode

- 我们得到**yolov7_quantized.har**

6. 编译模型 --------------------

\code{.py} hailo 编译器 yolov7_quantized.har \endcode

我们得到**yolov7.hef**，将其复制到\jvpro 的 microSD 中。

编译器预测此模型的 FPS 为 12.27，考虑到其大小，这个数字听起来相当不错。请注意，它的目标是计算利用率达到 75%，而且确实实现了这一目标。也许可以通过一些参数来提高这一数字。为了获得更快的 FPS，可以使用 yolov7-tiny，或者可以减小输入大小。

7. 创建 JeVois-Pro YAML zoo 文件 ----------------------------------

- 我们从 JeVois microSD 中已有的动物园文件 spu.yml 中的任何 YOLO 条目开始（并且可以在 GUI 的“配置”选项卡中使用）。

- 对于 YOLO 后处理，我们需要定义锚点（用于预测对象框的原型框形状）。我们从 https://github.com/WongKinYiu/yolov7/blob/main/cfg/deploy/yolov7.yaml 中获取这些内容，位于顶部：\code{.py} 锚点：
- [12,16, 19,36, 40,28] # P3/8
- [36,75, 76,55, 72,146] # P4/16
- [142,110, 192,243, 459,401] # P5/32 \endcode 在下面的 YAML 文件中，我们将用分号分隔 3 个 YOLO 尺度的 3 组锚点。

- 由于 YOLOv7 使用“新样式”的 YOLO 坐标，我们需要禁用后处理器 sigmoid 并将后处理器 scalexy 设置为 2.0。对于 YOLOv5/v7，您可能希望这样做。相反，将 sigmoid 设置为 true 并将 scalexy 设置为 0.0（默认值）以使用 YOLOv2/v3/v4 的旧样式框坐标。您可以在 jevois::dnn::PostProcessorDetectYOLO::yolo_one() 中查看差异

- 实际上，我们用于输出的这 3 个 Conv 层在该特定模型中似乎具有线性激活（请在 Netron 中查看）。因此我们需要将 sigmoid 设置为 true，因为后处理器将需要它来进行 YOLO 解码。

- 我们只需修改名称和文件位置，将 spu.yml 中的所有全局定义放入我们的文件中（例如 preproc、nettype 等，它们在 spu.yml 中全局设置，因此不会在我们要复制的条目中重复），最后得到以下 **yolov7.yml**：\code{.py} %YAML 1.0 ---

yolov7：preproc：Blob 平均值：“0 0 0” 比例：0.0039215686 nettype：SPU 模型：“dnn/custom/yolov7.hef” postproc：检测 检测类型：RAWYOLO 锚点：“12,16、19,36、40,28；36,75、76,55、72,146；142,110、192,243、459,401” 类：“npu/detection/coco-labels.txt” sigmoid：true scalexy：2.0 \endcode

\note 我们不需要（也不能）使用 Hailo 模型指定 **intensors** 和 **outtensors**，这些规格嵌入在 HEF 文件中。

- 我们将 yolov7.yml 和 yolov7.hef 复制到 JeVois-Pro 上的 /jevoispro/share/dnn/custom/ 然后尝试一下！

8. 测试模型并调整任何参数 -------------------------------------------

- 选择 \jvmod{DNN} 机器视觉模块

- 将 \p 管道参数设置为 **SPU:Detect:yolov7**

\jvimg{spu-yolov7.png, 70%}

成功了！正如编译器所承诺的那样，网络推理的速度确实达到了 12.2 FPS。这是一个大型模型，并且使用 640x640 输入。如果您需要更高的帧速率，请尝试较小的输入或 yolov7-tiny。或者尝试 Hailo 团队提供的 YOLOv5m-640，它在 JeVois-Pro 上的运行速度超过 45 FPS。

提示 ====

- 您可能希望从 [Hailo Model Zoo](https://hailo.ai/products/hailo-software-suite/model-zoo/) 中的模型开始。这些模型应该转换得很好，而且您还可以通过查看 GFLOPS 数字预先了解它们的速度。但请注意，一些检测模型已使用非常不寻常的输出集进行转换，JeVois PostProcessor 可能不支持这些输出集。

- Hailo Model Zoo Github 上有多个 docker 和关于如何重新训练其中一些模型的说明：https://github.com/hailo-ai/hailo_model_zoo/tree/master/training

- 另请参阅 \ref UserDNNtips

*/

